+ module load python
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load python
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
PYTHONUNBUFFERED=1;' export 'PYTHONUNBUFFERED;
MODULES_LMCONFLICT_modshare=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:python/3.10.4;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh;
conda' activate 'python-3.10.4;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ PYTHONUNBUFFERED=1
++ export PYTHONUNBUFFERED
++ MODULES_LMCONFLICT_modshare='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:python/3.10.4
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate python-3.10.4
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate python-3.10.4
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate python-3.10.4
+++ /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda shell.posix activate python-3.10.4
++ ask_conda='PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
++ eval 'PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
+++ PS1='(python-3.10.4) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=python-3.10.4
+++ CONDA_DEFAULT_ENV=python-3.10.4
+++ export 'CONDA_PROMPT_MODIFIER=(python-3.10.4) '
+++ CONDA_PROMPT_MODIFIER='(python-3.10.4) '
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh
++++ [[ -n '' ]]
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal ']'
++++ export GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ export GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ [[ ! -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins ]]
++++ unset GDAL_DRIVER_PATH
++++ export CPL_ZIP_ENCODING=UTF-8
++++ CPL_ZIP_ENCODING=UTF-8
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/epsg_csv ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/Library/share/epsg_csv ']'
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh
++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ export GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
++++ GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh
++++ '[' -n '' ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj ']'
++++ export PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ '[' -f /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj/copyright_and_licenses.csv ']'
++++ export PROJ_NETWORK=ON
++++ PROJ_NETWORK=ON
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ export PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ accelerate launch LEGAL-PE/SIGIR_experiments/distributedTraining/dist_deepspeed_LLM_torch_lexglue_.py --to_train True --batch_size 6 --learning_rate 2e-6 --num_warmup_steps 1000 --to_test True --strat 0 --data_path LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/ --dataset_subset ecthr_a --hggfc_model_name EleutherAI/gpt-neo-2.7B
2023-05-05 23:17:08.919062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-05 23:17:15.585984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-05 23:18:02.077036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-05 23:18:02.077074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-05 23:18:02.077208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-05 23:18:02.077220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-05 23:18:02.077237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-05 23:18:02.077238: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
----------------------------------------------------------------------------------------------------
--------------------



Report
ReportReportReportReport
Report



--------------------
--------------------------------------------------------------------------------
--------------------




Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ecthr_a', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ecthr_a/EleutherAI_gpt-neo-2.7B/Strategy_0/sub_strategy_0/Training_data_EleutherAI_gpt-neo-2.7B/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)





------------------------------------------------------------------------------------------------------------------------





                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]
                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]
                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]


                                                   text     labels
0     [11.  At the beginning of the events relevant ...        [4]
1     [9.  The applicant is the monarch of Liechtens...         []
2     [9.  In June 1949 plots of agricultural land o...        [3]
3     [8.  In 1991 Mr Dušan Slobodník, a research wo...        [6]
4     [9.  The applicant is an Italian citizen, born...         []
...                                                 ...        ...
8995  [5.  The applicant was born in 1960 and lives ...         []
8996  [5.  The applicant was born in 1946 and is cur...         []
8997  [5.  The applicants are Russian nationals who,...  [0, 1, 2]
8998  [8.  In all cases the applicants brought civil...     [3, 9]
8999  [4.  The applicant was born in 1971 and lives ...        [3]

[9000 rows x 2 columns]
[2023-05-05 23:18:20,682] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
train_labels:torch.Size([48595, 10])
train_labels:torch.Size([48595, 10])
train_labels:torch.Size([48595, 10])
train_labels:torch.Size([48595, 10])
train_labels:torch.Size([48595, 10])
train_labels:torch.Size([48595, 10])
[2023-05-05 23:18:43,486] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 2.65B parameters
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-05 23:18:43,802] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
[2023-05-05 23:18:43,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-05 23:18:43,814] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-05 23:18:43,815] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-05 23:18:43,834] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-05 23:18:43,834] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>
[2023-05-05 23:18:43,834] [WARNING] [engine.py:1098:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2023-05-05 23:18:43,834] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-05-05 23:18:44,156] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-05-05 23:18:44,156] [INFO] [utils.py:786:see_memory_usage] MA 0.96 GB         Max_MA 1.04 GB         CA 1.12 GB         Max_CA 1 GB 
[2023-05-05 23:18:44,157] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.53 GB, percent = 8.1%
[2023-05-05 23:18:44,158] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-05-05 23:18:44,158] [INFO] [stage3.py:114:__init__] Prefetch bucket size 50,000,000
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...

Emitting ninja build file /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...Loading extension module utils...
Loading extension module utils...
Loading extension module utils...

Time to load utils op: 0.5342254638671875 secondsTime to load utils op: 0.5361876487731934 secondsTime to load utils op: 0.534738302230835 seconds
Time to load utils op: 0.5337252616882324 secondsTime to load utils op: 0.5337262153625488 seconds
Time to load utils op: 0.5339527130126953 seconds



[2023-05-05 23:18:53,894] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-05-05 23:18:53,894] [INFO] [utils.py:786:see_memory_usage] MA 0.96 GB         Max_MA 0.96 GB         CA 1.12 GB         Max_CA 1 GB 
[2023-05-05 23:18:53,895] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
Parameter Offload: Total persistent parameters: 849920 in 227 params
[2023-05-05 23:18:54,108] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-05-05 23:18:54,109] [INFO] [utils.py:786:see_memory_usage] MA 0.96 GB         Max_MA 0.96 GB         CA 1.12 GB         Max_CA 1 GB 
[2023-05-05 23:18:54,109] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:54,305] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-05-05 23:18:54,305] [INFO] [utils.py:786:see_memory_usage] MA 0.96 GB         Max_MA 0.96 GB         CA 1.12 GB         Max_CA 1 GB 
[2023-05-05 23:18:54,305] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,106] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1
[2023-05-05 23:18:56,107] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.96 GB         CA 1.89 GB         Max_CA 2 GB 
[2023-05-05 23:18:56,107] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,305] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-05-05 23:18:56,306] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.89 GB         Max_CA 2 GB 
[2023-05-05 23:18:56,306] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,506] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-05-05 23:18:56,506] [INFO] [utils.py:786:see_memory_usage] MA 2.6 GB         Max_MA 3.42 GB         CA 4.36 GB         Max_CA 4 GB 
[2023-05-05 23:18:56,506] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,703] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-05-05 23:18:56,704] [INFO] [utils.py:786:see_memory_usage] MA 2.6 GB         Max_MA 2.6 GB         CA 4.36 GB         Max_CA 4 GB 
[2023-05-05 23:18:56,704] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,907] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-05-05 23:18:56,908] [INFO] [utils.py:786:see_memory_usage] MA 5.89 GB         Max_MA 9.18 GB         CA 10.95 GB         Max_CA 11 GB 
[2023-05-05 23:18:56,908] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.59 GB, percent = 8.1%
[2023-05-05 23:18:56,908] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005726814270019531 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006673336029052734 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...No modifications detected for re-loaded extension module utils, skipping build step...

Loading extension module utils...
Time to load utils op: 0.0007097721099853516 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006601810455322266 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006034374237060547 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
  0%|          | 0/3 [00:00<?, ?it/s]Training...
======== Epoch 1 / 3 ========
Training...  0%|          | 0/3 [00:00<?, ?it/s]
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
======== Epoch 1 / 3 ========Training...

Training...

  0%|          | 0/1350 [00:00<?, ?it/s][A
  0%|          | 0/1350 [00:00<?, ?it/s][A
  0%|          | 0/1350 [00:00<?, ?it/s][A

  0%|          | 0/1350 [00:00<?, ?it/s][A  0%|          | 0/1350 [00:00<?, ?it/s][A[2023-05-05 23:18:57,259] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-05-05 23:18:57,260] [INFO] [utils.py:786:see_memory_usage] MA 7.64 GB         Max_MA 8.12 GB         CA 10.95 GB         Max_CA 11 GB 
[2023-05-05 23:18:57,261] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 40.6 GB, percent = 8.1%
[2023-05-05 23:18:57,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-05 23:18:57,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-05 23:18:57,261] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-05 23:18:57,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2023-05-05 23:18:57,262] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-05-05 23:18:57,262] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-05 23:18:57,262] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-05 23:18:57,262] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-05-05 23:18:57,262] [INFO] [config.py:957:print]   amp_params ................... False
[2023-05-05 23:18:57,262] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   bfloat16_enabled ............. True
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1526055b4af0>
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   dump_state ................... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 1
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   loss_scale ................... 1.0
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-05 23:18:57,263] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   pld_params ................... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   steps_per_print .............. inf
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   train_batch_size ............. 36
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  6
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   world_size ................... 6
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  True
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-05 23:18:57,264] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-05-05 23:18:57,264] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 36, 
    "train_micro_batch_size_per_gpu": 6, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005099773406982422 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/1350 [00:00<?, ?it/s][A
  0%|          | 1/1350 [00:04<1:33:54,  4.18s/it][A
  0%|          | 1/1350 [00:03<1:29:43,  3.99s/it][A
  0%|          | 1/1350 [00:04<1:34:09,  4.19s/it][A

  0%|          | 1/1350 [00:04<1:34:15,  4.19s/it][A  0%|          | 1/1350 [00:04<1:34:15,  4.19s/it][A
  0%|          | 1/1350 [00:04<1:34:15,  4.19s/it][A
  0%|          | 2/1350 [00:05<1:02:02,  2.76s/it][A
  0%|          | 2/1350 [00:05<1:02:05,  2.76s/it][A


  0%|          | 2/1350 [00:05<1:00:32,  2.69s/it][A  0%|          | 2/1350 [00:05<1:02:12,  2.77s/it][A  0%|          | 2/1350 [00:05<1:02:16,  2.77s/it][A
  0%|          | 2/1350 [00:05<1:02:15,  2.77s/it][A
  0%|          | 3/1350 [00:07<47:05,  2.10s/it]  [A
  0%|          | 3/1350 [00:07<47:09,  2.10s/it]  [A
  0%|          | 3/1350 [00:07<47:10,  2.10s/it]  [A
  0%|          | 3/1350 [00:07<47:11,  2.10s/it]  [A
  0%|          | 3/1350 [00:07<46:15,  2.06s/it]  [A
  0%|          | 3/1350 [00:07<47:12,  2.10s/it]  [A
  0%|          | 4/1350 [00:08<40:01,  1.78s/it][A
  0%|          | 4/1350 [00:08<39:35,  1.76s/it][A
  0%|          | 4/1350 [00:08<40:14,  1.79s/it][A
  0%|          | 4/1350 [00:08<40:17,  1.80s/it][A
  0%|          | 4/1350 [00:08<40:18,  1.80s/it][A
  0%|          | 4/1350 [00:08<40:19,  1.80s/it][A
  0%|          | 5/1350 [00:09<36:12,  1.62s/it][A
  0%|          | 5/1350 [00:09<36:16,  1.62s/it][A
  0%|          | 5/1350 [00:09<36:19,  1.62s/it][A
  0%|          | 5/1350 [00:09<35:57,  1.60s/it][A
  0%|          | 5/1350 [00:09<36:21,  1.62s/it][A
  0%|          | 5/1350 [00:09<36:23,  1.62s/it][A
  0%|          | 6/1350 [00:11<33:50,  1.51s/it][A
  0%|          | 6/1350 [00:11<34:01,  1.52s/it][A
  0%|          | 6/1350 [00:11<34:01,  1.52s/it][A
  0%|          | 6/1350 [00:11<34:00,  1.52s/it][A
  0%|          | 6/1350 [00:11<33:49,  1.51s/it][A
  0%|          | 6/1350 [00:11<34:01,  1.52s/it][A
  1%|          | 7/1350 [00:12<32:26,  1.45s/it][A
  1%|          | 7/1350 [00:12<32:28,  1.45s/it][A
  1%|          | 7/1350 [00:12<32:17,  1.44s/it][A
  1%|          | 7/1350 [00:12<32:30,  1.45s/it][A
  1%|          | 7/1350 [00:12<32:28,  1.45s/it][A
  1%|          | 7/1350 [00:12<32:25,  1.45s/it][A
  1%|          | 8/1350 [00:13<31:23,  1.40s/it][A
  1%|          | 8/1350 [00:13<31:31,  1.41s/it][A
  1%|          | 8/1350 [00:13<31:34,  1.41s/it][A
  1%|          | 8/1350 [00:13<31:35,  1.41s/it][A
  1%|          | 8/1350 [00:13<31:35,  1.41s/it][A
  1%|          | 8/1350 [00:13<31:34,  1.41s/it][A
  1%|          | 9/1350 [00:14<30:44,  1.38s/it][A
  1%|          | 9/1350 [00:15<30:50,  1.38s/it][A
  1%|          | 9/1350 [00:15<30:57,  1.38s/it][A

  1%|          | 9/1350 [00:15<30:56,  1.38s/it][A  1%|          | 9/1350 [00:15<30:56,  1.38s/it][A
  1%|          | 9/1350 [00:15<30:54,  1.38s/it][A
  1%|          | 10/1350 [00:16<30:30,  1.37s/it][A
  1%|          | 10/1350 [00:16<30:28,  1.36s/it][A
  1%|          | 10/1350 [00:16<30:30,  1.37s/it][A

  1%|          | 10/1350 [00:16<30:29,  1.37s/it][A  1%|          | 10/1350 [00:16<30:29,  1.36s/it][A
  1%|          | 10/1350 [00:16<30:28,  1.36s/it][A
  1%|          | 11/1350 [00:17<30:04,  1.35s/it][A
  1%|          | 11/1350 [00:17<30:08,  1.35s/it][A
  1%|          | 11/1350 [00:17<30:06,  1.35s/it][A
  1%|          | 11/1350 [00:17<30:08,  1.35s/it][A
  1%|          | 11/1350 [00:17<30:08,  1.35s/it][A
  1%|          | 11/1350 [00:17<30:08,  1.35s/it][A
  1%|          | 12/1350 [00:19<29:58,  1.34s/it][A
  1%|          | 12/1350 [00:19<29:58,  1.34s/it][A
  1%|          | 12/1350 [00:19<30:00,  1.35s/it][A
  1%|          | 12/1350 [00:18<30:00,  1.35s/it][A
  1%|          | 12/1350 [00:19<30:00,  1.35s/it][A
  1%|          | 12/1350 [00:19<29:59,  1.34s/it][A
  1%|          | 13/1350 [00:20<29:46,  1.34s/it][A


  1%|          | 13/1350 [00:20<29:45,  1.34s/it][A  1%|          | 13/1350 [00:20<29:45,  1.34s/it][A  1%|          | 13/1350 [00:20<29:46,  1.34s/it][A
  1%|          | 13/1350 [00:20<29:46,  1.34s/it][A
  1%|          | 13/1350 [00:20<29:44,  1.34s/it][A
  1%|          | 14/1350 [00:21<30:51,  1.39s/it][A
  1%|          | 14/1350 [00:21<30:57,  1.39s/it][A
  1%|          | 14/1350 [00:21<30:58,  1.39s/it][A
  1%|          | 14/1350 [00:21<30:58,  1.39s/it][A
  1%|          | 14/1350 [00:21<31:00,  1.39s/it][A
  1%|          | 14/1350 [00:22<30:58,  1.39s/it][A
  1%|          | 15/1350 [00:23<32:00,  1.44s/it][A
  1%|          | 15/1350 [00:23<32:03,  1.44s/it][A
  1%|          | 15/1350 [00:23<32:02,  1.44s/it][A
  1%|          | 15/1350 [00:23<32:07,  1.44s/it][A
  1%|          | 15/1350 [00:23<32:07,  1.44s/it][A
  1%|          | 15/1350 [00:23<32:07,  1.44s/it][A
  1%|          | 16/1350 [00:24<31:16,  1.41s/it][A

  1%|          | 16/1350 [00:24<31:13,  1.40s/it][A  1%|          | 16/1350 [00:24<31:14,  1.41s/it][A
  1%|          | 16/1350 [00:24<31:15,  1.41s/it][A
  1%|          | 16/1350 [00:24<31:15,  1.41s/it][A
  1%|          | 16/1350 [00:24<31:15,  1.41s/it][A
  1%|▏         | 17/1350 [00:26<30:36,  1.38s/it][A
  1%|▏         | 17/1350 [00:26<30:36,  1.38s/it][A
  1%|▏         | 17/1350 [00:26<30:39,  1.38s/it][A
  1%|▏         | 17/1350 [00:26<30:38,  1.38s/it][A
  1%|▏         | 17/1350 [00:26<30:41,  1.38s/it][A
  1%|▏         | 17/1350 [00:26<30:45,  1.38s/it][A
  1%|▏         | 18/1350 [00:27<30:12,  1.36s/it][A
  1%|▏         | 18/1350 [00:27<30:15,  1.36s/it][A
  1%|▏         | 18/1350 [00:27<30:14,  1.36s/it][A
  1%|▏         | 18/1350 [00:27<30:16,  1.36s/it][A
  1%|▏         | 18/1350 [00:27<30:18,  1.36s/it][A
  1%|▏         | 18/1350 [00:27<30:15,  1.36s/it][A
  1%|▏         | 19/1350 [00:28<29:56,  1.35s/it][A
  1%|▏         | 19/1350 [00:28<29:57,  1.35s/it][A
  1%|▏         | 19/1350 [00:28<29:57,  1.35s/it][A
  1%|▏         | 19/1350 [00:28<29:59,  1.35s/it][A

  1%|▏         | 19/1350 [00:28<29:57,  1.35s/it][A  1%|▏         | 19/1350 [00:28<30:00,  1.35s/it][A
  1%|▏         | 20/1350 [00:29<29:39,  1.34s/it][A
  1%|▏         | 20/1350 [00:30<29:46,  1.34s/it][A
  1%|▏         | 20/1350 [00:30<29:49,  1.35s/it][A
  1%|▏         | 20/1350 [00:30<29:48,  1.34s/it][A
  1%|▏         | 20/1350 [00:30<29:52,  1.35s/it][A
  1%|▏         | 20/1350 [00:30<29:52,  1.35s/it][A
  2%|▏         | 21/1350 [00:31<29:43,  1.34s/it][A
  2%|▏         | 21/1350 [00:31<29:46,  1.34s/it][A
  2%|▏         | 21/1350 [00:31<29:46,  1.34s/it][A
  2%|▏         | 21/1350 [00:31<29:53,  1.35s/it][A

  2%|▏         | 21/1350 [00:31<29:50,  1.35s/it][A  2%|▏         | 21/1350 [00:31<29:51,  1.35s/it][A
  2%|▏         | 22/1350 [00:32<29:46,  1.35s/it][A
  2%|▏         | 22/1350 [00:32<29:50,  1.35s/it][A
  2%|▏         | 22/1350 [00:32<29:49,  1.35s/it][A

  2%|▏         | 22/1350 [00:32<29:49,  1.35s/it][A  2%|▏         | 22/1350 [00:32<29:48,  1.35s/it][A
  2%|▏         | 22/1350 [00:32<29:49,  1.35s/it][A
  2%|▏         | 23/1350 [00:34<29:40,  1.34s/it][A
  2%|▏         | 23/1350 [00:34<29:45,  1.35s/it][A
  2%|▏         | 23/1350 [00:34<29:47,  1.35s/it][A
  2%|▏         | 23/1350 [00:34<29:47,  1.35s/it][A
  2%|▏         | 23/1350 [00:34<29:48,  1.35s/it][A
  2%|▏         | 23/1350 [00:34<29:49,  1.35s/it][A
  2%|▏         | 24/1350 [00:35<29:43,  1.35s/it][A
  2%|▏         | 24/1350 [00:35<29:44,  1.35s/it][A
  2%|▏         | 24/1350 [00:35<29:45,  1.35s/it][A


  2%|▏         | 24/1350 [00:35<29:49,  1.35s/it]  2%|▏         | 24/1350 [00:35<29:48,  1.35s/it][A[A  2%|▏         | 24/1350 [00:35<29:46,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:44,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:45,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:47,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:45,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:46,  1.35s/it][A
  2%|▏         | 25/1350 [00:36<29:46,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:42,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:44,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:50,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:46,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:46,  1.35s/it][A
  2%|▏         | 26/1350 [00:38<29:47,  1.35s/it][A
  2%|▏         | 27/1350 [00:39<29:42,  1.35s/it][A
  2%|▏         | 27/1350 [00:39<29:43,  1.35s/it][A
  2%|▏         | 27/1350 [00:39<29:45,  1.35s/it][A
  2%|▏         | 27/1350 [00:39<29:45,  1.35s/it]
[A  2%|▏         | 27/1350 [00:39<29:44,  1.35s/it][A
  2%|▏         | 27/1350 [00:39<29:48,  1.35s/it][A
  2%|▏         | 28/1350 [00:40<29:46,  1.35s/it][A
  2%|▏         | 28/1350 [00:40<29:46,  1.35s/it][A
  2%|▏         | 28/1350 [00:40<29:47,  1.35s/it][A
  2%|▏         | 28/1350 [00:40<29:52,  1.36s/it][A

  2%|▏         | 28/1350 [00:40<29:53,  1.36s/it][A  2%|▏         | 28/1350 [00:40<29:52,  1.36s/it][A
  2%|▏         | 29/1350 [00:42<29:40,  1.35s/it][A
  2%|▏         | 29/1350 [00:42<29:49,  1.35s/it][A
  2%|▏         | 29/1350 [00:42<29:48,  1.35s/it][A
  2%|▏         | 29/1350 [00:42<29:51,  1.36s/it][A

  2%|▏         | 29/1350 [00:42<29:51,  1.36s/it][A  2%|▏         | 29/1350 [00:42<29:51,  1.36s/it][A
  2%|▏         | 30/1350 [00:43<31:20,  1.42s/it][A
  2%|▏         | 30/1350 [00:43<31:21,  1.43s/it][A
  2%|▏         | 30/1350 [00:43<31:22,  1.43s/it][A
  2%|▏         | 30/1350 [00:43<31:26,  1.43s/it][A
  2%|▏         | 30/1350 [00:43<31:23,  1.43s/it][A
  2%|▏         | 30/1350 [00:43<31:28,  1.43s/it][A
  2%|▏         | 31/1350 [00:45<32:22,  1.47s/it][A
  2%|▏         | 31/1350 [00:45<32:22,  1.47s/it][A
  2%|▏         | 31/1350 [00:45<32:24,  1.47s/it][A
  2%|▏         | 31/1350 [00:45<32:26,  1.48s/it][A
  2%|▏         | 31/1350 [00:45<32:24,  1.47s/it][A
  2%|▏         | 31/1350 [00:45<32:25,  1.47s/it][A
  2%|▏         | 32/1350 [00:46<31:33,  1.44s/it][A
  2%|▏         | 32/1350 [00:46<31:37,  1.44s/it][A
  2%|▏         | 32/1350 [00:46<31:36,  1.44s/it][A
  2%|▏         | 32/1350 [00:46<31:42,  1.44s/it][A
  2%|▏         | 32/1350 [00:46<31:40,  1.44s/it][A
  2%|▏         | 32/1350 [00:46<31:41,  1.44s/it][A
  2%|▏         | 33/1350 [00:48<30:59,  1.41s/it][A

  2%|▏         | 33/1350 [00:48<31:07,  1.42s/it][A  2%|▏         | 33/1350 [00:48<31:06,  1.42s/it][A
  2%|▏         | 33/1350 [00:48<31:05,  1.42s/it][A
  2%|▏         | 33/1350 [00:48<31:09,  1.42s/it][A
  2%|▏         | 33/1350 [00:48<31:07,  1.42s/it][A
  3%|▎         | 34/1350 [00:49<30:38,  1.40s/it][A
  3%|▎         | 34/1350 [00:49<30:39,  1.40s/it][A

  3%|▎         | 34/1350 [00:49<30:41,  1.40s/it][A  3%|▎         | 34/1350 [00:49<30:41,  1.40s/it][A
  3%|▎         | 34/1350 [00:49<30:39,  1.40s/it][A
  3%|▎         | 34/1350 [00:49<30:43,  1.40s/it][A

  3%|▎         | 35/1350 [00:50<30:22,  1.39s/it][A  3%|▎         | 35/1350 [00:50<30:23,  1.39s/it][A
  3%|▎         | 35/1350 [00:50<30:22,  1.39s/it][A

  3%|▎         | 35/1350 [00:50<30:24,  1.39s/it][A  3%|▎         | 35/1350 [00:50<30:25,  1.39s/it][A
  3%|▎         | 35/1350 [00:50<30:26,  1.39s/it][A
  3%|▎         | 36/1350 [00:52<30:11,  1.38s/it][A
  3%|▎         | 36/1350 [00:52<30:13,  1.38s/it][A
  3%|▎         | 36/1350 [00:52<30:13,  1.38s/it][A

  3%|▎         | 36/1350 [00:52<30:14,  1.38s/it][A  3%|▎         | 36/1350 [00:52<30:14,  1.38s/it][A
  3%|▎         | 36/1350 [00:52<30:12,  1.38s/it][A
  3%|▎         | 37/1350 [00:53<30:00,  1.37s/it][A
  3%|▎         | 37/1350 [00:53<30:01,  1.37s/it][A
  3%|▎         | 37/1350 [00:53<30:03,  1.37s/it][A
  3%|▎         | 37/1350 [00:53<30:04,  1.37s/it][A
  3%|▎         | 37/1350 [00:53<30:03,  1.37s/it][A
  3%|▎         | 37/1350 [00:53<30:05,  1.38s/it][A
  3%|▎         | 38/1350 [00:55<29:55,  1.37s/it][A
  3%|▎         | 38/1350 [00:55<29:55,  1.37s/it][A
  3%|▎         | 38/1350 [00:55<29:59,  1.37s/it][A

  3%|▎         | 38/1350 [00:55<29:57,  1.37s/it]  3%|▎         | 38/1350 [00:54<29:58,  1.37s/it][A[A
  3%|▎         | 38/1350 [00:55<29:59,  1.37s/it][A


  3%|▎         | 39/1350 [00:56<29:53,  1.37s/it]  3%|▎         | 39/1350 [00:56<29:52,  1.37s/it][A[A  3%|▎         | 39/1350 [00:56<29:53,  1.37s/it][A
  3%|▎         | 39/1350 [00:56<29:54,  1.37s/it][A
  3%|▎         | 39/1350 [00:56<29:54,  1.37s/it][A
  3%|▎         | 39/1350 [00:56<29:54,  1.37s/it][A
  3%|▎         | 40/1350 [00:57<29:48,  1.37s/it][A
  3%|▎         | 40/1350 [00:57<29:50,  1.37s/it][A

  3%|▎         | 40/1350 [00:57<29:50,  1.37s/it][A
  3%|▎         | 40/1350 [00:57<29:50,  1.37s/it][A  3%|▎         | 40/1350 [00:57<29:51,  1.37s/it][A
  3%|▎         | 40/1350 [00:57<29:51,  1.37s/it][A
  3%|▎         | 41/1350 [00:59<29:42,  1.36s/it][A
  3%|▎         | 41/1350 [00:59<29:44,  1.36s/it][A

  3%|▎         | 41/1350 [00:59<29:44,  1.36s/it][A  3%|▎         | 41/1350 [00:58<29:45,  1.36s/it][A
  3%|▎         | 41/1350 [00:59<29:46,  1.36s/it][A
  3%|▎         | 41/1350 [00:59<29:46,  1.36s/it][A
  3%|▎         | 42/1350 [01:00<29:45,  1.36s/it][A
  3%|▎         | 42/1350 [01:00<29:44,  1.36s/it]
[A  3%|▎         | 42/1350 [01:00<29:45,  1.36s/it][A

  3%|▎         | 42/1350 [01:00<29:46,  1.37s/it][A  3%|▎         | 42/1350 [01:00<29:45,  1.37s/it][A
  3%|▎         | 42/1350 [01:00<29:46,  1.37s/it][A
  3%|▎         | 43/1350 [01:01<29:36,  1.36s/it][A
  3%|▎         | 43/1350 [01:01<29:38,  1.36s/it][A

  3%|▎         | 43/1350 [01:01<29:42,  1.36s/it][A  3%|▎         | 43/1350 [01:01<29:42,  1.36s/it][A
  3%|▎         | 43/1350 [01:01<29:44,  1.37s/it][A
  3%|▎         | 43/1350 [01:01<29:45,  1.37s/it][A
  3%|▎         | 44/1350 [01:03<29:36,  1.36s/it][A
  3%|▎         | 44/1350 [01:03<29:37,  1.36s/it][A
  3%|▎         | 44/1350 [01:03<29:39,  1.36s/it][A
  3%|▎         | 44/1350 [01:03<29:41,  1.36s/it][A
  3%|▎         | 44/1350 [01:03<29:39,  1.36s/it][A
  3%|▎         | 44/1350 [01:03<29:40,  1.36s/it][A



  3%|▎         | 45/1350 [01:04<29:35,  1.36s/it][A  3%|▎         | 45/1350 [01:04<29:34,  1.36s/it][A  3%|▎         | 45/1350 [01:04<29:34,  1.36s/it][A  3%|▎         | 45/1350 [01:04<29:36,  1.36s/it][A
  3%|▎         | 45/1350 [01:04<29:33,  1.36s/it][A
  3%|▎         | 45/1350 [01:04<29:35,  1.36s/it][A
  3%|▎         | 46/1350 [01:06<30:13,  1.39s/it][A
  3%|▎         | 46/1350 [01:06<30:15,  1.39s/it][A
  3%|▎         | 46/1350 [01:06<30:20,  1.40s/it][A
  3%|▎         | 46/1350 [01:06<30:18,  1.39s/it][A
  3%|▎         | 46/1350 [01:06<30:22,  1.40s/it][A
  3%|▎         | 46/1350 [01:05<30:25,  1.40s/it][A
  3%|▎         | 47/1350 [01:07<30:43,  1.42s/it][A
  3%|▎         | 47/1350 [01:07<30:55,  1.42s/it][A
  3%|▎         | 47/1350 [01:07<30:58,  1.43s/it][A
  3%|▎         | 47/1350 [01:07<30:57,  1.43s/it][A
  3%|▎         | 47/1350 [01:07<30:59,  1.43s/it][A
  3%|▎         | 47/1350 [01:07<30:59,  1.43s/it][A
  4%|▎         | 48/1350 [01:08<30:29,  1.41s/it][A

  4%|▎         | 48/1350 [01:08<30:28,  1.40s/it][A  4%|▎         | 48/1350 [01:08<30:29,  1.41s/it][A
  4%|▎         | 48/1350 [01:08<30:30,  1.41s/it][A
  4%|▎         | 48/1350 [01:08<30:30,  1.41s/it][A
  4%|▎         | 48/1350 [01:08<30:33,  1.41s/it][A
  4%|▎         | 49/1350 [01:10<30:12,  1.39s/it][A
  4%|▎         | 49/1350 [01:10<30:11,  1.39s/it][A
  4%|▎         | 49/1350 [01:10<30:12,  1.39s/it][A
  4%|▎         | 49/1350 [01:10<30:14,  1.39s/it][A
  4%|▎         | 49/1350 [01:10<30:15,  1.40s/it][A
  4%|▎         | 49/1350 [01:10<30:15,  1.40s/it][A
  4%|▎         | 50/1350 [01:11<29:58,  1.38s/it][A
  4%|▎         | 50/1350 [01:11<29:58,  1.38s/it][A
  4%|▎         | 50/1350 [01:11<29:58,  1.38s/it][A
  4%|▎         | 50/1350 [01:11<29:59,  1.38s/it][A
  4%|▎         | 50/1350 [01:11<29:59,  1.38s/it][A
  4%|▎         | 50/1350 [01:11<30:00,  1.39s/it][A


  4%|▍         | 51/1350 [01:12<29:51,  1.38s/it][A  4%|▍         | 51/1350 [01:12<29:50,  1.38s/it][A  4%|▍         | 51/1350 [01:12<29:50,  1.38s/it][A


  4%|▍         | 51/1350 [01:12<29:51,  1.38s/it][A  4%|▍         | 51/1350 [01:12<29:50,  1.38s/it][A  4%|▍         | 51/1350 [01:12<29:51,  1.38s/it][A

  4%|▍         | 52/1350 [01:14<29:43,  1.37s/it][A  4%|▍         | 52/1350 [01:14<29:44,  1.37s/it][A

  4%|▍         | 52/1350 [01:14<29:45,  1.38s/it][A
  4%|▍         | 52/1350 [01:14<29:46,  1.38s/it][A  4%|▍         | 52/1350 [01:14<29:46,  1.38s/it][A
  4%|▍         | 52/1350 [01:14<29:45,  1.38s/it][A
  4%|▍         | 53/1350 [01:15<29:26,  1.36s/it][A
  4%|▍         | 53/1350 [01:15<29:35,  1.37s/it][A
  4%|▍         | 53/1350 [01:15<29:35,  1.37s/it][A
  4%|▍         | 53/1350 [01:15<29:39,  1.37s/it][A
  4%|▍         | 53/1350 [01:15<29:39,  1.37s/it][A
  4%|▍         | 53/1350 [01:15<29:40,  1.37s/it][A
  4%|▍         | 54/1350 [01:17<29:28,  1.36s/it][A
  4%|▍         | 54/1350 [01:17<29:31,  1.37s/it][A
  4%|▍         | 54/1350 [01:17<29:31,  1.37s/it][A
  4%|▍         | 54/1350 [01:16<29:33,  1.37s/it][A
  4%|▍         | 54/1350 [01:17<29:32,  1.37s/it][A
  4%|▍         | 54/1350 [01:17<29:37,  1.37s/it][A
  4%|▍         | 55/1350 [01:18<29:23,  1.36s/it][A
  4%|▍         | 55/1350 [01:18<29:26,  1.36s/it][A
  4%|▍         | 55/1350 [01:18<29:26,  1.36s/it][A
  4%|▍         | 55/1350 [01:18<29:27,  1.36s/it][A
  4%|▍         | 55/1350 [01:18<29:28,  1.37s/it][A
  4%|▍         | 55/1350 [01:18<29:28,  1.37s/it][A
  4%|▍         | 56/1350 [01:19<29:18,  1.36s/it][A
  4%|▍         | 56/1350 [01:19<29:20,  1.36s/it][A
  4%|▍         | 56/1350 [01:19<29:23,  1.36s/it][A
  4%|▍         | 56/1350 [01:19<29:26,  1.36s/it][A
  4%|▍         | 56/1350 [01:19<29:25,  1.36s/it][A
  4%|▍         | 56/1350 [01:19<29:23,  1.36s/it][A

  4%|▍         | 57/1350 [01:21<29:21,  1.36s/it][A  4%|▍         | 57/1350 [01:21<29:20,  1.36s/it][A

  4%|▍         | 57/1350 [01:21<29:23,  1.36s/it][A  4%|▍         | 57/1350 [01:21<29:22,  1.36s/it][A
  4%|▍         | 57/1350 [01:20<29:24,  1.36s/it][A
  4%|▍         | 57/1350 [01:21<29:24,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:17,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:17,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:18,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:17,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:18,  1.36s/it][A
  4%|▍         | 58/1350 [01:22<29:20,  1.36s/it][A
  4%|▍         | 59/1350 [01:23<29:18,  1.36s/it][A



  4%|▍         | 59/1350 [01:23<29:18,  1.36s/it]
[A  4%|▍         | 59/1350 [01:23<29:18,  1.36s/it][A  4%|▍         | 59/1350 [01:23<29:18,  1.36s/it][A  4%|▍         | 59/1350 [01:23<29:18,  1.36s/it]  4%|▍         | 59/1350 [01:23<29:17,  1.36s/it][A[A
  4%|▍         | 60/1350 [01:25<29:20,  1.36s/it][A
  4%|▍         | 60/1350 [01:25<29:21,  1.37s/it][A
  4%|▍         | 60/1350 [01:25<29:22,  1.37s/it][A
  4%|▍         | 60/1350 [01:25<29:22,  1.37s/it][A
  4%|▍         | 60/1350 [01:25<29:23,  1.37s/it][A
  4%|▍         | 60/1350 [01:25<29:24,  1.37s/it][A
  5%|▍         | 61/1350 [01:26<30:50,  1.44s/it][A
  5%|▍         | 61/1350 [01:26<30:52,  1.44s/it][A

  5%|▍         | 61/1350 [01:26<30:53,  1.44s/it][A  5%|▍         | 61/1350 [01:26<30:52,  1.44s/it][A
  5%|▍         | 61/1350 [01:26<30:53,  1.44s/it][A
  5%|▍         | 61/1350 [01:26<30:54,  1.44s/it][A
  5%|▍         | 62/1350 [01:28<31:50,  1.48s/it][A
  5%|▍         | 62/1350 [01:28<31:51,  1.48s/it][A
  5%|▍         | 62/1350 [01:28<31:52,  1.48s/it][A
  5%|▍         | 62/1350 [01:28<31:54,  1.49s/it][A
  5%|▍         | 62/1350 [01:28<31:54,  1.49s/it][A
  5%|▍         | 62/1350 [01:28<31:56,  1.49s/it][A
  5%|▍         | 63/1350 [01:29<31:02,  1.45s/it][A

  5%|▍         | 63/1350 [01:29<31:03,  1.45s/it][A  5%|▍         | 63/1350 [01:29<31:03,  1.45s/it][A
  5%|▍         | 63/1350 [01:29<31:05,  1.45s/it][A
  5%|▍         | 63/1350 [01:29<31:05,  1.45s/it][A
  5%|▍         | 63/1350 [01:29<31:06,  1.45s/it][A
  5%|▍         | 64/1350 [01:31<30:27,  1.42s/it][A
  5%|▍         | 64/1350 [01:30<30:28,  1.42s/it][A
  5%|▍         | 64/1350 [01:31<30:28,  1.42s/it][A

  5%|▍         | 64/1350 [01:31<30:29,  1.42s/it][A  5%|▍         | 64/1350 [01:31<30:28,  1.42s/it][A
  5%|▍         | 64/1350 [01:31<30:29,  1.42s/it][A
  5%|▍         | 65/1350 [01:32<30:03,  1.40s/it][A
  5%|▍         | 65/1350 [01:32<30:03,  1.40s/it][A
  5%|▍         | 65/1350 [01:32<30:04,  1.40s/it][A
  5%|▍         | 65/1350 [01:32<30:07,  1.41s/it][A
  5%|▍         | 65/1350 [01:32<30:07,  1.41s/it][A
  5%|▍         | 65/1350 [01:32<30:10,  1.41s/it][A
  5%|▍         | 66/1350 [01:33<29:45,  1.39s/it][A

  5%|▍         | 66/1350 [01:33<29:47,  1.39s/it][A  5%|▍         | 66/1350 [01:33<29:45,  1.39s/it][A
  5%|▍         | 66/1350 [01:33<29:49,  1.39s/it][A
  5%|▍         | 66/1350 [01:33<29:47,  1.39s/it][A
  5%|▍         | 66/1350 [01:33<29:50,  1.39s/it][A
  5%|▍         | 67/1350 [01:35<29:35,  1.38s/it][A

  5%|▍         | 67/1350 [01:35<29:37,  1.39s/it][A  5%|▍         | 67/1350 [01:35<29:37,  1.39s/it][A
  5%|▍         | 67/1350 [01:35<29:38,  1.39s/it][A
  5%|▍         | 67/1350 [01:35<29:38,  1.39s/it][A
  5%|▍         | 67/1350 [01:35<29:37,  1.39s/it][A
  5%|▌         | 68/1350 [01:36<29:21,  1.37s/it][A
  5%|▌         | 68/1350 [01:36<29:22,  1.37s/it][A
  5%|▌         | 68/1350 [01:36<29:22,  1.37s/it][A
  5%|▌         | 68/1350 [01:36<29:22,  1.38s/it][A
  5%|▌         | 68/1350 [01:36<29:24,  1.38s/it][A
  5%|▌         | 68/1350 [01:36<29:23,  1.38s/it][A
  5%|▌         | 69/1350 [01:37<29:13,  1.37s/it][A
  5%|▌         | 69/1350 [01:37<29:16,  1.37s/it][A
  5%|▌         | 69/1350 [01:37<29:18,  1.37s/it][A

  5%|▌         | 69/1350 [01:37<29:18,  1.37s/it][A  5%|▌         | 69/1350 [01:37<29:18,  1.37s/it][A
  5%|▌         | 69/1350 [01:37<29:19,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:11,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:12,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:12,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:12,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:15,  1.37s/it][A
  5%|▌         | 70/1350 [01:39<29:15,  1.37s/it][A
  5%|▌         | 71/1350 [01:40<29:09,  1.37s/it][A

  5%|▌         | 71/1350 [01:40<29:09,  1.37s/it][A

  5%|▌         | 71/1350 [01:40<29:09,  1.37s/it][A  5%|▌         | 71/1350 [01:40<29:09,  1.37s/it][A  5%|▌         | 71/1350 [01:40<29:10,  1.37s/it][A
  5%|▌         | 71/1350 [01:40<29:17,  1.37s/it][A
  5%|▌         | 72/1350 [01:41<29:09,  1.37s/it][A
  5%|▌         | 72/1350 [01:42<29:10,  1.37s/it][A
  5%|▌         | 72/1350 [01:42<29:11,  1.37s/it][A

  5%|▌         | 72/1350 [01:42<29:13,  1.37s/it]  5%|▌         | 72/1350 [01:42<29:12,  1.37s/it][A[A
  5%|▌         | 72/1350 [01:42<29:10,  1.37s/it][A
  5%|▌         | 73/1350 [01:43<28:59,  1.36s/it][A
  5%|▌         | 73/1350 [01:43<29:03,  1.37s/it][A
  5%|▌         | 73/1350 [01:43<29:03,  1.36s/it][A
  5%|▌         | 73/1350 [01:43<29:08,  1.37s/it][A

  5%|▌         | 73/1350 [01:43<29:09,  1.37s/it][A  5%|▌         | 73/1350 [01:43<29:09,  1.37s/it][A
  5%|▌         | 74/1350 [01:44<28:56,  1.36s/it][A
  5%|▌         | 74/1350 [01:44<29:01,  1.36s/it][A
  5%|▌         | 74/1350 [01:44<29:05,  1.37s/it][A
  5%|▌         | 74/1350 [01:44<29:04,  1.37s/it][A
  5%|▌         | 74/1350 [01:44<29:06,  1.37s/it][A
  5%|▌         | 74/1350 [01:44<29:05,  1.37s/it][A
  6%|▌         | 75/1350 [01:45<28:59,  1.36s/it][A
  6%|▌         | 75/1350 [01:46<29:03,  1.37s/it][A
  6%|▌         | 75/1350 [01:46<29:01,  1.37s/it][A
  6%|▌         | 75/1350 [01:46<29:03,  1.37s/it][A
  6%|▌         | 75/1350 [01:46<29:04,  1.37s/it][A
  6%|▌         | 75/1350 [01:46<29:07,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:01,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:00,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:02,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:03,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:03,  1.37s/it][A
  6%|▌         | 76/1350 [01:47<29:05,  1.37s/it][A
  6%|▌         | 77/1350 [01:49<30:19,  1.43s/it][A
  6%|▌         | 77/1350 [01:49<30:21,  1.43s/it][A
  6%|▌         | 77/1350 [01:49<30:22,  1.43s/it][A
  6%|▌         | 77/1350 [01:49<30:21,  1.43s/it][A
  6%|▌         | 77/1350 [01:48<30:24,  1.43s/it][A
  6%|▌         | 77/1350 [01:49<30:25,  1.43s/it][A

  6%|▌         | 78/1350 [01:50<31:12,  1.47s/it][A  6%|▌         | 78/1350 [01:50<31:13,  1.47s/it][A
  6%|▌         | 78/1350 [01:50<31:15,  1.47s/it][A
  6%|▌         | 78/1350 [01:50<31:16,  1.48s/it][A

  6%|▌         | 78/1350 [01:50<31:15,  1.47s/it][A  6%|▌         | 78/1350 [01:50<31:16,  1.48s/it][A

  6%|▌         | 79/1350 [01:52<30:31,  1.44s/it][A  6%|▌         | 79/1350 [01:52<30:32,  1.44s/it][A
  6%|▌         | 79/1350 [01:52<30:32,  1.44s/it][A
  6%|▌         | 79/1350 [01:51<30:31,  1.44s/it][A
  6%|▌         | 79/1350 [01:52<30:31,  1.44s/it][A
  6%|▌         | 79/1350 [01:52<30:33,  1.44s/it][A
  6%|▌         | 80/1350 [01:53<29:54,  1.41s/it][A
  6%|▌         | 80/1350 [01:53<29:54,  1.41s/it][A
  6%|▌         | 80/1350 [01:53<29:54,  1.41s/it][A
  6%|▌         | 80/1350 [01:53<29:58,  1.42s/it][A
  6%|▌         | 80/1350 [01:53<29:58,  1.42s/it][A
  6%|▌         | 80/1350 [01:53<30:05,  1.42s/it][A
  6%|▌         | 81/1350 [01:54<29:39,  1.40s/it][A
  6%|▌         | 81/1350 [01:54<29:39,  1.40s/it][A
  6%|▌         | 81/1350 [01:54<29:36,  1.40s/it][A
  6%|▌         | 81/1350 [01:54<29:39,  1.40s/it][A
  6%|▌         | 81/1350 [01:54<29:40,  1.40s/it][A
  6%|▌         | 81/1350 [01:54<29:41,  1.40s/it][A
  6%|▌         | 82/1350 [01:56<29:20,  1.39s/it][A
  6%|▌         | 82/1350 [01:56<29:21,  1.39s/it][A
  6%|▌         | 82/1350 [01:56<29:24,  1.39s/it][A
  6%|▌         | 82/1350 [01:56<29:24,  1.39s/it][A
  6%|▌         | 82/1350 [01:55<29:24,  1.39s/it][A
  6%|▌         | 82/1350 [01:56<29:29,  1.40s/it][A
  6%|▌         | 83/1350 [01:57<29:15,  1.39s/it][A
  6%|▌         | 83/1350 [01:57<29:15,  1.39s/it][A
  6%|▌         | 83/1350 [01:57<29:16,  1.39s/it][A
  6%|▌         | 83/1350 [01:57<29:15,  1.39s/it][A
  6%|▌         | 83/1350 [01:57<29:17,  1.39s/it][A
  6%|▌         | 83/1350 [01:57<29:14,  1.38s/it][A
  6%|▌         | 84/1350 [01:58<29:03,  1.38s/it][A
  6%|▌         | 84/1350 [01:58<29:08,  1.38s/it][A

  6%|▌         | 84/1350 [01:58<29:09,  1.38s/it]
[A  6%|▌         | 84/1350 [01:58<29:09,  1.38s/it][A  6%|▌         | 84/1350 [01:58<29:09,  1.38s/it][A
  6%|▌         | 84/1350 [01:58<29:08,  1.38s/it][A
  6%|▋         | 85/1350 [02:00<28:49,  1.37s/it][A
  6%|▋         | 85/1350 [02:00<28:58,  1.37s/it][A

  6%|▋         | 85/1350 [02:00<29:00,  1.38s/it][A  6%|▋         | 85/1350 [02:00<28:58,  1.37s/it][A

  6%|▋         | 85/1350 [02:00<29:01,  1.38s/it][A  6%|▋         | 85/1350 [02:00<29:02,  1.38s/it][A
  6%|▋         | 86/1350 [02:01<28:47,  1.37s/it][A
  6%|▋         | 86/1350 [02:01<28:53,  1.37s/it][A

  6%|▋         | 86/1350 [02:01<28:50,  1.37s/it][A  6%|▋         | 86/1350 [02:01<28:51,  1.37s/it][A
  6%|▋         | 86/1350 [02:01<28:50,  1.37s/it][A
  6%|▋         | 86/1350 [02:01<28:51,  1.37s/it][A
  6%|▋         | 87/1350 [02:02<28:42,  1.36s/it][A
  6%|▋         | 87/1350 [02:02<28:43,  1.36s/it][A
  6%|▋         | 87/1350 [02:02<28:45,  1.37s/it][A


  6%|▋         | 87/1350 [02:02<28:48,  1.37s/it][A  6%|▋         | 87/1350 [02:02<28:46,  1.37s/it][A  6%|▋         | 87/1350 [02:02<28:47,  1.37s/it][A
  7%|▋         | 88/1350 [02:04<28:39,  1.36s/it][A
  7%|▋         | 88/1350 [02:04<28:40,  1.36s/it][A
  7%|▋         | 88/1350 [02:04<28:45,  1.37s/it][A

  7%|▋         | 88/1350 [02:04<28:47,  1.37s/it][A  7%|▋         | 88/1350 [02:04<28:45,  1.37s/it][A
  7%|▋         | 88/1350 [02:04<28:46,  1.37s/it][A
  7%|▋         | 89/1350 [02:05<28:40,  1.36s/it][A
  7%|▋         | 89/1350 [02:05<28:39,  1.36s/it][A
  7%|▋         | 89/1350 [02:05<28:40,  1.36s/it][A

  7%|▋         | 89/1350 [02:05<28:43,  1.37s/it][A  7%|▋         | 89/1350 [02:05<28:42,  1.37s/it][A
  7%|▋         | 89/1350 [02:05<28:44,  1.37s/it][A

  7%|▋         | 90/1350 [02:07<28:37,  1.36s/it][A  7%|▋         | 90/1350 [02:07<28:37,  1.36s/it][A
  7%|▋         | 90/1350 [02:07<28:37,  1.36s/it][A
  7%|▋         | 90/1350 [02:06<28:38,  1.36s/it][A

  7%|▋         | 90/1350 [02:07<28:40,  1.37s/it][A  7%|▋         | 90/1350 [02:07<28:39,  1.36s/it][A


  7%|▋         | 91/1350 [02:08<28:39,  1.37s/it][A  7%|▋         | 91/1350 [02:08<28:40,  1.37s/it][A
  7%|▋         | 91/1350 [02:08<28:40,  1.37s/it]
[A  7%|▋         | 91/1350 [02:08<28:39,  1.37s/it][A  7%|▋         | 91/1350 [02:08<28:40,  1.37s/it][A
  7%|▋         | 91/1350 [02:08<28:41,  1.37s/it][A
  7%|▋         | 92/1350 [02:09<28:35,  1.36s/it][A
  7%|▋         | 92/1350 [02:09<28:35,  1.36s/it][A
  7%|▋         | 92/1350 [02:09<28:35,  1.36s/it][A
  7%|▋         | 92/1350 [02:09<28:38,  1.37s/it][A

  7%|▋         | 92/1350 [02:09<28:39,  1.37s/it][A  7%|▋         | 92/1350 [02:09<28:39,  1.37s/it][A
  7%|▋         | 93/1350 [02:11<29:23,  1.40s/it][A
  7%|▋         | 93/1350 [02:11<29:25,  1.40s/it][A
  7%|▋         | 93/1350 [02:11<29:25,  1.40s/it][A
  7%|▋         | 93/1350 [02:11<29:26,  1.41s/it][A
  7%|▋         | 93/1350 [02:11<29:26,  1.41s/it][A
  7%|▋         | 93/1350 [02:11<29:30,  1.41s/it][A
  7%|▋         | 94/1350 [02:12<29:47,  1.42s/it][A
  7%|▋         | 94/1350 [02:12<30:02,  1.44s/it][A

  7%|▋         | 94/1350 [02:12<30:01,  1.43s/it][A  7%|▋         | 94/1350 [02:12<30:02,  1.44s/it][A
  7%|▋         | 94/1350 [02:12<30:03,  1.44s/it][A
  7%|▋         | 94/1350 [02:12<30:03,  1.44s/it][A

  7%|▋         | 95/1350 [02:14<29:30,  1.41s/it][A
  7%|▋         | 95/1350 [02:14<29:31,  1.41s/it][A  7%|▋         | 95/1350 [02:14<29:31,  1.41s/it]
[A  7%|▋         | 95/1350 [02:14<29:31,  1.41s/it][A
  7%|▋         | 95/1350 [02:13<29:33,  1.41s/it][A
  7%|▋         | 95/1350 [02:14<29:32,  1.41s/it][A
  7%|▋         | 96/1350 [02:15<29:07,  1.39s/it][A
  7%|▋         | 96/1350 [02:15<29:12,  1.40s/it][A
  7%|▋         | 96/1350 [02:15<29:13,  1.40s/it][A
  7%|▋         | 96/1350 [02:15<29:14,  1.40s/it][A
  7%|▋         | 96/1350 [02:15<29:15,  1.40s/it][A
  7%|▋         | 96/1350 [02:15<29:15,  1.40s/it][A
  7%|▋         | 97/1350 [02:16<28:58,  1.39s/it][A
  7%|▋         | 97/1350 [02:16<29:00,  1.39s/it][A

  7%|▋         | 97/1350 [02:16<29:00,  1.39s/it][A  7%|▋         | 97/1350 [02:16<28:59,  1.39s/it][A
  7%|▋         | 97/1350 [02:16<28:59,  1.39s/it][A
  7%|▋         | 97/1350 [02:16<29:00,  1.39s/it][A
  7%|▋         | 98/1350 [02:18<28:45,  1.38s/it][A
  7%|▋         | 98/1350 [02:18<28:46,  1.38s/it][A

  7%|▋         | 98/1350 [02:18<28:48,  1.38s/it][A  7%|▋         | 98/1350 [02:18<28:49,  1.38s/it][A
  7%|▋         | 98/1350 [02:18<28:49,  1.38s/it][A
  7%|▋         | 98/1350 [02:18<28:49,  1.38s/it][A

  7%|▋         | 99/1350 [02:19<28:39,  1.37s/it][A  7%|▋         | 99/1350 [02:19<28:40,  1.38s/it][A

  7%|▋         | 99/1350 [02:19<28:39,  1.37s/it][A  7%|▋         | 99/1350 [02:19<28:39,  1.37s/it][A
  7%|▋         | 99/1350 [02:19<28:40,  1.38s/it][A
  7%|▋         | 99/1350 [02:19<28:41,  1.38s/it][A

  7%|▋         | 100/1350 [02:20<28:31,  1.37s/it][A  7%|▋         | 100/1350 [02:20<28:31,  1.37s/it][A

  7%|▋         | 100/1350 [02:20<28:32,  1.37s/it][A  7%|▋         | 100/1350 [02:20<28:32,  1.37s/it][A
  7%|▋         | 100/1350 [02:20<28:32,  1.37s/it][A
  7%|▋         | 100/1350 [02:20<28:34,  1.37s/it][A
  7%|▋         | 101/1350 [02:22<28:24,  1.37s/it][A
  7%|▋         | 101/1350 [02:22<28:25,  1.37s/it][A
  7%|▋         | 101/1350 [02:22<28:26,  1.37s/it][A
  7%|▋         | 101/1350 [02:22<28:26,  1.37s/it][A

  7%|▋         | 101/1350 [02:22<28:27,  1.37s/it][A  7%|▋         | 101/1350 [02:22<28:27,  1.37s/it][A

  8%|▊         | 102/1350 [02:23<28:24,  1.37s/it][A  8%|▊         | 102/1350 [02:23<28:23,  1.37s/it][A
  8%|▊         | 102/1350 [02:23<28:24,  1.37s/it][A

  8%|▊         | 102/1350 [02:23<28:25,  1.37s/it]
[A  8%|▊         | 102/1350 [02:23<28:25,  1.37s/it][A  8%|▊         | 102/1350 [02:23<28:25,  1.37s/it][A
  8%|▊         | 103/1350 [02:25<28:21,  1.36s/it][A
  8%|▊         | 103/1350 [02:25<28:21,  1.36s/it][A

  8%|▊         | 103/1350 [02:25<28:21,  1.36s/it][A  8%|▊         | 103/1350 [02:25<28:22,  1.37s/it][A
  8%|▊         | 103/1350 [02:25<28:22,  1.37s/it][A
  8%|▊         | 103/1350 [02:24<28:22,  1.37s/it][A
  8%|▊         | 104/1350 [02:26<28:17,  1.36s/it][A

  8%|▊         | 104/1350 [02:26<28:20,  1.36s/it][A  8%|▊         | 104/1350 [02:26<28:20,  1.36s/it][A


  8%|▊         | 104/1350 [02:26<28:20,  1.36s/it][A  8%|▊         | 104/1350 [02:26<28:20,  1.36s/it][A  8%|▊         | 104/1350 [02:26<28:20,  1.36s/it][A
  8%|▊         | 105/1350 [02:27<28:15,  1.36s/it][A
  8%|▊         | 105/1350 [02:27<28:15,  1.36s/it][A
  8%|▊         | 105/1350 [02:27<28:19,  1.36s/it][A
  8%|▊         | 105/1350 [02:27<28:20,  1.37s/it][A
  8%|▊         | 105/1350 [02:27<28:20,  1.37s/it][A
  8%|▊         | 105/1350 [02:27<28:20,  1.37s/it][A
  8%|▊         | 106/1350 [02:29<28:17,  1.36s/it][A
  8%|▊         | 106/1350 [02:28<28:19,  1.37s/it][A
  8%|▊         | 106/1350 [02:29<28:21,  1.37s/it][A
  8%|▊         | 106/1350 [02:29<28:22,  1.37s/it][A
  8%|▊         | 106/1350 [02:29<28:22,  1.37s/it][A
  8%|▊         | 106/1350 [02:29<28:23,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:19,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:20,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:20,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:20,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:20,  1.37s/it][A
  8%|▊         | 107/1350 [02:30<28:20,  1.37s/it][A
  8%|▊         | 108/1350 [02:32<29:39,  1.43s/it][A
  8%|▊         | 108/1350 [02:32<29:41,  1.43s/it][A

  8%|▊         | 108/1350 [02:32<29:41,  1.43s/it][A  8%|▊         | 108/1350 [02:32<29:41,  1.43s/it][A
  8%|▊         | 108/1350 [02:32<29:41,  1.43s/it][A
  8%|▊         | 108/1350 [02:31<29:42,  1.44s/it][A
  8%|▊         | 109/1350 [02:33<30:40,  1.48s/it][A
  8%|▊         | 109/1350 [02:33<30:40,  1.48s/it][A
  8%|▊         | 109/1350 [02:33<30:44,  1.49s/it][A
  8%|▊         | 109/1350 [02:33<30:46,  1.49s/it][A
  8%|▊         | 109/1350 [02:33<30:47,  1.49s/it][A
  8%|▊         | 109/1350 [02:33<30:48,  1.49s/it][A
  8%|▊         | 110/1350 [02:35<29:57,  1.45s/it][A
  8%|▊         | 110/1350 [02:35<29:58,  1.45s/it][A
  8%|▊         | 110/1350 [02:35<29:58,  1.45s/it][A
  8%|▊         | 110/1350 [02:35<30:01,  1.45s/it][A
  8%|▊         | 110/1350 [02:34<29:59,  1.45s/it][A
  8%|▊         | 110/1350 [02:35<30:02,  1.45s/it][A
  8%|▊         | 111/1350 [02:36<29:21,  1.42s/it][A
  8%|▊         | 111/1350 [02:36<29:21,  1.42s/it][A
  8%|▊         | 111/1350 [02:36<29:24,  1.42s/it][A
  8%|▊         | 111/1350 [02:36<29:24,  1.42s/it][A
  8%|▊         | 111/1350 [02:36<29:26,  1.43s/it][A
  8%|▊         | 111/1350 [02:36<29:26,  1.43s/it][A
  8%|▊         | 112/1350 [02:37<28:56,  1.40s/it][A
  8%|▊         | 112/1350 [02:37<28:57,  1.40s/it][A
  8%|▊         | 112/1350 [02:37<29:00,  1.41s/it][A
  8%|▊         | 112/1350 [02:37<29:00,  1.41s/it][A
  8%|▊         | 112/1350 [02:37<29:01,  1.41s/it][A
  8%|▊         | 112/1350 [02:37<28:59,  1.41s/it][A
  8%|▊         | 113/1350 [02:39<28:40,  1.39s/it][A


  8%|▊         | 113/1350 [02:39<28:44,  1.39s/it]
[A  8%|▊         | 113/1350 [02:39<28:43,  1.39s/it][A  8%|▊         | 113/1350 [02:39<28:43,  1.39s/it][A  8%|▊         | 113/1350 [02:39<28:42,  1.39s/it][A
  8%|▊         | 113/1350 [02:39<28:44,  1.39s/it][A
  8%|▊         | 114/1350 [02:40<28:21,  1.38s/it][A
  8%|▊         | 114/1350 [02:40<28:24,  1.38s/it][A
  8%|▊         | 114/1350 [02:40<28:29,  1.38s/it][A
  8%|▊         | 114/1350 [02:40<28:31,  1.38s/it][A
  8%|▊         | 114/1350 [02:40<28:31,  1.38s/it][A
  8%|▊         | 114/1350 [02:40<28:35,  1.39s/it][A
  9%|▊         | 115/1350 [02:41<28:13,  1.37s/it][A
  9%|▊         | 115/1350 [02:41<28:15,  1.37s/it][A
  9%|▊         | 115/1350 [02:41<28:18,  1.38s/it][A
  9%|▊         | 115/1350 [02:41<28:20,  1.38s/it][A

  9%|▊         | 115/1350 [02:41<28:21,  1.38s/it][A  9%|▊         | 115/1350 [02:41<28:22,  1.38s/it][A
  9%|▊         | 116/1350 [02:43<28:07,  1.37s/it][A
  9%|▊         | 116/1350 [02:43<28:08,  1.37s/it][A
  9%|▊         | 116/1350 [02:43<28:09,  1.37s/it][A
  9%|▊         | 116/1350 [02:43<28:10,  1.37s/it][A
  9%|▊         | 116/1350 [02:43<28:11,  1.37s/it][A
  9%|▊         | 116/1350 [02:43<28:11,  1.37s/it][A
  9%|▊         | 117/1350 [02:44<28:05,  1.37s/it][A
  9%|▊         | 117/1350 [02:44<28:06,  1.37s/it][A
  9%|▊         | 117/1350 [02:44<28:06,  1.37s/it][A

  9%|▊         | 117/1350 [02:44<28:07,  1.37s/it][A  9%|▊         | 117/1350 [02:44<28:07,  1.37s/it][A
  9%|▊         | 117/1350 [02:44<28:07,  1.37s/it][A
  9%|▊         | 118/1350 [02:45<28:03,  1.37s/it][A
  9%|▊         | 118/1350 [02:45<28:05,  1.37s/it][A
  9%|▊         | 118/1350 [02:45<28:05,  1.37s/it][A
  9%|▊         | 118/1350 [02:45<28:05,  1.37s/it][A
  9%|▊         | 118/1350 [02:46<28:06,  1.37s/it][A
  9%|▊         | 118/1350 [02:46<28:07,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:01,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:02,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:03,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:05,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:06,  1.37s/it][A
  9%|▉         | 119/1350 [02:47<28:06,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:04,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:04,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:06,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:06,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:07,  1.37s/it][A
  9%|▉         | 120/1350 [02:48<28:06,  1.37s/it][A
  9%|▉         | 121/1350 [02:49<28:02,  1.37s/it][A
  9%|▉         | 121/1350 [02:50<28:01,  1.37s/it][A
  9%|▉         | 121/1350 [02:50<28:03,  1.37s/it][A
  9%|▉         | 121/1350 [02:50<28:04,  1.37s/it][A
  9%|▉         | 121/1350 [02:50<28:04,  1.37s/it][A
  9%|▉         | 121/1350 [02:50<28:05,  1.37s/it][A
  9%|▉         | 122/1350 [02:51<27:54,  1.36s/it][A
  9%|▉         | 122/1350 [02:51<27:57,  1.37s/it][A
  9%|▉         | 122/1350 [02:51<27:59,  1.37s/it][A
  9%|▉         | 122/1350 [02:51<28:00,  1.37s/it][A

  9%|▉         | 122/1350 [02:51<28:01,  1.37s/it][A  9%|▉         | 122/1350 [02:51<28:02,  1.37s/it][A
  9%|▉         | 123/1350 [02:52<27:54,  1.36s/it][A

  9%|▉         | 123/1350 [02:52<27:56,  1.37s/it][A  9%|▉         | 123/1350 [02:52<27:57,  1.37s/it][A
  9%|▉         | 123/1350 [02:52<27:56,  1.37s/it][A

  9%|▉         | 123/1350 [02:52<27:57,  1.37s/it][A  9%|▉         | 123/1350 [02:52<27:57,  1.37s/it][A
  9%|▉         | 124/1350 [02:54<29:06,  1.42s/it][A
  9%|▉         | 124/1350 [02:54<29:08,  1.43s/it][A
  9%|▉         | 124/1350 [02:54<29:08,  1.43s/it][A
  9%|▉         | 124/1350 [02:54<29:11,  1.43s/it][A
  9%|▉         | 124/1350 [02:54<29:10,  1.43s/it][A
  9%|▉         | 124/1350 [02:54<29:12,  1.43s/it][A
  9%|▉         | 125/1350 [02:55<30:03,  1.47s/it][A

  9%|▉         | 125/1350 [02:55<30:01,  1.47s/it][A

  9%|▉         | 125/1350 [02:55<30:02,  1.47s/it][A  9%|▉         | 125/1350 [02:55<30:03,  1.47s/it]  9%|▉         | 125/1350 [02:55<30:04,  1.47s/it][A[A
  9%|▉         | 125/1350 [02:55<30:02,  1.47s/it][A
  9%|▉         | 126/1350 [02:57<29:18,  1.44s/it][A
  9%|▉         | 126/1350 [02:57<29:18,  1.44s/it][A
  9%|▉         | 126/1350 [02:57<29:18,  1.44s/it][A
  9%|▉         | 126/1350 [02:57<29:20,  1.44s/it][A
  9%|▉         | 126/1350 [02:57<29:20,  1.44s/it][A
  9%|▉         | 126/1350 [02:57<29:20,  1.44s/it][A
  9%|▉         | 127/1350 [02:58<28:46,  1.41s/it][A
  9%|▉         | 127/1350 [02:58<28:48,  1.41s/it][A

  9%|▉         | 127/1350 [02:58<28:47,  1.41s/it][A  9%|▉         | 127/1350 [02:58<28:47,  1.41s/it][A
  9%|▉         | 127/1350 [02:58<28:48,  1.41s/it][A
  9%|▉         | 127/1350 [02:58<28:50,  1.42s/it][A
  9%|▉         | 128/1350 [03:00<28:27,  1.40s/it][A
  9%|▉         | 128/1350 [03:00<28:27,  1.40s/it][A
  9%|▉         | 128/1350 [03:00<28:29,  1.40s/it][A
  9%|▉         | 128/1350 [03:00<28:29,  1.40s/it][A
  9%|▉         | 128/1350 [02:59<28:29,  1.40s/it][A
  9%|▉         | 128/1350 [03:00<28:29,  1.40s/it][A
 10%|▉         | 129/1350 [03:01<28:12,  1.39s/it][A
 10%|▉         | 129/1350 [03:01<28:13,  1.39s/it][A

 10%|▉         | 129/1350 [03:01<28:13,  1.39s/it][A 10%|▉         | 129/1350 [03:01<28:14,  1.39s/it][A
 10%|▉         | 129/1350 [03:01<28:14,  1.39s/it][A
 10%|▉         | 129/1350 [03:01<28:14,  1.39s/it][A
 10%|▉         | 130/1350 [03:02<28:03,  1.38s/it][A
 10%|▉         | 130/1350 [03:02<28:04,  1.38s/it][A
 10%|▉         | 130/1350 [03:02<28:03,  1.38s/it][A
 10%|▉         | 130/1350 [03:02<28:03,  1.38s/it][A
 10%|▉         | 130/1350 [03:02<28:04,  1.38s/it][A
 10%|▉         | 130/1350 [03:02<28:05,  1.38s/it][A

 10%|▉         | 131/1350 [03:04<27:57,  1.38s/it][A
 10%|▉         | 131/1350 [03:04<27:57,  1.38s/it][A 10%|▉         | 131/1350 [03:04<27:57,  1.38s/it][A

 10%|▉         | 131/1350 [03:03<27:57,  1.38s/it][A 10%|▉         | 131/1350 [03:04<27:58,  1.38s/it][A
 10%|▉         | 131/1350 [03:04<27:58,  1.38s/it][A
 10%|▉         | 132/1350 [03:05<27:50,  1.37s/it][A
 10%|▉         | 132/1350 [03:05<27:51,  1.37s/it][A
 10%|▉         | 132/1350 [03:05<27:52,  1.37s/it][A

 10%|▉         | 132/1350 [03:05<27:52,  1.37s/it][A 10%|▉         | 132/1350 [03:05<27:53,  1.37s/it][A
 10%|▉         | 132/1350 [03:05<27:52,  1.37s/it][A
 10%|▉         | 133/1350 [03:06<27:44,  1.37s/it][A
 10%|▉         | 133/1350 [03:06<27:46,  1.37s/it][A
 10%|▉         | 133/1350 [03:06<27:45,  1.37s/it][A

 10%|▉         | 133/1350 [03:06<27:48,  1.37s/it][A 10%|▉         | 133/1350 [03:06<27:48,  1.37s/it][A
 10%|▉         | 133/1350 [03:06<27:48,  1.37s/it][A
 10%|▉         | 134/1350 [03:08<27:38,  1.36s/it][A
 10%|▉         | 134/1350 [03:08<27:38,  1.36s/it][A
 10%|▉         | 134/1350 [03:08<27:40,  1.37s/it][A
 10%|▉         | 134/1350 [03:08<27:41,  1.37s/it][A
 10%|▉         | 134/1350 [03:08<27:43,  1.37s/it][A
 10%|▉         | 134/1350 [03:08<27:42,  1.37s/it][A
 10%|█         | 135/1350 [03:09<27:38,  1.37s/it][A
 10%|█         | 135/1350 [03:09<27:38,  1.36s/it][A
 10%|█         | 135/1350 [03:09<27:39,  1.37s/it][A
 10%|█         | 135/1350 [03:09<27:41,  1.37s/it][A

 10%|█         | 135/1350 [03:09<27:41,  1.37s/it][A 10%|█         | 135/1350 [03:09<27:40,  1.37s/it][A
 10%|█         | 136/1350 [03:10<27:33,  1.36s/it][A
 10%|█         | 136/1350 [03:10<27:34,  1.36s/it][A
 10%|█         | 136/1350 [03:10<27:36,  1.36s/it][A

 10%|█         | 136/1350 [03:10<27:35,  1.36s/it][A 10%|█         | 136/1350 [03:10<27:36,  1.36s/it][A
 10%|█         | 136/1350 [03:10<27:36,  1.36s/it][A
 10%|█         | 137/1350 [03:12<27:36,  1.37s/it][A
 10%|█         | 137/1350 [03:12<27:37,  1.37s/it][A
 10%|█         | 137/1350 [03:12<27:37,  1.37s/it][A
 10%|█         | 137/1350 [03:12<27:38,  1.37s/it][A
 10%|█         | 137/1350 [03:12<27:38,  1.37s/it][A
 10%|█         | 137/1350 [03:12<27:39,  1.37s/it][A

 10%|█         | 138/1350 [03:13<27:36,  1.37s/it][A 10%|█         | 138/1350 [03:13<27:35,  1.37s/it][A
 10%|█         | 138/1350 [03:13<27:37,  1.37s/it][A
 10%|█         | 138/1350 [03:13<27:37,  1.37s/it][A
 10%|█         | 138/1350 [03:13<27:37,  1.37s/it][A
 10%|█         | 138/1350 [03:13<27:38,  1.37s/it][A
 10%|█         | 139/1350 [03:15<27:31,  1.36s/it][A
 10%|█         | 139/1350 [03:15<27:31,  1.36s/it][A
 10%|█         | 139/1350 [03:14<27:33,  1.37s/it][A
 10%|█         | 139/1350 [03:15<27:34,  1.37s/it][A
 10%|█         | 139/1350 [03:15<27:34,  1.37s/it][A
 10%|█         | 139/1350 [03:15<27:33,  1.37s/it][A
 10%|█         | 140/1350 [03:16<28:12,  1.40s/it][A
 10%|█         | 140/1350 [03:16<28:13,  1.40s/it][A
 10%|█         | 140/1350 [03:16<28:16,  1.40s/it][A
 10%|█         | 140/1350 [03:16<28:18,  1.40s/it][A
 10%|█         | 140/1350 [03:16<28:18,  1.40s/it][A
 10%|█         | 140/1350 [03:16<28:23,  1.41s/it][A
 10%|█         | 141/1350 [03:17<28:39,  1.42s/it][A
 10%|█         | 141/1350 [03:18<28:53,  1.43s/it][A

 10%|█         | 141/1350 [03:18<28:55,  1.44s/it][A 10%|█         | 141/1350 [03:18<28:54,  1.43s/it][A
 10%|█         | 141/1350 [03:18<28:56,  1.44s/it][A
 10%|█         | 141/1350 [03:18<28:55,  1.44s/it][A

 11%|█         | 142/1350 [03:19<28:23,  1.41s/it][A 11%|█         | 142/1350 [03:19<28:24,  1.41s/it][A
 11%|█         | 142/1350 [03:19<28:25,  1.41s/it][A
 11%|█         | 142/1350 [03:19<28:27,  1.41s/it][A
 11%|█         | 142/1350 [03:19<28:29,  1.41s/it][A
 11%|█         | 142/1350 [03:19<28:31,  1.42s/it][A
 11%|█         | 143/1350 [03:20<28:06,  1.40s/it][A
 11%|█         | 143/1350 [03:20<28:05,  1.40s/it][A
 11%|█         | 143/1350 [03:20<28:05,  1.40s/it][A
 11%|█         | 143/1350 [03:20<28:06,  1.40s/it][A
 11%|█         | 143/1350 [03:20<28:07,  1.40s/it][A
 11%|█         | 143/1350 [03:20<28:09,  1.40s/it][A
 11%|█         | 144/1350 [03:22<27:45,  1.38s/it][A
 11%|█         | 144/1350 [03:22<27:50,  1.39s/it][A

 11%|█         | 144/1350 [03:22<27:51,  1.39s/it][A 11%|█         | 144/1350 [03:22<27:52,  1.39s/it][A
 11%|█         | 144/1350 [03:22<27:52,  1.39s/it][A
 11%|█         | 144/1350 [03:21<27:54,  1.39s/it][A


 11%|█         | 145/1350 [03:23<27:40,  1.38s/it]
[A 11%|█         | 145/1350 [03:23<27:41,  1.38s/it][A 11%|█         | 145/1350 [03:23<27:40,  1.38s/it][A
 11%|█         | 145/1350 [03:23<27:40,  1.38s/it][A 11%|█         | 145/1350 [03:23<27:40,  1.38s/it][A
 11%|█         | 145/1350 [03:23<27:43,  1.38s/it][A
 11%|█         | 146/1350 [03:24<27:31,  1.37s/it][A
 11%|█         | 146/1350 [03:24<27:31,  1.37s/it][A


 11%|█         | 146/1350 [03:24<27:33,  1.37s/it][A 11%|█         | 146/1350 [03:24<27:32,  1.37s/it] 11%|█         | 146/1350 [03:24<27:32,  1.37s/it][A[A
 11%|█         | 146/1350 [03:24<27:32,  1.37s/it][A
 11%|█         | 147/1350 [03:26<27:23,  1.37s/it][A
 11%|█         | 147/1350 [03:26<27:24,  1.37s/it][A
 11%|█         | 147/1350 [03:26<27:24,  1.37s/it][A
 11%|█         | 147/1350 [03:26<27:25,  1.37s/it][A
 11%|█         | 147/1350 [03:26<27:25,  1.37s/it]
[A 11%|█         | 147/1350 [03:26<27:25,  1.37s/it][A
 11%|█         | 148/1350 [03:27<27:20,  1.36s/it][A

 11%|█         | 148/1350 [03:27<27:22,  1.37s/it][A 11%|█         | 148/1350 [03:27<27:21,  1.37s/it][A


 11%|█         | 148/1350 [03:27<27:22,  1.37s/it][A 11%|█         | 148/1350 [03:27<27:22,  1.37s/it][A 11%|█         | 148/1350 [03:27<27:21,  1.37s/it][A
 11%|█         | 149/1350 [03:28<27:14,  1.36s/it][A
 11%|█         | 149/1350 [03:28<27:14,  1.36s/it][A
 11%|█         | 149/1350 [03:28<27:17,  1.36s/it][A

 11%|█         | 149/1350 [03:28<27:18,  1.36s/it][A
 11%|█         | 149/1350 [03:28<27:17,  1.36s/it][A 11%|█         | 149/1350 [03:28<27:17,  1.36s/it][A
 11%|█         | 150/1350 [03:30<27:12,  1.36s/it][A
 11%|█         | 150/1350 [03:30<27:14,  1.36s/it][A
 11%|█         | 150/1350 [03:30<27:15,  1.36s/it][A

 11%|█         | 150/1350 [03:30<27:16,  1.36s/it][A 11%|█         | 150/1350 [03:30<27:16,  1.36s/it][A
 11%|█         | 150/1350 [03:30<27:17,  1.36s/it][A
 11%|█         | 151/1350 [03:31<27:15,  1.36s/it][A


 11%|█         | 151/1350 [03:31<27:16,  1.36s/it][A 11%|█         | 151/1350 [03:31<27:15,  1.36s/it][A 11%|█         | 151/1350 [03:31<27:15,  1.36s/it][A
 11%|█         | 151/1350 [03:31<27:17,  1.37s/it][A
 11%|█         | 151/1350 [03:31<27:16,  1.36s/it][A
 11%|█▏        | 152/1350 [03:33<27:13,  1.36s/it][A

 11%|█▏        | 152/1350 [03:32<27:13,  1.36s/it] 11%|█▏        | 152/1350 [03:33<27:13,  1.36s/it][A
[A

 11%|█▏        | 152/1350 [03:33<27:14,  1.36s/it][A 11%|█▏        | 152/1350 [03:33<27:14,  1.36s/it][A 11%|█▏        | 152/1350 [03:33<27:13,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:11,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:11,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:11,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:11,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:13,  1.36s/it][A
 11%|█▏        | 153/1350 [03:34<27:12,  1.36s/it][A
 11%|█▏        | 154/1350 [03:35<27:11,  1.36s/it][A
 11%|█▏        | 154/1350 [03:35<27:12,  1.37s/it][A

 11%|█▏        | 154/1350 [03:35<27:12,  1.37s/it][A 11%|█▏        | 154/1350 [03:35<27:13,  1.37s/it][A
 11%|█▏        | 154/1350 [03:35<27:13,  1.37s/it][A
 11%|█▏        | 154/1350 [03:35<27:14,  1.37s/it][A
 11%|█▏        | 155/1350 [03:37<28:26,  1.43s/it][A
 11%|█▏        | 155/1350 [03:37<28:27,  1.43s/it][A
 11%|█▏        | 155/1350 [03:37<28:30,  1.43s/it][A
 11%|█▏        | 155/1350 [03:37<28:30,  1.43s/it][A
 11%|█▏        | 155/1350 [03:37<28:32,  1.43s/it][A
 11%|█▏        | 155/1350 [03:37<28:32,  1.43s/it][A
 12%|█▏        | 156/1350 [03:38<29:23,  1.48s/it][A
 12%|█▏        | 156/1350 [03:38<29:25,  1.48s/it][A
 12%|█▏        | 156/1350 [03:38<29:31,  1.48s/it][A
 12%|█▏        | 156/1350 [03:38<29:33,  1.48s/it][A

 12%|█▏        | 156/1350 [03:38<29:35,  1.49s/it][A 12%|█▏        | 156/1350 [03:38<29:35,  1.49s/it][A
 12%|█▏        | 157/1350 [03:40<28:48,  1.45s/it][A
 12%|█▏        | 157/1350 [03:40<28:47,  1.45s/it][A
 12%|█▏        | 157/1350 [03:40<28:49,  1.45s/it][A
 12%|█▏        | 157/1350 [03:40<28:50,  1.45s/it][A
 12%|█▏        | 157/1350 [03:40<28:51,  1.45s/it][A
 12%|█▏        | 157/1350 [03:40<28:52,  1.45s/it][A
 12%|█▏        | 158/1350 [03:41<28:13,  1.42s/it][A
 12%|█▏        | 158/1350 [03:41<28:16,  1.42s/it][A
 12%|█▏        | 158/1350 [03:41<28:17,  1.42s/it][A
 12%|█▏        | 158/1350 [03:41<28:16,  1.42s/it][A
 12%|█▏        | 158/1350 [03:41<28:18,  1.43s/it][A
 12%|█▏        | 158/1350 [03:41<28:18,  1.42s/it][A
 12%|█▏        | 159/1350 [03:43<27:50,  1.40s/it][A
 12%|█▏        | 159/1350 [03:43<27:49,  1.40s/it][A
 12%|█▏        | 159/1350 [03:43<27:51,  1.40s/it][A

 12%|█▏        | 159/1350 [03:43<27:51,  1.40s/it][A 12%|█▏        | 159/1350 [03:42<27:50,  1.40s/it][A
 12%|█▏        | 159/1350 [03:43<27:52,  1.40s/it][A
 12%|█▏        | 160/1350 [03:44<27:34,  1.39s/it][A


 12%|█▏        | 160/1350 [03:44<27:35,  1.39s/it][A 12%|█▏        | 160/1350 [03:44<27:35,  1.39s/it][A 12%|█▏        | 160/1350 [03:44<27:35,  1.39s/it][A

 12%|█▏        | 160/1350 [03:44<27:36,  1.39s/it][A 12%|█▏        | 160/1350 [03:44<27:36,  1.39s/it][A
 12%|█▏        | 161/1350 [03:45<27:20,  1.38s/it][A
 12%|█▏        | 161/1350 [03:45<27:21,  1.38s/it][A
 12%|█▏        | 161/1350 [03:45<27:22,  1.38s/it][A
 12%|█▏        | 161/1350 [03:45<27:27,  1.39s/it][A
 12%|█▏        | 161/1350 [03:45<27:28,  1.39s/it][A
 12%|█▏        | 161/1350 [03:45<27:27,  1.39s/it][A
 12%|█▏        | 162/1350 [03:47<27:13,  1.37s/it][A
 12%|█▏        | 162/1350 [03:47<27:16,  1.38s/it][A
 12%|█▏        | 162/1350 [03:46<27:16,  1.38s/it][A

 12%|█▏        | 162/1350 [03:47<27:14,  1.38s/it][A 12%|█▏        | 162/1350 [03:47<27:15,  1.38s/it][A
 12%|█▏        | 162/1350 [03:47<27:17,  1.38s/it][A


 12%|█▏        | 163/1350 [03:48<27:11,  1.37s/it][A 12%|█▏        | 163/1350 [03:48<27:12,  1.38s/it] 12%|█▏        | 163/1350 [03:48<27:13,  1.38s/it][A[A
 12%|█▏        | 163/1350 [03:48<27:11,  1.37s/it][A

 12%|█▏        | 163/1350 [03:48<27:12,  1.37s/it][A 12%|█▏        | 163/1350 [03:48<27:12,  1.38s/it][A
 12%|█▏        | 164/1350 [03:49<27:00,  1.37s/it][A
 12%|█▏        | 164/1350 [03:49<27:02,  1.37s/it][A
 12%|█▏        | 164/1350 [03:49<27:04,  1.37s/it][A
 12%|█▏        | 164/1350 [03:49<27:07,  1.37s/it][A
 12%|█▏        | 164/1350 [03:49<27:08,  1.37s/it][A
 12%|█▏        | 164/1350 [03:49<27:09,  1.37s/it][A

 12%|█▏        | 165/1350 [03:51<26:58,  1.37s/it][A 12%|█▏        | 165/1350 [03:51<26:59,  1.37s/it][A

 12%|█▏        | 165/1350 [03:51<27:01,  1.37s/it]
[A 12%|█▏        | 165/1350 [03:51<27:00,  1.37s/it][A 12%|█▏        | 165/1350 [03:51<27:00,  1.37s/it][A
 12%|█▏        | 165/1350 [03:51<27:01,  1.37s/it][A
 12%|█▏        | 166/1350 [03:52<26:56,  1.37s/it][A

 12%|█▏        | 166/1350 [03:52<26:56,  1.37s/it][A 12%|█▏        | 166/1350 [03:52<26:57,  1.37s/it][A
 12%|█▏        | 166/1350 [03:52<26:56,  1.37s/it][A

 12%|█▏        | 166/1350 [03:52<26:57,  1.37s/it][A 12%|█▏        | 166/1350 [03:52<26:57,  1.37s/it][A
 12%|█▏        | 167/1350 [03:53<26:50,  1.36s/it][A
 12%|█▏        | 167/1350 [03:53<26:53,  1.36s/it][A
 12%|█▏        | 167/1350 [03:53<26:54,  1.37s/it][A
 12%|█▏        | 167/1350 [03:53<26:55,  1.37s/it][A
 12%|█▏        | 167/1350 [03:53<26:55,  1.37s/it][A
 12%|█▏        | 167/1350 [03:53<26:56,  1.37s/it][A
 12%|█▏        | 168/1350 [03:55<26:50,  1.36s/it][A
 12%|█▏        | 168/1350 [03:55<26:52,  1.36s/it][A
 12%|█▏        | 168/1350 [03:55<26:54,  1.37s/it][A

 12%|█▏        | 168/1350 [03:55<26:53,  1.36s/it][A 12%|█▏        | 168/1350 [03:55<26:54,  1.37s/it][A
 12%|█▏        | 168/1350 [03:55<26:54,  1.37s/it][A
 13%|█▎        | 169/1350 [03:56<26:45,  1.36s/it][A
 13%|█▎        | 169/1350 [03:56<26:45,  1.36s/it][A
 13%|█▎        | 169/1350 [03:56<26:51,  1.36s/it][A

 13%|█▎        | 169/1350 [03:56<26:51,  1.36s/it][A 13%|█▎        | 169/1350 [03:56<26:52,  1.37s/it][A
 13%|█▎        | 169/1350 [03:56<26:51,  1.36s/it][A
 13%|█▎        | 170/1350 [03:58<26:45,  1.36s/it][A
 13%|█▎        | 170/1350 [03:57<26:45,  1.36s/it][A
 13%|█▎        | 170/1350 [03:58<26:45,  1.36s/it][A
 13%|█▎        | 170/1350 [03:58<26:48,  1.36s/it][A

 13%|█▎        | 170/1350 [03:58<26:49,  1.36s/it][A 13%|█▎        | 170/1350 [03:58<26:50,  1.36s/it][A
 13%|█▎        | 171/1350 [03:59<28:03,  1.43s/it][A
 13%|█▎        | 171/1350 [03:59<28:03,  1.43s/it][A
 13%|█▎        | 171/1350 [03:59<28:08,  1.43s/it][A
 13%|█▎        | 171/1350 [03:59<28:06,  1.43s/it][A
 13%|█▎        | 171/1350 [03:59<28:07,  1.43s/it][A
 13%|█▎        | 171/1350 [03:59<28:09,  1.43s/it][A
 13%|█▎        | 172/1350 [04:01<28:52,  1.47s/it][A
 13%|█▎        | 172/1350 [04:01<28:54,  1.47s/it][A
 13%|█▎        | 172/1350 [04:01<28:56,  1.47s/it][A

 13%|█▎        | 172/1350 [04:01<28:56,  1.47s/it][A 13%|█▎        | 172/1350 [04:01<28:59,  1.48s/it][A
 13%|█▎        | 172/1350 [04:01<28:57,  1.48s/it][A
 13%|█▎        | 173/1350 [04:02<28:17,  1.44s/it][A
 13%|█▎        | 173/1350 [04:02<28:17,  1.44s/it][A

 13%|█▎        | 173/1350 [04:02<28:17,  1.44s/it][A

 13%|█▎        | 173/1350 [04:02<28:16,  1.44s/it][A 13%|█▎        | 173/1350 [04:02<28:18,  1.44s/it][A 13%|█▎        | 173/1350 [04:02<28:17,  1.44s/it][A
 13%|█▎        | 174/1350 [04:03<27:45,  1.42s/it][A
 13%|█▎        | 174/1350 [04:03<27:46,  1.42s/it][A
 13%|█▎        | 174/1350 [04:03<27:47,  1.42s/it][A
 13%|█▎        | 174/1350 [04:03<27:47,  1.42s/it][A
 13%|█▎        | 174/1350 [04:03<27:49,  1.42s/it][A
 13%|█▎        | 174/1350 [04:03<27:50,  1.42s/it][A
 13%|█▎        | 175/1350 [04:05<27:20,  1.40s/it][A
 13%|█▎        | 175/1350 [04:05<27:22,  1.40s/it][A
 13%|█▎        | 175/1350 [04:05<27:25,  1.40s/it][A
 13%|█▎        | 175/1350 [04:05<27:26,  1.40s/it][A
 13%|█▎        | 175/1350 [04:05<27:26,  1.40s/it][A
 13%|█▎        | 175/1350 [04:05<27:27,  1.40s/it][A
 13%|█▎        | 176/1350 [04:06<27:06,  1.39s/it][A
 13%|█▎        | 176/1350 [04:06<27:08,  1.39s/it][A
 13%|█▎        | 176/1350 [04:06<27:10,  1.39s/it][A
 13%|█▎        | 176/1350 [04:06<27:11,  1.39s/it][A
 13%|█▎        | 176/1350 [04:06<27:10,  1.39s/it][A
 13%|█▎        | 176/1350 [04:06<27:10,  1.39s/it][A
 13%|█▎        | 177/1350 [04:07<26:56,  1.38s/it][A
 13%|█▎        | 177/1350 [04:07<26:56,  1.38s/it][A
 13%|█▎        | 177/1350 [04:08<26:59,  1.38s/it][A
 13%|█▎        | 177/1350 [04:08<27:01,  1.38s/it][A

 13%|█▎        | 177/1350 [04:07<26:59,  1.38s/it][A 13%|█▎        | 177/1350 [04:08<27:00,  1.38s/it][A
 13%|█▎        | 178/1350 [04:09<26:49,  1.37s/it][A
 13%|█▎        | 178/1350 [04:09<26:50,  1.37s/it][A



 13%|█▎        | 178/1350 [04:09<26:49,  1.37s/it][A 13%|█▎        | 178/1350 [04:09<26:50,  1.37s/it][A 13%|█▎        | 178/1350 [04:09<26:49,  1.37s/it] 13%|█▎        | 178/1350 [04:09<26:50,  1.37s/it][A[A
 13%|█▎        | 179/1350 [04:10<26:39,  1.37s/it][A
 13%|█▎        | 179/1350 [04:10<26:40,  1.37s/it][A
 13%|█▎        | 179/1350 [04:10<26:42,  1.37s/it][A
 13%|█▎        | 179/1350 [04:10<26:41,  1.37s/it][A
 13%|█▎        | 179/1350 [04:10<26:45,  1.37s/it][A
 13%|█▎        | 179/1350 [04:10<26:48,  1.37s/it][A
 13%|█▎        | 180/1350 [04:12<26:39,  1.37s/it][A
 13%|█▎        | 180/1350 [04:12<26:39,  1.37s/it][A
 13%|█▎        | 180/1350 [04:12<26:39,  1.37s/it][A
 13%|█▎        | 180/1350 [04:12<26:41,  1.37s/it][A
 13%|█▎        | 180/1350 [04:12<26:43,  1.37s/it][A
 13%|█▎        | 180/1350 [04:11<26:41,  1.37s/it][A
 13%|█▎        | 181/1350 [04:13<26:33,  1.36s/it][A
 13%|█▎        | 181/1350 [04:13<26:32,  1.36s/it][A

 13%|█▎        | 181/1350 [04:13<26:35,  1.36s/it][A 13%|█▎        | 181/1350 [04:13<26:35,  1.36s/it][A
 13%|█▎        | 181/1350 [04:13<26:36,  1.37s/it][A
 13%|█▎        | 181/1350 [04:13<26:36,  1.37s/it][A
 13%|█▎        | 182/1350 [04:14<26:27,  1.36s/it][A
 13%|█▎        | 182/1350 [04:14<26:32,  1.36s/it][A
 13%|█▎        | 182/1350 [04:14<26:34,  1.36s/it][A
 13%|█▎        | 182/1350 [04:14<26:33,  1.36s/it][A

 13%|█▎        | 182/1350 [04:14<26:38,  1.37s/it][A 13%|█▎        | 182/1350 [04:14<26:35,  1.37s/it][A
 14%|█▎        | 183/1350 [04:15<26:27,  1.36s/it][A
 14%|█▎        | 183/1350 [04:16<26:28,  1.36s/it][A
 14%|█▎        | 183/1350 [04:16<26:30,  1.36s/it][A
 14%|█▎        | 183/1350 [04:16<26:30,  1.36s/it][A
 14%|█▎        | 183/1350 [04:16<26:33,  1.37s/it][A
 14%|█▎        | 183/1350 [04:16<26:30,  1.36s/it][A
 14%|█▎        | 184/1350 [04:17<26:32,  1.37s/it][A
 14%|█▎        | 184/1350 [04:17<26:33,  1.37s/it][A
 14%|█▎        | 184/1350 [04:17<26:30,  1.36s/it][A
 14%|█▎        | 184/1350 [04:17<26:35,  1.37s/it][A
 14%|█▎        | 184/1350 [04:17<26:33,  1.37s/it][A
 14%|█▎        | 184/1350 [04:17<26:34,  1.37s/it][A
 14%|█▎        | 185/1350 [04:18<26:29,  1.36s/it][A
 14%|█▎        | 185/1350 [04:18<26:28,  1.36s/it][A
 14%|█▎        | 185/1350 [04:18<26:28,  1.36s/it][A

 14%|█▎        | 185/1350 [04:18<26:31,  1.37s/it][A 14%|█▎        | 185/1350 [04:18<26:31,  1.37s/it][A
 14%|█▎        | 185/1350 [04:18<26:31,  1.37s/it][A
 14%|█▍        | 186/1350 [04:20<26:16,  1.35s/it][A
 14%|█▍        | 186/1350 [04:20<26:17,  1.36s/it][A
 14%|█▍        | 186/1350 [04:20<26:26,  1.36s/it][A
 14%|█▍        | 186/1350 [04:20<26:29,  1.37s/it][A
 14%|█▍        | 186/1350 [04:20<26:30,  1.37s/it]
[A 14%|█▍        | 186/1350 [04:20<26:31,  1.37s/it][A
 14%|█▍        | 187/1350 [04:21<27:08,  1.40s/it][A
 14%|█▍        | 187/1350 [04:21<27:09,  1.40s/it][A

 14%|█▍        | 187/1350 [04:21<27:13,  1.40s/it][A 14%|█▍        | 187/1350 [04:21<27:10,  1.40s/it][A
 14%|█▍        | 187/1350 [04:21<27:11,  1.40s/it][A
 14%|█▍        | 187/1350 [04:21<27:19,  1.41s/it][A
 14%|█▍        | 188/1350 [04:23<27:37,  1.43s/it][A
 14%|█▍        | 188/1350 [04:23<27:39,  1.43s/it][A
 14%|█▍        | 188/1350 [04:23<27:41,  1.43s/it][A
 14%|█▍        | 188/1350 [04:23<27:45,  1.43s/it][A
 14%|█▍        | 188/1350 [04:23<27:48,  1.44s/it][A
 14%|█▍        | 188/1350 [04:23<27:45,  1.43s/it][A
 14%|█▍        | 189/1350 [04:24<27:14,  1.41s/it][A
 14%|█▍        | 189/1350 [04:24<27:16,  1.41s/it][A
 14%|█▍        | 189/1350 [04:24<27:15,  1.41s/it][A
 14%|█▍        | 189/1350 [04:24<27:18,  1.41s/it][A

 14%|█▍        | 189/1350 [04:24<27:16,  1.41s/it][A 14%|█▍        | 189/1350 [04:24<27:15,  1.41s/it][A
 14%|█▍        | 190/1350 [04:25<26:58,  1.40s/it][A

 14%|█▍        | 190/1350 [04:25<27:01,  1.40s/it][A 14%|█▍        | 190/1350 [04:25<27:01,  1.40s/it]
[A
 14%|█▍        | 190/1350 [04:25<27:01,  1.40s/it][A 14%|█▍        | 190/1350 [04:25<27:03,  1.40s/it][A
 14%|█▍        | 190/1350 [04:25<26:59,  1.40s/it][A
 14%|█▍        | 191/1350 [04:27<26:46,  1.39s/it][A
 14%|█▍        | 191/1350 [04:27<26:46,  1.39s/it][A

 14%|█▍        | 191/1350 [04:27<26:45,  1.39s/it] 14%|█▍        | 191/1350 [04:27<26:43,  1.38s/it][A[A
 14%|█▍        | 191/1350 [04:27<26:46,  1.39s/it][A
 14%|█▍        | 191/1350 [04:27<26:47,  1.39s/it][A
 14%|█▍        | 192/1350 [04:28<26:37,  1.38s/it][A
 14%|█▍        | 192/1350 [04:28<26:38,  1.38s/it][A
 14%|█▍        | 192/1350 [04:28<26:38,  1.38s/it][A
 14%|█▍        | 192/1350 [04:28<26:40,  1.38s/it][A
 14%|█▍        | 192/1350 [04:28<26:41,  1.38s/it][A
 14%|█▍        | 192/1350 [04:28<26:42,  1.38s/it][A
 14%|█▍        | 193/1350 [04:30<26:30,  1.37s/it][A

 14%|█▍        | 193/1350 [04:30<26:30,  1.37s/it][A 14%|█▍        | 193/1350 [04:30<26:30,  1.38s/it]
[A 14%|█▍        | 193/1350 [04:29<26:31,  1.38s/it][A
 14%|█▍        | 193/1350 [04:30<26:33,  1.38s/it][A
 14%|█▍        | 193/1350 [04:30<26:34,  1.38s/it][A
 14%|█▍        | 194/1350 [04:31<26:28,  1.37s/it][A
 14%|█▍        | 194/1350 [04:31<26:30,  1.38s/it][A


 14%|█▍        | 194/1350 [04:31<26:30,  1.38s/it][A 14%|█▍        | 194/1350 [04:31<26:30,  1.38s/it][A 14%|█▍        | 194/1350 [04:31<26:28,  1.37s/it][A
 14%|█▍        | 194/1350 [04:31<26:31,  1.38s/it][A
 14%|█▍        | 195/1350 [04:32<26:21,  1.37s/it][A
 14%|█▍        | 195/1350 [04:32<26:21,  1.37s/it][A
 14%|█▍        | 195/1350 [04:32<26:24,  1.37s/it][A

 14%|█▍        | 195/1350 [04:32<26:22,  1.37s/it][A 14%|█▍        | 195/1350 [04:32<26:24,  1.37s/it][A
 14%|█▍        | 195/1350 [04:32<26:24,  1.37s/it][A
 15%|█▍        | 196/1350 [04:34<26:16,  1.37s/it][A
 15%|█▍        | 196/1350 [04:34<26:16,  1.37s/it][A
 15%|█▍        | 196/1350 [04:34<26:16,  1.37s/it][A

 15%|█▍        | 196/1350 [04:34<26:18,  1.37s/it][A 15%|█▍        | 196/1350 [04:34<26:18,  1.37s/it][A
 15%|█▍        | 196/1350 [04:33<26:18,  1.37s/it][A
 15%|█▍        | 197/1350 [04:35<26:13,  1.36s/it][A
 15%|█▍        | 197/1350 [04:35<26:14,  1.37s/it][A
 15%|█▍        | 197/1350 [04:35<26:15,  1.37s/it][A
 15%|█▍        | 197/1350 [04:35<26:18,  1.37s/it][A
 15%|█▍        | 197/1350 [04:35<26:18,  1.37s/it][A
 15%|█▍        | 197/1350 [04:35<26:17,  1.37s/it][A
 15%|█▍        | 198/1350 [04:36<26:08,  1.36s/it][A

 15%|█▍        | 198/1350 [04:36<26:11,  1.36s/it][A 15%|█▍        | 198/1350 [04:36<26:10,  1.36s/it][A

 15%|█▍        | 198/1350 [04:36<26:14,  1.37s/it][A 15%|█▍        | 198/1350 [04:36<26:14,  1.37s/it][A
 15%|█▍        | 198/1350 [04:36<26:15,  1.37s/it][A
 15%|█▍        | 199/1350 [04:38<26:06,  1.36s/it][A
 15%|█▍        | 199/1350 [04:38<26:09,  1.36s/it][A
 15%|█▍        | 199/1350 [04:38<26:10,  1.36s/it][A
 15%|█▍        | 199/1350 [04:38<26:09,  1.36s/it][A
 15%|█▍        | 199/1350 [04:38<26:10,  1.36s/it][A
 15%|█▍        | 199/1350 [04:38<26:10,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:03,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:06,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:05,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:05,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:07,  1.36s/it][A
 15%|█▍        | 200/1350 [04:39<26:06,  1.36s/it][A
 15%|█▍        | 201/1350 [04:40<26:00,  1.36s/it][A
 15%|█▍        | 201/1350 [04:40<26:01,  1.36s/it][A

 15%|█▍        | 201/1350 [04:40<26:04,  1.36s/it][A 15%|█▍        | 201/1350 [04:40<26:05,  1.36s/it][A
 15%|█▍        | 201/1350 [04:40<26:04,  1.36s/it][A
 15%|█▍        | 201/1350 [04:40<26:06,  1.36s/it][A
 15%|█▍        | 202/1350 [04:42<27:20,  1.43s/it][A
 15%|█▍        | 202/1350 [04:42<27:20,  1.43s/it][A
 15%|█▍        | 202/1350 [04:42<27:19,  1.43s/it][A
 15%|█▍        | 202/1350 [04:42<27:20,  1.43s/it][A
 15%|█▍        | 202/1350 [04:42<27:21,  1.43s/it][A
 15%|█▍        | 202/1350 [04:42<27:21,  1.43s/it][A
 15%|█▌        | 203/1350 [04:43<28:13,  1.48s/it][A
 15%|█▌        | 203/1350 [04:44<28:15,  1.48s/it][A
 15%|█▌        | 203/1350 [04:44<28:17,  1.48s/it][A
 15%|█▌        | 203/1350 [04:44<28:17,  1.48s/it][A
 15%|█▌        | 203/1350 [04:44<28:19,  1.48s/it][A
 15%|█▌        | 203/1350 [04:44<28:19,  1.48s/it][A
 15%|█▌        | 204/1350 [04:45<27:32,  1.44s/it][A
 15%|█▌        | 204/1350 [04:45<27:35,  1.44s/it][A
 15%|█▌        | 204/1350 [04:45<27:37,  1.45s/it][A
 15%|█▌        | 204/1350 [04:45<27:36,  1.45s/it][A
 15%|█▌        | 204/1350 [04:45<27:37,  1.45s/it][A
 15%|█▌        | 204/1350 [04:45<27:38,  1.45s/it][A
 15%|█▌        | 205/1350 [04:46<27:02,  1.42s/it][A
 15%|█▌        | 205/1350 [04:46<27:02,  1.42s/it][A
 15%|█▌        | 205/1350 [04:46<27:04,  1.42s/it][A
 15%|█▌        | 205/1350 [04:46<27:05,  1.42s/it][A
 15%|█▌        | 205/1350 [04:46<27:05,  1.42s/it][A
 15%|█▌        | 205/1350 [04:46<27:05,  1.42s/it][A
 15%|█▌        | 206/1350 [04:48<26:43,  1.40s/it][A
 15%|█▌        | 206/1350 [04:48<26:43,  1.40s/it][A
 15%|█▌        | 206/1350 [04:48<26:46,  1.40s/it][A
 15%|█▌        | 206/1350 [04:48<26:46,  1.40s/it][A
 15%|█▌        | 206/1350 [04:48<26:46,  1.40s/it][A
 15%|█▌        | 206/1350 [04:48<26:47,  1.40s/it][A
 15%|█▌        | 207/1350 [04:49<26:29,  1.39s/it][A
 15%|█▌        | 207/1350 [04:49<26:31,  1.39s/it][A
 15%|█▌        | 207/1350 [04:49<26:31,  1.39s/it][A

 15%|█▌        | 207/1350 [04:49<26:33,  1.39s/it][A 15%|█▌        | 207/1350 [04:49<26:32,  1.39s/it][A
 15%|█▌        | 207/1350 [04:49<26:32,  1.39s/it][A
 15%|█▌        | 208/1350 [04:50<26:19,  1.38s/it][A
 15%|█▌        | 208/1350 [04:50<26:20,  1.38s/it][A
 15%|█▌        | 208/1350 [04:50<26:21,  1.38s/it][A
 15%|█▌        | 208/1350 [04:50<26:21,  1.38s/it][A
 15%|█▌        | 208/1350 [04:50<26:21,  1.38s/it][A
 15%|█▌        | 208/1350 [04:50<26:22,  1.39s/it][A
 15%|█▌        | 209/1350 [04:52<26:11,  1.38s/it][A
 15%|█▌        | 209/1350 [04:52<26:11,  1.38s/it][A
 15%|█▌        | 209/1350 [04:52<26:12,  1.38s/it][A
 15%|█▌        | 209/1350 [04:52<26:13,  1.38s/it][A
 15%|█▌        | 209/1350 [04:52<26:14,  1.38s/it][A
 15%|█▌        | 209/1350 [04:52<26:14,  1.38s/it][A
 16%|█▌        | 210/1350 [04:53<26:02,  1.37s/it][A
 16%|█▌        | 210/1350 [04:53<26:04,  1.37s/it][A
 16%|█▌        | 210/1350 [04:53<26:04,  1.37s/it][A
 16%|█▌        | 210/1350 [04:53<26:08,  1.38s/it][A
 16%|█▌        | 210/1350 [04:53<26:09,  1.38s/it][A
 16%|█▌        | 210/1350 [04:53<26:09,  1.38s/it][A
 16%|█▌        | 211/1350 [04:55<25:57,  1.37s/it][A

 16%|█▌        | 211/1350 [04:55<25:58,  1.37s/it]
[A 16%|█▌        | 211/1350 [04:54<26:01,  1.37s/it][A 16%|█▌        | 211/1350 [04:55<26:01,  1.37s/it][A

 16%|█▌        | 211/1350 [04:55<26:00,  1.37s/it][A 16%|█▌        | 211/1350 [04:55<26:01,  1.37s/it][A
 16%|█▌        | 212/1350 [04:56<25:52,  1.36s/it][A
 16%|█▌        | 212/1350 [04:56<25:52,  1.36s/it][A
 16%|█▌        | 212/1350 [04:56<25:57,  1.37s/it][A
 16%|█▌        | 212/1350 [04:56<25:57,  1.37s/it][A

 16%|█▌        | 212/1350 [04:56<25:57,  1.37s/it][A 16%|█▌        | 212/1350 [04:56<25:57,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:53,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:53,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:52,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:53,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:56,  1.37s/it][A
 16%|█▌        | 213/1350 [04:57<25:57,  1.37s/it][A
 16%|█▌        | 214/1350 [04:58<25:52,  1.37s/it][A
 16%|█▌        | 214/1350 [04:59<25:54,  1.37s/it][A
 16%|█▌        | 214/1350 [04:59<25:53,  1.37s/it][A
 16%|█▌        | 214/1350 [04:59<25:53,  1.37s/it][A
 16%|█▌        | 214/1350 [04:59<25:55,  1.37s/it][A
 16%|█▌        | 214/1350 [04:59<25:54,  1.37s/it][A

 16%|█▌        | 215/1350 [05:00<25:46,  1.36s/it][A 16%|█▌        | 215/1350 [05:00<25:47,  1.36s/it][A
 16%|█▌        | 215/1350 [05:00<25:48,  1.36s/it][A
 16%|█▌        | 215/1350 [05:00<25:47,  1.36s/it][A
 16%|█▌        | 215/1350 [05:00<25:48,  1.36s/it][A
 16%|█▌        | 215/1350 [05:00<25:47,  1.36s/it][A

 16%|█▌        | 216/1350 [05:01<25:44,  1.36s/it][A 16%|█▌        | 216/1350 [05:01<25:42,  1.36s/it][A
 16%|█▌        | 216/1350 [05:01<25:46,  1.36s/it][A
 16%|█▌        | 216/1350 [05:01<25:46,  1.36s/it][A
 16%|█▌        | 216/1350 [05:01<25:47,  1.36s/it][A
 16%|█▌        | 216/1350 [05:01<25:48,  1.37s/it][A
 16%|█▌        | 217/1350 [05:03<25:39,  1.36s/it][A
 16%|█▌        | 217/1350 [05:03<25:37,  1.36s/it][A
 16%|█▌        | 217/1350 [05:03<25:45,  1.36s/it][A
 16%|█▌        | 217/1350 [05:03<25:45,  1.36s/it][A
 16%|█▌        | 217/1350 [05:03<25:44,  1.36s/it][A
 16%|█▌        | 217/1350 [05:03<25:45,  1.36s/it][A
 16%|█▌        | 218/1350 [05:04<26:48,  1.42s/it][A
 16%|█▌        | 218/1350 [05:04<26:49,  1.42s/it][A
 16%|█▌        | 218/1350 [05:04<26:52,  1.42s/it][A
 16%|█▌        | 218/1350 [05:04<26:51,  1.42s/it][A
 16%|█▌        | 218/1350 [05:04<26:52,  1.42s/it][A
 16%|█▌        | 218/1350 [05:04<26:55,  1.43s/it][A
 16%|█▌        | 219/1350 [05:06<27:38,  1.47s/it][A
 16%|█▌        | 219/1350 [05:06<27:43,  1.47s/it][A
 16%|█▌        | 219/1350 [05:06<27:42,  1.47s/it][A
 16%|█▌        | 219/1350 [05:06<27:44,  1.47s/it][A

 16%|█▌        | 219/1350 [05:06<27:43,  1.47s/it][A 16%|█▌        | 219/1350 [05:06<27:44,  1.47s/it][A
 16%|█▋        | 220/1350 [05:07<27:04,  1.44s/it][A
 16%|█▋        | 220/1350 [05:07<27:06,  1.44s/it][A
 16%|█▋        | 220/1350 [05:07<27:05,  1.44s/it][A

 16%|█▋        | 220/1350 [05:07<27:06,  1.44s/it][A 16%|█▋        | 220/1350 [05:07<27:09,  1.44s/it][A
 16%|█▋        | 220/1350 [05:07<27:07,  1.44s/it][A

 16%|█▋        | 221/1350 [05:08<26:41,  1.42s/it][A 16%|█▋        | 221/1350 [05:09<26:40,  1.42s/it][A
 16%|█▋        | 221/1350 [05:09<26:39,  1.42s/it][A
 16%|█▋        | 221/1350 [05:09<26:41,  1.42s/it][A
 16%|█▋        | 221/1350 [05:09<26:41,  1.42s/it][A
 16%|█▋        | 221/1350 [05:09<26:42,  1.42s/it][A

 16%|█▋        | 222/1350 [05:10<26:24,  1.40s/it][A 16%|█▋        | 222/1350 [05:10<26:23,  1.40s/it][A
 16%|█▋        | 222/1350 [05:10<26:25,  1.41s/it][A
 16%|█▋        | 222/1350 [05:10<26:25,  1.41s/it][A
 16%|█▋        | 222/1350 [05:10<26:26,  1.41s/it][A
 16%|█▋        | 222/1350 [05:10<26:29,  1.41s/it][A
 17%|█▋        | 223/1350 [05:11<26:11,  1.39s/it][A
 17%|█▋        | 223/1350 [05:11<26:12,  1.39s/it][A

 17%|█▋        | 223/1350 [05:11<26:14,  1.40s/it][A 17%|█▋        | 223/1350 [05:11<26:14,  1.40s/it][A

 17%|█▋        | 223/1350 [05:11<26:16,  1.40s/it][A 17%|█▋        | 223/1350 [05:11<26:15,  1.40s/it][A
 17%|█▋        | 224/1350 [05:13<25:58,  1.38s/it][A
 17%|█▋        | 224/1350 [05:13<25:59,  1.38s/it][A
 17%|█▋        | 224/1350 [05:13<26:00,  1.39s/it][A
 17%|█▋        | 224/1350 [05:13<26:00,  1.39s/it][A
 17%|█▋        | 224/1350 [05:13<26:01,  1.39s/it][A
 17%|█▋        | 224/1350 [05:13<26:02,  1.39s/it][A
 17%|█▋        | 225/1350 [05:14<25:49,  1.38s/it][A
 17%|█▋        | 225/1350 [05:14<25:52,  1.38s/it][A
 17%|█▋        | 225/1350 [05:14<25:52,  1.38s/it][A
 17%|█▋        | 225/1350 [05:14<25:52,  1.38s/it][A

 17%|█▋        | 225/1350 [05:14<25:53,  1.38s/it][A 17%|█▋        | 225/1350 [05:14<25:52,  1.38s/it][A
 17%|█▋        | 226/1350 [05:16<25:57,  1.39s/it][A
 17%|█▋        | 226/1350 [05:16<25:57,  1.39s/it][A
 17%|█▋        | 226/1350 [05:15<25:57,  1.39s/it][A
 17%|█▋        | 226/1350 [05:16<25:58,  1.39s/it][A
 17%|█▋        | 226/1350 [05:16<25:58,  1.39s/it][A
 17%|█▋        | 226/1350 [05:16<25:59,  1.39s/it][A
 17%|█▋        | 227/1350 [05:17<25:45,  1.38s/it][A
 17%|█▋        | 227/1350 [05:17<25:46,  1.38s/it][A
 17%|█▋        | 227/1350 [05:17<25:47,  1.38s/it][A
 17%|█▋        | 227/1350 [05:17<25:50,  1.38s/it][A
 17%|█▋        | 227/1350 [05:17<25:50,  1.38s/it][A
 17%|█▋        | 227/1350 [05:17<25:51,  1.38s/it][A
 17%|█▋        | 228/1350 [05:18<25:39,  1.37s/it][A
 17%|█▋        | 228/1350 [05:18<25:39,  1.37s/it][A
 17%|█▋        | 228/1350 [05:18<25:40,  1.37s/it][A
 17%|█▋        | 228/1350 [05:18<25:42,  1.37s/it][A
 17%|█▋        | 228/1350 [05:18<25:42,  1.37s/it][A
 17%|█▋        | 228/1350 [05:18<25:42,  1.38s/it][A
 17%|█▋        | 229/1350 [05:20<25:29,  1.36s/it][A
 17%|█▋        | 229/1350 [05:19<25:32,  1.37s/it][A
 17%|█▋        | 229/1350 [05:20<25:35,  1.37s/it][A
 17%|█▋        | 229/1350 [05:20<25:37,  1.37s/it][A
 17%|█▋        | 229/1350 [05:20<25:38,  1.37s/it][A
 17%|█▋        | 229/1350 [05:20<25:38,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:35,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:37,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:35,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:37,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:38,  1.37s/it][A
 17%|█▋        | 230/1350 [05:21<25:37,  1.37s/it][A

 17%|█▋        | 231/1350 [05:22<25:32,  1.37s/it][A 17%|█▋        | 231/1350 [05:22<25:31,  1.37s/it][A
 17%|█▋        | 231/1350 [05:22<25:31,  1.37s/it][A
 17%|█▋        | 231/1350 [05:22<25:33,  1.37s/it][A
 17%|█▋        | 231/1350 [05:22<25:32,  1.37s/it][A
 17%|█▋        | 231/1350 [05:22<25:34,  1.37s/it][A

 17%|█▋        | 232/1350 [05:24<25:30,  1.37s/it][A 17%|█▋        | 232/1350 [05:24<25:30,  1.37s/it][A
 17%|█▋        | 232/1350 [05:24<25:31,  1.37s/it][A
 17%|█▋        | 232/1350 [05:24<25:31,  1.37s/it][A
 17%|█▋        | 232/1350 [05:24<25:31,  1.37s/it][A
 17%|█▋        | 232/1350 [05:24<25:33,  1.37s/it][A

 17%|█▋        | 233/1350 [05:25<25:26,  1.37s/it][A 17%|█▋        | 233/1350 [05:25<25:26,  1.37s/it][A
 17%|█▋        | 233/1350 [05:25<25:26,  1.37s/it][A
 17%|█▋        | 233/1350 [05:25<25:28,  1.37s/it][A
 17%|█▋        | 233/1350 [05:25<25:29,  1.37s/it]
[A 17%|█▋        | 233/1350 [05:25<25:30,  1.37s/it][A
 17%|█▋        | 234/1350 [05:27<26:04,  1.40s/it][A
 17%|█▋        | 234/1350 [05:27<26:06,  1.40s/it][A
 17%|█▋        | 234/1350 [05:27<26:06,  1.40s/it][A
 17%|█▋        | 234/1350 [05:27<26:06,  1.40s/it][A
 17%|█▋        | 234/1350 [05:27<26:07,  1.40s/it][A
 17%|█▋        | 234/1350 [05:26<26:11,  1.41s/it][A
 17%|█▋        | 235/1350 [05:28<26:26,  1.42s/it][A
 17%|█▋        | 235/1350 [05:28<26:36,  1.43s/it][A
 17%|█▋        | 235/1350 [05:28<26:37,  1.43s/it][A
 17%|█▋        | 235/1350 [05:28<26:38,  1.43s/it][A

 17%|█▋        | 235/1350 [05:28<26:39,  1.43s/it][A 17%|█▋        | 235/1350 [05:28<26:39,  1.43s/it][A
 17%|█▋        | 236/1350 [05:29<26:10,  1.41s/it][A
 17%|█▋        | 236/1350 [05:29<26:12,  1.41s/it][A
 17%|█▋        | 236/1350 [05:29<26:13,  1.41s/it][A
 17%|█▋        | 236/1350 [05:29<26:15,  1.41s/it][A
 17%|█▋        | 236/1350 [05:29<26:18,  1.42s/it][A
 17%|█▋        | 236/1350 [05:29<26:17,  1.42s/it][A

 18%|█▊        | 237/1350 [05:31<25:55,  1.40s/it][A 18%|█▊        | 237/1350 [05:31<25:57,  1.40s/it][A


 18%|█▊        | 237/1350 [05:31<25:56,  1.40s/it][A 18%|█▊        | 237/1350 [05:31<25:57,  1.40s/it][A 18%|█▊        | 237/1350 [05:31<25:57,  1.40s/it][A
 18%|█▊        | 237/1350 [05:31<25:57,  1.40s/it][A
 18%|█▊        | 238/1350 [05:32<25:44,  1.39s/it][A

 18%|█▊        | 238/1350 [05:32<25:45,  1.39s/it][A 18%|█▊        | 238/1350 [05:32<25:44,  1.39s/it][A
 18%|█▊        | 238/1350 [05:32<25:45,  1.39s/it][A

 18%|█▊        | 238/1350 [05:32<25:45,  1.39s/it][A 18%|█▊        | 238/1350 [05:32<25:46,  1.39s/it][A
 18%|█▊        | 239/1350 [05:34<25:33,  1.38s/it][A
 18%|█▊        | 239/1350 [05:34<25:35,  1.38s/it][A
 18%|█▊        | 239/1350 [05:34<25:35,  1.38s/it][A
 18%|█▊        | 239/1350 [05:33<25:36,  1.38s/it][A

 18%|█▊        | 239/1350 [05:34<25:37,  1.38s/it][A 18%|█▊        | 239/1350 [05:34<25:37,  1.38s/it][A
 18%|█▊        | 240/1350 [05:35<25:24,  1.37s/it][A
 18%|█▊        | 240/1350 [05:35<25:26,  1.38s/it][A
 18%|█▊        | 240/1350 [05:35<25:28,  1.38s/it][A

 18%|█▊        | 240/1350 [05:35<25:29,  1.38s/it][A
 18%|█▊        | 240/1350 [05:35<25:29,  1.38s/it][A 18%|█▊        | 240/1350 [05:35<25:29,  1.38s/it][A

 18%|█▊        | 241/1350 [05:36<25:24,  1.37s/it][A 18%|█▊        | 241/1350 [05:36<25:23,  1.37s/it][A
 18%|█▊        | 241/1350 [05:36<25:24,  1.37s/it][A
 18%|█▊        | 241/1350 [05:36<25:24,  1.37s/it][A

 18%|█▊        | 241/1350 [05:36<25:26,  1.38s/it][A 18%|█▊        | 241/1350 [05:36<25:27,  1.38s/it][A
 18%|█▊        | 242/1350 [05:38<25:18,  1.37s/it][A
 18%|█▊        | 242/1350 [05:38<25:17,  1.37s/it][A
 18%|█▊        | 242/1350 [05:38<25:20,  1.37s/it][A
 18%|█▊        | 242/1350 [05:37<25:20,  1.37s/it][A
 18%|█▊        | 242/1350 [05:38<25:20,  1.37s/it][A
 18%|█▊        | 242/1350 [05:38<25:22,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:14,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:17,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:15,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:16,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:16,  1.37s/it][A
 18%|█▊        | 243/1350 [05:39<25:17,  1.37s/it][A
 18%|█▊        | 244/1350 [05:40<25:09,  1.36s/it][A
 18%|█▊        | 244/1350 [05:40<25:08,  1.36s/it][A
 18%|█▊        | 244/1350 [05:40<25:12,  1.37s/it][A
 18%|█▊        | 244/1350 [05:40<25:13,  1.37s/it][A
 18%|█▊        | 244/1350 [05:40<25:13,  1.37s/it][A
 18%|█▊        | 244/1350 [05:40<25:13,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:09,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:09,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:13,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:12,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:12,  1.37s/it][A
 18%|█▊        | 245/1350 [05:42<25:16,  1.37s/it][A
 18%|█▊        | 246/1350 [05:43<25:02,  1.36s/it][A
 18%|█▊        | 246/1350 [05:43<25:03,  1.36s/it][A
 18%|█▊        | 246/1350 [05:43<25:08,  1.37s/it][A
 18%|█▊        | 246/1350 [05:43<25:10,  1.37s/it][A
 18%|█▊        | 246/1350 [05:43<25:11,  1.37s/it][A
 18%|█▊        | 246/1350 [05:43<25:11,  1.37s/it][A
 18%|█▊        | 247/1350 [05:44<25:03,  1.36s/it][A
 18%|█▊        | 247/1350 [05:44<25:04,  1.36s/it][A
 18%|█▊        | 247/1350 [05:44<25:06,  1.37s/it][A
 18%|█▊        | 247/1350 [05:44<25:09,  1.37s/it][A
 18%|█▊        | 247/1350 [05:44<25:09,  1.37s/it][A
 18%|█▊        | 247/1350 [05:44<25:10,  1.37s/it][A


 18%|█▊        | 248/1350 [05:46<25:05,  1.37s/it][A 18%|█▊        | 248/1350 [05:46<25:05,  1.37s/it][A 18%|█▊        | 248/1350 [05:46<25:05,  1.37s/it][A
 18%|█▊        | 248/1350 [05:46<25:04,  1.37s/it][A

 18%|█▊        | 248/1350 [05:46<25:06,  1.37s/it][A 18%|█▊        | 248/1350 [05:46<25:05,  1.37s/it][A
 18%|█▊        | 249/1350 [05:47<26:15,  1.43s/it][A
 18%|█▊        | 249/1350 [05:47<26:15,  1.43s/it][A
 18%|█▊        | 249/1350 [05:47<26:16,  1.43s/it][A
 18%|█▊        | 249/1350 [05:47<26:18,  1.43s/it][A
 18%|█▊        | 249/1350 [05:47<26:20,  1.44s/it][A
 18%|█▊        | 249/1350 [05:47<26:18,  1.43s/it][A
 19%|█▊        | 250/1350 [05:49<27:11,  1.48s/it][A
 19%|█▊        | 250/1350 [05:49<27:14,  1.49s/it][A
 19%|█▊        | 250/1350 [05:49<27:14,  1.49s/it][A
 19%|█▊        | 250/1350 [05:49<27:16,  1.49s/it][A
 19%|█▊        | 250/1350 [05:49<27:17,  1.49s/it][A
 19%|█▊        | 250/1350 [05:49<27:16,  1.49s/it][A


 19%|█▊        | 251/1350 [05:50<26:32,  1.45s/it][A 19%|█▊        | 251/1350 [05:50<26:32,  1.45s/it][A 19%|█▊        | 251/1350 [05:50<26:31,  1.45s/it][A
 19%|█▊        | 251/1350 [05:50<26:33,  1.45s/it][A

 19%|█▊        | 251/1350 [05:50<26:35,  1.45s/it][A 19%|█▊        | 251/1350 [05:50<26:34,  1.45s/it][A
 19%|█▊        | 252/1350 [05:52<25:58,  1.42s/it][A
 19%|█▊        | 252/1350 [05:52<26:01,  1.42s/it][A
 19%|█▊        | 252/1350 [05:52<26:04,  1.43s/it][A
 19%|█▊        | 252/1350 [05:52<26:06,  1.43s/it][A
 19%|█▊        | 252/1350 [05:52<26:06,  1.43s/it][A
 19%|█▊        | 252/1350 [05:52<26:08,  1.43s/it][A
 19%|█▊        | 253/1350 [05:53<25:45,  1.41s/it][A
 19%|█▊        | 253/1350 [05:53<25:45,  1.41s/it][A
 19%|█▊        | 253/1350 [05:53<25:48,  1.41s/it][A
 19%|█▊        | 253/1350 [05:53<25:48,  1.41s/it][A
 19%|█▊        | 253/1350 [05:53<25:47,  1.41s/it][A
 19%|█▊        | 253/1350 [05:53<25:48,  1.41s/it][A
 19%|█▉        | 254/1350 [05:54<25:28,  1.39s/it][A
 19%|█▉        | 254/1350 [05:54<25:31,  1.40s/it][A
 19%|█▉        | 254/1350 [05:54<25:30,  1.40s/it][A


 19%|█▉        | 254/1350 [05:54<25:31,  1.40s/it][A 19%|█▉        | 254/1350 [05:54<25:30,  1.40s/it][A 19%|█▉        | 254/1350 [05:54<25:31,  1.40s/it][A
 19%|█▉        | 255/1350 [05:56<25:14,  1.38s/it][A
 19%|█▉        | 255/1350 [05:56<25:16,  1.39s/it][A
 19%|█▉        | 255/1350 [05:56<25:20,  1.39s/it][A
 19%|█▉        | 255/1350 [05:56<25:21,  1.39s/it][A

 19%|█▉        | 255/1350 [05:56<25:21,  1.39s/it][A 19%|█▉        | 255/1350 [05:56<25:20,  1.39s/it][A
 19%|█▉        | 256/1350 [05:57<25:11,  1.38s/it][A
 19%|█▉        | 256/1350 [05:57<25:10,  1.38s/it][A
 19%|█▉        | 256/1350 [05:57<25:10,  1.38s/it][A
 19%|█▉        | 256/1350 [05:57<25:10,  1.38s/it][A
 19%|█▉        | 256/1350 [05:57<25:12,  1.38s/it][A
 19%|█▉        | 256/1350 [05:57<25:12,  1.38s/it][A
 19%|█▉        | 257/1350 [05:58<25:04,  1.38s/it][A
 19%|█▉        | 257/1350 [05:59<25:05,  1.38s/it][A
 19%|█▉        | 257/1350 [05:59<25:06,  1.38s/it][A
 19%|█▉        | 257/1350 [05:59<25:07,  1.38s/it][A

 19%|█▉        | 257/1350 [05:59<25:06,  1.38s/it][A 19%|█▉        | 257/1350 [05:59<25:06,  1.38s/it][A
 19%|█▉        | 258/1350 [06:00<25:01,  1.37s/it][A

 19%|█▉        | 258/1350 [06:00<25:01,  1.37s/it][A 19%|█▉        | 258/1350 [06:00<25:01,  1.37s/it][A
 19%|█▉        | 258/1350 [06:00<25:01,  1.38s/it][A
 19%|█▉        | 258/1350 [06:00<25:02,  1.38s/it][A
 19%|█▉        | 258/1350 [06:00<25:03,  1.38s/it][A
 19%|█▉        | 259/1350 [06:01<24:58,  1.37s/it][A
 19%|█▉        | 259/1350 [06:01<24:58,  1.37s/it][A
 19%|█▉        | 259/1350 [06:01<24:59,  1.37s/it][A
 19%|█▉        | 259/1350 [06:01<25:00,  1.38s/it][A
 19%|█▉        | 259/1350 [06:01<25:01,  1.38s/it][A
 19%|█▉        | 259/1350 [06:01<25:01,  1.38s/it][A
 19%|█▉        | 260/1350 [06:03<24:57,  1.37s/it][A
 19%|█▉        | 260/1350 [06:03<24:57,  1.37s/it][A
 19%|█▉        | 260/1350 [06:03<24:57,  1.37s/it][A

 19%|█▉        | 260/1350 [06:03<24:58,  1.37s/it][A 19%|█▉        | 260/1350 [06:03<24:58,  1.37s/it][A
 19%|█▉        | 260/1350 [06:03<25:00,  1.38s/it][A
 19%|█▉        | 261/1350 [06:04<24:55,  1.37s/it][A
 19%|█▉        | 261/1350 [06:04<24:56,  1.37s/it][A
 19%|█▉        | 261/1350 [06:04<24:57,  1.38s/it][A
 19%|█▉        | 261/1350 [06:04<24:56,  1.37s/it]
[A 19%|█▉        | 261/1350 [06:04<24:57,  1.37s/it][A
 19%|█▉        | 261/1350 [06:04<24:57,  1.37s/it][A
 19%|█▉        | 262/1350 [06:05<24:49,  1.37s/it][A
 19%|█▉        | 262/1350 [06:05<24:50,  1.37s/it][A
 19%|█▉        | 262/1350 [06:05<24:51,  1.37s/it][A


 19%|█▉        | 262/1350 [06:05<24:52,  1.37s/it][A 19%|█▉        | 262/1350 [06:05<24:53,  1.37s/it][A 19%|█▉        | 262/1350 [06:05<24:52,  1.37s/it][A
 19%|█▉        | 263/1350 [06:07<24:51,  1.37s/it][A
 19%|█▉        | 263/1350 [06:07<24:52,  1.37s/it][A

 19%|█▉        | 263/1350 [06:07<24:52,  1.37s/it][A 19%|█▉        | 263/1350 [06:07<24:52,  1.37s/it][A
 19%|█▉        | 263/1350 [06:07<24:53,  1.37s/it][A
 19%|█▉        | 263/1350 [06:07<24:54,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:50,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:51,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:50,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:50,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:50,  1.37s/it][A
 20%|█▉        | 264/1350 [06:08<24:52,  1.37s/it][A
 20%|█▉        | 265/1350 [06:10<25:56,  1.43s/it][A

 20%|█▉        | 265/1350 [06:10<25:56,  1.43s/it][A 20%|█▉        | 265/1350 [06:10<25:57,  1.44s/it][A
 20%|█▉        | 265/1350 [06:10<25:57,  1.44s/it][A

 20%|█▉        | 265/1350 [06:10<25:57,  1.44s/it][A 20%|█▉        | 265/1350 [06:10<25:57,  1.44s/it][A
 20%|█▉        | 266/1350 [06:11<26:47,  1.48s/it][A

 20%|█▉        | 266/1350 [06:11<26:47,  1.48s/it]
[A
 20%|█▉        | 266/1350 [06:11<26:48,  1.48s/it][A
 20%|█▉        | 266/1350 [06:11<26:48,  1.48s/it][A 20%|█▉        | 266/1350 [06:11<26:47,  1.48s/it][A 20%|█▉        | 266/1350 [06:11<26:48,  1.48s/it][A
 20%|█▉        | 267/1350 [06:13<26:07,  1.45s/it][A

 20%|█▉        | 267/1350 [06:13<26:08,  1.45s/it][A 20%|█▉        | 267/1350 [06:13<26:09,  1.45s/it][A

 20%|█▉        | 267/1350 [06:13<26:09,  1.45s/it][A 20%|█▉        | 267/1350 [06:13<26:08,  1.45s/it][A
 20%|█▉        | 267/1350 [06:13<26:09,  1.45s/it][A
 20%|█▉        | 268/1350 [06:14<25:39,  1.42s/it][A
 20%|█▉        | 268/1350 [06:14<25:40,  1.42s/it][A
 20%|█▉        | 268/1350 [06:14<25:40,  1.42s/it][A
 20%|█▉        | 268/1350 [06:14<25:41,  1.42s/it][A

 20%|█▉        | 268/1350 [06:14<25:41,  1.43s/it][A 20%|█▉        | 268/1350 [06:14<25:41,  1.42s/it][A
 20%|█▉        | 269/1350 [06:15<25:24,  1.41s/it][A
 20%|█▉        | 269/1350 [06:15<25:24,  1.41s/it][A


 20%|█▉        | 269/1350 [06:15<25:24,  1.41s/it][A 20%|█▉        | 269/1350 [06:15<25:24,  1.41s/it][A 20%|█▉        | 269/1350 [06:15<25:24,  1.41s/it][A
 20%|█▉        | 269/1350 [06:15<25:25,  1.41s/it][A
 20%|██        | 270/1350 [06:17<25:10,  1.40s/it][A


 20%|██        | 270/1350 [06:17<25:12,  1.40s/it][A 20%|██        | 270/1350 [06:17<25:12,  1.40s/it]
[A
 20%|██        | 270/1350 [06:17<25:12,  1.40s/it][A 20%|██        | 270/1350 [06:17<25:12,  1.40s/it][A 20%|██        | 270/1350 [06:17<25:12,  1.40s/it][A
 20%|██        | 271/1350 [06:18<25:01,  1.39s/it][A
 20%|██        | 271/1350 [06:18<25:01,  1.39s/it][A
 20%|██        | 271/1350 [06:18<25:02,  1.39s/it][A
 20%|██        | 271/1350 [06:18<25:02,  1.39s/it][A

 20%|██        | 271/1350 [06:18<25:02,  1.39s/it][A 20%|██        | 271/1350 [06:18<25:02,  1.39s/it][A
 20%|██        | 272/1350 [06:19<24:52,  1.38s/it][A
 20%|██        | 272/1350 [06:20<24:52,  1.38s/it][A
 20%|██        | 272/1350 [06:20<24:53,  1.39s/it][A
 20%|██        | 272/1350 [06:20<24:55,  1.39s/it][A

 20%|██        | 272/1350 [06:20<24:55,  1.39s/it] 20%|██        | 272/1350 [06:20<24:55,  1.39s/it][A[A
 20%|██        | 273/1350 [06:21<24:45,  1.38s/it][A
 20%|██        | 273/1350 [06:21<24:47,  1.38s/it][A

 20%|██        | 273/1350 [06:21<24:47,  1.38s/it][A 20%|██        | 273/1350 [06:21<24:48,  1.38s/it][A

 20%|██        | 273/1350 [06:21<24:49,  1.38s/it][A 20%|██        | 273/1350 [06:21<24:50,  1.38s/it][A
 20%|██        | 274/1350 [06:22<24:39,  1.38s/it][A

 20%|██        | 274/1350 [06:22<24:41,  1.38s/it][A 20%|██        | 274/1350 [06:22<24:41,  1.38s/it][A
 20%|██        | 274/1350 [06:22<24:43,  1.38s/it][A
 20%|██        | 274/1350 [06:22<24:43,  1.38s/it][A
 20%|██        | 274/1350 [06:22<24:44,  1.38s/it][A
 20%|██        | 275/1350 [06:24<24:32,  1.37s/it][A
 20%|██        | 275/1350 [06:24<24:34,  1.37s/it][A
 20%|██        | 275/1350 [06:24<24:37,  1.37s/it][A
 20%|██        | 275/1350 [06:24<24:38,  1.37s/it][A
 20%|██        | 275/1350 [06:24<24:40,  1.38s/it][A
 20%|██        | 275/1350 [06:24<24:40,  1.38s/it][A
 20%|██        | 276/1350 [06:25<24:32,  1.37s/it][A
 20%|██        | 276/1350 [06:25<24:34,  1.37s/it][A
 20%|██        | 276/1350 [06:25<24:37,  1.38s/it][A
 20%|██        | 276/1350 [06:25<24:35,  1.37s/it][A
 20%|██        | 276/1350 [06:25<24:36,  1.37s/it][A
 20%|██        | 276/1350 [06:25<24:37,  1.38s/it][A
 21%|██        | 277/1350 [06:26<24:30,  1.37s/it][A
 21%|██        | 277/1350 [06:26<24:32,  1.37s/it][A
 21%|██        | 277/1350 [06:26<24:33,  1.37s/it][A
 21%|██        | 277/1350 [06:26<24:33,  1.37s/it][A
 21%|██        | 277/1350 [06:26<24:34,  1.37s/it][A
 21%|██        | 277/1350 [06:26<24:37,  1.38s/it][A
 21%|██        | 278/1350 [06:28<24:27,  1.37s/it][A
 21%|██        | 278/1350 [06:28<24:29,  1.37s/it][A
 21%|██        | 278/1350 [06:28<24:30,  1.37s/it][A
 21%|██        | 278/1350 [06:28<24:31,  1.37s/it][A
 21%|██        | 278/1350 [06:28<24:32,  1.37s/it][A
 21%|██        | 278/1350 [06:28<24:32,  1.37s/it][A

 21%|██        | 279/1350 [06:29<24:28,  1.37s/it][A 21%|██        | 279/1350 [06:29<24:29,  1.37s/it][A
 21%|██        | 279/1350 [06:29<24:29,  1.37s/it][A
 21%|██        | 279/1350 [06:29<24:31,  1.37s/it][A
 21%|██        | 279/1350 [06:29<24:31,  1.37s/it][A
 21%|██        | 279/1350 [06:29<24:33,  1.38s/it][A
 21%|██        | 280/1350 [06:31<24:24,  1.37s/it][A
 21%|██        | 280/1350 [06:31<24:25,  1.37s/it][A
 21%|██        | 280/1350 [06:31<24:29,  1.37s/it][A
 21%|██        | 280/1350 [06:31<24:30,  1.37s/it][A
 21%|██        | 280/1350 [06:30<24:30,  1.37s/it][A
 21%|██        | 280/1350 [06:31<24:33,  1.38s/it][A
 21%|██        | 281/1350 [06:32<25:03,  1.41s/it][A
 21%|██        | 281/1350 [06:32<25:07,  1.41s/it][A
 21%|██        | 281/1350 [06:32<25:10,  1.41s/it][A
 21%|██        | 281/1350 [06:32<25:07,  1.41s/it][A
 21%|██        | 281/1350 [06:32<25:09,  1.41s/it][A
 21%|██        | 281/1350 [06:32<25:12,  1.42s/it][A
 21%|██        | 282/1350 [06:33<25:22,  1.43s/it][A
 21%|██        | 282/1350 [06:34<25:35,  1.44s/it][A

 21%|██        | 282/1350 [06:34<25:37,  1.44s/it][A 21%|██        | 282/1350 [06:34<25:38,  1.44s/it][A
 21%|██        | 282/1350 [06:34<25:37,  1.44s/it][A
 21%|██        | 282/1350 [06:34<25:36,  1.44s/it][A
 21%|██        | 283/1350 [06:35<25:11,  1.42s/it][A
 21%|██        | 283/1350 [06:35<25:11,  1.42s/it][A

 21%|██        | 283/1350 [06:35<25:10,  1.42s/it][A
 21%|██        | 283/1350 [06:35<25:11,  1.42s/it][A 21%|██        | 283/1350 [06:35<25:09,  1.42s/it][A
 21%|██        | 283/1350 [06:35<25:13,  1.42s/it][A
 21%|██        | 284/1350 [06:36<24:54,  1.40s/it][A
 21%|██        | 284/1350 [06:36<24:55,  1.40s/it][A
 21%|██        | 284/1350 [06:36<24:55,  1.40s/it][A
 21%|██        | 284/1350 [06:36<24:57,  1.40s/it][A
 21%|██        | 284/1350 [06:36<24:57,  1.40s/it][A
 21%|██        | 284/1350 [06:36<24:56,  1.40s/it][A
 21%|██        | 285/1350 [06:38<24:42,  1.39s/it][A
 21%|██        | 285/1350 [06:38<24:42,  1.39s/it][A
 21%|██        | 285/1350 [06:38<24:44,  1.39s/it][A

 21%|██        | 285/1350 [06:38<24:44,  1.39s/it][A 21%|██        | 285/1350 [06:38<24:44,  1.39s/it]
[A 21%|██        | 285/1350 [06:37<24:44,  1.39s/it][A
 21%|██        | 286/1350 [06:39<24:33,  1.39s/it][A
 21%|██        | 286/1350 [06:39<24:33,  1.39s/it][A
 21%|██        | 286/1350 [06:39<24:34,  1.39s/it][A

 21%|██        | 286/1350 [06:39<24:34,  1.39s/it][A 21%|██        | 286/1350 [06:39<24:34,  1.39s/it][A
 21%|██        | 286/1350 [06:39<24:35,  1.39s/it][A
 21%|██▏       | 287/1350 [06:40<24:24,  1.38s/it][A
 21%|██▏       | 287/1350 [06:40<24:25,  1.38s/it][A
 21%|██▏       | 287/1350 [06:40<24:26,  1.38s/it][A
 21%|██▏       | 287/1350 [06:40<24:28,  1.38s/it][A
 21%|██▏       | 287/1350 [06:40<24:28,  1.38s/it][A
 21%|██▏       | 287/1350 [06:40<24:28,  1.38s/it][A
 21%|██▏       | 288/1350 [06:42<24:21,  1.38s/it][A
 21%|██▏       | 288/1350 [06:42<24:21,  1.38s/it][A
 21%|██▏       | 288/1350 [06:42<24:22,  1.38s/it][A


 21%|██▏       | 288/1350 [06:42<24:24,  1.38s/it][A 21%|██▏       | 288/1350 [06:42<24:23,  1.38s/it][A 21%|██▏       | 288/1350 [06:42<24:24,  1.38s/it][A
 21%|██▏       | 289/1350 [06:43<24:17,  1.37s/it][A
 21%|██▏       | 289/1350 [06:43<24:18,  1.37s/it][A
 21%|██▏       | 289/1350 [06:43<24:18,  1.37s/it][A
 21%|██▏       | 289/1350 [06:43<24:19,  1.38s/it][A
 21%|██▏       | 289/1350 [06:43<24:19,  1.38s/it][A
 21%|██▏       | 289/1350 [06:43<24:19,  1.38s/it][A
 21%|██▏       | 290/1350 [06:45<24:13,  1.37s/it][A

 21%|██▏       | 290/1350 [06:45<24:14,  1.37s/it][A 21%|██▏       | 290/1350 [06:44<24:14,  1.37s/it][A
 21%|██▏       | 290/1350 [06:45<24:14,  1.37s/it][A
 21%|██▏       | 290/1350 [06:45<24:15,  1.37s/it][A
 21%|██▏       | 290/1350 [06:45<24:16,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:10,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:11,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:12,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:13,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:13,  1.37s/it][A
 22%|██▏       | 291/1350 [06:46<24:14,  1.37s/it][A
 22%|██▏       | 292/1350 [06:47<24:07,  1.37s/it][A
 22%|██▏       | 292/1350 [06:47<24:09,  1.37s/it][A
 22%|██▏       | 292/1350 [06:47<24:10,  1.37s/it][A

 22%|██▏       | 292/1350 [06:47<24:10,  1.37s/it][A 22%|██▏       | 292/1350 [06:47<24:11,  1.37s/it][A
 22%|██▏       | 292/1350 [06:47<24:11,  1.37s/it][A

 22%|██▏       | 293/1350 [06:48<24:06,  1.37s/it][A 22%|██▏       | 293/1350 [06:49<24:07,  1.37s/it][A
 22%|██▏       | 293/1350 [06:49<24:07,  1.37s/it][A
 22%|██▏       | 293/1350 [06:49<24:07,  1.37s/it][A
 22%|██▏       | 293/1350 [06:49<24:09,  1.37s/it][A
 22%|██▏       | 293/1350 [06:49<24:09,  1.37s/it][A
 22%|██▏       | 294/1350 [06:50<24:03,  1.37s/it][A
 22%|██▏       | 294/1350 [06:50<24:06,  1.37s/it][A
 22%|██▏       | 294/1350 [06:50<24:08,  1.37s/it][A
 22%|██▏       | 294/1350 [06:50<24:08,  1.37s/it][A

 22%|██▏       | 294/1350 [06:50<24:10,  1.37s/it][A 22%|██▏       | 294/1350 [06:50<24:10,  1.37s/it][A
 22%|██▏       | 295/1350 [06:51<24:03,  1.37s/it][A
 22%|██▏       | 295/1350 [06:51<24:03,  1.37s/it][A
 22%|██▏       | 295/1350 [06:51<24:07,  1.37s/it][A
 22%|██▏       | 295/1350 [06:51<24:06,  1.37s/it][A

 22%|██▏       | 295/1350 [06:51<24:05,  1.37s/it][A 22%|██▏       | 295/1350 [06:51<24:06,  1.37s/it][A
 22%|██▏       | 296/1350 [06:53<25:12,  1.44s/it][A
 22%|██▏       | 296/1350 [06:53<25:13,  1.44s/it][A
 22%|██▏       | 296/1350 [06:53<25:15,  1.44s/it][A
 22%|██▏       | 296/1350 [06:53<25:15,  1.44s/it][A
 22%|██▏       | 296/1350 [06:53<25:16,  1.44s/it][A
 22%|██▏       | 296/1350 [06:53<25:16,  1.44s/it][A
 22%|██▏       | 297/1350 [06:55<26:00,  1.48s/it][A
 22%|██▏       | 297/1350 [06:54<26:00,  1.48s/it][A
 22%|██▏       | 297/1350 [06:55<26:02,  1.48s/it][A
 22%|██▏       | 297/1350 [06:55<26:04,  1.49s/it][A
 22%|██▏       | 297/1350 [06:55<26:05,  1.49s/it][A
 22%|██▏       | 297/1350 [06:55<26:06,  1.49s/it][A
 22%|██▏       | 298/1350 [06:56<25:28,  1.45s/it][A
 22%|██▏       | 298/1350 [06:56<25:29,  1.45s/it][A
 22%|██▏       | 298/1350 [06:56<25:28,  1.45s/it][A
 22%|██▏       | 298/1350 [06:56<25:29,  1.45s/it][A
 22%|██▏       | 298/1350 [06:56<25:30,  1.46s/it][A
 22%|██▏       | 298/1350 [06:56<25:29,  1.45s/it][A
 22%|██▏       | 299/1350 [06:57<24:57,  1.42s/it][A
 22%|██▏       | 299/1350 [06:57<25:00,  1.43s/it][A
 22%|██▏       | 299/1350 [06:57<24:59,  1.43s/it][A
 22%|██▏       | 299/1350 [06:57<25:01,  1.43s/it][A
 22%|██▏       | 299/1350 [06:57<25:01,  1.43s/it][A
 22%|██▏       | 299/1350 [06:57<25:02,  1.43s/it][A
 22%|██▏       | 300/1350 [06:59<24:39,  1.41s/it][A
 22%|██▏       | 300/1350 [06:59<24:38,  1.41s/it][A
 22%|██▏       | 300/1350 [06:58<24:42,  1.41s/it]
[A
 22%|██▏       | 300/1350 [06:59<24:43,  1.41s/it][A 22%|██▏       | 300/1350 [06:59<24:43,  1.41s/it]
[A 22%|██▏       | 300/1350 [06:59<24:44,  1.41s/it][A
 22%|██▏       | 301/1350 [07:00<24:27,  1.40s/it][A
 22%|██▏       | 301/1350 [07:00<24:26,  1.40s/it][A
 22%|██▏       | 301/1350 [07:00<24:29,  1.40s/it][A


 22%|██▏       | 301/1350 [07:00<24:27,  1.40s/it][A 22%|██▏       | 301/1350 [07:00<24:29,  1.40s/it][A 22%|██▏       | 301/1350 [07:00<24:28,  1.40s/it][A
 22%|██▏       | 302/1350 [07:01<24:09,  1.38s/it][A
 22%|██▏       | 302/1350 [07:01<24:12,  1.39s/it][A
 22%|██▏       | 302/1350 [07:01<24:18,  1.39s/it][A
 22%|██▏       | 302/1350 [07:01<24:17,  1.39s/it][A

 22%|██▏       | 302/1350 [07:01<24:17,  1.39s/it][A 22%|██▏       | 302/1350 [07:01<24:17,  1.39s/it][A
 22%|██▏       | 303/1350 [07:03<24:07,  1.38s/it][A
 22%|██▏       | 303/1350 [07:03<24:07,  1.38s/it][A
 22%|██▏       | 303/1350 [07:03<24:09,  1.38s/it][A
 22%|██▏       | 303/1350 [07:03<24:09,  1.38s/it][A
 22%|██▏       | 303/1350 [07:03<24:09,  1.38s/it][A
 22%|██▏       | 303/1350 [07:03<24:12,  1.39s/it][A
 23%|██▎       | 304/1350 [07:04<23:59,  1.38s/it][A
 23%|██▎       | 304/1350 [07:04<23:59,  1.38s/it][A
 23%|██▎       | 304/1350 [07:04<23:59,  1.38s/it][A
 23%|██▎       | 304/1350 [07:04<24:02,  1.38s/it][A
 23%|██▎       | 304/1350 [07:04<24:03,  1.38s/it][A
 23%|██▎       | 304/1350 [07:04<24:04,  1.38s/it][A
 23%|██▎       | 305/1350 [07:06<23:57,  1.38s/it][A
 23%|██▎       | 305/1350 [07:06<23:59,  1.38s/it][A
 23%|██▎       | 305/1350 [07:05<23:58,  1.38s/it][A
 23%|██▎       | 305/1350 [07:06<23:59,  1.38s/it][A
 23%|██▎       | 305/1350 [07:06<24:00,  1.38s/it][A
 23%|██▎       | 305/1350 [07:06<24:00,  1.38s/it][A

 23%|██▎       | 306/1350 [07:07<23:51,  1.37s/it][A 23%|██▎       | 306/1350 [07:07<23:51,  1.37s/it][A
 23%|██▎       | 306/1350 [07:07<23:51,  1.37s/it][A
 23%|██▎       | 306/1350 [07:07<23:52,  1.37s/it][A
 23%|██▎       | 306/1350 [07:07<23:53,  1.37s/it][A
 23%|██▎       | 306/1350 [07:07<23:54,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:46,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:48,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:49,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:49,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:51,  1.37s/it][A
 23%|██▎       | 307/1350 [07:08<23:51,  1.37s/it][A
 23%|██▎       | 308/1350 [07:10<23:47,  1.37s/it][A
 23%|██▎       | 308/1350 [07:10<23:48,  1.37s/it][A
 23%|██▎       | 308/1350 [07:10<23:49,  1.37s/it][A
 23%|██▎       | 308/1350 [07:10<23:50,  1.37s/it][A

 23%|██▎       | 308/1350 [07:10<23:50,  1.37s/it] 23%|██▎       | 308/1350 [07:09<23:50,  1.37s/it][A[A
 23%|██▎       | 309/1350 [07:11<23:45,  1.37s/it][A
 23%|██▎       | 309/1350 [07:11<23:45,  1.37s/it][A
 23%|██▎       | 309/1350 [07:11<23:45,  1.37s/it][A
 23%|██▎       | 309/1350 [07:11<23:45,  1.37s/it][A
 23%|██▎       | 309/1350 [07:11<23:46,  1.37s/it][A
 23%|██▎       | 309/1350 [07:11<23:46,  1.37s/it][A
 23%|██▎       | 310/1350 [07:12<23:41,  1.37s/it][A
 23%|██▎       | 310/1350 [07:12<23:41,  1.37s/it][A


 23%|██▎       | 310/1350 [07:12<23:43,  1.37s/it][A 23%|██▎       | 310/1350 [07:12<23:42,  1.37s/it][A 23%|██▎       | 310/1350 [07:12<23:42,  1.37s/it][A
 23%|██▎       | 310/1350 [07:12<23:43,  1.37s/it][A
 23%|██▎       | 311/1350 [07:14<23:36,  1.36s/it][A
 23%|██▎       | 311/1350 [07:14<23:38,  1.37s/it][A
 23%|██▎       | 311/1350 [07:14<23:40,  1.37s/it][A
 23%|██▎       | 311/1350 [07:14<23:40,  1.37s/it][A
 23%|██▎       | 311/1350 [07:14<23:42,  1.37s/it][A
 23%|██▎       | 311/1350 [07:14<23:42,  1.37s/it][A
 23%|██▎       | 312/1350 [07:15<24:48,  1.43s/it][A

 23%|██▎       | 312/1350 [07:15<24:50,  1.44s/it][A
 23%|██▎       | 312/1350 [07:15<24:50,  1.44s/it][A 23%|██▎       | 312/1350 [07:15<24:50,  1.44s/it][A
 23%|██▎       | 312/1350 [07:15<24:50,  1.44s/it][A
 23%|██▎       | 312/1350 [07:15<24:52,  1.44s/it][A
 23%|██▎       | 313/1350 [07:17<25:28,  1.47s/it][A
 23%|██▎       | 313/1350 [07:17<25:28,  1.47s/it][A
 23%|██▎       | 313/1350 [07:17<25:33,  1.48s/it][A
 23%|██▎       | 313/1350 [07:17<25:32,  1.48s/it][A
 23%|██▎       | 313/1350 [07:17<25:35,  1.48s/it][A
 23%|██▎       | 313/1350 [07:17<25:34,  1.48s/it][A
 23%|██▎       | 314/1350 [07:18<24:57,  1.45s/it][A
 23%|██▎       | 314/1350 [07:18<24:55,  1.44s/it][A

 23%|██▎       | 314/1350 [07:18<24:57,  1.45s/it][A
 23%|██▎       | 314/1350 [07:18<24:58,  1.45s/it][A 23%|██▎       | 314/1350 [07:18<24:57,  1.45s/it][A
 23%|██▎       | 314/1350 [07:18<24:57,  1.44s/it][A
 23%|██▎       | 315/1350 [07:20<24:32,  1.42s/it][A
 23%|██▎       | 315/1350 [07:20<24:32,  1.42s/it][A
 23%|██▎       | 315/1350 [07:20<24:36,  1.43s/it][A
 23%|██▎       | 315/1350 [07:20<24:35,  1.43s/it][A

 23%|██▎       | 315/1350 [07:20<24:36,  1.43s/it][A 23%|██▎       | 315/1350 [07:19<24:37,  1.43s/it][A
 23%|██▎       | 316/1350 [07:21<24:13,  1.41s/it][A
 23%|██▎       | 316/1350 [07:21<24:14,  1.41s/it][A

 23%|██▎       | 316/1350 [07:21<24:14,  1.41s/it][A 23%|██▎       | 316/1350 [07:21<24:15,  1.41s/it][A
 23%|██▎       | 316/1350 [07:21<24:15,  1.41s/it][A
 23%|██▎       | 316/1350 [07:21<24:15,  1.41s/it][A
 23%|██▎       | 317/1350 [07:22<23:56,  1.39s/it][A
 23%|██▎       | 317/1350 [07:22<23:56,  1.39s/it][A
 23%|██▎       | 317/1350 [07:22<24:01,  1.40s/it][A
 23%|██▎       | 317/1350 [07:22<24:02,  1.40s/it][A
 23%|██▎       | 317/1350 [07:22<24:02,  1.40s/it][A
 23%|██▎       | 317/1350 [07:22<24:02,  1.40s/it][A
 24%|██▎       | 318/1350 [07:24<23:47,  1.38s/it][A
 24%|██▎       | 318/1350 [07:24<23:46,  1.38s/it][A
 24%|██▎       | 318/1350 [07:24<23:46,  1.38s/it][A
 24%|██▎       | 318/1350 [07:24<23:48,  1.38s/it][A
 24%|██▎       | 318/1350 [07:24<23:49,  1.39s/it][A
 24%|██▎       | 318/1350 [07:24<23:50,  1.39s/it][A
 24%|██▎       | 319/1350 [07:25<23:46,  1.38s/it][A
 24%|██▎       | 319/1350 [07:25<23:47,  1.38s/it][A
 24%|██▎       | 319/1350 [07:25<23:47,  1.39s/it][A
 24%|██▎       | 319/1350 [07:25<23:48,  1.39s/it][A
 24%|██▎       | 319/1350 [07:25<23:48,  1.39s/it][A
 24%|██▎       | 319/1350 [07:25<23:50,  1.39s/it][A
 24%|██▎       | 320/1350 [07:26<23:37,  1.38s/it][A
 24%|██▎       | 320/1350 [07:26<23:40,  1.38s/it][A
 24%|██▎       | 320/1350 [07:26<23:40,  1.38s/it][A
 24%|██▎       | 320/1350 [07:26<23:41,  1.38s/it][A
 24%|██▎       | 320/1350 [07:26<23:40,  1.38s/it][A
 24%|██▎       | 320/1350 [07:26<23:41,  1.38s/it][A
 24%|██▍       | 321/1350 [07:28<23:33,  1.37s/it][A
 24%|██▍       | 321/1350 [07:28<23:34,  1.37s/it][A

 24%|██▍       | 321/1350 [07:28<23:34,  1.37s/it][A 24%|██▍       | 321/1350 [07:28<23:34,  1.37s/it][A
 24%|██▍       | 321/1350 [07:28<23:34,  1.37s/it][A
 24%|██▍       | 321/1350 [07:28<23:34,  1.38s/it][A
 24%|██▍       | 322/1350 [07:29<23:26,  1.37s/it][A

 24%|██▍       | 322/1350 [07:29<23:28,  1.37s/it][A 24%|██▍       | 322/1350 [07:29<23:28,  1.37s/it][A
 24%|██▍       | 322/1350 [07:29<23:29,  1.37s/it][A

 24%|██▍       | 322/1350 [07:29<23:29,  1.37s/it][A 24%|██▍       | 322/1350 [07:29<23:29,  1.37s/it][A
 24%|██▍       | 323/1350 [07:30<23:26,  1.37s/it][A
 24%|██▍       | 323/1350 [07:31<23:25,  1.37s/it][A
 24%|██▍       | 323/1350 [07:31<23:27,  1.37s/it][A
 24%|██▍       | 323/1350 [07:31<23:27,  1.37s/it][A
 24%|██▍       | 323/1350 [07:31<23:28,  1.37s/it][A
 24%|██▍       | 323/1350 [07:31<23:29,  1.37s/it][A
 24%|██▍       | 324/1350 [07:32<23:21,  1.37s/it][A
 24%|██▍       | 324/1350 [07:32<23:22,  1.37s/it][A

 24%|██▍       | 324/1350 [07:32<23:26,  1.37s/it][A 24%|██▍       | 324/1350 [07:32<23:27,  1.37s/it][A

 24%|██▍       | 324/1350 [07:32<23:26,  1.37s/it] 24%|██▍       | 324/1350 [07:32<23:26,  1.37s/it][A[A
 24%|██▍       | 325/1350 [07:33<23:21,  1.37s/it][A
 24%|██▍       | 325/1350 [07:33<23:23,  1.37s/it][A

 24%|██▍       | 325/1350 [07:33<23:24,  1.37s/it][A 24%|██▍       | 325/1350 [07:33<23:24,  1.37s/it][A

 24%|██▍       | 325/1350 [07:33<23:26,  1.37s/it][A 24%|██▍       | 325/1350 [07:33<23:26,  1.37s/it][A
 24%|██▍       | 326/1350 [07:35<23:21,  1.37s/it][A
 24%|██▍       | 326/1350 [07:35<23:21,  1.37s/it][A

 24%|██▍       | 326/1350 [07:34<23:23,  1.37s/it][A 24%|██▍       | 326/1350 [07:35<23:23,  1.37s/it][A
 24%|██▍       | 326/1350 [07:35<23:22,  1.37s/it][A
 24%|██▍       | 326/1350 [07:35<23:22,  1.37s/it][A
 24%|██▍       | 327/1350 [07:36<23:19,  1.37s/it][A
 24%|██▍       | 327/1350 [07:36<23:19,  1.37s/it][A

 24%|██▍       | 327/1350 [07:36<23:21,  1.37s/it][A 24%|██▍       | 327/1350 [07:36<23:21,  1.37s/it][A
 24%|██▍       | 327/1350 [07:36<23:22,  1.37s/it][A
 24%|██▍       | 327/1350 [07:36<23:21,  1.37s/it][A
 24%|██▍       | 328/1350 [07:38<23:55,  1.40s/it]
[A 24%|██▍       | 328/1350 [07:38<23:55,  1.40s/it][A
 24%|██▍       | 328/1350 [07:38<23:56,  1.41s/it][A
 24%|██▍       | 328/1350 [07:38<23:56,  1.41s/it][A
 24%|██▍       | 328/1350 [07:38<23:58,  1.41s/it][A
 24%|██▍       | 328/1350 [07:37<24:02,  1.41s/it][A
 24%|██▍       | 329/1350 [07:39<24:19,  1.43s/it][A
 24%|██▍       | 329/1350 [07:39<24:25,  1.44s/it][A
 24%|██▍       | 329/1350 [07:39<24:24,  1.43s/it][A

 24%|██▍       | 329/1350 [07:39<24:29,  1.44s/it][A
 24%|██▍       | 329/1350 [07:39<24:29,  1.44s/it][A 24%|██▍       | 329/1350 [07:39<24:30,  1.44s/it][A
 24%|██▍       | 330/1350 [07:40<24:00,  1.41s/it][A
 24%|██▍       | 330/1350 [07:40<24:00,  1.41s/it][A
 24%|██▍       | 330/1350 [07:40<24:01,  1.41s/it][A

 24%|██▍       | 330/1350 [07:40<24:03,  1.41s/it][A 24%|██▍       | 330/1350 [07:40<24:04,  1.42s/it][A
 24%|██▍       | 330/1350 [07:40<24:04,  1.42s/it][A
 25%|██▍       | 331/1350 [07:42<23:45,  1.40s/it][A

 25%|██▍       | 331/1350 [07:42<23:46,  1.40s/it][A 25%|██▍       | 331/1350 [07:42<23:45,  1.40s/it][A
 25%|██▍       | 331/1350 [07:42<23:46,  1.40s/it][A
 25%|██▍       | 331/1350 [07:42<23:46,  1.40s/it][A
 25%|██▍       | 331/1350 [07:42<23:48,  1.40s/it][A

 25%|██▍       | 332/1350 [07:43<23:36,  1.39s/it][A 25%|██▍       | 332/1350 [07:43<23:36,  1.39s/it][A

 25%|██▍       | 332/1350 [07:43<23:37,  1.39s/it][A 25%|██▍       | 332/1350 [07:43<23:36,  1.39s/it][A

 25%|██▍       | 332/1350 [07:43<23:36,  1.39s/it][A 25%|██▍       | 332/1350 [07:43<23:36,  1.39s/it][A
 25%|██▍       | 333/1350 [07:45<23:25,  1.38s/it][A

 25%|██▍       | 333/1350 [07:45<23:25,  1.38s/it][A

 25%|██▍       | 333/1350 [07:44<23:26,  1.38s/it][A 25%|██▍       | 333/1350 [07:45<23:25,  1.38s/it][A 25%|██▍       | 333/1350 [07:45<23:26,  1.38s/it][A
 25%|██▍       | 333/1350 [07:45<23:26,  1.38s/it][A
 25%|██▍       | 334/1350 [07:46<23:20,  1.38s/it][A


 25%|██▍       | 334/1350 [07:46<23:19,  1.38s/it][A 25%|██▍       | 334/1350 [07:46<23:20,  1.38s/it][A 25%|██▍       | 334/1350 [07:46<23:20,  1.38s/it][A
 25%|██▍       | 334/1350 [07:46<23:20,  1.38s/it][A
 25%|██▍       | 334/1350 [07:46<23:21,  1.38s/it][A
 25%|██▍       | 335/1350 [07:47<23:15,  1.37s/it][A

 25%|██▍       | 335/1350 [07:47<23:15,  1.38s/it][A 25%|██▍       | 335/1350 [07:47<23:15,  1.38s/it][A

 25%|██▍       | 335/1350 [07:47<23:15,  1.38s/it][A
 25%|██▍       | 335/1350 [07:47<23:15,  1.38s/it][A 25%|██▍       | 335/1350 [07:47<23:15,  1.37s/it][A
 25%|██▍       | 336/1350 [07:48<23:11,  1.37s/it][A
 25%|██▍       | 336/1350 [07:49<23:11,  1.37s/it][A
 25%|██▍       | 336/1350 [07:49<23:11,  1.37s/it][A
 25%|██▍       | 336/1350 [07:49<23:12,  1.37s/it][A
 25%|██▍       | 336/1350 [07:49<23:12,  1.37s/it][A
 25%|██▍       | 336/1350 [07:49<23:13,  1.37s/it][A
 25%|██▍       | 337/1350 [07:50<23:07,  1.37s/it][A
 25%|██▍       | 337/1350 [07:50<23:08,  1.37s/it][A
 25%|██▍       | 337/1350 [07:50<23:08,  1.37s/it][A
 25%|██▍       | 337/1350 [07:50<23:09,  1.37s/it]
[A 25%|██▍       | 337/1350 [07:50<23:09,  1.37s/it][A
 25%|██▍       | 337/1350 [07:50<23:11,  1.37s/it][A