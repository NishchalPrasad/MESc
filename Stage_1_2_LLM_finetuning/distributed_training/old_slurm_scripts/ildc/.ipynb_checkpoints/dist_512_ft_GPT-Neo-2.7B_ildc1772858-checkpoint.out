+ module load python
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load python
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
PYTHONUNBUFFERED=1;' export 'PYTHONUNBUFFERED;
MODULES_LMCONFLICT_modshare=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:python/3.10.4;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh;
conda' activate 'python-3.10.4;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ PYTHONUNBUFFERED=1
++ export PYTHONUNBUFFERED
++ MODULES_LMCONFLICT_modshare='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:python/3.10.4
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate python-3.10.4
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate python-3.10.4
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate python-3.10.4
+++ /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda shell.posix activate python-3.10.4
++ ask_conda='PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
++ eval 'PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
+++ PS1='(python-3.10.4) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=python-3.10.4
+++ CONDA_DEFAULT_ENV=python-3.10.4
+++ export 'CONDA_PROMPT_MODIFIER=(python-3.10.4) '
+++ CONDA_PROMPT_MODIFIER='(python-3.10.4) '
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh
++++ [[ -n '' ]]
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal ']'
++++ export GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ export GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ [[ ! -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins ]]
++++ unset GDAL_DRIVER_PATH
++++ export CPL_ZIP_ENCODING=UTF-8
++++ CPL_ZIP_ENCODING=UTF-8
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/epsg_csv ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/Library/share/epsg_csv ']'
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh
++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ export GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
++++ GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh
++++ '[' -n '' ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj ']'
++++ export PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ '[' -f /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj/copyright_and_licenses.csv ']'
++++ export PROJ_NETWORK=ON
++++ PROJ_NETWORK=ON
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ export PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ accelerate launch LEGAL-PE/SIGIR_experiments/distributedTraining/dist_deepspeed_LLM_torch_lexglue_.py --to_train True --batch_size 6 --learning_rate 2e-6 --num_warmup_steps 1000 --to_test True --strat 0 --data_path LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/ --dataset_subset ildc --hggfc_model_name EleutherAI/gpt-neo-2.7B
2023-05-20 18:04:20.031239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-20 18:04:21.640358: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:04:29.885470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:04:29.885624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:04:29.885640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-20 18:05:17.553820: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.553914: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.554085: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.554087: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.554819: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.562182: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:24.445062: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.445085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.445092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.445102: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.445121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.445125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.458931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.458957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458992: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.458992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.458999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.459008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.459015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.459053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
--------------------
--------------------Report
--------------------
Report--------------------
----------------------------------------
--------------------
Report

--------------------
Report
Report
Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Report
--------------------


--------------------Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)
------------------------------------------------------------

Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)


--------------------
Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)
--------------------Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)



------------------------------------------------------------


[2023-05-20 18:05:44,695] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])train_labels:torch.Size([392632])

train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
[2023-05-20 18:06:28,452] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 2.65B parameters
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-20 18:06:28,555] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-20 18:06:28,628] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-20 18:06:28,630] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-20 18:06:28,630] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-20 18:06:28,647] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-20 18:06:28,647] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>
[2023-05-20 18:06:28,647] [WARNING] [engine.py:1098:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2023-05-20 18:06:28,647] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-05-20 18:06:28,949] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-05-20 18:06:28,949] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 1.04 GB         CA 3.01 GB         Max_CA 3 GB 
[2023-05-20 18:06:28,949] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 54.92 GB, percent = 10.9%
[2023-05-20 18:06:28,951] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-05-20 18:06:28,951] [INFO] [stage3.py:114:__init__] Prefetch bucket size 50,000,000
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Emitting ninja build file /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3317124843597412 seconds
Loading extension module utils...Loading extension module utils...
Loading extension module utils...
Loading extension module utils...Loading extension module utils...


Time to load utils op: 0.3519935607910156 secondsTime to load utils op: 0.3529808521270752 seconds

Time to load utils op: 0.35239386558532715 seconds
Time to load utils op: 0.35187816619873047 seconds
Time to load utils op: 0.35259342193603516 seconds
[2023-05-20 18:06:46,359] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-05-20 18:06:46,359] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 3.01 GB         Max_CA 3 GB 
[2023-05-20 18:06:46,359] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.03 GB, percent = 10.9%
Parameter Offload: Total persistent parameters: 829440 in 227 params
[2023-05-20 18:06:46,498] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-05-20 18:06:46,499] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 3.01 GB         Max_CA 3 GB 
[2023-05-20 18:06:46,499] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.03 GB, percent = 10.9%
[2023-05-20 18:06:46,622] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-05-20 18:06:46,622] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 3.01 GB         Max_CA 3 GB 
[2023-05-20 18:06:46,622] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.03 GB, percent = 10.9%
[2023-05-20 18:06:47,727] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1
[2023-05-20 18:06:47,728] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.91 GB         Max_CA 3 GB 
[2023-05-20 18:06:47,728] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 58.28 GB, percent = 11.6%
[2023-05-20 18:06:47,854] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-05-20 18:06:47,855] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.91 GB         Max_CA 2 GB 
[2023-05-20 18:06:47,855] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 58.33 GB, percent = 11.6%
[2023-05-20 18:06:48,009] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-05-20 18:06:48,010] [INFO] [utils.py:786:see_memory_usage] MA 2.59 GB         Max_MA 3.42 GB         CA 4.38 GB         Max_CA 4 GB 
[2023-05-20 18:06:48,010] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 56.68 GB, percent = 11.3%
[2023-05-20 18:06:48,209] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-05-20 18:06:48,209] [INFO] [utils.py:786:see_memory_usage] MA 2.59 GB         Max_MA 2.59 GB         CA 4.38 GB         Max_CA 4 GB 
[2023-05-20 18:06:48,210] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
[2023-05-20 18:06:48,338] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-05-20 18:06:48,338] [INFO] [utils.py:786:see_memory_usage] MA 5.89 GB         Max_MA 9.18 GB         CA 10.97 GB         Max_CA 11 GB 
[2023-05-20 18:06:48,338] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
[2023-05-20 18:06:48,339] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0005834102630615234 seconds
Time to load utils op: 0.0005316734313964844 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006160736083984375 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006225109100341797 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007171630859375 seconds
  0%|          | 0/3 [00:00<?, ?it/s]  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========  0%|          | 0/3 [00:00<?, ?it/s]
  0%|          | 0/3 [00:00<?, ?it/s]
Training...======== Epoch 1 / 3 ================ Epoch 1 / 3 ========Training...
======== Epoch 1 / 3 ========



Training...Training...Training...




  0%|          | 0/10907 [00:00<?, ?it/s][A  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 0/10907 [00:00<?, ?it/s]
[A  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 0/10907 [00:00<?, ?it/s][A[2023-05-20 18:06:48,613] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-05-20 18:06:48,613] [INFO] [utils.py:786:see_memory_usage] MA 7.64 GB         Max_MA 8.12 GB         CA 10.97 GB         Max_CA 11 GB 
[2023-05-20 18:06:48,613] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
[2023-05-20 18:06:48,614] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-20 18:06:48,614] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-20 18:06:48,614] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-20 18:06:48,614] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2023-05-20 18:06:48,614] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   amp_params ................... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   bfloat16_enabled ............. True
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x150b9c0c4dc0>
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   dump_state ................... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-20 18:06:48,615] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 1
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   loss_scale ................... 1.0
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   pld_params ................... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   steps_per_print .............. inf
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   train_batch_size ............. 36
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  6
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   world_size ................... 6
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  True
[2023-05-20 18:06:48,616] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-05-20 18:06:48,617] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-05-20 18:06:48,617] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-20 18:06:48,617] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-05-20 18:06:48,617] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 36, 
    "train_micro_batch_size_per_gpu": 6, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00046515464782714844 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 1/10907 [00:04<13:47:09,  4.55s/it][A
  0%|          | 1/10907 [00:04<13:47:25,  4.55s/it][A
  0%|          | 1/10907 [00:04<13:50:30,  4.57s/it][A

  0%|          | 1/10907 [00:04<13:30:43,  4.46s/it][A  0%|          | 1/10907 [00:04<13:50:58,  4.57s/it][A
  0%|          | 1/10907 [00:04<13:51:04,  4.57s/it][A
  0%|          | 2/10907 [00:06<8:47:58,  2.90s/it] [A
  0%|          | 2/10907 [00:06<8:49:03,  2.91s/it] [A
  0%|          | 2/10907 [00:06<8:49:27,  2.91s/it] [A
  0%|          | 2/10907 [00:06<8:41:03,  2.87s/it] [A
  0%|          | 2/10907 [00:06<8:50:11,  2.92s/it] [A
  0%|          | 2/10907 [00:06<8:50:24,  2.92s/it] [A
  0%|          | 3/10907 [00:07<6:26:50,  2.13s/it][A
  0%|          | 3/10907 [00:07<6:33:34,  2.17s/it][A
  0%|          | 3/10907 [00:07<6:34:25,  2.17s/it][A
  0%|          | 3/10907 [00:07<6:34:27,  2.17s/it][A

  0%|          | 3/10907 [00:07<6:35:17,  2.18s/it][A  0%|          | 3/10907 [00:07<6:35:11,  2.17s/it][A
  0%|          | 4/10907 [00:08<5:31:23,  1.82s/it][A
  0%|          | 4/10907 [00:08<5:31:22,  1.82s/it][A
  0%|          | 4/10907 [00:08<5:32:05,  1.83s/it][A

  0%|          | 4/10907 [00:08<5:29:49,  1.82s/it][A  0%|          | 4/10907 [00:08<5:31:50,  1.83s/it][A
  0%|          | 4/10907 [00:08<5:32:16,  1.83s/it][A
  0%|          | 5/10907 [00:10<4:57:18,  1.64s/it][A
  0%|          | 5/10907 [00:10<4:57:10,  1.64s/it][A
  0%|          | 5/10907 [00:10<4:55:57,  1.63s/it][A
  0%|          | 5/10907 [00:10<4:57:32,  1.64s/it][A
  0%|          | 5/10907 [00:10<4:57:32,  1.64s/it][A
  0%|          | 5/10907 [00:10<4:57:31,  1.64s/it][A
  0%|          | 6/10907 [00:11<4:36:24,  1.52s/it][A
  0%|          | 6/10907 [00:11<4:36:37,  1.52s/it][A
  0%|          | 6/10907 [00:11<4:37:01,  1.52s/it][A

  0%|          | 6/10907 [00:11<4:37:12,  1.53s/it][A  0%|          | 6/10907 [00:11<4:36:21,  1.52s/it][A
  0%|          | 6/10907 [00:11<4:37:25,  1.53s/it][A
  0%|          | 7/10907 [00:12<4:23:56,  1.45s/it][A
  0%|          | 7/10907 [00:12<4:24:06,  1.45s/it][A


  0%|          | 7/10907 [00:12<4:23:59,  1.45s/it][A  0%|          | 7/10907 [00:12<4:23:14,  1.45s/it][A  0%|          | 7/10907 [00:12<4:23:49,  1.45s/it][A
  0%|          | 7/10907 [00:12<4:23:56,  1.45s/it][A
  0%|          | 8/10907 [00:14<4:14:18,  1.40s/it][A
  0%|          | 8/10907 [00:14<4:14:45,  1.40s/it][A

  0%|          | 8/10907 [00:14<4:15:07,  1.40s/it][A  0%|          | 8/10907 [00:14<4:15:14,  1.41s/it][A
  0%|          | 8/10907 [00:14<4:15:28,  1.41s/it][A
  0%|          | 8/10907 [00:14<4:15:08,  1.40s/it][A
  0%|          | 9/10907 [00:15<4:08:31,  1.37s/it][A
  0%|          | 9/10907 [00:15<4:08:57,  1.37s/it][A

  0%|          | 9/10907 [00:15<4:08:46,  1.37s/it][A  0%|          | 9/10907 [00:15<4:09:01,  1.37s/it][A
  0%|          | 9/10907 [00:15<4:09:12,  1.37s/it][A
  0%|          | 9/10907 [00:15<4:09:40,  1.37s/it][A
  0%|          | 10/10907 [00:16<4:05:35,  1.35s/it][A

  0%|          | 10/10907 [00:16<4:05:57,  1.35s/it][A  0%|          | 10/10907 [00:16<4:06:07,  1.36s/it][A

  0%|          | 10/10907 [00:16<4:05:32,  1.35s/it][A  0%|          | 10/10907 [00:16<4:05:48,  1.35s/it][A
  0%|          | 10/10907 [00:16<4:06:21,  1.36s/it][A
  0%|          | 11/10907 [00:18<4:03:18,  1.34s/it][A
  0%|          | 11/10907 [00:17<4:03:21,  1.34s/it][A
  0%|          | 11/10907 [00:18<4:03:36,  1.34s/it][A
  0%|          | 11/10907 [00:18<4:03:56,  1.34s/it][A
  0%|          | 11/10907 [00:18<4:04:01,  1.34s/it][A
  0%|          | 11/10907 [00:18<4:03:53,  1.34s/it][A
  0%|          | 12/10907 [00:19<4:01:28,  1.33s/it][A
  0%|          | 12/10907 [00:19<4:01:40,  1.33s/it][A
  0%|          | 12/10907 [00:19<4:01:54,  1.33s/it][A
  0%|          | 12/10907 [00:19<4:01:55,  1.33s/it][A

  0%|          | 12/10907 [00:19<4:01:56,  1.33s/it][A  0%|          | 12/10907 [00:19<4:01:48,  1.33s/it][A
  0%|          | 13/10907 [00:20<4:00:21,  1.32s/it][A
  0%|          | 13/10907 [00:20<4:00:38,  1.33s/it][A
  0%|          | 13/10907 [00:20<4:00:49,  1.33s/it][A
  0%|          | 13/10907 [00:20<4:00:38,  1.33s/it][A
  0%|          | 13/10907 [00:20<4:00:37,  1.33s/it][A
  0%|          | 13/10907 [00:20<4:00:48,  1.33s/it][A
  0%|          | 14/10907 [00:22<4:11:46,  1.39s/it][A
  0%|          | 14/10907 [00:22<4:12:12,  1.39s/it][A
  0%|          | 14/10907 [00:22<4:12:09,  1.39s/it][A

  0%|          | 14/10907 [00:22<4:12:23,  1.39s/it][A  0%|          | 14/10907 [00:22<4:12:54,  1.39s/it][A
  0%|          | 14/10907 [00:22<4:12:30,  1.39s/it][A
  0%|          | 15/10907 [00:23<4:13:02,  1.39s/it][A
  0%|          | 15/10907 [00:23<4:13:35,  1.40s/it][A
  0%|          | 15/10907 [00:23<4:13:37,  1.40s/it][A
  0%|          | 15/10907 [00:23<4:13:46,  1.40s/it][A
  0%|          | 15/10907 [00:23<4:14:25,  1.40s/it][A
  0%|          | 15/10907 [00:23<4:14:32,  1.40s/it][A
  0%|          | 16/10907 [00:24<4:09:16,  1.37s/it][A
  0%|          | 16/10907 [00:24<4:09:53,  1.38s/it][A
  0%|          | 16/10907 [00:24<4:09:39,  1.38s/it][A
  0%|          | 16/10907 [00:24<4:10:26,  1.38s/it][A
  0%|          | 16/10907 [00:24<4:09:49,  1.38s/it][A
  0%|          | 16/10907 [00:24<4:10:11,  1.38s/it][A

  0%|          | 17/10907 [00:26<4:06:17,  1.36s/it][A  0%|          | 17/10907 [00:26<4:06:21,  1.36s/it][A
  0%|          | 17/10907 [00:26<4:06:03,  1.36s/it][A
  0%|          | 17/10907 [00:26<4:06:26,  1.36s/it][A

  0%|          | 17/10907 [00:26<4:06:34,  1.36s/it][A  0%|          | 17/10907 [00:26<4:06:36,  1.36s/it][A
  0%|          | 18/10907 [00:27<4:04:23,  1.35s/it][A
  0%|          | 18/10907 [00:27<4:04:27,  1.35s/it][A
  0%|          | 18/10907 [00:27<4:04:42,  1.35s/it][A
  0%|          | 18/10907 [00:27<4:04:37,  1.35s/it][A

  0%|          | 18/10907 [00:27<4:04:58,  1.35s/it][A  0%|          | 18/10907 [00:27<4:04:39,  1.35s/it][A
  0%|          | 19/10907 [00:28<4:03:23,  1.34s/it][A
  0%|          | 19/10907 [00:28<4:03:37,  1.34s/it][A
  0%|          | 19/10907 [00:28<4:03:36,  1.34s/it][A

  0%|          | 19/10907 [00:28<4:03:30,  1.34s/it][A
  0%|          | 19/10907 [00:28<4:03:25,  1.34s/it][A  0%|          | 19/10907 [00:28<4:03:26,  1.34s/it][A

  0%|          | 20/10907 [00:30<4:02:01,  1.33s/it][A  0%|          | 20/10907 [00:30<4:02:01,  1.33s/it][A
  0%|          | 20/10907 [00:30<4:01:57,  1.33s/it][A
  0%|          | 20/10907 [00:30<4:02:05,  1.33s/it][A
  0%|          | 20/10907 [00:30<4:02:13,  1.33s/it][A
  0%|          | 20/10907 [00:30<4:02:14,  1.33s/it][A
  0%|          | 21/10907 [00:31<4:01:29,  1.33s/it][A
  0%|          | 21/10907 [00:31<4:01:36,  1.33s/it][A

  0%|          | 21/10907 [00:31<4:01:42,  1.33s/it][A
  0%|          | 21/10907 [00:31<4:01:46,  1.33s/it][A  0%|          | 21/10907 [00:31<4:01:34,  1.33s/it][A
  0%|          | 21/10907 [00:31<4:01:37,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:00:56,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:01:01,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:00:56,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:00:52,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:00:55,  1.33s/it][A
  0%|          | 22/10907 [00:32<4:01:06,  1.33s/it][A
  0%|          | 23/10907 [00:34<4:00:23,  1.33s/it][A
  0%|          | 23/10907 [00:34<4:00:27,  1.33s/it][A
  0%|          | 23/10907 [00:34<4:00:13,  1.32s/it][A
  0%|          | 23/10907 [00:34<4:00:09,  1.32s/it][A
  0%|          | 23/10907 [00:34<4:00:23,  1.33s/it][A
  0%|          | 23/10907 [00:34<4:00:21,  1.32s/it][A
  0%|          | 24/10907 [00:35<3:59:11,  1.32s/it][A
  0%|          | 24/10907 [00:35<4:00:08,  1.32s/it][A
  0%|          | 24/10907 [00:35<3:59:26,  1.32s/it][A

  0%|          | 24/10907 [00:35<4:00:13,  1.32s/it][A  0%|          | 24/10907 [00:35<4:00:09,  1.32s/it][A
  0%|          | 24/10907 [00:35<4:00:17,  1.32s/it][A
  0%|          | 25/10907 [00:36<3:59:39,  1.32s/it][A
  0%|          | 25/10907 [00:36<4:00:01,  1.32s/it][A
  0%|          | 25/10907 [00:36<3:59:37,  1.32s/it][A
  0%|          | 25/10907 [00:36<3:59:47,  1.32s/it][A

  0%|          | 25/10907 [00:36<3:59:47,  1.32s/it][A  0%|          | 25/10907 [00:36<3:59:58,  1.32s/it][A
  0%|          | 26/10907 [00:38<3:59:28,  1.32s/it][A
  0%|          | 26/10907 [00:38<3:59:22,  1.32s/it][A
  0%|          | 26/10907 [00:38<3:59:58,  1.32s/it][A
  0%|          | 26/10907 [00:38<4:00:00,  1.32s/it][A
  0%|          | 26/10907 [00:38<4:00:06,  1.32s/it][A
  0%|          | 26/10907 [00:38<4:00:54,  1.33s/it][A
  0%|          | 27/10907 [00:39<3:59:49,  1.32s/it][A
  0%|          | 27/10907 [00:39<3:59:34,  1.32s/it][A
  0%|          | 27/10907 [00:39<4:00:13,  1.32s/it][A
  0%|          | 27/10907 [00:39<4:00:09,  1.32s/it][A

  0%|          | 27/10907 [00:39<4:00:02,  1.32s/it][A  0%|          | 27/10907 [00:39<4:00:32,  1.33s/it][A
  0%|          | 28/10907 [00:40<4:00:56,  1.33s/it][A
  0%|          | 28/10907 [00:40<4:00:33,  1.33s/it][A
  0%|          | 28/10907 [00:40<4:00:42,  1.33s/it][A


  0%|          | 28/10907 [00:40<4:00:22,  1.33s/it][A  0%|          | 28/10907 [00:40<4:00:40,  1.33s/it][A  0%|          | 28/10907 [00:40<4:00:29,  1.33s/it][A
  0%|          | 29/10907 [00:42<4:00:57,  1.33s/it][A
  0%|          | 29/10907 [00:42<4:00:35,  1.33s/it][A
  0%|          | 29/10907 [00:42<4:00:40,  1.33s/it][A
  0%|          | 29/10907 [00:42<4:00:33,  1.33s/it][A
  0%|          | 29/10907 [00:42<4:00:30,  1.33s/it]
[A  0%|          | 29/10907 [00:42<4:00:43,  1.33s/it][A
  0%|          | 30/10907 [00:43<4:07:15,  1.36s/it][A
  0%|          | 30/10907 [00:43<4:06:59,  1.36s/it][A
  0%|          | 30/10907 [00:43<4:07:13,  1.36s/it][A
  0%|          | 30/10907 [00:43<4:07:31,  1.37s/it][A
  0%|          | 30/10907 [00:43<4:07:23,  1.36s/it][A
  0%|          | 30/10907 [00:43<4:07:58,  1.37s/it][A
  0%|          | 31/10907 [00:44<4:09:25,  1.38s/it][A
  0%|          | 31/10907 [00:45<4:10:22,  1.38s/it][A
  0%|          | 31/10907 [00:45<4:10:30,  1.38s/it][A
  0%|          | 31/10907 [00:45<4:10:27,  1.38s/it][A

  0%|          | 31/10907 [00:45<4:10:29,  1.38s/it][A  0%|          | 31/10907 [00:45<4:10:44,  1.38s/it][A
  0%|          | 32/10907 [00:46<4:07:37,  1.37s/it][A
  0%|          | 32/10907 [00:46<4:07:39,  1.37s/it][A
  0%|          | 32/10907 [00:46<4:07:47,  1.37s/it][A
  0%|          | 32/10907 [00:46<4:07:59,  1.37s/it][A

  0%|          | 32/10907 [00:46<4:08:14,  1.37s/it][A  0%|          | 32/10907 [00:46<4:07:53,  1.37s/it][A
  0%|          | 33/10907 [00:47<4:06:46,  1.36s/it][A


  0%|          | 33/10907 [00:47<4:06:30,  1.36s/it][A  0%|          | 33/10907 [00:47<4:06:37,  1.36s/it][A  0%|          | 33/10907 [00:47<4:06:23,  1.36s/it][A
  0%|          | 33/10907 [00:47<4:06:40,  1.36s/it][A
  0%|          | 33/10907 [00:47<4:06:41,  1.36s/it][A
  0%|          | 34/10907 [00:49<4:04:53,  1.35s/it][A

  0%|          | 34/10907 [00:49<4:04:39,  1.35s/it][A  0%|          | 34/10907 [00:49<4:04:41,  1.35s/it][A
  0%|          | 34/10907 [00:49<4:04:42,  1.35s/it][A
  0%|          | 34/10907 [00:49<4:04:45,  1.35s/it][A
  0%|          | 34/10907 [00:48<4:05:05,  1.35s/it][A
  0%|          | 35/10907 [00:50<4:03:29,  1.34s/it][A
  0%|          | 35/10907 [00:50<4:03:25,  1.34s/it][A
  0%|          | 35/10907 [00:50<4:03:22,  1.34s/it][A
  0%|          | 35/10907 [00:50<4:03:20,  1.34s/it][A
  0%|          | 35/10907 [00:50<4:03:49,  1.35s/it][A
  0%|          | 35/10907 [00:50<4:03:51,  1.35s/it][A
  0%|          | 36/10907 [00:51<4:02:29,  1.34s/it][A
  0%|          | 36/10907 [00:51<4:02:23,  1.34s/it][A
  0%|          | 36/10907 [00:51<4:02:45,  1.34s/it][A
  0%|          | 36/10907 [00:51<4:02:38,  1.34s/it][A
  0%|          | 36/10907 [00:51<4:02:41,  1.34s/it][A
  0%|          | 36/10907 [00:51<4:02:47,  1.34s/it][A
  0%|          | 37/10907 [00:53<4:02:01,  1.34s/it][A

  0%|          | 37/10907 [00:53<4:01:59,  1.34s/it][A  0%|          | 37/10907 [00:53<4:01:57,  1.34s/it][A
  0%|          | 37/10907 [00:53<4:01:54,  1.34s/it][A
  0%|          | 37/10907 [00:52<4:02:00,  1.34s/it][A
  0%|          | 37/10907 [00:53<4:02:00,  1.34s/it][A
  0%|          | 38/10907 [00:54<4:01:53,  1.34s/it][A
  0%|          | 38/10907 [00:54<4:02:44,  1.34s/it][A

  0%|          | 38/10907 [00:54<4:01:55,  1.34s/it][A  0%|          | 38/10907 [00:54<4:01:59,  1.34s/it][A
  0%|          | 38/10907 [00:54<4:01:58,  1.34s/it][A
  0%|          | 38/10907 [00:54<4:02:07,  1.34s/it][A
  0%|          | 39/10907 [00:55<4:01:47,  1.33s/it][A
  0%|          | 39/10907 [00:55<4:01:44,  1.33s/it][A
  0%|          | 39/10907 [00:55<4:01:51,  1.34s/it][A
  0%|          | 39/10907 [00:55<4:01:50,  1.34s/it][A
  0%|          | 39/10907 [00:55<4:02:01,  1.34s/it][A
  0%|          | 39/10907 [00:55<4:01:55,  1.34s/it][A
  0%|          | 40/10907 [00:57<4:01:48,  1.34s/it][A
  0%|          | 40/10907 [00:56<4:01:42,  1.33s/it][A

  0%|          | 40/10907 [00:57<4:01:50,  1.34s/it][A  0%|          | 40/10907 [00:57<4:01:44,  1.33s/it][A
  0%|          | 40/10907 [00:57<4:01:54,  1.34s/it][A
  0%|          | 40/10907 [00:57<4:01:59,  1.34s/it][A
  0%|          | 41/10907 [00:58<4:00:54,  1.33s/it][A
  0%|          | 41/10907 [00:58<4:01:53,  1.34s/it][A
  0%|          | 41/10907 [00:58<4:01:28,  1.33s/it][A
  0%|          | 41/10907 [00:58<4:01:50,  1.34s/it][A
  0%|          | 41/10907 [00:58<4:01:55,  1.34s/it][A
  0%|          | 41/10907 [00:58<4:01:50,  1.34s/it][A
  0%|          | 42/10907 [00:59<4:01:56,  1.34s/it][A
  0%|          | 42/10907 [00:59<4:01:20,  1.33s/it][A
  0%|          | 42/10907 [00:59<4:01:25,  1.33s/it][A
  0%|          | 42/10907 [00:59<4:01:51,  1.34s/it][A
  0%|          | 42/10907 [00:59<4:01:49,  1.34s/it][A
  0%|          | 42/10907 [00:59<4:02:05,  1.34s/it][A
  0%|          | 43/10907 [01:01<4:00:56,  1.33s/it][A

  0%|          | 43/10907 [01:01<4:01:03,  1.33s/it][A  0%|          | 43/10907 [01:00<4:00:59,  1.33s/it][A
  0%|          | 43/10907 [01:01<4:01:11,  1.33s/it][A

  0%|          | 43/10907 [01:01<4:01:32,  1.33s/it][A  0%|          | 43/10907 [01:01<4:01:23,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:00:23,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:00:31,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:01:33,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:01:35,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:01:32,  1.33s/it][A
  0%|          | 44/10907 [01:02<4:01:33,  1.33s/it][A
  0%|          | 45/10907 [01:03<4:11:36,  1.39s/it][A
  0%|          | 45/10907 [01:03<4:11:09,  1.39s/it][A
  0%|          | 45/10907 [01:03<4:11:06,  1.39s/it][A
  0%|          | 45/10907 [01:03<4:11:29,  1.39s/it][A
  0%|          | 45/10907 [01:03<4:11:44,  1.39s/it][A
  0%|          | 45/10907 [01:03<4:11:47,  1.39s/it][A
  0%|          | 46/10907 [01:05<4:12:46,  1.40s/it][A
  0%|          | 46/10907 [01:05<4:12:42,  1.40s/it][A
  0%|          | 46/10907 [01:05<4:12:59,  1.40s/it][A
  0%|          | 46/10907 [01:05<4:13:06,  1.40s/it][A
  0%|          | 46/10907 [01:05<4:13:21,  1.40s/it]
[A  0%|          | 46/10907 [01:05<4:13:10,  1.40s/it][A
  0%|          | 47/10907 [01:06<4:09:27,  1.38s/it][A
  0%|          | 47/10907 [01:06<4:09:35,  1.38s/it][A
  0%|          | 47/10907 [01:06<4:09:27,  1.38s/it][A
  0%|          | 47/10907 [01:06<4:09:40,  1.38s/it][A
  0%|          | 47/10907 [01:06<4:09:51,  1.38s/it][A
  0%|          | 47/10907 [01:06<4:09:53,  1.38s/it][A
  0%|          | 48/10907 [01:07<4:06:46,  1.36s/it][A
  0%|          | 48/10907 [01:07<4:06:36,  1.36s/it][A
  0%|          | 48/10907 [01:07<4:07:04,  1.37s/it][A
  0%|          | 48/10907 [01:07<4:07:02,  1.37s/it][A
  0%|          | 48/10907 [01:07<4:07:09,  1.37s/it][A
  0%|          | 48/10907 [01:07<4:07:08,  1.37s/it][A
  0%|          | 49/10907 [01:09<4:04:43,  1.35s/it][A

  0%|          | 49/10907 [01:09<4:04:51,  1.35s/it][A  0%|          | 49/10907 [01:09<4:04:56,  1.35s/it][A
  0%|          | 49/10907 [01:09<4:04:46,  1.35s/it][A
  0%|          | 49/10907 [01:09<4:04:51,  1.35s/it][A
  0%|          | 49/10907 [01:09<4:05:02,  1.35s/it][A
  0%|          | 50/10907 [01:10<4:03:43,  1.35s/it][A
  0%|          | 50/10907 [01:10<4:03:38,  1.35s/it][A


  0%|          | 50/10907 [01:10<4:03:40,  1.35s/it][A  0%|          | 50/10907 [01:10<4:03:38,  1.35s/it][A  0%|          | 50/10907 [01:10<4:03:35,  1.35s/it][A
  0%|          | 50/10907 [01:10<4:03:50,  1.35s/it][A
  0%|          | 51/10907 [01:11<4:01:45,  1.34s/it][A
  0%|          | 51/10907 [01:11<4:01:29,  1.33s/it][A
  0%|          | 51/10907 [01:11<4:02:24,  1.34s/it][A
  0%|          | 51/10907 [01:11<4:02:48,  1.34s/it][A

  0%|          | 51/10907 [01:11<4:02:44,  1.34s/it][A  0%|          | 51/10907 [01:11<4:02:47,  1.34s/it][A
  0%|          | 52/10907 [01:13<4:02:10,  1.34s/it][A

  0%|          | 52/10907 [01:13<4:01:52,  1.34s/it][A  0%|          | 52/10907 [01:13<4:01:48,  1.34s/it][A
  0%|          | 52/10907 [01:13<4:02:03,  1.34s/it][A

  0%|          | 52/10907 [01:13<4:02:02,  1.34s/it][A  0%|          | 52/10907 [01:13<4:02:29,  1.34s/it][A
  0%|          | 53/10907 [01:14<4:01:22,  1.33s/it][A

  0%|          | 53/10907 [01:14<4:01:18,  1.33s/it][A
  0%|          | 53/10907 [01:14<4:01:00,  1.33s/it][A  0%|          | 53/10907 [01:14<4:01:06,  1.33s/it][A
  0%|          | 53/10907 [01:14<4:01:33,  1.34s/it][A
  0%|          | 53/10907 [01:14<4:01:36,  1.34s/it][A