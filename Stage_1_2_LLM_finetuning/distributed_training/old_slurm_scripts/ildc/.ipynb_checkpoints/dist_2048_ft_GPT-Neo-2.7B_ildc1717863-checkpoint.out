+ module load python
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load python
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
PYTHONUNBUFFERED=1;' export 'PYTHONUNBUFFERED;
MODULES_LMCONFLICT_modshare=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:python/3.10.4;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh;
conda' activate 'python-3.10.4;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ PYTHONUNBUFFERED=1
++ export PYTHONUNBUFFERED
++ MODULES_LMCONFLICT_modshare='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:python/3.10.4
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate python-3.10.4
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate python-3.10.4
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate python-3.10.4
+++ /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda shell.posix activate python-3.10.4
++ ask_conda='PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
++ eval 'PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
+++ PS1='(python-3.10.4) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=python-3.10.4
+++ CONDA_DEFAULT_ENV=python-3.10.4
+++ export 'CONDA_PROMPT_MODIFIER=(python-3.10.4) '
+++ CONDA_PROMPT_MODIFIER='(python-3.10.4) '
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh
++++ [[ -n '' ]]
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal ']'
++++ export GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ export GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ [[ ! -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins ]]
++++ unset GDAL_DRIVER_PATH
++++ export CPL_ZIP_ENCODING=UTF-8
++++ CPL_ZIP_ENCODING=UTF-8
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/epsg_csv ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/Library/share/epsg_csv ']'
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh
++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ export GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
++++ GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh
++++ '[' -n '' ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj ']'
++++ export PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ '[' -f /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj/copyright_and_licenses.csv ']'
++++ export PROJ_NETWORK=ON
++++ PROJ_NETWORK=ON
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ export PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ accelerate launch LEGAL-PE/SIGIR_experiments/distributedTraining/dist_deepspeed_LLM_torch_lexglue_.py --to_train True --batch_size 2 --learning_rate 2e-6 --num_warmup_steps 1000 --to_test True --strat 0 --data_path LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/ --dataset_subset ildc --hggfc_model_name EleutherAI/gpt-neo-2.7B
2023-05-16 13:06:51.644503: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-16 13:06:53.153330: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:01.231920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:07:01.232073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:07:01.232089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-16 13:07:58.319357: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:58.320576: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:58.320596: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:58.320794: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:58.320830: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:07:58.321889: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-16 13:08:00.592296: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592306: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592578: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-16 13:08:00.592613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-16 13:08:00.592612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-16 13:08:00.592646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-16 13:08:00.592658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-16 13:08:00.592671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-16 13:08:00.592688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
----------------------------------------------------------------------------------------------------
--------------------



Report
ReportReportReportReport
Report



--------------------
--------------------------------------------------------------------------------
--------------------




Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)Namespace(to_train=True, batch_size=2, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/', hggfc_model_name='EleutherAI/gpt-neo-2.7B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/ildc/EleutherAI_gpt-neo-2.7B/Strategy_0/Training_data/chunks_with_100_overlap_and_2048_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)





------------------------------------------------------------------------------------------------------------------------





[2023-05-16 13:08:22,308] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
train_labels:torch.Size([99031])
train_labels:torch.Size([99031])
train_labels:torch.Size([99031])
train_labels:torch.Size([99031])
train_labels:torch.Size([99031])
train_labels:torch.Size([99031])
[2023-05-16 13:08:43,787] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 2.65B parameters
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-16 13:08:43,868] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-neo-2.7B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50257, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- wpe.weight: found shape torch.Size([2048, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.28.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.29.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.30.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_1.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.k_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.v_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.q_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.weight: found shape torch.Size([2560, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.attn.attention.out_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.ln_2.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.weight: found shape torch.Size([10240, 2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_fc.bias: found shape torch.Size([10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.weight: found shape torch.Size([2560, 10240]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.31.mlp.c_proj.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([2560]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-16 13:08:43,981] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-16 13:08:43,982] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-16 13:08:43,982] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-16 13:08:44,000] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-16 13:08:44,000] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>
[2023-05-16 13:08:44,000] [WARNING] [engine.py:1098:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2023-05-16 13:08:44,000] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-05-16 13:08:44,139] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-05-16 13:08:44,140] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 1.04 GB         CA 1.86 GB         Max_CA 2 GB 
[2023-05-16 13:08:44,140] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.26 GB, percent = 10.4%
[2023-05-16 13:08:44,142] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-05-16 13:08:44,142] [INFO] [stage3.py:114:__init__] Prefetch bucket size 50,000,000
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...

Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...

Loading extension module utils...Loading extension module utils...Loading extension module utils...Loading extension module utils...Loading extension module utils...Loading extension module utils...





Time to load utils op: 0.6131899356842041 secondsTime to load utils op: 0.6140999794006348 secondsTime to load utils op: 0.6129436492919922 seconds

Time to load utils op: 0.6126894950866699 secondsTime to load utils op: 0.6125946044921875 seconds
Time to load utils op: 0.6146743297576904 seconds


[2023-05-16 13:08:53,365] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-05-16 13:08:53,366] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.86 GB         Max_CA 2 GB 
[2023-05-16 13:08:53,366] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.31 GB, percent = 10.4%
Parameter Offload: Total persistent parameters: 829440 in 227 params
[2023-05-16 13:08:53,493] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-05-16 13:08:53,493] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.86 GB         Max_CA 2 GB 
[2023-05-16 13:08:53,494] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.31 GB, percent = 10.4%
[2023-05-16 13:08:53,604] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-05-16 13:08:53,605] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.86 GB         Max_CA 2 GB 
[2023-05-16 13:08:53,605] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.31 GB, percent = 10.4%
[2023-05-16 13:08:55,061] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1
[2023-05-16 13:08:55,062] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.84 GB         Max_CA 2 GB 
[2023-05-16 13:08:55,062] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,202] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-05-16 13:08:55,203] [INFO] [utils.py:786:see_memory_usage] MA 0.95 GB         Max_MA 0.95 GB         CA 1.84 GB         Max_CA 2 GB 
[2023-05-16 13:08:55,203] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,344] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-05-16 13:08:55,344] [INFO] [utils.py:786:see_memory_usage] MA 2.6 GB         Max_MA 3.42 GB         CA 4.31 GB         Max_CA 4 GB 
[2023-05-16 13:08:55,344] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,481] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-05-16 13:08:55,482] [INFO] [utils.py:786:see_memory_usage] MA 2.6 GB         Max_MA 2.6 GB         CA 4.31 GB         Max_CA 4 GB 
[2023-05-16 13:08:55,482] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,623] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-05-16 13:08:55,624] [INFO] [utils.py:786:see_memory_usage] MA 5.89 GB         Max_MA 9.18 GB         CA 10.9 GB         Max_CA 11 GB 
[2023-05-16 13:08:55,624] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,625] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Time to load utils op: 0.0009970664978027344 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00064849853515625 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006549358367919922 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006132125854492188 seconds
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
  0%|          | 0/3 [00:00<?, ?it/s]  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
======== Epoch 1 / 3 ========Training...

Training...  0%|          | 0/3 [00:00<?, ?it/s]
No modifications detected for re-loaded extension module utils, skipping build step...======== Epoch 1 / 3 ========

Loading extension module utils...
Training...
Time to load utils op: 0.0006403923034667969 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/8253 [00:00<?, ?it/s][A
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/8253 [00:00<?, ?it/s][A  0%|          | 0/8253 [00:00<?, ?it/s][A
  0%|          | 0/8253 [00:00<?, ?it/s][A
  0%|          | 0/8253 [00:00<?, ?it/s][A[2023-05-16 13:08:55,913] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-05-16 13:08:55,914] [INFO] [utils.py:786:see_memory_usage] MA 7.64 GB         Max_MA 8.12 GB         CA 10.9 GB         Max_CA 11 GB 
[2023-05-16 13:08:55,914] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 52.32 GB, percent = 10.4%
[2023-05-16 13:08:55,914] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-16 13:08:55,914] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-16 13:08:55,914] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-16 13:08:55,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2023-05-16 13:08:55,915] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   amp_params ................... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   bfloat16_enabled ............. True
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x14988c6c8df0>
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   dump_state ................... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-05-16 13:08:55,916] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 1
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   loss_scale ................... 1.0
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   pld_params ................... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   steps_per_print .............. inf
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   train_batch_size ............. 12
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  2
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   world_size ................... 6
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  True
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-16 13:08:55,917] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-05-16 13:08:55,917] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 12, 
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00047588348388671875 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/8253 [00:00<?, ?it/s][A
  0%|          | 1/8253 [00:03<8:27:01,  3.69s/it][A
  0%|          | 1/8253 [00:03<8:27:38,  3.69s/it][A

  0%|          | 1/8253 [00:03<8:27:33,  3.69s/it][A  0%|          | 1/8253 [00:03<8:27:44,  3.69s/it][A

  0%|          | 1/8253 [00:03<8:07:42,  3.55s/it][A  0%|          | 1/8253 [00:03<8:27:47,  3.69s/it][A
  0%|          | 2/8253 [00:05<6:03:38,  2.64s/it][A
  0%|          | 2/8253 [00:05<6:03:36,  2.64s/it][A
  0%|          | 2/8253 [00:05<6:04:02,  2.65s/it][A

  0%|          | 2/8253 [00:05<5:55:55,  2.59s/it][A  0%|          | 2/8253 [00:05<6:04:12,  2.65s/it]
[A  0%|          | 2/8253 [00:05<6:04:22,  2.65s/it][A
  0%|          | 3/8253 [00:07<5:11:58,  2.27s/it][A
  0%|          | 3/8253 [00:07<5:16:57,  2.31s/it][A
  0%|          | 3/8253 [00:07<5:17:10,  2.31s/it][A
  0%|          | 3/8253 [00:07<5:17:28,  2.31s/it][A
  0%|          | 3/8253 [00:07<5:17:30,  2.31s/it][A
  0%|          | 3/8253 [00:07<5:17:36,  2.31s/it][A
  0%|          | 4/8253 [00:09<5:00:12,  2.18s/it][A
  0%|          | 4/8253 [00:09<4:57:45,  2.17s/it][A
  0%|          | 4/8253 [00:09<5:00:20,  2.18s/it][A
  0%|          | 4/8253 [00:09<5:00:48,  2.19s/it][A
  0%|          | 4/8253 [00:09<5:00:50,  2.19s/it][A
  0%|          | 4/8253 [00:09<5:01:06,  2.19s/it][A
  0%|          | 5/8253 [00:11<4:48:58,  2.10s/it][A
  0%|          | 5/8253 [00:11<4:49:02,  2.10s/it][A
  0%|          | 5/8253 [00:11<4:49:16,  2.10s/it][A
  0%|          | 5/8253 [00:11<4:47:44,  2.09s/it][A
  0%|          | 5/8253 [00:11<4:49:17,  2.10s/it][A
  0%|          | 5/8253 [00:11<4:49:24,  2.11s/it][A
  0%|          | 6/8253 [00:13<4:44:40,  2.07s/it][A
  0%|          | 6/8253 [00:13<4:44:51,  2.07s/it][A
  0%|          | 6/8253 [00:13<4:45:00,  2.07s/it][A

  0%|          | 6/8253 [00:13<4:44:49,  2.07s/it][A  0%|          | 6/8253 [00:13<4:44:54,  2.07s/it][A
  0%|          | 6/8253 [00:13<4:44:03,  2.07s/it][A
  0%|          | 7/8253 [00:15<4:38:43,  2.03s/it][A
  0%|          | 7/8253 [00:15<4:38:12,  2.02s/it][A
  0%|          | 7/8253 [00:15<4:38:56,  2.03s/it][A

  0%|          | 7/8253 [00:15<4:39:28,  2.03s/it][A  0%|          | 7/8253 [00:15<4:39:32,  2.03s/it][A
  0%|          | 7/8253 [00:15<4:39:16,  2.03s/it][A
  0%|          | 8/8253 [00:17<4:36:33,  2.01s/it][A
  0%|          | 8/8253 [00:17<4:36:04,  2.01s/it][A
  0%|          | 8/8253 [00:17<4:36:44,  2.01s/it][A
  0%|          | 8/8253 [00:17<4:36:38,  2.01s/it][A
  0%|          | 8/8253 [00:17<4:37:01,  2.02s/it][A
  0%|          | 8/8253 [00:17<4:37:00,  2.02s/it][A
  0%|          | 9/8253 [00:19<4:35:41,  2.01s/it][A
  0%|          | 9/8253 [00:19<4:35:56,  2.01s/it][A
  0%|          | 9/8253 [00:19<4:35:42,  2.01s/it][A
  0%|          | 9/8253 [00:19<4:36:14,  2.01s/it][A
  0%|          | 9/8253 [00:19<4:36:02,  2.01s/it][A
  0%|          | 9/8253 [00:19<4:36:09,  2.01s/it][A
  0%|          | 10/8253 [00:21<4:36:01,  2.01s/it][A
  0%|          | 10/8253 [00:21<4:36:15,  2.01s/it][A
  0%|          | 10/8253 [00:21<4:36:33,  2.01s/it][A

  0%|          | 10/8253 [00:21<4:36:24,  2.01s/it][A  0%|          | 10/8253 [00:21<4:36:51,  2.02s/it][A
  0%|          | 10/8253 [00:21<4:36:35,  2.01s/it][A
  0%|          | 11/8253 [00:23<4:33:46,  1.99s/it][A
  0%|          | 11/8253 [00:23<4:33:42,  1.99s/it][A
  0%|          | 11/8253 [00:23<4:34:07,  2.00s/it][A
  0%|          | 11/8253 [00:23<4:34:25,  2.00s/it][A
  0%|          | 11/8253 [00:23<4:33:57,  1.99s/it][A
  0%|          | 11/8253 [00:23<4:34:20,  2.00s/it][A
  0%|          | 12/8253 [00:25<4:33:27,  1.99s/it][A

  0%|          | 12/8253 [00:25<4:33:52,  1.99s/it][A  0%|          | 12/8253 [00:25<4:33:31,  1.99s/it][A
  0%|          | 12/8253 [00:25<4:33:52,  1.99s/it][A
  0%|          | 12/8253 [00:25<4:33:52,  1.99s/it][A
  0%|          | 12/8253 [00:25<4:33:50,  1.99s/it][A
  0%|          | 13/8253 [00:27<4:31:55,  1.98s/it][A
  0%|          | 13/8253 [00:27<4:32:15,  1.98s/it][A
  0%|          | 13/8253 [00:27<4:32:19,  1.98s/it][A
  0%|          | 13/8253 [00:27<4:32:13,  1.98s/it][A
  0%|          | 13/8253 [00:27<4:32:36,  1.99s/it][A
  0%|          | 13/8253 [00:27<4:32:32,  1.98s/it][A
  0%|          | 14/8253 [00:29<4:40:02,  2.04s/it][A
  0%|          | 14/8253 [00:29<4:40:04,  2.04s/it][A
  0%|          | 14/8253 [00:29<4:40:04,  2.04s/it][A

  0%|          | 14/8253 [00:29<4:40:32,  2.04s/it]  0%|          | 14/8253 [00:29<4:40:16,  2.04s/it][A[A
  0%|          | 14/8253 [00:29<4:40:20,  2.04s/it][A
  0%|          | 15/8253 [00:31<4:40:44,  2.04s/it][A
  0%|          | 15/8253 [00:31<4:41:39,  2.05s/it][A
  0%|          | 15/8253 [00:31<4:41:30,  2.05s/it][A
  0%|          | 15/8253 [00:31<4:41:47,  2.05s/it][A

  0%|          | 15/8253 [00:31<4:41:44,  2.05s/it][A  0%|          | 15/8253 [00:31<4:42:00,  2.05s/it][A
  0%|          | 16/8253 [00:33<4:41:22,  2.05s/it][A
  0%|          | 16/8253 [00:33<4:41:45,  2.05s/it][A
  0%|          | 16/8253 [00:33<4:41:36,  2.05s/it][A
  0%|          | 16/8253 [00:33<4:41:45,  2.05s/it][A
  0%|          | 16/8253 [00:33<4:42:17,  2.06s/it][A
  0%|          | 16/8253 [00:33<4:42:03,  2.05s/it][A
  0%|          | 17/8253 [00:35<4:40:01,  2.04s/it][A
  0%|          | 17/8253 [00:35<4:40:17,  2.04s/it][A
  0%|          | 17/8253 [00:35<4:40:33,  2.04s/it][A
  0%|          | 17/8253 [00:35<4:40:30,  2.04s/it][A
  0%|          | 17/8253 [00:35<4:40:28,  2.04s/it][A
  0%|          | 17/8253 [00:35<4:40:47,  2.05s/it][A
  0%|          | 18/8253 [00:37<4:38:57,  2.03s/it][A

  0%|          | 18/8253 [00:37<4:39:02,  2.03s/it][A  0%|          | 18/8253 [00:37<4:39:23,  2.04s/it][A
  0%|          | 18/8253 [00:37<4:39:27,  2.04s/it][A
  0%|          | 18/8253 [00:37<4:39:12,  2.03s/it][A
  0%|          | 18/8253 [00:37<4:39:24,  2.04s/it][A
  0%|          | 19/8253 [00:39<4:38:19,  2.03s/it][A
  0%|          | 19/8253 [00:39<4:38:29,  2.03s/it][A
  0%|          | 19/8253 [00:39<4:38:41,  2.03s/it][A
  0%|          | 19/8253 [00:39<4:39:13,  2.03s/it][A
  0%|          | 19/8253 [00:39<4:39:18,  2.04s/it][A
  0%|          | 19/8253 [00:39<4:39:11,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:18,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:28,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:36,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:48,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:57,  2.03s/it][A
  0%|          | 20/8253 [00:41<4:38:52,  2.03s/it][A
  0%|          | 21/8253 [00:43<4:37:56,  2.03s/it][A
  0%|          | 21/8253 [00:43<4:38:04,  2.03s/it][A
  0%|          | 21/8253 [00:43<4:38:02,  2.03s/it][A

  0%|          | 21/8253 [00:43<4:38:17,  2.03s/it]
[A  0%|          | 21/8253 [00:43<4:38:31,  2.03s/it]  0%|          | 21/8253 [00:43<4:38:30,  2.03s/it][A[A
  0%|          | 22/8253 [00:45<4:35:00,  2.00s/it][A
  0%|          | 22/8253 [00:45<4:35:12,  2.01s/it][A

  0%|          | 22/8253 [00:45<4:35:31,  2.01s/it][A  0%|          | 22/8253 [00:45<4:35:36,  2.01s/it][A
  0%|          | 22/8253 [00:45<4:35:24,  2.01s/it][A
  0%|          | 22/8253 [00:45<4:35:35,  2.01s/it][A
  0%|          | 23/8253 [00:47<4:34:48,  2.00s/it][A
  0%|          | 23/8253 [00:47<4:34:48,  2.00s/it][A
  0%|          | 23/8253 [00:47<4:34:45,  2.00s/it][A
  0%|          | 23/8253 [00:47<4:34:53,  2.00s/it][A
  0%|          | 23/8253 [00:47<4:35:15,  2.01s/it][A
  0%|          | 23/8253 [00:47<4:34:57,  2.00s/it][A
  0%|          | 24/8253 [00:49<4:35:51,  2.01s/it][A

  0%|          | 24/8253 [00:49<4:36:09,  2.01s/it][A  0%|          | 24/8253 [00:49<4:36:14,  2.01s/it][A
  0%|          | 24/8253 [00:49<4:36:26,  2.02s/it][A

  0%|          | 24/8253 [00:49<4:36:17,  2.01s/it][A  0%|          | 24/8253 [00:49<4:36:28,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:32,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:31,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:33,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:34,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:44,  2.02s/it][A
  0%|          | 25/8253 [00:51<4:36:55,  2.02s/it][A
  0%|          | 26/8253 [00:53<4:36:26,  2.02s/it][A
  0%|          | 26/8253 [00:53<4:36:27,  2.02s/it][A
  0%|          | 26/8253 [00:53<4:36:30,  2.02s/it][A


  0%|          | 26/8253 [00:53<4:36:51,  2.02s/it][A  0%|          | 26/8253 [00:53<4:36:57,  2.02s/it][A  0%|          | 26/8253 [00:53<4:36:51,  2.02s/it][A
  0%|          | 27/8253 [00:55<4:33:30,  1.99s/it][A
  0%|          | 27/8253 [00:55<4:33:23,  1.99s/it][A
  0%|          | 27/8253 [00:55<4:33:50,  2.00s/it][A
  0%|          | 27/8253 [00:55<4:33:35,  2.00s/it][A
  0%|          | 27/8253 [00:55<4:33:41,  2.00s/it][A
  0%|          | 27/8253 [00:55<4:33:58,  2.00s/it][A
  0%|          | 28/8253 [00:57<4:33:06,  1.99s/it][A
  0%|          | 28/8253 [00:57<4:33:16,  1.99s/it][A
  0%|          | 28/8253 [00:57<4:33:15,  1.99s/it][A
  0%|          | 28/8253 [00:57<4:33:15,  1.99s/it][A
  0%|          | 28/8253 [00:57<4:33:19,  1.99s/it][A
  0%|          | 28/8253 [00:57<4:33:39,  2.00s/it][A
  0%|          | 29/8253 [00:59<4:31:22,  1.98s/it][A
  0%|          | 29/8253 [00:59<4:31:29,  1.98s/it][A
  0%|          | 29/8253 [00:59<4:31:37,  1.98s/it][A


  0%|          | 29/8253 [00:59<4:31:39,  1.98s/it][A  0%|          | 29/8253 [00:59<4:31:58,  1.98s/it]  0%|          | 29/8253 [00:59<4:31:48,  1.98s/it][A[A
  0%|          | 30/8253 [01:01<4:31:33,  1.98s/it][A


  0%|          | 30/8253 [01:01<4:31:54,  1.98s/it]  0%|          | 30/8253 [01:01<4:31:48,  1.98s/it][A[A  0%|          | 30/8253 [01:01<4:32:01,  1.98s/it][A
  0%|          | 30/8253 [01:01<4:32:00,  1.98s/it][A
  0%|          | 30/8253 [01:01<4:32:11,  1.99s/it][A
  0%|          | 31/8253 [01:03<4:31:02,  1.98s/it][A
  0%|          | 31/8253 [01:03<4:31:14,  1.98s/it][A
  0%|          | 31/8253 [01:03<4:31:18,  1.98s/it][A

  0%|          | 31/8253 [01:03<4:31:29,  1.98s/it]  0%|          | 31/8253 [01:03<4:31:31,  1.98s/it][A[A
  0%|          | 31/8253 [01:03<4:31:41,  1.98s/it][A
  0%|          | 32/8253 [01:05<4:29:14,  1.97s/it][A
  0%|          | 32/8253 [01:05<4:29:36,  1.97s/it][A
  0%|          | 32/8253 [01:05<4:29:30,  1.97s/it][A
  0%|          | 32/8253 [01:05<4:29:37,  1.97s/it][A
  0%|          | 32/8253 [01:05<4:29:51,  1.97s/it][A
  0%|          | 32/8253 [01:05<4:29:52,  1.97s/it][A
  0%|          | 33/8253 [01:07<4:29:34,  1.97s/it][A
  0%|          | 33/8253 [01:07<4:29:44,  1.97s/it][A
  0%|          | 33/8253 [01:07<4:29:51,  1.97s/it][A


  0%|          | 33/8253 [01:07<4:29:58,  1.97s/it][A  0%|          | 33/8253 [01:07<4:29:52,  1.97s/it][A  0%|          | 33/8253 [01:07<4:30:11,  1.97s/it][A
  0%|          | 34/8253 [01:09<4:30:09,  1.97s/it][A
  0%|          | 34/8253 [01:09<4:30:48,  1.98s/it][A
  0%|          | 34/8253 [01:09<4:31:06,  1.98s/it][A
  0%|          | 34/8253 [01:09<4:31:05,  1.98s/it][A
  0%|          | 34/8253 [01:09<4:31:28,  1.98s/it][A
  0%|          | 34/8253 [01:09<4:31:19,  1.98s/it][A
  0%|          | 35/8253 [01:11<4:29:30,  1.97s/it][A
  0%|          | 35/8253 [01:11<4:29:43,  1.97s/it][A
  0%|          | 35/8253 [01:11<4:29:36,  1.97s/it][A
  0%|          | 35/8253 [01:11<4:29:58,  1.97s/it][A
  0%|          | 35/8253 [01:11<4:29:55,  1.97s/it][A
  0%|          | 35/8253 [01:11<4:29:49,  1.97s/it][A
  0%|          | 36/8253 [01:13<4:31:19,  1.98s/it][A
  0%|          | 36/8253 [01:13<4:31:44,  1.98s/it][A
  0%|          | 36/8253 [01:13<4:31:53,  1.99s/it][A
  0%|          | 36/8253 [01:13<4:32:00,  1.99s/it][A
  0%|          | 36/8253 [01:13<4:32:06,  1.99s/it][A
  0%|          | 36/8253 [01:13<4:31:57,  1.99s/it][A
  0%|          | 37/8253 [01:15<4:31:23,  1.98s/it][A
  0%|          | 37/8253 [01:15<4:31:57,  1.99s/it][A


  0%|          | 37/8253 [01:15<4:32:15,  1.99s/it][A  0%|          | 37/8253 [01:15<4:32:04,  1.99s/it][A
  0%|          | 37/8253 [01:15<4:31:45,  1.98s/it][A  0%|          | 37/8253 [01:15<4:31:56,  1.99s/it][A
  0%|          | 38/8253 [01:17<4:29:28,  1.97s/it][A

  0%|          | 38/8253 [01:17<4:29:40,  1.97s/it][A  0%|          | 38/8253 [01:17<4:29:16,  1.97s/it][A
  0%|          | 38/8253 [01:17<4:29:25,  1.97s/it][A
  0%|          | 38/8253 [01:17<4:29:15,  1.97s/it][A
  0%|          | 38/8253 [01:17<4:29:34,  1.97s/it][A
  0%|          | 39/8253 [01:19<4:27:43,  1.96s/it][A
  0%|          | 39/8253 [01:19<4:28:19,  1.96s/it][A
  0%|          | 39/8253 [01:19<4:28:05,  1.96s/it][A
  0%|          | 39/8253 [01:19<4:28:25,  1.96s/it][A
  0%|          | 39/8253 [01:19<4:28:26,  1.96s/it][A
  0%|          | 39/8253 [01:19<4:28:21,  1.96s/it][A
  0%|          | 40/8253 [01:21<4:27:30,  1.95s/it][A
  0%|          | 40/8253 [01:21<4:27:49,  1.96s/it][A
  0%|          | 40/8253 [01:21<4:27:45,  1.96s/it][A
  0%|          | 40/8253 [01:21<4:27:54,  1.96s/it][A
  0%|          | 40/8253 [01:21<4:28:18,  1.96s/it][A
  0%|          | 40/8253 [01:21<4:28:22,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:27:45,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:27:55,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:27:50,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:28:02,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:28:00,  1.96s/it][A
  0%|          | 41/8253 [01:23<4:27:55,  1.96s/it][A
  1%|          | 42/8253 [01:25<4:28:57,  1.97s/it][A
  1%|          | 42/8253 [01:25<4:29:14,  1.97s/it][A

  1%|          | 42/8253 [01:25<4:29:42,  1.97s/it][A  1%|          | 42/8253 [01:25<4:29:42,  1.97s/it][A
  1%|          | 42/8253 [01:25<4:29:40,  1.97s/it][A
  1%|          | 42/8253 [01:25<4:29:47,  1.97s/it][A
  1%|          | 43/8253 [01:27<4:31:35,  1.98s/it][A
  1%|          | 43/8253 [01:27<4:31:58,  1.99s/it][A
  1%|          | 43/8253 [01:27<4:32:12,  1.99s/it][A

  1%|          | 43/8253 [01:27<4:32:14,  1.99s/it][A  1%|          | 43/8253 [01:27<4:32:13,  1.99s/it][A
  1%|          | 43/8253 [01:27<4:32:19,  1.99s/it][A
  1%|          | 44/8253 [01:29<4:29:33,  1.97s/it][A
  1%|          | 44/8253 [01:29<4:29:38,  1.97s/it][A
  1%|          | 44/8253 [01:29<4:29:32,  1.97s/it][A
  1%|          | 44/8253 [01:29<4:29:46,  1.97s/it][A
  1%|          | 44/8253 [01:29<4:29:45,  1.97s/it][A
  1%|          | 44/8253 [01:29<4:29:51,  1.97s/it][A
  1%|          | 45/8253 [01:31<4:38:13,  2.03s/it][A
  1%|          | 45/8253 [01:31<4:38:10,  2.03s/it][A
  1%|          | 45/8253 [01:31<4:38:14,  2.03s/it][A
  1%|          | 45/8253 [01:31<4:38:33,  2.04s/it][A
  1%|          | 45/8253 [01:31<4:38:24,  2.04s/it][A
  1%|          | 45/8253 [01:31<4:38:27,  2.04s/it][A
  1%|          | 46/8253 [01:33<4:32:36,  1.99s/it][A
  1%|          | 46/8253 [01:33<4:32:50,  1.99s/it][A
  1%|          | 46/8253 [01:33<4:32:56,  2.00s/it][A
  1%|          | 46/8253 [01:33<4:32:59,  2.00s/it][A
  1%|          | 46/8253 [01:33<4:33:06,  2.00s/it][A
  1%|          | 46/8253 [01:33<4:33:44,  2.00s/it][A
  1%|          | 47/8253 [01:35<4:30:37,  1.98s/it][A
  1%|          | 47/8253 [01:35<4:30:51,  1.98s/it][A
  1%|          | 47/8253 [01:35<4:30:57,  1.98s/it][A
  1%|          | 47/8253 [01:35<4:31:01,  1.98s/it][A
  1%|          | 47/8253 [01:35<4:30:52,  1.98s/it][A
  1%|          | 47/8253 [01:35<4:30:57,  1.98s/it][A
  1%|          | 48/8253 [01:37<4:29:10,  1.97s/it][A
  1%|          | 48/8253 [01:37<4:29:19,  1.97s/it][A
  1%|          | 48/8253 [01:37<4:29:56,  1.97s/it][A
  1%|          | 48/8253 [01:37<4:29:43,  1.97s/it][A
  1%|          | 48/8253 [01:37<4:29:53,  1.97s/it][A
  1%|          | 48/8253 [01:37<4:30:05,  1.98s/it][A
  1%|          | 49/8253 [01:39<4:28:03,  1.96s/it][A
  1%|          | 49/8253 [01:39<4:28:15,  1.96s/it][A
  1%|          | 49/8253 [01:39<4:28:23,  1.96s/it][A
  1%|          | 49/8253 [01:39<4:28:11,  1.96s/it][A
  1%|          | 49/8253 [01:39<4:28:20,  1.96s/it][A
  1%|          | 49/8253 [01:39<4:28:18,  1.96s/it][A
  1%|          | 50/8253 [01:40<4:26:25,  1.95s/it][A
  1%|          | 50/8253 [01:41<4:26:42,  1.95s/it][A
  1%|          | 50/8253 [01:41<4:26:29,  1.95s/it][A
  1%|          | 50/8253 [01:41<4:26:54,  1.95s/it][A
  1%|          | 50/8253 [01:41<4:26:41,  1.95s/it][A
  1%|          | 50/8253 [01:41<4:26:45,  1.95s/it][A
  1%|          | 51/8253 [01:43<4:25:35,  1.94s/it][A
  1%|          | 51/8253 [01:43<4:25:26,  1.94s/it][A
  1%|          | 51/8253 [01:43<4:26:08,  1.95s/it][A
  1%|          | 51/8253 [01:42<4:26:28,  1.95s/it][A
  1%|          | 51/8253 [01:43<4:26:13,  1.95s/it][A
  1%|          | 51/8253 [01:43<4:26:09,  1.95s/it][A
  1%|          | 52/8253 [01:44<4:25:05,  1.94s/it][A
  1%|          | 52/8253 [01:44<4:25:07,  1.94s/it][A
  1%|          | 52/8253 [01:44<4:25:19,  1.94s/it][A


  1%|          | 52/8253 [01:44<4:25:15,  1.94s/it][A  1%|          | 52/8253 [01:44<4:25:31,  1.94s/it][A  1%|          | 52/8253 [01:44<4:25:32,  1.94s/it][A
  1%|          | 53/8253 [01:46<4:25:33,  1.94s/it][A
  1%|          | 53/8253 [01:46<4:25:59,  1.95s/it][A
  1%|          | 53/8253 [01:46<4:26:03,  1.95s/it][A
  1%|          | 53/8253 [01:46<4:26:19,  1.95s/it][A
  1%|          | 53/8253 [01:46<4:26:08,  1.95s/it][A
  1%|          | 53/8253 [01:46<4:26:35,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:01,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:19,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:25,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:23,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:25,  1.95s/it][A
  1%|          | 54/8253 [01:48<4:26:52,  1.95s/it][A
  1%|          | 55/8253 [01:50<4:26:01,  1.95s/it][A
  1%|          | 55/8253 [01:50<4:26:31,  1.95s/it][A
  1%|          | 55/8253 [01:50<4:26:48,  1.95s/it][A

  1%|          | 55/8253 [01:50<4:26:53,  1.95s/it][A  1%|          | 55/8253 [01:50<4:26:43,  1.95s/it][A
  1%|          | 55/8253 [01:50<4:26:42,  1.95s/it][A
  1%|          | 56/8253 [01:52<4:26:58,  1.95s/it][A
  1%|          | 56/8253 [01:52<4:27:29,  1.96s/it][A
  1%|          | 56/8253 [01:52<4:27:22,  1.96s/it][A

  1%|          | 56/8253 [01:52<4:27:26,  1.96s/it][A  1%|          | 56/8253 [01:52<4:27:48,  1.96s/it][A
  1%|          | 56/8253 [01:52<4:27:31,  1.96s/it][A
  1%|          | 57/8253 [01:54<4:26:42,  1.95s/it][A
  1%|          | 57/8253 [01:54<4:27:00,  1.95s/it][A
  1%|          | 57/8253 [01:54<4:27:25,  1.96s/it][A

  1%|          | 57/8253 [01:54<4:27:21,  1.96s/it][A  1%|          | 57/8253 [01:54<4:27:19,  1.96s/it][A
  1%|          | 57/8253 [01:54<4:27:07,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:27:22,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:27:48,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:27:43,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:27:55,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:27:43,  1.96s/it][A
  1%|          | 58/8253 [01:56<4:28:17,  1.96s/it][A
  1%|          | 59/8253 [01:58<4:26:57,  1.95s/it][A
  1%|          | 59/8253 [01:58<4:27:17,  1.96s/it][A
  1%|          | 59/8253 [01:58<4:27:15,  1.96s/it][A
  1%|          | 59/8253 [01:58<4:27:08,  1.96s/it][A
  1%|          | 59/8253 [01:58<4:27:40,  1.96s/it][A
  1%|          | 59/8253 [01:58<4:27:29,  1.96s/it][A
  1%|          | 60/8253 [02:00<4:26:22,  1.95s/it][A
  1%|          | 60/8253 [02:00<4:26:41,  1.95s/it][A
  1%|          | 60/8253 [02:00<4:26:39,  1.95s/it][A
  1%|          | 60/8253 [02:00<4:26:47,  1.95s/it][A
  1%|          | 60/8253 [02:00<4:27:03,  1.96s/it][A
  1%|          | 60/8253 [02:00<4:26:55,  1.95s/it][A
  1%|          | 61/8253 [02:02<4:28:04,  1.96s/it][A
  1%|          | 61/8253 [02:02<4:27:55,  1.96s/it][A
  1%|          | 61/8253 [02:02<4:28:13,  1.96s/it][A
  1%|          | 61/8253 [02:02<4:28:47,  1.97s/it][A
  1%|          | 61/8253 [02:02<4:28:38,  1.97s/it][A
  1%|          | 61/8253 [02:02<4:28:27,  1.97s/it][A
  1%|          | 62/8253 [02:04<4:28:01,  1.96s/it][A
  1%|          | 62/8253 [02:04<4:28:02,  1.96s/it][A
  1%|          | 62/8253 [02:04<4:28:08,  1.96s/it][A

  1%|          | 62/8253 [02:04<4:28:10,  1.96s/it][A  1%|          | 62/8253 [02:04<4:28:20,  1.97s/it][A
  1%|          | 62/8253 [02:04<4:28:46,  1.97s/it][A
  1%|          | 63/8253 [02:06<4:27:43,  1.96s/it][A
  1%|          | 63/8253 [02:06<4:27:35,  1.96s/it][A
  1%|          | 63/8253 [02:06<4:27:52,  1.96s/it][A
  1%|          | 63/8253 [02:06<4:27:49,  1.96s/it][A
  1%|          | 63/8253 [02:06<4:28:09,  1.96s/it][A
  1%|          | 63/8253 [02:06<4:27:53,  1.96s/it][A
  1%|          | 64/8253 [02:08<4:28:37,  1.97s/it][A

  1%|          | 64/8253 [02:08<4:28:44,  1.97s/it][A  1%|          | 64/8253 [02:08<4:28:32,  1.97s/it][A
  1%|          | 64/8253 [02:08<4:28:46,  1.97s/it][A
  1%|          | 64/8253 [02:08<4:28:45,  1.97s/it][A
  1%|          | 64/8253 [02:08<4:28:38,  1.97s/it][A
  1%|          | 65/8253 [02:10<4:30:27,  1.98s/it][A
  1%|          | 65/8253 [02:10<4:30:19,  1.98s/it][A
  1%|          | 65/8253 [02:10<4:30:05,  1.98s/it][A
  1%|          | 65/8253 [02:10<4:30:29,  1.98s/it][A
  1%|          | 65/8253 [02:10<4:30:25,  1.98s/it][A
  1%|          | 65/8253 [02:10<4:30:26,  1.98s/it][A

  1%|          | 66/8253 [02:12<4:30:52,  1.99s/it]
[A  1%|          | 66/8253 [02:12<4:30:46,  1.98s/it][A  1%|          | 66/8253 [02:12<4:30:56,  1.99s/it][A
  1%|          | 66/8253 [02:12<4:30:55,  1.99s/it][A
  1%|          | 66/8253 [02:12<4:31:23,  1.99s/it][A
  1%|          | 66/8253 [02:12<4:31:26,  1.99s/it][A
  1%|          | 67/8253 [02:14<4:29:03,  1.97s/it][A
  1%|          | 67/8253 [02:14<4:29:24,  1.97s/it][A
  1%|          | 67/8253 [02:14<4:29:23,  1.97s/it][A
  1%|          | 67/8253 [02:14<4:29:27,  1.98s/it][A
  1%|          | 67/8253 [02:14<4:29:34,  1.98s/it][A
  1%|          | 67/8253 [02:14<4:29:38,  1.98s/it][A
  1%|          | 68/8253 [02:16<4:28:21,  1.97s/it][A
  1%|          | 68/8253 [02:16<4:28:37,  1.97s/it][A
  1%|          | 68/8253 [02:16<4:28:43,  1.97s/it][A
  1%|          | 68/8253 [02:16<4:28:47,  1.97s/it][A
  1%|          | 68/8253 [02:16<4:29:09,  1.97s/it][A
  1%|          | 68/8253 [02:16<4:29:23,  1.97s/it][A
  1%|          | 69/8253 [02:18<4:26:13,  1.95s/it][A
  1%|          | 69/8253 [02:18<4:26:49,  1.96s/it][A
  1%|          | 69/8253 [02:18<4:26:50,  1.96s/it][A
  1%|          | 69/8253 [02:18<4:26:56,  1.96s/it][A
  1%|          | 69/8253 [02:18<4:26:57,  1.96s/it][A
  1%|          | 69/8253 [02:18<4:27:05,  1.96s/it][A
  1%|          | 70/8253 [02:20<4:25:57,  1.95s/it][A
  1%|          | 70/8253 [02:20<4:26:17,  1.95s/it][A
  1%|          | 70/8253 [02:20<4:26:07,  1.95s/it][A
  1%|          | 70/8253 [02:20<4:26:12,  1.95s/it][A
  1%|          | 70/8253 [02:20<4:26:17,  1.95s/it][A
  1%|          | 70/8253 [02:20<4:26:23,  1.95s/it][A
  1%|          | 71/8253 [02:22<4:24:47,  1.94s/it][A
  1%|          | 71/8253 [02:22<4:24:53,  1.94s/it][A
  1%|          | 71/8253 [02:22<4:24:58,  1.94s/it][A
  1%|          | 71/8253 [02:22<4:25:11,  1.94s/it][A
  1%|          | 71/8253 [02:22<4:25:23,  1.95s/it][A
  1%|          | 71/8253 [02:22<4:25:15,  1.95s/it][A
  1%|          | 72/8253 [02:24<4:26:20,  1.95s/it][A

  1%|          | 72/8253 [02:24<4:26:28,  1.95s/it][A  1%|          | 72/8253 [02:24<4:26:31,  1.95s/it][A
  1%|          | 72/8253 [02:24<4:26:24,  1.95s/it][A
  1%|          | 72/8253 [02:24<4:26:46,  1.96s/it][A
  1%|          | 72/8253 [02:24<4:26:46,  1.96s/it][A
  1%|          | 73/8253 [02:26<4:24:56,  1.94s/it][A
  1%|          | 73/8253 [02:26<4:25:11,  1.95s/it][A
  1%|          | 73/8253 [02:26<4:25:05,  1.94s/it][A

  1%|          | 73/8253 [02:26<4:25:05,  1.94s/it][A  1%|          | 73/8253 [02:25<4:25:11,  1.95s/it][A
  1%|          | 73/8253 [02:26<4:25:20,  1.95s/it][A
  1%|          | 74/8253 [02:28<4:22:46,  1.93s/it][A
  1%|          | 74/8253 [02:28<4:23:03,  1.93s/it][A
  1%|          | 74/8253 [02:27<4:23:07,  1.93s/it][A
  1%|          | 74/8253 [02:28<4:23:12,  1.93s/it][A
  1%|          | 74/8253 [02:28<4:23:19,  1.93s/it][A
  1%|          | 74/8253 [02:28<4:23:33,  1.93s/it][A
  1%|          | 75/8253 [02:29<4:23:09,  1.93s/it][A
  1%|          | 75/8253 [02:29<4:23:15,  1.93s/it][A
  1%|          | 75/8253 [02:29<4:23:22,  1.93s/it][A
  1%|          | 75/8253 [02:29<4:23:49,  1.94s/it][A
  1%|          | 75/8253 [02:29<4:23:49,  1.94s/it][A
  1%|          | 75/8253 [02:29<4:23:55,  1.94s/it][A
  1%|          | 76/8253 [02:32<4:34:55,  2.02s/it][A
  1%|          | 76/8253 [02:32<4:35:14,  2.02s/it][A
  1%|          | 76/8253 [02:32<4:35:08,  2.02s/it][A
  1%|          | 76/8253 [02:32<4:35:22,  2.02s/it][A
  1%|          | 76/8253 [02:32<4:35:14,  2.02s/it][A
  1%|          | 76/8253 [02:32<4:35:21,  2.02s/it][A
  1%|          | 77/8253 [02:34<4:32:42,  2.00s/it][A
  1%|          | 77/8253 [02:33<4:33:12,  2.00s/it][A

  1%|          | 77/8253 [02:34<4:33:26,  2.01s/it][A  1%|          | 77/8253 [02:34<4:33:30,  2.01s/it][A
  1%|          | 77/8253 [02:34<4:33:37,  2.01s/it][A
  1%|          | 77/8253 [02:34<4:33:27,  2.01s/it][A
  1%|          | 78/8253 [02:36<4:32:30,  2.00s/it][A
  1%|          | 78/8253 [02:36<4:32:42,  2.00s/it][A
  1%|          | 78/8253 [02:36<4:32:42,  2.00s/it][A
  1%|          | 78/8253 [02:36<4:32:30,  2.00s/it][A
  1%|          | 78/8253 [02:35<4:32:49,  2.00s/it][A
  1%|          | 78/8253 [02:36<4:33:02,  2.00s/it][A
  1%|          | 79/8253 [02:38<4:33:13,  2.01s/it][A
  1%|          | 79/8253 [02:38<4:33:12,  2.01s/it][A
  1%|          | 79/8253 [02:38<4:33:34,  2.01s/it][A
  1%|          | 79/8253 [02:38<4:33:34,  2.01s/it][A

  1%|          | 79/8253 [02:38<4:33:35,  2.01s/it][A  1%|          | 79/8253 [02:38<4:33:21,  2.01s/it][A
  1%|          | 80/8253 [02:40<4:30:30,  1.99s/it][A
  1%|          | 80/8253 [02:40<4:30:50,  1.99s/it][A
  1%|          | 80/8253 [02:40<4:30:54,  1.99s/it][A
  1%|          | 80/8253 [02:40<4:31:25,  1.99s/it][A
  1%|          | 80/8253 [02:39<4:31:25,  1.99s/it][A
  1%|          | 80/8253 [02:40<4:31:24,  1.99s/it][A
  1%|          | 81/8253 [02:41<4:27:54,  1.97s/it][A
  1%|          | 81/8253 [02:42<4:28:20,  1.97s/it][A
  1%|          | 81/8253 [02:42<4:28:21,  1.97s/it][A
  1%|          | 81/8253 [02:42<4:28:24,  1.97s/it][A
  1%|          | 81/8253 [02:42<4:28:30,  1.97s/it][A
  1%|          | 81/8253 [02:42<4:28:36,  1.97s/it][A
  1%|          | 82/8253 [02:43<4:27:30,  1.96s/it][A
  1%|          | 82/8253 [02:43<4:27:33,  1.96s/it][A
  1%|          | 82/8253 [02:43<4:27:57,  1.97s/it][A
  1%|          | 82/8253 [02:43<4:27:59,  1.97s/it][A
  1%|          | 82/8253 [02:43<4:27:46,  1.97s/it][A
  1%|          | 82/8253 [02:43<4:28:11,  1.97s/it][A
  1%|          | 83/8253 [02:45<4:26:55,  1.96s/it][A
  1%|          | 83/8253 [02:45<4:26:53,  1.96s/it][A
  1%|          | 83/8253 [02:45<4:27:01,  1.96s/it][A
  1%|          | 83/8253 [02:45<4:27:06,  1.96s/it][A
  1%|          | 83/8253 [02:45<4:27:21,  1.96s/it][A
  1%|          | 83/8253 [02:45<4:27:23,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:26:33,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:27:01,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:26:51,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:26:57,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:27:02,  1.96s/it][A
  1%|          | 84/8253 [02:47<4:27:14,  1.96s/it][A
  1%|          | 85/8253 [02:49<4:25:52,  1.95s/it][A
  1%|          | 85/8253 [02:49<4:25:50,  1.95s/it][A
  1%|          | 85/8253 [02:49<4:26:01,  1.95s/it][A
  1%|          | 85/8253 [02:49<4:26:15,  1.96s/it][A
  1%|          | 85/8253 [02:49<4:26:10,  1.96s/it][A
  1%|          | 85/8253 [02:49<4:26:30,  1.96s/it][A
  1%|          | 86/8253 [02:51<4:24:56,  1.95s/it][A
  1%|          | 86/8253 [02:51<4:25:17,  1.95s/it][A
  1%|          | 86/8253 [02:51<4:25:14,  1.95s/it][A
  1%|          | 86/8253 [02:51<4:25:19,  1.95s/it][A
  1%|          | 86/8253 [02:51<4:25:28,  1.95s/it][A
  1%|          | 86/8253 [02:51<4:25:27,  1.95s/it][A
  1%|          | 87/8253 [02:53<4:23:24,  1.94s/it][A
  1%|          | 87/8253 [02:53<4:23:36,  1.94s/it][A
  1%|          | 87/8253 [02:53<4:23:47,  1.94s/it][A
  1%|          | 87/8253 [02:53<4:23:47,  1.94s/it][A

  1%|          | 87/8253 [02:53<4:24:02,  1.94s/it][A  1%|          | 87/8253 [02:53<4:23:58,  1.94s/it][A

  1%|          | 88/8253 [02:55<4:24:45,  1.95s/it][A  1%|          | 88/8253 [02:55<4:24:37,  1.94s/it][A
  1%|          | 88/8253 [02:55<4:25:01,  1.95s/it][A
  1%|          | 88/8253 [02:55<4:25:03,  1.95s/it][A
  1%|          | 88/8253 [02:55<4:25:15,  1.95s/it][A
  1%|          | 88/8253 [02:55<4:25:08,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:24:52,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:24:59,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:25:15,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:25:10,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:25:20,  1.95s/it][A
  1%|          | 89/8253 [02:57<4:25:22,  1.95s/it][A
  1%|          | 90/8253 [02:59<4:24:30,  1.94s/it][A
  1%|          | 90/8253 [02:59<4:24:48,  1.95s/it][A
  1%|          | 90/8253 [02:59<4:24:51,  1.95s/it][A
  1%|          | 90/8253 [02:59<4:25:00,  1.95s/it][A
  1%|          | 90/8253 [02:59<4:25:08,  1.95s/it][A
  1%|          | 90/8253 [02:59<4:25:25,  1.95s/it][A
  1%|          | 91/8253 [03:01<4:24:41,  1.95s/it][A
  1%|          | 91/8253 [03:01<4:24:44,  1.95s/it][A
  1%|          | 91/8253 [03:01<4:24:44,  1.95s/it][A


  1%|          | 91/8253 [03:01<4:24:56,  1.95s/it]  1%|          | 91/8253 [03:01<4:25:06,  1.95s/it][A[A  1%|          | 91/8253 [03:01<4:24:57,  1.95s/it][A
  1%|          | 92/8253 [03:03<4:26:27,  1.96s/it][A
  1%|          | 92/8253 [03:03<4:26:28,  1.96s/it][A
  1%|          | 92/8253 [03:03<4:26:41,  1.96s/it][A
  1%|          | 92/8253 [03:03<4:26:45,  1.96s/it][A
  1%|          | 92/8253 [03:03<4:26:50,  1.96s/it][A
  1%|          | 92/8253 [03:03<4:26:53,  1.96s/it][A
  1%|          | 93/8253 [03:05<4:24:24,  1.94s/it][A
  1%|          | 93/8253 [03:05<4:24:34,  1.95s/it][A
  1%|          | 93/8253 [03:05<4:24:28,  1.94s/it][A
  1%|          | 93/8253 [03:05<4:24:43,  1.95s/it][A
  1%|          | 93/8253 [03:05<4:24:46,  1.95s/it][A
  1%|          | 93/8253 [03:05<4:24:56,  1.95s/it][A
  1%|          | 94/8253 [03:07<4:23:04,  1.93s/it][A

  1%|          | 94/8253 [03:07<4:23:34,  1.94s/it][A  1%|          | 94/8253 [03:07<4:23:35,  1.94s/it][A

  1%|          | 94/8253 [03:07<4:23:34,  1.94s/it][A  1%|          | 94/8253 [03:07<4:23:37,  1.94s/it][A
  1%|          | 94/8253 [03:07<4:23:51,  1.94s/it][A
  1%|          | 95/8253 [03:09<4:24:16,  1.94s/it][A
  1%|          | 95/8253 [03:09<4:24:25,  1.94s/it][A
  1%|          | 95/8253 [03:09<4:24:54,  1.95s/it][A
  1%|          | 95/8253 [03:09<4:24:44,  1.95s/it][A
  1%|          | 95/8253 [03:09<4:24:48,  1.95s/it][A
  1%|          | 95/8253 [03:09<4:24:51,  1.95s/it][A
  1%|          | 96/8253 [03:11<4:28:43,  1.98s/it][A
  1%|          | 96/8253 [03:11<4:28:56,  1.98s/it][A

  1%|          | 96/8253 [03:11<4:29:01,  1.98s/it][A  1%|          | 96/8253 [03:11<4:29:12,  1.98s/it][A
  1%|          | 96/8253 [03:11<4:29:21,  1.98s/it][A
  1%|          | 96/8253 [03:11<4:29:07,  1.98s/it][A
  1%|          | 97/8253 [03:13<4:27:54,  1.97s/it][A
  1%|          | 97/8253 [03:13<4:28:10,  1.97s/it][A
  1%|          | 97/8253 [03:13<4:28:37,  1.98s/it][A
  1%|          | 97/8253 [03:13<4:28:36,  1.98s/it][A
  1%|          | 97/8253 [03:13<4:28:57,  1.98s/it][A
  1%|          | 97/8253 [03:13<4:28:56,  1.98s/it][A
  1%|          | 98/8253 [03:15<4:26:35,  1.96s/it][A
  1%|          | 98/8253 [03:15<4:26:25,  1.96s/it][A

  1%|          | 98/8253 [03:15<4:26:49,  1.96s/it][A  1%|          | 98/8253 [03:15<4:26:36,  1.96s/it][A
  1%|          | 98/8253 [03:15<4:26:33,  1.96s/it][A
  1%|          | 98/8253 [03:15<4:26:58,  1.96s/it][A
  1%|          | 99/8253 [03:17<4:25:11,  1.95s/it][A
  1%|          | 99/8253 [03:17<4:25:07,  1.95s/it][A
  1%|          | 99/8253 [03:17<4:25:30,  1.95s/it][A
  1%|          | 99/8253 [03:17<4:25:41,  1.96s/it][A
  1%|          | 99/8253 [03:17<4:25:34,  1.95s/it][A
  1%|          | 99/8253 [03:17<4:25:40,  1.95s/it][A
  1%|          | 100/8253 [03:19<4:24:59,  1.95s/it][A
  1%|          | 100/8253 [03:19<4:24:52,  1.95s/it][A
  1%|          | 100/8253 [03:19<4:25:26,  1.95s/it][A
  1%|          | 100/8253 [03:19<4:25:25,  1.95s/it][A
  1%|          | 100/8253 [03:18<4:25:41,  1.96s/it][A
  1%|          | 100/8253 [03:19<4:25:44,  1.96s/it][A
  1%|          | 101/8253 [03:21<4:27:08,  1.97s/it][A
  1%|          | 101/8253 [03:20<4:27:09,  1.97s/it][A
  1%|          | 101/8253 [03:21<4:27:35,  1.97s/it][A
  1%|          | 101/8253 [03:21<4:27:31,  1.97s/it][A
  1%|          | 101/8253 [03:21<4:27:32,  1.97s/it][A
  1%|          | 101/8253 [03:21<4:28:02,  1.97s/it][A
  1%|          | 102/8253 [03:23<4:27:39,  1.97s/it][A
  1%|          | 102/8253 [03:23<4:27:58,  1.97s/it][A
  1%|          | 102/8253 [03:23<4:28:12,  1.97s/it][A
  1%|          | 102/8253 [03:23<4:28:16,  1.97s/it][A
  1%|          | 102/8253 [03:22<4:28:30,  1.98s/it][A
  1%|          | 102/8253 [03:23<4:28:29,  1.98s/it][A
  1%|          | 103/8253 [03:24<4:27:50,  1.97s/it][A
  1%|          | 103/8253 [03:25<4:28:10,  1.97s/it][A
  1%|          | 103/8253 [03:25<4:28:18,  1.98s/it][A
  1%|          | 103/8253 [03:25<4:28:23,  1.98s/it][A
  1%|          | 103/8253 [03:25<4:28:18,  1.98s/it][A
  1%|          | 103/8253 [03:25<4:28:26,  1.98s/it][A
  1%|▏         | 104/8253 [03:26<4:23:05,  1.94s/it][A
  1%|▏         | 104/8253 [03:26<4:23:16,  1.94s/it][A
  1%|▏         | 104/8253 [03:26<4:23:33,  1.94s/it][A
  1%|▏         | 104/8253 [03:26<4:23:39,  1.94s/it][A
  1%|▏         | 104/8253 [03:26<4:23:35,  1.94s/it][A
  1%|▏         | 104/8253 [03:26<4:23:56,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:22:49,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:23:11,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:23:10,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:23:14,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:23:26,  1.94s/it][A
  1%|▏         | 105/8253 [03:28<4:23:14,  1.94s/it][A

  1%|▏         | 106/8253 [03:30<4:23:27,  1.94s/it][A  1%|▏         | 106/8253 [03:30<4:23:30,  1.94s/it][A
  1%|▏         | 106/8253 [03:30<4:23:44,  1.94s/it][A

  1%|▏         | 106/8253 [03:30<4:24:02,  1.94s/it][A  1%|▏         | 106/8253 [03:30<4:23:51,  1.94s/it][A
  1%|▏         | 106/8253 [03:30<4:24:06,  1.95s/it][A
  1%|▏         | 107/8253 [03:33<4:40:13,  2.06s/it][A
  1%|▏         | 107/8253 [03:33<4:40:32,  2.07s/it][A
  1%|▏         | 107/8253 [03:33<4:40:45,  2.07s/it][A
  1%|▏         | 107/8253 [03:33<4:40:42,  2.07s/it][A
  1%|▏         | 107/8253 [03:33<4:40:50,  2.07s/it][A
  1%|▏         | 107/8253 [03:33<4:41:11,  2.07s/it][A
  1%|▏         | 108/8253 [03:35<4:35:45,  2.03s/it][A
  1%|▏         | 108/8253 [03:35<4:35:47,  2.03s/it][A
  1%|▏         | 108/8253 [03:35<4:36:06,  2.03s/it][A
  1%|▏         | 108/8253 [03:35<4:36:03,  2.03s/it][A

  1%|▏         | 108/8253 [03:35<4:36:02,  2.03s/it][A  1%|▏         | 108/8253 [03:35<4:36:03,  2.03s/it][A
  1%|▏         | 109/8253 [03:37<4:32:02,  2.00s/it][A
  1%|▏         | 109/8253 [03:37<4:32:37,  2.01s/it][A
  1%|▏         | 109/8253 [03:37<4:32:51,  2.01s/it][A
  1%|▏         | 109/8253 [03:36<4:32:57,  2.01s/it][A
  1%|▏         | 109/8253 [03:37<4:32:36,  2.01s/it][A
  1%|▏         | 109/8253 [03:37<4:32:47,  2.01s/it][A
  1%|▏         | 110/8253 [03:39<4:28:30,  1.98s/it][A
  1%|▏         | 110/8253 [03:38<4:28:48,  1.98s/it][A

  1%|▏         | 110/8253 [03:39<4:28:43,  1.98s/it][A  1%|▏         | 110/8253 [03:39<4:29:06,  1.98s/it][A
  1%|▏         | 110/8253 [03:39<4:28:48,  1.98s/it][A
  1%|▏         | 110/8253 [03:39<4:29:12,  1.98s/it][A
  1%|▏         | 111/8253 [03:40<4:26:13,  1.96s/it][A
  1%|▏         | 111/8253 [03:40<4:26:27,  1.96s/it][A
  1%|▏         | 111/8253 [03:40<4:26:44,  1.97s/it][A
  1%|▏         | 111/8253 [03:40<4:26:49,  1.97s/it][A

  1%|▏         | 111/8253 [03:40<4:26:43,  1.97s/it][A  1%|▏         | 111/8253 [03:40<4:26:46,  1.97s/it][A
  1%|▏         | 112/8253 [03:42<4:22:55,  1.94s/it][A
  1%|▏         | 112/8253 [03:42<4:23:11,  1.94s/it][A
  1%|▏         | 112/8253 [03:42<4:23:55,  1.95s/it][A
  1%|▏         | 112/8253 [03:42<4:23:37,  1.94s/it][A
  1%|▏         | 112/8253 [03:42<4:23:42,  1.94s/it][A
  1%|▏         | 112/8253 [03:42<4:24:00,  1.95s/it][A
  1%|▏         | 113/8253 [03:44<4:23:11,  1.94s/it][A
  1%|▏         | 113/8253 [03:44<4:23:44,  1.94s/it][A

  1%|▏         | 113/8253 [03:44<4:24:04,  1.95s/it][A  1%|▏         | 113/8253 [03:44<4:24:22,  1.95s/it][A
  1%|▏         | 113/8253 [03:44<4:24:32,  1.95s/it][A
  1%|▏         | 113/8253 [03:44<4:24:08,  1.95s/it][A
  1%|▏         | 114/8253 [03:46<4:23:38,  1.94s/it][A
  1%|▏         | 114/8253 [03:46<4:23:38,  1.94s/it][A
  1%|▏         | 114/8253 [03:46<4:23:50,  1.95s/it][A
  1%|▏         | 114/8253 [03:46<4:24:10,  1.95s/it][A
  1%|▏         | 114/8253 [03:46<4:23:53,  1.95s/it][A
  1%|▏         | 114/8253 [03:46<4:24:13,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:14,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:28,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:49,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:49,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:43,  1.95s/it][A
  1%|▏         | 115/8253 [03:48<4:24:37,  1.95s/it][A
  1%|▏         | 116/8253 [03:50<4:23:25,  1.94s/it][A
  1%|▏         | 116/8253 [03:50<4:23:29,  1.94s/it][A
  1%|▏         | 116/8253 [03:50<4:23:41,  1.94s/it][A
  1%|▏         | 116/8253 [03:50<4:23:32,  1.94s/it][A
  1%|▏         | 116/8253 [03:50<4:24:13,  1.95s/it][A
  1%|▏         | 116/8253 [03:50<4:24:07,  1.95s/it][A
  1%|▏         | 117/8253 [03:52<4:26:48,  1.97s/it][A
  1%|▏         | 117/8253 [03:52<4:27:25,  1.97s/it][A
  1%|▏         | 117/8253 [03:52<4:27:10,  1.97s/it][A

  1%|▏         | 117/8253 [03:52<4:27:26,  1.97s/it][A  1%|▏         | 117/8253 [03:52<4:27:10,  1.97s/it][A
  1%|▏         | 117/8253 [03:52<4:27:15,  1.97s/it][A
  1%|▏         | 118/8253 [03:54<4:26:18,  1.96s/it][A
  1%|▏         | 118/8253 [03:54<4:26:39,  1.97s/it][A
  1%|▏         | 118/8253 [03:54<4:26:40,  1.97s/it][A
  1%|▏         | 118/8253 [03:54<4:26:19,  1.96s/it][A
  1%|▏         | 118/8253 [03:54<4:26:31,  1.97s/it][A
  1%|▏         | 118/8253 [03:54<4:26:57,  1.97s/it][A
  1%|▏         | 119/8253 [03:56<4:24:46,  1.95s/it][A
  1%|▏         | 119/8253 [03:56<4:24:51,  1.95s/it][A
  1%|▏         | 119/8253 [03:56<4:25:15,  1.96s/it][A

  1%|▏         | 119/8253 [03:56<4:25:39,  1.96s/it][A  1%|▏         | 119/8253 [03:56<4:25:30,  1.96s/it][A
  1%|▏         | 119/8253 [03:56<4:25:14,  1.96s/it][A
  1%|▏         | 120/8253 [03:58<4:24:33,  1.95s/it][A
  1%|▏         | 120/8253 [03:58<4:24:48,  1.95s/it][A
  1%|▏         | 120/8253 [03:58<4:25:04,  1.96s/it][A
  1%|▏         | 120/8253 [03:58<4:24:57,  1.95s/it][A
  1%|▏         | 120/8253 [03:58<4:25:03,  1.96s/it][A
  1%|▏         | 120/8253 [03:58<4:24:50,  1.95s/it][A
  1%|▏         | 121/8253 [04:00<4:26:59,  1.97s/it][A
  1%|▏         | 121/8253 [04:00<4:27:06,  1.97s/it][A

  1%|▏         | 121/8253 [04:00<4:27:17,  1.97s/it][A  1%|▏         | 121/8253 [04:00<4:27:15,  1.97s/it][A
  1%|▏         | 121/8253 [04:00<4:27:29,  1.97s/it][A
  1%|▏         | 121/8253 [04:00<4:27:18,  1.97s/it][A
  1%|▏         | 122/8253 [04:02<4:24:23,  1.95s/it][A
  1%|▏         | 122/8253 [04:02<4:24:28,  1.95s/it][A
  1%|▏         | 122/8253 [04:02<4:24:42,  1.95s/it][A
  1%|▏         | 122/8253 [04:02<4:24:53,  1.95s/it][A

  1%|▏         | 122/8253 [04:02<4:24:27,  1.95s/it][A  1%|▏         | 122/8253 [04:02<4:24:35,  1.95s/it][A
  1%|▏         | 123/8253 [04:04<4:27:31,  1.97s/it][A
  1%|▏         | 123/8253 [04:04<4:27:24,  1.97s/it][A
  1%|▏         | 123/8253 [04:04<4:27:58,  1.98s/it][A
  1%|▏         | 123/8253 [04:04<4:27:57,  1.98s/it][A
  1%|▏         | 123/8253 [04:04<4:28:06,  1.98s/it][A
  1%|▏         | 123/8253 [04:04<4:28:22,  1.98s/it][A
  2%|▏         | 124/8253 [04:06<4:26:14,  1.97s/it][A
  2%|▏         | 124/8253 [04:06<4:26:13,  1.96s/it][A
  2%|▏         | 124/8253 [04:06<4:26:40,  1.97s/it][A
  2%|▏         | 124/8253 [04:06<4:26:34,  1.97s/it][A
  2%|▏         | 124/8253 [04:06<4:26:39,  1.97s/it][A
  2%|▏         | 124/8253 [04:06<4:26:36,  1.97s/it][A

  2%|▏         | 125/8253 [04:08<4:23:57,  1.95s/it][A  2%|▏         | 125/8253 [04:08<4:24:15,  1.95s/it][A
  2%|▏         | 125/8253 [04:08<4:24:30,  1.95s/it][A
  2%|▏         | 125/8253 [04:08<4:24:37,  1.95s/it][A
  2%|▏         | 125/8253 [04:08<4:24:54,  1.96s/it][A
  2%|▏         | 125/8253 [04:08<4:24:46,  1.95s/it][A
  2%|▏         | 126/8253 [04:10<4:24:25,  1.95s/it][A
  2%|▏         | 126/8253 [04:10<4:24:26,  1.95s/it][A
  2%|▏         | 126/8253 [04:10<4:24:47,  1.95s/it][A


  2%|▏         | 126/8253 [04:10<4:24:35,  1.95s/it][A  2%|▏         | 126/8253 [04:10<4:25:00,  1.96s/it][A  2%|▏         | 126/8253 [04:10<4:24:49,  1.96s/it][A
  2%|▏         | 127/8253 [04:12<4:23:27,  1.95s/it][A
  2%|▏         | 127/8253 [04:12<4:23:37,  1.95s/it][A
  2%|▏         | 127/8253 [04:12<4:23:29,  1.95s/it][A

  2%|▏         | 127/8253 [04:12<4:23:52,  1.95s/it][A  2%|▏         | 127/8253 [04:12<4:23:44,  1.95s/it]
[A  2%|▏         | 127/8253 [04:12<4:23:54,  1.95s/it][A
  2%|▏         | 128/8253 [04:14<4:24:55,  1.96s/it][A

  2%|▏         | 128/8253 [04:14<4:24:50,  1.96s/it][A  2%|▏         | 128/8253 [04:14<4:24:50,  1.96s/it][A
  2%|▏         | 128/8253 [04:14<4:25:21,  1.96s/it][A
  2%|▏         | 128/8253 [04:14<4:25:14,  1.96s/it][A
  2%|▏         | 128/8253 [04:14<4:25:12,  1.96s/it][A
  2%|▏         | 129/8253 [04:15<4:24:28,  1.95s/it][A
  2%|▏         | 129/8253 [04:16<4:24:40,  1.95s/it][A
  2%|▏         | 129/8253 [04:16<4:24:38,  1.95s/it][A
  2%|▏         | 129/8253 [04:16<4:25:13,  1.96s/it][A
  2%|▏         | 129/8253 [04:16<4:25:21,  1.96s/it][A
  2%|▏         | 129/8253 [04:16<4:25:27,  1.96s/it][A
  2%|▏         | 130/8253 [04:17<4:25:39,  1.96s/it][A
  2%|▏         | 130/8253 [04:18<4:25:50,  1.96s/it][A
  2%|▏         | 130/8253 [04:18<4:25:40,  1.96s/it][A
  2%|▏         | 130/8253 [04:18<4:25:42,  1.96s/it][A
  2%|▏         | 130/8253 [04:18<4:26:04,  1.97s/it][A
  2%|▏         | 130/8253 [04:18<4:26:13,  1.97s/it][A
  2%|▏         | 131/8253 [04:20<4:24:21,  1.95s/it][A
  2%|▏         | 131/8253 [04:20<4:24:27,  1.95s/it][A
  2%|▏         | 131/8253 [04:20<4:24:29,  1.95s/it][A

  2%|▏         | 131/8253 [04:19<4:24:59,  1.96s/it][A  2%|▏         | 131/8253 [04:20<4:24:44,  1.96s/it][A
  2%|▏         | 131/8253 [04:20<4:24:57,  1.96s/it][A
  2%|▏         | 132/8253 [04:22<4:25:46,  1.96s/it][A

  2%|▏         | 132/8253 [04:22<4:26:07,  1.97s/it][A  2%|▏         | 132/8253 [04:21<4:26:16,  1.97s/it][A
  2%|▏         | 132/8253 [04:22<4:26:23,  1.97s/it][A

  2%|▏         | 132/8253 [04:22<4:26:27,  1.97s/it][A  2%|▏         | 132/8253 [04:22<4:26:17,  1.97s/it][A
  2%|▏         | 133/8253 [04:23<4:24:04,  1.95s/it][A
  2%|▏         | 133/8253 [04:23<4:23:41,  1.95s/it][A
  2%|▏         | 133/8253 [04:23<4:24:08,  1.95s/it][A
  2%|▏         | 133/8253 [04:23<4:24:09,  1.95s/it][A
  2%|▏         | 133/8253 [04:23<4:24:11,  1.95s/it][A
  2%|▏         | 133/8253 [04:23<4:24:15,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:23:32,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:23:32,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:23:50,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:23:57,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:23:49,  1.95s/it][A
  2%|▏         | 134/8253 [04:25<4:24:25,  1.95s/it][A
  2%|▏         | 135/8253 [04:27<4:23:52,  1.95s/it][A
  2%|▏         | 135/8253 [04:27<4:24:06,  1.95s/it][A
  2%|▏         | 135/8253 [04:27<4:24:01,  1.95s/it][A
  2%|▏         | 135/8253 [04:27<4:24:10,  1.95s/it][A
  2%|▏         | 135/8253 [04:27<4:24:38,  1.96s/it][A
  2%|▏         | 135/8253 [04:27<4:24:43,  1.96s/it][A
  2%|▏         | 136/8253 [04:29<4:22:21,  1.94s/it][A
  2%|▏         | 136/8253 [04:29<4:23:09,  1.95s/it][A
  2%|▏         | 136/8253 [04:29<4:22:49,  1.94s/it][A
  2%|▏         | 136/8253 [04:29<4:22:54,  1.94s/it][A
  2%|▏         | 136/8253 [04:29<4:22:59,  1.94s/it][A
  2%|▏         | 136/8253 [04:29<4:23:10,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:23:33,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:23:36,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:23:42,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:24:06,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:23:53,  1.95s/it][A
  2%|▏         | 137/8253 [04:31<4:23:54,  1.95s/it][A
  2%|▏         | 138/8253 [04:33<4:25:04,  1.96s/it][A
  2%|▏         | 138/8253 [04:33<4:25:19,  1.96s/it][A
  2%|▏         | 138/8253 [04:33<4:25:31,  1.96s/it][A
  2%|▏         | 138/8253 [04:33<4:25:26,  1.96s/it][A
  2%|▏         | 138/8253 [04:33<4:25:23,  1.96s/it][A
  2%|▏         | 138/8253 [04:33<4:25:42,  1.96s/it][A

  2%|▏         | 139/8253 [04:35<4:22:17,  1.94s/it][A  2%|▏         | 139/8253 [04:35<4:22:17,  1.94s/it][A
  2%|▏         | 139/8253 [04:35<4:22:17,  1.94s/it][A
  2%|▏         | 139/8253 [04:35<4:22:19,  1.94s/it][A
  2%|▏         | 139/8253 [04:35<4:22:27,  1.94s/it][A
  2%|▏         | 139/8253 [04:35<4:22:14,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:19,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:25,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:22,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:17,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:25,  1.94s/it][A
  2%|▏         | 140/8253 [04:37<4:22:33,  1.94s/it][A
  2%|▏         | 141/8253 [04:39<4:22:25,  1.94s/it][A
  2%|▏         | 141/8253 [04:39<4:22:24,  1.94s/it][A
  2%|▏         | 141/8253 [04:39<4:22:35,  1.94s/it][A

  2%|▏         | 141/8253 [04:39<4:22:57,  1.94s/it][A  2%|▏         | 141/8253 [04:39<4:22:57,  1.94s/it][A
  2%|▏         | 141/8253 [04:39<4:22:59,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:23:31,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:23:50,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:23:40,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:23:50,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:24:08,  1.95s/it][A
  2%|▏         | 142/8253 [04:41<4:23:59,  1.95s/it][A
  2%|▏         | 143/8253 [04:43<4:26:26,  1.97s/it][A
  2%|▏         | 143/8253 [04:43<4:26:39,  1.97s/it][A
  2%|▏         | 143/8253 [04:43<4:26:54,  1.97s/it][A
  2%|▏         | 143/8253 [04:43<4:27:03,  1.98s/it][A
  2%|▏         | 143/8253 [04:43<4:27:11,  1.98s/it][A
  2%|▏         | 143/8253 [04:43<4:27:06,  1.98s/it][A
  2%|▏         | 144/8253 [04:45<4:23:27,  1.95s/it][A
  2%|▏         | 144/8253 [04:45<4:23:42,  1.95s/it][A
  2%|▏         | 144/8253 [04:45<4:24:02,  1.95s/it][A
  2%|▏         | 144/8253 [04:45<4:24:05,  1.95s/it][A
  2%|▏         | 144/8253 [04:45<4:24:25,  1.96s/it][A
  2%|▏         | 144/8253 [04:45<4:24:21,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:24:35,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:24:59,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:25:09,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:25:21,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:25:19,  1.96s/it][A
  2%|▏         | 145/8253 [04:47<4:25:29,  1.96s/it][A
  2%|▏         | 146/8253 [04:49<4:23:40,  1.95s/it][A
  2%|▏         | 146/8253 [04:49<4:23:51,  1.95s/it][A
  2%|▏         | 146/8253 [04:49<4:23:48,  1.95s/it][A
  2%|▏         | 146/8253 [04:49<4:24:12,  1.96s/it][A
  2%|▏         | 146/8253 [04:49<4:24:08,  1.95s/it][A
  2%|▏         | 146/8253 [04:49<4:24:17,  1.96s/it][A
  2%|▏         | 147/8253 [04:51<4:22:04,  1.94s/it][A
  2%|▏         | 147/8253 [04:51<4:21:59,  1.94s/it][A
  2%|▏         | 147/8253 [04:51<4:22:03,  1.94s/it][A
  2%|▏         | 147/8253 [04:51<4:22:19,  1.94s/it][A
  2%|▏         | 147/8253 [04:51<4:22:22,  1.94s/it][A
  2%|▏         | 147/8253 [04:51<4:22:30,  1.94s/it][A
  2%|▏         | 148/8253 [04:53<4:23:49,  1.95s/it][A
  2%|▏         | 148/8253 [04:53<4:23:39,  1.95s/it][A
  2%|▏         | 148/8253 [04:53<4:23:47,  1.95s/it][A

  2%|▏         | 148/8253 [04:53<4:23:45,  1.95s/it][A  2%|▏         | 148/8253 [04:53<4:23:47,  1.95s/it][A
  2%|▏         | 148/8253 [04:53<4:23:58,  1.95s/it][A
  2%|▏         | 149/8253 [04:55<4:22:20,  1.94s/it][A
  2%|▏         | 149/8253 [04:55<4:22:18,  1.94s/it][A
  2%|▏         | 149/8253 [04:55<4:22:23,  1.94s/it][A
  2%|▏         | 149/8253 [04:55<4:22:23,  1.94s/it][A
  2%|▏         | 149/8253 [04:55<4:22:18,  1.94s/it][A
  2%|▏         | 149/8253 [04:55<4:22:39,  1.94s/it][A
  2%|▏         | 150/8253 [04:57<4:23:54,  1.95s/it][A
  2%|▏         | 150/8253 [04:57<4:24:04,  1.96s/it][A
  2%|▏         | 150/8253 [04:57<4:24:32,  1.96s/it][A
  2%|▏         | 150/8253 [04:57<4:24:16,  1.96s/it][A
  2%|▏         | 150/8253 [04:57<4:24:26,  1.96s/it][A
  2%|▏         | 150/8253 [04:57<4:24:37,  1.96s/it][A
  2%|▏         | 151/8253 [04:59<4:24:35,  1.96s/it][A
  2%|▏         | 151/8253 [04:59<4:25:04,  1.96s/it][A
  2%|▏         | 151/8253 [04:59<4:24:57,  1.96s/it][A
  2%|▏         | 151/8253 [04:59<4:25:09,  1.96s/it][A
  2%|▏         | 151/8253 [04:59<4:25:31,  1.97s/it][A
  2%|▏         | 151/8253 [04:58<4:25:22,  1.97s/it][A
  2%|▏         | 152/8253 [05:01<4:27:05,  1.98s/it][A
  2%|▏         | 152/8253 [05:01<4:27:28,  1.98s/it][A
  2%|▏         | 152/8253 [05:01<4:27:18,  1.98s/it][A
  2%|▏         | 152/8253 [05:01<4:27:23,  1.98s/it][A
  2%|▏         | 152/8253 [05:01<4:27:29,  1.98s/it][A
  2%|▏         | 152/8253 [05:01<4:27:48,  1.98s/it][A
  2%|▏         | 153/8253 [05:02<4:27:38,  1.98s/it][A
  2%|▏         | 153/8253 [05:03<4:28:05,  1.99s/it][A

  2%|▏         | 153/8253 [05:03<4:28:02,  1.99s/it][A  2%|▏         | 153/8253 [05:03<4:28:21,  1.99s/it][A
  2%|▏         | 153/8253 [05:03<4:28:13,  1.99s/it][A
  2%|▏         | 153/8253 [05:03<4:28:16,  1.99s/it][A
  2%|▏         | 154/8253 [05:05<4:27:07,  1.98s/it][A
  2%|▏         | 154/8253 [05:04<4:27:33,  1.98s/it][A

  2%|▏         | 154/8253 [05:05<4:27:46,  1.98s/it]  2%|▏         | 154/8253 [05:05<4:27:50,  1.98s/it][A[A
  2%|▏         | 154/8253 [05:05<4:27:48,  1.98s/it][A
  2%|▏         | 154/8253 [05:05<4:28:02,  1.99s/it][A
  2%|▏         | 155/8253 [05:06<4:25:09,  1.96s/it][A
  2%|▏         | 155/8253 [05:07<4:25:11,  1.96s/it][A
  2%|▏         | 155/8253 [05:07<4:25:19,  1.97s/it][A
  2%|▏         | 155/8253 [05:07<4:25:44,  1.97s/it][A
  2%|▏         | 155/8253 [05:07<4:25:27,  1.97s/it][A
  2%|▏         | 155/8253 [05:07<4:25:49,  1.97s/it][A
  2%|▏         | 156/8253 [05:08<4:23:00,  1.95s/it][A
  2%|▏         | 156/8253 [05:08<4:22:52,  1.95s/it][A
  2%|▏         | 156/8253 [05:08<4:23:35,  1.95s/it][A
  2%|▏         | 156/8253 [05:08<4:23:53,  1.96s/it][A
  2%|▏         | 156/8253 [05:08<4:23:55,  1.96s/it][A
  2%|▏         | 156/8253 [05:08<4:23:45,  1.95s/it][A
  2%|▏         | 157/8253 [05:10<4:24:36,  1.96s/it][A
  2%|▏         | 157/8253 [05:10<4:24:46,  1.96s/it][A
  2%|▏         | 157/8253 [05:10<4:24:36,  1.96s/it][A

  2%|▏         | 157/8253 [05:10<4:25:18,  1.97s/it][A  2%|▏         | 157/8253 [05:10<4:24:51,  1.96s/it][A
  2%|▏         | 157/8253 [05:10<4:25:01,  1.96s/it][A
  2%|▏         | 158/8253 [05:12<4:26:51,  1.98s/it][A
  2%|▏         | 158/8253 [05:12<4:27:19,  1.98s/it][A
  2%|▏         | 158/8253 [05:12<4:27:06,  1.98s/it][A
  2%|▏         | 158/8253 [05:12<4:27:20,  1.98s/it][A
  2%|▏         | 158/8253 [05:12<4:27:37,  1.98s/it][A
  2%|▏         | 158/8253 [05:12<4:27:46,  1.98s/it][A
  2%|▏         | 159/8253 [05:14<4:28:18,  1.99s/it][A
  2%|▏         | 159/8253 [05:14<4:28:19,  1.99s/it][A
  2%|▏         | 159/8253 [05:15<4:28:34,  1.99s/it][A
  2%|▏         | 159/8253 [05:15<4:28:45,  1.99s/it][A
  2%|▏         | 159/8253 [05:15<4:28:37,  1.99s/it][A
  2%|▏         | 159/8253 [05:14<4:29:02,  1.99s/it][A
  2%|▏         | 160/8253 [05:16<4:27:44,  1.98s/it][A
  2%|▏         | 160/8253 [05:16<4:27:43,  1.98s/it][A
  2%|▏         | 160/8253 [05:16<4:28:08,  1.99s/it][A
  2%|▏         | 160/8253 [05:16<4:28:12,  1.99s/it][A
  2%|▏         | 160/8253 [05:16<4:28:28,  1.99s/it][A
  2%|▏         | 160/8253 [05:16<4:28:23,  1.99s/it][A
  2%|▏         | 161/8253 [05:18<4:24:37,  1.96s/it][A
  2%|▏         | 161/8253 [05:18<4:25:09,  1.97s/it][A
  2%|▏         | 161/8253 [05:18<4:25:17,  1.97s/it][A
  2%|▏         | 161/8253 [05:18<4:25:19,  1.97s/it][A

  2%|▏         | 161/8253 [05:18<4:25:19,  1.97s/it][A  2%|▏         | 161/8253 [05:18<4:25:21,  1.97s/it][A
  2%|▏         | 162/8253 [05:20<4:23:50,  1.96s/it][A
  2%|▏         | 162/8253 [05:20<4:23:28,  1.95s/it][A
  2%|▏         | 162/8253 [05:20<4:23:44,  1.96s/it][A
  2%|▏         | 162/8253 [05:20<4:23:55,  1.96s/it][A
  2%|▏         | 162/8253 [05:20<4:24:02,  1.96s/it][A
  2%|▏         | 162/8253 [05:20<4:24:07,  1.96s/it][A
  2%|▏         | 163/8253 [05:22<4:23:02,  1.95s/it][A
  2%|▏         | 163/8253 [05:22<4:22:45,  1.95s/it][A
  2%|▏         | 163/8253 [05:22<4:22:52,  1.95s/it][A
  2%|▏         | 163/8253 [05:22<4:22:59,  1.95s/it][A
  2%|▏         | 163/8253 [05:22<4:23:11,  1.95s/it][A
  2%|▏         | 163/8253 [05:22<4:23:03,  1.95s/it][A
  2%|▏         | 164/8253 [05:24<4:20:28,  1.93s/it][A
  2%|▏         | 164/8253 [05:24<4:21:00,  1.94s/it][A
  2%|▏         | 164/8253 [05:24<4:20:38,  1.93s/it][A
  2%|▏         | 164/8253 [05:24<4:21:02,  1.94s/it][A
  2%|▏         | 164/8253 [05:24<4:21:07,  1.94s/it][A
  2%|▏         | 164/8253 [05:24<4:21:00,  1.94s/it][A
  2%|▏         | 165/8253 [05:26<4:20:29,  1.93s/it][A
  2%|▏         | 165/8253 [05:26<4:20:42,  1.93s/it][A
  2%|▏         | 165/8253 [05:26<4:20:31,  1.93s/it][A
  2%|▏         | 165/8253 [05:26<4:21:02,  1.94s/it][A

  2%|▏         | 165/8253 [05:26<4:20:53,  1.94s/it][A  2%|▏         | 165/8253 [05:26<4:20:47,  1.93s/it][A
  2%|▏         | 166/8253 [05:28<4:21:19,  1.94s/it][A
  2%|▏         | 166/8253 [05:28<4:21:56,  1.94s/it][A
  2%|▏         | 166/8253 [05:28<4:21:46,  1.94s/it][A
  2%|▏         | 166/8253 [05:28<4:21:45,  1.94s/it][A
  2%|▏         | 166/8253 [05:28<4:22:02,  1.94s/it][A
  2%|▏         | 166/8253 [05:28<4:22:07,  1.94s/it][A
  2%|▏         | 167/8253 [05:30<4:23:21,  1.95s/it][A
  2%|▏         | 167/8253 [05:30<4:23:26,  1.95s/it][A
  2%|▏         | 167/8253 [05:30<4:23:35,  1.96s/it][A
  2%|▏         | 167/8253 [05:30<4:23:35,  1.96s/it][A

  2%|▏         | 167/8253 [05:30<4:23:35,  1.96s/it][A  2%|▏         | 167/8253 [05:30<4:23:36,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:23:59,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:24:10,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:24:17,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:24:42,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:24:32,  1.96s/it][A
  2%|▏         | 168/8253 [05:32<4:24:35,  1.96s/it][A
  2%|▏         | 169/8253 [05:34<4:29:16,  2.00s/it][A
  2%|▏         | 169/8253 [05:34<4:29:32,  2.00s/it][A
  2%|▏         | 169/8253 [05:34<4:29:37,  2.00s/it][A
  2%|▏         | 169/8253 [05:34<4:29:41,  2.00s/it][A
  2%|▏         | 169/8253 [05:34<4:30:16,  2.01s/it][A
  2%|▏         | 169/8253 [05:34<4:30:06,  2.00s/it][A
  2%|▏         | 170/8253 [05:36<4:27:37,  1.99s/it][A
  2%|▏         | 170/8253 [05:36<4:27:48,  1.99s/it][A
  2%|▏         | 170/8253 [05:36<4:28:01,  1.99s/it][A
  2%|▏         | 170/8253 [05:36<4:28:05,  1.99s/it][A
  2%|▏         | 170/8253 [05:36<4:28:15,  1.99s/it][A
  2%|▏         | 170/8253 [05:36<4:28:04,  1.99s/it][A
  2%|▏         | 171/8253 [05:38<4:25:40,  1.97s/it][A

  2%|▏         | 171/8253 [05:38<4:25:54,  1.97s/it][A
  2%|▏         | 171/8253 [05:38<4:26:05,  1.98s/it][A  2%|▏         | 171/8253 [05:38<4:26:00,  1.97s/it][A
  2%|▏         | 171/8253 [05:38<4:25:56,  1.97s/it][A
  2%|▏         | 171/8253 [05:38<4:25:50,  1.97s/it][A
  2%|▏         | 172/8253 [05:40<4:24:07,  1.96s/it][A
  2%|▏         | 172/8253 [05:40<4:24:14,  1.96s/it][A
  2%|▏         | 172/8253 [05:40<4:24:37,  1.96s/it][A
  2%|▏         | 172/8253 [05:40<4:24:40,  1.97s/it][A
  2%|▏         | 172/8253 [05:40<4:24:52,  1.97s/it][A
  2%|▏         | 172/8253 [05:40<4:24:37,  1.96s/it][A
  2%|▏         | 173/8253 [05:42<4:23:15,  1.95s/it][A
  2%|▏         | 173/8253 [05:42<4:23:24,  1.96s/it][A
  2%|▏         | 173/8253 [05:42<4:23:39,  1.96s/it][A
  2%|▏         | 173/8253 [05:42<4:23:36,  1.96s/it][A
  2%|▏         | 173/8253 [05:42<4:23:40,  1.96s/it][A
  2%|▏         | 173/8253 [05:42<4:23:37,  1.96s/it][A
  2%|▏         | 174/8253 [05:44<4:24:25,  1.96s/it][A
  2%|▏         | 174/8253 [05:44<4:24:23,  1.96s/it][A
  2%|▏         | 174/8253 [05:44<4:24:18,  1.96s/it][A
  2%|▏         | 174/8253 [05:44<4:24:33,  1.96s/it][A
  2%|▏         | 174/8253 [05:44<4:24:54,  1.97s/it][A
  2%|▏         | 174/8253 [05:44<4:24:46,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:27,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:17,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:31,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:43,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:50,  1.97s/it][A
  2%|▏         | 175/8253 [05:46<4:25:38,  1.97s/it][A
  2%|▏         | 176/8253 [05:48<4:23:36,  1.96s/it][A
  2%|▏         | 176/8253 [05:48<4:23:38,  1.96s/it][A
  2%|▏         | 176/8253 [05:48<4:23:40,  1.96s/it][A
  2%|▏         | 176/8253 [05:48<4:23:58,  1.96s/it][A
  2%|▏         | 176/8253 [05:48<4:23:59,  1.96s/it][A
  2%|▏         | 176/8253 [05:48<4:24:09,  1.96s/it][A
  2%|▏         | 177/8253 [05:50<4:24:17,  1.96s/it][A
  2%|▏         | 177/8253 [05:50<4:24:20,  1.96s/it][A
  2%|▏         | 177/8253 [05:50<4:24:35,  1.97s/it][A
  2%|▏         | 177/8253 [05:50<4:24:37,  1.97s/it][A
  2%|▏         | 177/8253 [05:50<4:24:49,  1.97s/it][A
  2%|▏         | 177/8253 [05:50<4:24:49,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:24:41,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:24:48,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:25:09,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:25:04,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:25:10,  1.97s/it][A
  2%|▏         | 178/8253 [05:52<4:25:20,  1.97s/it][A
  2%|▏         | 179/8253 [05:53<4:21:35,  1.94s/it][A

  2%|▏         | 179/8253 [05:54<4:22:09,  1.95s/it][A  2%|▏         | 179/8253 [05:54<4:22:05,  1.95s/it][A
  2%|▏         | 179/8253 [05:54<4:21:57,  1.95s/it]
[A
  2%|▏         | 179/8253 [05:54<4:22:00,  1.95s/it][A  2%|▏         | 179/8253 [05:54<4:22:03,  1.95s/it][A
  2%|▏         | 180/8253 [05:56<4:20:32,  1.94s/it][A
  2%|▏         | 180/8253 [05:56<4:20:28,  1.94s/it][A
  2%|▏         | 180/8253 [05:56<4:20:55,  1.94s/it][A
  2%|▏         | 180/8253 [05:56<4:20:46,  1.94s/it][A
  2%|▏         | 180/8253 [05:55<4:21:08,  1.94s/it][A
  2%|▏         | 180/8253 [05:56<4:20:55,  1.94s/it][A
  2%|▏         | 181/8253 [05:57<4:21:09,  1.94s/it][A
  2%|▏         | 181/8253 [05:58<4:21:34,  1.94s/it][A

  2%|▏         | 181/8253 [05:58<4:21:39,  1.94s/it][A  2%|▏         | 181/8253 [05:58<4:21:29,  1.94s/it][A

  2%|▏         | 181/8253 [05:58<4:21:30,  1.94s/it][A  2%|▏         | 181/8253 [05:58<4:21:35,  1.94s/it][A
  2%|▏         | 182/8253 [05:59<4:21:51,  1.95s/it][A
  2%|▏         | 182/8253 [05:59<4:21:36,  1.94s/it][A
  2%|▏         | 182/8253 [05:59<4:21:46,  1.95s/it][A
  2%|▏         | 182/8253 [05:59<4:21:59,  1.95s/it][A
  2%|▏         | 182/8253 [05:59<4:22:17,  1.95s/it][A
  2%|▏         | 182/8253 [05:59<4:22:13,  1.95s/it][A
  2%|▏         | 183/8253 [06:01<4:21:07,  1.94s/it][A
  2%|▏         | 183/8253 [06:01<4:20:58,  1.94s/it][A
  2%|▏         | 183/8253 [06:01<4:21:16,  1.94s/it][A
  2%|▏         | 183/8253 [06:01<4:21:24,  1.94s/it][A

  2%|▏         | 183/8253 [06:01<4:21:18,  1.94s/it][A  2%|▏         | 183/8253 [06:01<4:21:12,  1.94s/it][A
  2%|▏         | 184/8253 [06:03<4:22:32,  1.95s/it][A
  2%|▏         | 184/8253 [06:03<4:22:38,  1.95s/it][A
  2%|▏         | 184/8253 [06:03<4:22:51,  1.95s/it][A
  2%|▏         | 184/8253 [06:03<4:22:52,  1.95s/it][A
  2%|▏         | 184/8253 [06:03<4:23:03,  1.96s/it][A
  2%|▏         | 184/8253 [06:03<4:23:19,  1.96s/it][A
  2%|▏         | 185/8253 [06:05<4:24:41,  1.97s/it][A
  2%|▏         | 185/8253 [06:05<4:25:09,  1.97s/it][A
  2%|▏         | 185/8253 [06:05<4:24:57,  1.97s/it][A
  2%|▏         | 185/8253 [06:05<4:25:11,  1.97s/it][A
  2%|▏         | 185/8253 [06:05<4:25:31,  1.97s/it][A
  2%|▏         | 185/8253 [06:05<4:25:40,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:01,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:14,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:12,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:22,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:12,  1.98s/it][A
  2%|▏         | 186/8253 [06:07<4:26:23,  1.98s/it][A
  2%|▏         | 187/8253 [06:09<4:25:10,  1.97s/it][A
  2%|▏         | 187/8253 [06:09<4:25:28,  1.97s/it][A
  2%|▏         | 187/8253 [06:09<4:25:54,  1.98s/it][A
  2%|▏         | 187/8253 [06:09<4:26:12,  1.98s/it][A
  2%|▏         | 187/8253 [06:09<4:25:58,  1.98s/it][A
  2%|▏         | 187/8253 [06:09<4:25:47,  1.98s/it][A
  2%|▏         | 188/8253 [06:11<4:25:27,  1.97s/it][A
  2%|▏         | 188/8253 [06:11<4:25:37,  1.98s/it][A

  2%|▏         | 188/8253 [06:11<4:25:52,  1.98s/it][A  2%|▏         | 188/8253 [06:11<4:25:54,  1.98s/it][A
  2%|▏         | 188/8253 [06:11<4:25:37,  1.98s/it][A
  2%|▏         | 188/8253 [06:11<4:25:51,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:25:59,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:26:01,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:26:28,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:26:31,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:26:43,  1.98s/it][A
  2%|▏         | 189/8253 [06:13<4:26:28,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:25:49,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:26:02,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:25:54,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:26:02,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:25:52,  1.98s/it][A
  2%|▏         | 190/8253 [06:15<4:26:02,  1.98s/it][A

  2%|▏         | 191/8253 [06:17<4:23:49,  1.96s/it][A  2%|▏         | 191/8253 [06:17<4:23:41,  1.96s/it][A
  2%|▏         | 191/8253 [06:17<4:23:54,  1.96s/it][A
  2%|▏         | 191/8253 [06:17<4:23:50,  1.96s/it][A
  2%|▏         | 191/8253 [06:17<4:23:42,  1.96s/it]
[A  2%|▏         | 191/8253 [06:17<4:23:46,  1.96s/it][A

  2%|▏         | 192/8253 [06:19<4:24:42,  1.97s/it][A  2%|▏         | 192/8253 [06:19<4:24:46,  1.97s/it][A
  2%|▏         | 192/8253 [06:19<4:24:41,  1.97s/it][A
  2%|▏         | 192/8253 [06:19<4:25:09,  1.97s/it][A

  2%|▏         | 192/8253 [06:19<4:25:13,  1.97s/it][A  2%|▏         | 192/8253 [06:19<4:25:05,  1.97s/it][A
  2%|▏         | 193/8253 [06:21<4:22:19,  1.95s/it][A
  2%|▏         | 193/8253 [06:21<4:22:21,  1.95s/it][A
  2%|▏         | 193/8253 [06:21<4:22:35,  1.95s/it][A
  2%|▏         | 193/8253 [06:21<4:22:43,  1.96s/it][A
  2%|▏         | 193/8253 [06:21<4:22:36,  1.95s/it][A
  2%|▏         | 193/8253 [06:21<4:22:36,  1.95s/it][A
  2%|▏         | 194/8253 [06:23<4:24:04,  1.97s/it][A
  2%|▏         | 194/8253 [06:23<4:24:18,  1.97s/it][A
  2%|▏         | 194/8253 [06:23<4:24:41,  1.97s/it][A
  2%|▏         | 194/8253 [06:23<4:24:37,  1.97s/it][A
  2%|▏         | 194/8253 [06:23<4:24:55,  1.97s/it][A
  2%|▏         | 194/8253 [06:23<4:24:44,  1.97s/it][A
  2%|▏         | 195/8253 [06:25<4:22:55,  1.96s/it][A
  2%|▏         | 195/8253 [06:25<4:23:20,  1.96s/it][A
  2%|▏         | 195/8253 [06:25<4:23:14,  1.96s/it][A
  2%|▏         | 195/8253 [06:25<4:23:46,  1.96s/it][A
  2%|▏         | 195/8253 [06:25<4:23:38,  1.96s/it][A
  2%|▏         | 195/8253 [06:25<4:23:36,  1.96s/it][A
  2%|▏         | 196/8253 [06:27<4:21:19,  1.95s/it][A
  2%|▏         | 196/8253 [06:27<4:21:47,  1.95s/it][A
  2%|▏         | 196/8253 [06:27<4:21:57,  1.95s/it]
[A  2%|▏         | 196/8253 [06:27<4:21:50,  1.95s/it][A
  2%|▏         | 196/8253 [06:27<4:21:59,  1.95s/it][A
  2%|▏         | 196/8253 [06:27<4:21:59,  1.95s/it][A
  2%|▏         | 197/8253 [06:29<4:21:44,  1.95s/it][A

  2%|▏         | 197/8253 [06:29<4:22:19,  1.95s/it][A  2%|▏         | 197/8253 [06:29<4:22:13,  1.95s/it][A

  2%|▏         | 197/8253 [06:29<4:22:36,  1.96s/it][A  2%|▏         | 197/8253 [06:29<4:22:22,  1.95s/it][A
  2%|▏         | 197/8253 [06:29<4:22:20,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:21:38,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:21:52,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:21:59,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:22:12,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:22:12,  1.95s/it][A
  2%|▏         | 198/8253 [06:31<4:22:33,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:22:28,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:22:49,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:22:52,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:22:53,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:22:53,  1.96s/it][A
  2%|▏         | 199/8253 [06:33<4:23:07,  1.96s/it][A
  2%|▏         | 200/8253 [06:35<4:29:12,  2.01s/it][A
  2%|▏         | 200/8253 [06:35<4:29:34,  2.01s/it][A
  2%|▏         | 200/8253 [06:35<4:29:43,  2.01s/it][A
  2%|▏         | 200/8253 [06:35<4:30:00,  2.01s/it][A
  2%|▏         | 200/8253 [06:35<4:30:01,  2.01s/it][A
  2%|▏         | 200/8253 [06:35<4:29:51,  2.01s/it][A
  2%|▏         | 201/8253 [06:37<4:28:04,  2.00s/it][A
  2%|▏         | 201/8253 [06:37<4:28:09,  2.00s/it][A
  2%|▏         | 201/8253 [06:37<4:28:32,  2.00s/it][A
  2%|▏         | 201/8253 [06:37<4:29:04,  2.01s/it][A

  2%|▏         | 201/8253 [06:37<4:29:05,  2.01s/it][A  2%|▏         | 201/8253 [06:37<4:29:15,  2.01s/it][A
  2%|▏         | 202/8253 [06:39<4:30:23,  2.02s/it][A
  2%|▏         | 202/8253 [06:39<4:30:12,  2.01s/it][A
  2%|▏         | 202/8253 [06:39<4:30:36,  2.02s/it][A
  2%|▏         | 202/8253 [06:39<4:30:50,  2.02s/it][A
  2%|▏         | 202/8253 [06:39<4:30:47,  2.02s/it][A
  2%|▏         | 202/8253 [06:39<4:31:00,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:30:51,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:31:16,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:31:07,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:31:39,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:31:16,  2.02s/it][A
  2%|▏         | 203/8253 [06:41<4:31:20,  2.02s/it][A
  2%|▏         | 204/8253 [06:43<4:28:33,  2.00s/it][A
  2%|▏         | 204/8253 [06:43<4:28:25,  2.00s/it][A
  2%|▏         | 204/8253 [06:43<4:29:04,  2.01s/it][A
  2%|▏         | 204/8253 [06:43<4:28:54,  2.00s/it][A
  2%|▏         | 204/8253 [06:43<4:28:57,  2.00s/it][A
  2%|▏         | 204/8253 [06:43<4:29:17,  2.01s/it][A
  2%|▏         | 205/8253 [06:45<4:28:47,  2.00s/it][A
  2%|▏         | 205/8253 [06:45<4:29:11,  2.01s/it][A
  2%|▏         | 205/8253 [06:45<4:28:49,  2.00s/it][A
  2%|▏         | 205/8253 [06:45<4:29:17,  2.01s/it][A
  2%|▏         | 205/8253 [06:45<4:29:27,  2.01s/it][A
  2%|▏         | 205/8253 [06:45<4:29:31,  2.01s/it][A
  2%|▏         | 206/8253 [06:47<4:27:56,  2.00s/it][A
  2%|▏         | 206/8253 [06:47<4:28:08,  2.00s/it][A

  2%|▏         | 206/8253 [06:47<4:28:07,  2.00s/it][A  2%|▏         | 206/8253 [06:47<4:27:59,  2.00s/it][A

  2%|▏         | 206/8253 [06:47<4:28:26,  2.00s/it][A  2%|▏         | 206/8253 [06:47<4:28:28,  2.00s/it][A
  3%|▎         | 207/8253 [06:49<4:27:02,  1.99s/it][A
  3%|▎         | 207/8253 [06:49<4:27:07,  1.99s/it][A
  3%|▎         | 207/8253 [06:49<4:27:02,  1.99s/it][A
  3%|▎         | 207/8253 [06:49<4:27:29,  1.99s/it][A
  3%|▎         | 207/8253 [06:49<4:27:24,  1.99s/it][A
  3%|▎         | 207/8253 [06:49<4:27:16,  1.99s/it][A
  3%|▎         | 208/8253 [06:51<4:24:28,  1.97s/it][A
  3%|▎         | 208/8253 [06:51<4:24:25,  1.97s/it][A
  3%|▎         | 208/8253 [06:51<4:24:33,  1.97s/it][A

  3%|▎         | 208/8253 [06:51<4:24:28,  1.97s/it][A  3%|▎         | 208/8253 [06:51<4:24:44,  1.97s/it][A
  3%|▎         | 208/8253 [06:51<4:24:46,  1.97s/it][A

  3%|▎         | 209/8253 [06:53<4:23:32,  1.97s/it][A  3%|▎         | 209/8253 [06:53<4:23:10,  1.96s/it][A
  3%|▎         | 209/8253 [06:53<4:23:25,  1.96s/it][A
  3%|▎         | 209/8253 [06:53<4:23:24,  1.96s/it][A
  3%|▎         | 209/8253 [06:53<4:23:38,  1.97s/it][A
  3%|▎         | 209/8253 [06:53<4:23:43,  1.97s/it][A
  3%|▎         | 210/8253 [06:55<4:21:55,  1.95s/it][A
  3%|▎         | 210/8253 [06:55<4:22:14,  1.96s/it][A
  3%|▎         | 210/8253 [06:55<4:22:25,  1.96s/it][A
  3%|▎         | 210/8253 [06:55<4:22:34,  1.96s/it][A
  3%|▎         | 210/8253 [06:55<4:22:32,  1.96s/it][A
  3%|▎         | 210/8253 [06:55<4:22:35,  1.96s/it][A
  3%|▎         | 211/8253 [06:57<4:21:58,  1.95s/it][A
  3%|▎         | 211/8253 [06:57<4:21:42,  1.95s/it][A
  3%|▎         | 211/8253 [06:57<4:22:09,  1.96s/it][A
  3%|▎         | 211/8253 [06:57<4:22:07,  1.96s/it][A
  3%|▎         | 211/8253 [06:57<4:22:21,  1.96s/it][A
  3%|▎         | 211/8253 [06:57<4:22:13,  1.96s/it][A
  3%|▎         | 212/8253 [06:59<4:21:26,  1.95s/it][A
  3%|▎         | 212/8253 [06:59<4:21:26,  1.95s/it][A
  3%|▎         | 212/8253 [06:59<4:22:03,  1.96s/it][A
  3%|▎         | 212/8253 [06:59<4:21:30,  1.95s/it][A

  3%|▎         | 212/8253 [06:59<4:21:30,  1.95s/it][A  3%|▎         | 212/8253 [06:59<4:21:38,  1.95s/it][A
  3%|▎         | 213/8253 [07:01<4:20:26,  1.94s/it][A
  3%|▎         | 213/8253 [07:01<4:20:58,  1.95s/it][A
  3%|▎         | 213/8253 [07:01<4:20:28,  1.94s/it][A

  3%|▎         | 213/8253 [07:01<4:21:07,  1.95s/it][A
  3%|▎         | 213/8253 [07:01<4:21:06,  1.95s/it][A  3%|▎         | 213/8253 [07:01<4:20:50,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:10,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:21,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:15,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:29,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:18,  1.95s/it][A
  3%|▎         | 214/8253 [07:03<4:21:33,  1.95s/it][A
  3%|▎         | 215/8253 [07:05<4:23:00,  1.96s/it][A
  3%|▎         | 215/8253 [07:05<4:23:17,  1.97s/it][A
  3%|▎         | 215/8253 [07:05<4:23:41,  1.97s/it][A
  3%|▎         | 215/8253 [07:05<4:23:20,  1.97s/it][A
  3%|▎         | 215/8253 [07:05<4:23:24,  1.97s/it][A
  3%|▎         | 215/8253 [07:05<4:23:55,  1.97s/it][A
  3%|▎         | 216/8253 [07:07<4:22:34,  1.96s/it][A
  3%|▎         | 216/8253 [07:07<4:22:41,  1.96s/it][A
  3%|▎         | 216/8253 [07:07<4:23:05,  1.96s/it][A
  3%|▎         | 216/8253 [07:07<4:23:29,  1.97s/it][A
  3%|▎         | 216/8253 [07:07<4:23:36,  1.97s/it][A
  3%|▎         | 216/8253 [07:06<4:23:49,  1.97s/it][A
  3%|▎         | 217/8253 [07:09<4:22:06,  1.96s/it][A
  3%|▎         | 217/8253 [07:09<4:22:45,  1.96s/it][A
  3%|▎         | 217/8253 [07:09<4:22:54,  1.96s/it][A
  3%|▎         | 217/8253 [07:09<4:22:59,  1.96s/it][A
  3%|▎         | 217/8253 [07:08<4:23:00,  1.96s/it][A
  3%|▎         | 217/8253 [07:09<4:23:15,  1.97s/it][A
  3%|▎         | 218/8253 [07:11<4:24:49,  1.98s/it][A
  3%|▎         | 218/8253 [07:11<4:25:22,  1.98s/it][A
  3%|▎         | 218/8253 [07:11<4:25:09,  1.98s/it][A
  3%|▎         | 218/8253 [07:10<4:24:52,  1.98s/it][A
  3%|▎         | 218/8253 [07:11<4:25:00,  1.98s/it][A
  3%|▎         | 218/8253 [07:11<4:25:18,  1.98s/it][A
  3%|▎         | 219/8253 [07:12<4:23:41,  1.97s/it][A
  3%|▎         | 219/8253 [07:13<4:24:32,  1.98s/it][A
  3%|▎         | 219/8253 [07:13<4:24:43,  1.98s/it][A
  3%|▎         | 219/8253 [07:13<4:25:12,  1.98s/it][A
  3%|▎         | 219/8253 [07:13<4:25:27,  1.98s/it][A
  3%|▎         | 219/8253 [07:13<4:25:06,  1.98s/it][A
  3%|▎         | 220/8253 [07:14<4:22:26,  1.96s/it][A
  3%|▎         | 220/8253 [07:14<4:22:29,  1.96s/it][A
  3%|▎         | 220/8253 [07:14<4:22:51,  1.96s/it][A
  3%|▎         | 220/8253 [07:14<4:22:59,  1.96s/it][A
  3%|▎         | 220/8253 [07:14<4:23:11,  1.97s/it][A
  3%|▎         | 220/8253 [07:14<4:22:55,  1.96s/it][A
  3%|▎         | 221/8253 [07:16<4:24:12,  1.97s/it][A
  3%|▎         | 221/8253 [07:16<4:24:32,  1.98s/it][A
  3%|▎         | 221/8253 [07:17<4:24:50,  1.98s/it][A
  3%|▎         | 221/8253 [07:17<4:25:03,  1.98s/it][A
  3%|▎         | 221/8253 [07:17<4:24:52,  1.98s/it][A
  3%|▎         | 221/8253 [07:17<4:25:03,  1.98s/it][A
  3%|▎         | 222/8253 [07:18<4:21:49,  1.96s/it][A


  3%|▎         | 222/8253 [07:18<4:22:05,  1.96s/it][A  3%|▎         | 222/8253 [07:18<4:22:09,  1.96s/it][A  3%|▎         | 222/8253 [07:18<4:22:27,  1.96s/it]
[A  3%|▎         | 222/8253 [07:18<4:22:17,  1.96s/it][A
  3%|▎         | 222/8253 [07:18<4:22:06,  1.96s/it][A
  3%|▎         | 223/8253 [07:20<4:20:37,  1.95s/it][A
  3%|▎         | 223/8253 [07:20<4:21:00,  1.95s/it][A
  3%|▎         | 223/8253 [07:20<4:20:57,  1.95s/it][A
  3%|▎         | 223/8253 [07:20<4:21:23,  1.95s/it][A
  3%|▎         | 223/8253 [07:20<4:20:56,  1.95s/it][A
  3%|▎         | 223/8253 [07:20<4:21:29,  1.95s/it][A
  3%|▎         | 224/8253 [07:22<4:21:44,  1.96s/it][A
  3%|▎         | 224/8253 [07:22<4:22:07,  1.96s/it][A
  3%|▎         | 224/8253 [07:22<4:22:35,  1.96s/it][A
  3%|▎         | 224/8253 [07:22<4:22:28,  1.96s/it][A
  3%|▎         | 224/8253 [07:22<4:22:29,  1.96s/it][A
  3%|▎         | 224/8253 [07:22<4:22:38,  1.96s/it][A
  3%|▎         | 225/8253 [07:24<4:23:10,  1.97s/it][A
  3%|▎         | 225/8253 [07:24<4:23:31,  1.97s/it][A
  3%|▎         | 225/8253 [07:24<4:23:38,  1.97s/it][A
  3%|▎         | 225/8253 [07:24<4:23:45,  1.97s/it][A
  3%|▎         | 225/8253 [07:24<4:23:54,  1.97s/it][A
  3%|▎         | 225/8253 [07:24<4:23:50,  1.97s/it][A
  3%|▎         | 226/8253 [07:26<4:22:03,  1.96s/it][A
  3%|▎         | 226/8253 [07:26<4:22:11,  1.96s/it][A
  3%|▎         | 226/8253 [07:26<4:22:07,  1.96s/it][A
  3%|▎         | 226/8253 [07:26<4:22:19,  1.96s/it][A

  3%|▎         | 226/8253 [07:26<4:22:21,  1.96s/it][A  3%|▎         | 226/8253 [07:26<4:22:27,  1.96s/it][A


  3%|▎         | 227/8253 [07:28<4:20:17,  1.95s/it][A  3%|▎         | 227/8253 [07:28<4:20:22,  1.95s/it][A  3%|▎         | 227/8253 [07:28<4:20:13,  1.95s/it][A
  3%|▎         | 227/8253 [07:28<4:20:25,  1.95s/it][A

  3%|▎         | 227/8253 [07:28<4:20:56,  1.95s/it][A  3%|▎         | 227/8253 [07:28<4:20:40,  1.95s/it][A
  3%|▎         | 228/8253 [07:30<4:18:59,  1.94s/it][A
  3%|▎         | 228/8253 [07:30<4:19:42,  1.94s/it][A
  3%|▎         | 228/8253 [07:30<4:19:57,  1.94s/it][A

  3%|▎         | 228/8253 [07:30<4:20:19,  1.95s/it][A  3%|▎         | 228/8253 [07:30<4:20:15,  1.95s/it][A
  3%|▎         | 228/8253 [07:30<4:20:34,  1.95s/it][A
  3%|▎         | 229/8253 [07:32<4:23:23,  1.97s/it][A
  3%|▎         | 229/8253 [07:32<4:24:01,  1.97s/it][A
  3%|▎         | 229/8253 [07:32<4:23:44,  1.97s/it][A
  3%|▎         | 229/8253 [07:32<4:24:13,  1.98s/it][A
  3%|▎         | 229/8253 [07:32<4:23:53,  1.97s/it][A
  3%|▎         | 229/8253 [07:32<4:23:53,  1.97s/it][A
  3%|▎         | 230/8253 [07:34<4:22:16,  1.96s/it][A
  3%|▎         | 230/8253 [07:34<4:22:47,  1.97s/it][A
  3%|▎         | 230/8253 [07:34<4:22:50,  1.97s/it][A
  3%|▎         | 230/8253 [07:34<4:22:47,  1.97s/it][A
  3%|▎         | 230/8253 [07:34<4:22:50,  1.97s/it][A
  3%|▎         | 230/8253 [07:34<4:23:16,  1.97s/it][A
  3%|▎         | 231/8253 [07:36<4:24:15,  1.98s/it][A

  3%|▎         | 231/8253 [07:36<4:24:18,  1.98s/it][A  3%|▎         | 231/8253 [07:36<4:24:21,  1.98s/it][A
  3%|▎         | 231/8253 [07:36<4:24:33,  1.98s/it][A
  3%|▎         | 231/8253 [07:36<4:24:20,  1.98s/it][A
  3%|▎         | 231/8253 [07:36<4:24:45,  1.98s/it][A
  3%|▎         | 232/8253 [07:38<4:22:56,  1.97s/it][A
  3%|▎         | 232/8253 [07:38<4:22:50,  1.97s/it][A
  3%|▎         | 232/8253 [07:38<4:23:12,  1.97s/it][A
  3%|▎         | 232/8253 [07:38<4:23:41,  1.97s/it][A
  3%|▎         | 232/8253 [07:38<4:23:31,  1.97s/it][A
  3%|▎         | 232/8253 [07:38<4:23:37,  1.97s/it][A
  3%|▎         | 233/8253 [07:40<4:22:43,  1.97s/it][A
  3%|▎         | 233/8253 [07:40<4:22:42,  1.97s/it][A

  3%|▎         | 233/8253 [07:40<4:23:19,  1.97s/it][A  3%|▎         | 233/8253 [07:40<4:23:11,  1.97s/it][A
  3%|▎         | 233/8253 [07:40<4:22:59,  1.97s/it][A
  3%|▎         | 233/8253 [07:40<4:23:03,  1.97s/it][A
  3%|▎         | 234/8253 [07:42<4:21:22,  1.96s/it][A
  3%|▎         | 234/8253 [07:42<4:21:45,  1.96s/it][A
  3%|▎         | 234/8253 [07:42<4:21:42,  1.96s/it][A
  3%|▎         | 234/8253 [07:42<4:22:12,  1.96s/it][A
  3%|▎         | 234/8253 [07:42<4:22:15,  1.96s/it][A
  3%|▎         | 234/8253 [07:42<4:22:22,  1.96s/it][A
  3%|▎         | 235/8253 [07:44<4:21:34,  1.96s/it][A
  3%|▎         | 235/8253 [07:44<4:21:40,  1.96s/it][A
  3%|▎         | 235/8253 [07:44<4:21:45,  1.96s/it][A
  3%|▎         | 235/8253 [07:44<4:22:21,  1.96s/it][A

  3%|▎         | 235/8253 [07:44<4:22:25,  1.96s/it][A  3%|▎         | 235/8253 [07:44<4:22:24,  1.96s/it][A
  3%|▎         | 236/8253 [07:46<4:21:57,  1.96s/it][A
  3%|▎         | 236/8253 [07:46<4:22:15,  1.96s/it][A
  3%|▎         | 236/8253 [07:46<4:22:36,  1.97s/it][A
  3%|▎         | 236/8253 [07:46<4:22:36,  1.97s/it][A

  3%|▎         | 236/8253 [07:46<4:22:54,  1.97s/it][A  3%|▎         | 236/8253 [07:46<4:22:41,  1.97s/it][A
  3%|▎         | 237/8253 [07:48<4:21:41,  1.96s/it][A
  3%|▎         | 237/8253 [07:48<4:22:07,  1.96s/it][A
  3%|▎         | 237/8253 [07:48<4:22:22,  1.96s/it][A

  3%|▎         | 237/8253 [07:48<4:22:19,  1.96s/it][A
  3%|▎         | 237/8253 [07:48<4:22:29,  1.96s/it][A  3%|▎         | 237/8253 [07:48<4:22:20,  1.96s/it][A

  3%|▎         | 238/8253 [07:50<4:21:22,  1.96s/it][A  3%|▎         | 238/8253 [07:50<4:21:18,  1.96s/it][A

  3%|▎         | 238/8253 [07:50<4:21:18,  1.96s/it][A  3%|▎         | 238/8253 [07:50<4:21:18,  1.96s/it][A
  3%|▎         | 238/8253 [07:50<4:21:35,  1.96s/it][A
  3%|▎         | 238/8253 [07:50<4:21:41,  1.96s/it][A

  3%|▎         | 239/8253 [07:52<4:21:49,  1.96s/it][A
  3%|▎         | 239/8253 [07:52<4:21:54,  1.96s/it][A
  3%|▎         | 239/8253 [07:52<4:21:48,  1.96s/it][A  3%|▎         | 239/8253 [07:52<4:21:46,  1.96s/it]
[A  3%|▎         | 239/8253 [07:52<4:21:50,  1.96s/it][A
  3%|▎         | 239/8253 [07:52<4:22:04,  1.96s/it][A
  3%|▎         | 240/8253 [07:54<4:20:42,  1.95s/it][A
  3%|▎         | 240/8253 [07:54<4:20:51,  1.95s/it][A

  3%|▎         | 240/8253 [07:54<4:21:14,  1.96s/it][A  3%|▎         | 240/8253 [07:54<4:21:11,  1.96s/it][A

  3%|▎         | 240/8253 [07:54<4:21:12,  1.96s/it][A  3%|▎         | 240/8253 [07:54<4:21:10,  1.96s/it][A
  3%|▎         | 241/8253 [07:56<4:20:44,  1.95s/it][A
  3%|▎         | 241/8253 [07:56<4:20:52,  1.95s/it]
[A  3%|▎         | 241/8253 [07:56<4:20:55,  1.95s/it][A
  3%|▎         | 241/8253 [07:56<4:21:01,  1.95s/it][A

  3%|▎         | 241/8253 [07:56<4:21:13,  1.96s/it][A  3%|▎         | 241/8253 [07:56<4:21:07,  1.96s/it][A
  3%|▎         | 242/8253 [07:58<4:22:17,  1.96s/it][A
  3%|▎         | 242/8253 [07:58<4:22:27,  1.97s/it][A
  3%|▎         | 242/8253 [07:58<4:22:47,  1.97s/it][A

  3%|▎         | 242/8253 [07:58<4:22:58,  1.97s/it][A  3%|▎         | 242/8253 [07:58<4:23:00,  1.97s/it][A
  3%|▎         | 242/8253 [07:58<4:23:04,  1.97s/it][A
  3%|▎         | 243/8253 [07:59<4:20:10,  1.95s/it][A
  3%|▎         | 243/8253 [08:00<4:20:17,  1.95s/it][A
  3%|▎         | 243/8253 [08:00<4:20:22,  1.95s/it][A
  3%|▎         | 243/8253 [08:00<4:20:31,  1.95s/it][A
  3%|▎         | 243/8253 [08:00<4:20:42,  1.95s/it][A
  3%|▎         | 243/8253 [08:00<4:20:49,  1.95s/it][A
  3%|▎         | 244/8253 [08:02<4:20:34,  1.95s/it][A

  3%|▎         | 244/8253 [08:02<4:21:02,  1.96s/it][A  3%|▎         | 244/8253 [08:02<4:20:55,  1.95s/it][A
  3%|▎         | 244/8253 [08:02<4:21:00,  1.96s/it][A
  3%|▎         | 244/8253 [08:02<4:21:06,  1.96s/it][A
  3%|▎         | 244/8253 [08:01<4:21:16,  1.96s/it][A
  3%|▎         | 245/8253 [08:03<4:20:18,  1.95s/it][A
  3%|▎         | 245/8253 [08:03<4:20:21,  1.95s/it][A
  3%|▎         | 245/8253 [08:03<4:20:24,  1.95s/it][A
  3%|▎         | 245/8253 [08:03<4:20:39,  1.95s/it][A
  3%|▎         | 245/8253 [08:03<4:20:49,  1.95s/it][A
  3%|▎         | 245/8253 [08:03<4:20:54,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:20:10,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:19:55,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:19:58,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:19:56,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:20:06,  1.95s/it][A
  3%|▎         | 246/8253 [08:05<4:20:09,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:19:55,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:19:58,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:20:14,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:20:32,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:20:20,  1.95s/it][A
  3%|▎         | 247/8253 [08:07<4:20:15,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:19:46,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:19:53,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:20:13,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:20:02,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:20:14,  1.95s/it][A
  3%|▎         | 248/8253 [08:09<4:19:58,  1.95s/it][A
  3%|▎         | 249/8253 [08:11<4:19:41,  1.95s/it][A
  3%|▎         | 249/8253 [08:11<4:20:10,  1.95s/it][A
  3%|▎         | 249/8253 [08:11<4:20:04,  1.95s/it][A

  3%|▎         | 249/8253 [08:11<4:20:20,  1.95s/it][A  3%|▎         | 249/8253 [08:11<4:20:13,  1.95s/it][A
  3%|▎         | 249/8253 [08:11<4:20:28,  1.95s/it][A

  3%|▎         | 250/8253 [08:13<4:19:42,  1.95s/it][A  3%|▎         | 250/8253 [08:13<4:19:57,  1.95s/it][A
  3%|▎         | 250/8253 [08:13<4:19:50,  1.95s/it][A
  3%|▎         | 250/8253 [08:13<4:19:47,  1.95s/it][A
  3%|▎         | 250/8253 [08:13<4:20:06,  1.95s/it][A
  3%|▎         | 250/8253 [08:13<4:20:02,  1.95s/it][A
  3%|▎         | 251/8253 [08:15<4:20:40,  1.95s/it][A
  3%|▎         | 251/8253 [08:15<4:20:40,  1.95s/it][A
  3%|▎         | 251/8253 [08:15<4:20:50,  1.96s/it][A
  3%|▎         | 251/8253 [08:15<4:20:49,  1.96s/it][A
  3%|▎         | 251/8253 [08:15<4:20:40,  1.95s/it][A
  3%|▎         | 251/8253 [08:15<4:20:51,  1.96s/it][A
  3%|▎         | 252/8253 [08:17<4:19:45,  1.95s/it][A
  3%|▎         | 252/8253 [08:17<4:20:43,  1.96s/it][A
  3%|▎         | 252/8253 [08:17<4:20:48,  1.96s/it][A
  3%|▎         | 252/8253 [08:17<4:20:51,  1.96s/it][A
  3%|▎         | 252/8253 [08:17<4:20:59,  1.96s/it][A
  3%|▎         | 252/8253 [08:17<4:20:56,  1.96s/it][A
  3%|▎         | 253/8253 [08:19<4:19:37,  1.95s/it][A
  3%|▎         | 253/8253 [08:19<4:19:50,  1.95s/it][A
  3%|▎         | 253/8253 [08:19<4:20:16,  1.95s/it][A
  3%|▎         | 253/8253 [08:19<4:20:29,  1.95s/it][A
  3%|▎         | 253/8253 [08:19<4:20:17,  1.95s/it][A
  3%|▎         | 253/8253 [08:19<4:20:39,  1.95s/it][A
  3%|▎         | 254/8253 [08:21<4:19:12,  1.94s/it][A
  3%|▎         | 254/8253 [08:21<4:19:28,  1.95s/it][A
  3%|▎         | 254/8253 [08:21<4:19:36,  1.95s/it][A
  3%|▎         | 254/8253 [08:21<4:19:47,  1.95s/it][A

  3%|▎         | 254/8253 [08:21<4:19:46,  1.95s/it][A  3%|▎         | 254/8253 [08:21<4:19:55,  1.95s/it][A
  3%|▎         | 255/8253 [08:23<4:22:21,  1.97s/it][A

  3%|▎         | 255/8253 [08:23<4:22:48,  1.97s/it][A  3%|▎         | 255/8253 [08:23<4:22:36,  1.97s/it][A
  3%|▎         | 255/8253 [08:23<4:22:52,  1.97s/it][A
  3%|▎         | 255/8253 [08:23<4:22:51,  1.97s/it][A
  3%|▎         | 255/8253 [08:23<4:22:51,  1.97s/it][A
  3%|▎         | 256/8253 [08:25<4:20:04,  1.95s/it][A
  3%|▎         | 256/8253 [08:25<4:20:28,  1.95s/it][A
  3%|▎         | 256/8253 [08:25<4:20:48,  1.96s/it][A
  3%|▎         | 256/8253 [08:25<4:20:50,  1.96s/it][A

  3%|▎         | 256/8253 [08:25<4:21:05,  1.96s/it][A  3%|▎         | 256/8253 [08:25<4:20:48,  1.96s/it][A
  3%|▎         | 257/8253 [08:27<4:19:57,  1.95s/it][A
  3%|▎         | 257/8253 [08:27<4:20:22,  1.95s/it][A
  3%|▎         | 257/8253 [08:27<4:20:26,  1.95s/it][A
  3%|▎         | 257/8253 [08:27<4:20:37,  1.96s/it][A
  3%|▎         | 257/8253 [08:27<4:20:49,  1.96s/it][A
  3%|▎         | 257/8253 [08:27<4:20:45,  1.96s/it][A
  3%|▎         | 258/8253 [08:29<4:19:37,  1.95s/it][A
  3%|▎         | 258/8253 [08:29<4:19:48,  1.95s/it][A
  3%|▎         | 258/8253 [08:29<4:19:56,  1.95s/it][A
  3%|▎         | 258/8253 [08:29<4:20:07,  1.95s/it][A
  3%|▎         | 258/8253 [08:29<4:20:16,  1.95s/it][A
  3%|▎         | 258/8253 [08:29<4:20:22,  1.95s/it][A
  3%|▎         | 259/8253 [08:31<4:20:33,  1.96s/it][A
  3%|▎         | 259/8253 [08:31<4:20:51,  1.96s/it][A
  3%|▎         | 259/8253 [08:31<4:20:48,  1.96s/it][A
  3%|▎         | 259/8253 [08:31<4:20:58,  1.96s/it][A
  3%|▎         | 259/8253 [08:31<4:20:54,  1.96s/it][A
  3%|▎         | 259/8253 [08:31<4:21:02,  1.96s/it][A
  3%|▎         | 260/8253 [08:33<4:20:09,  1.95s/it][A
  3%|▎         | 260/8253 [08:33<4:20:27,  1.96s/it][A

  3%|▎         | 260/8253 [08:33<4:20:55,  1.96s/it][A  3%|▎         | 260/8253 [08:33<4:20:35,  1.96s/it][A
  3%|▎         | 260/8253 [08:33<4:20:40,  1.96s/it][A
  3%|▎         | 260/8253 [08:33<4:21:09,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:20:28,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:20:43,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:21:06,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:20:58,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:21:02,  1.96s/it][A
  3%|▎         | 261/8253 [08:35<4:21:08,  1.96s/it][A
  3%|▎         | 262/8253 [08:37<4:26:35,  2.00s/it][A
  3%|▎         | 262/8253 [08:37<4:26:48,  2.00s/it][A
  3%|▎         | 262/8253 [08:37<4:26:58,  2.00s/it][A
  3%|▎         | 262/8253 [08:37<4:27:12,  2.01s/it][A
  3%|▎         | 262/8253 [08:37<4:27:05,  2.01s/it][A
  3%|▎         | 262/8253 [08:37<4:27:09,  2.01s/it][A
  3%|▎         | 263/8253 [08:39<4:25:34,  1.99s/it][A
  3%|▎         | 263/8253 [08:39<4:25:28,  1.99s/it][A
  3%|▎         | 263/8253 [08:39<4:25:45,  2.00s/it][A
  3%|▎         | 263/8253 [08:39<4:25:54,  2.00s/it][A
  3%|▎         | 263/8253 [08:39<4:25:41,  2.00s/it][A
  3%|▎         | 263/8253 [08:39<4:25:52,  2.00s/it][A
  3%|▎         | 264/8253 [08:41<4:22:33,  1.97s/it][A
  3%|▎         | 264/8253 [08:41<4:22:56,  1.97s/it][A
  3%|▎         | 264/8253 [08:41<4:23:14,  1.98s/it][A
  3%|▎         | 264/8253 [08:41<4:23:18,  1.98s/it][A
  3%|▎         | 264/8253 [08:41<4:22:56,  1.97s/it][A
  3%|▎         | 264/8253 [08:41<4:23:23,  1.98s/it][A
  3%|▎         | 265/8253 [08:43<4:20:12,  1.95s/it][A
  3%|▎         | 265/8253 [08:43<4:20:57,  1.96s/it][A
  3%|▎         | 265/8253 [08:43<4:21:12,  1.96s/it][A

  3%|▎         | 265/8253 [08:43<4:21:21,  1.96s/it][A  3%|▎         | 265/8253 [08:43<4:21:19,  1.96s/it][A
  3%|▎         | 265/8253 [08:43<4:21:24,  1.96s/it][A
  3%|▎         | 266/8253 [08:45<4:20:14,  1.95s/it][A

  3%|▎         | 266/8253 [08:45<4:20:26,  1.96s/it][A  3%|▎         | 266/8253 [08:45<4:20:22,  1.96s/it][A
  3%|▎         | 266/8253 [08:45<4:20:08,  1.95s/it][A
  3%|▎         | 266/8253 [08:45<4:20:48,  1.96s/it][A
  3%|▎         | 266/8253 [08:45<4:21:07,  1.96s/it][A
  3%|▎         | 267/8253 [08:47<4:23:34,  1.98s/it][A
  3%|▎         | 267/8253 [08:47<4:23:42,  1.98s/it][A
  3%|▎         | 267/8253 [08:47<4:23:51,  1.98s/it][A
  3%|▎         | 267/8253 [08:47<4:23:49,  1.98s/it][A
  3%|▎         | 267/8253 [08:47<4:24:13,  1.99s/it][A
  3%|▎         | 267/8253 [08:47<4:24:17,  1.99s/it][A
  3%|▎         | 268/8253 [08:49<4:21:26,  1.96s/it][A
  3%|▎         | 268/8253 [08:48<4:21:46,  1.97s/it][A
  3%|▎         | 268/8253 [08:49<4:21:45,  1.97s/it][A
  3%|▎         | 268/8253 [08:49<4:21:47,  1.97s/it][A
  3%|▎         | 268/8253 [08:49<4:22:02,  1.97s/it][A
  3%|▎         | 268/8253 [08:49<4:21:49,  1.97s/it][A
  3%|▎         | 269/8253 [08:51<4:18:45,  1.94s/it][A
  3%|▎         | 269/8253 [08:50<4:19:12,  1.95s/it][A
  3%|▎         | 269/8253 [08:51<4:19:12,  1.95s/it][A
  3%|▎         | 269/8253 [08:51<4:19:33,  1.95s/it][A
  3%|▎         | 269/8253 [08:51<4:19:35,  1.95s/it][A
  3%|▎         | 269/8253 [08:51<4:19:35,  1.95s/it][A
  3%|▎         | 270/8253 [08:52<4:18:35,  1.94s/it][A
  3%|▎         | 270/8253 [08:52<4:18:39,  1.94s/it][A
  3%|▎         | 270/8253 [08:52<4:19:04,  1.95s/it][A
  3%|▎         | 270/8253 [08:52<4:19:10,  1.95s/it][A
  3%|▎         | 270/8253 [08:52<4:19:28,  1.95s/it][A
  3%|▎         | 270/8253 [08:52<4:19:09,  1.95s/it][A
  3%|▎         | 271/8253 [08:54<4:17:30,  1.94s/it][A
  3%|▎         | 271/8253 [08:54<4:17:46,  1.94s/it][A
  3%|▎         | 271/8253 [08:54<4:17:52,  1.94s/it][A
  3%|▎         | 271/8253 [08:54<4:18:10,  1.94s/it][A
  3%|▎         | 271/8253 [08:54<4:18:11,  1.94s/it][A
  3%|▎         | 271/8253 [08:54<4:18:01,  1.94s/it][A
  3%|▎         | 272/8253 [08:56<4:17:37,  1.94s/it][A
  3%|▎         | 272/8253 [08:56<4:17:48,  1.94s/it][A
  3%|▎         | 272/8253 [08:56<4:17:45,  1.94s/it][A
  3%|▎         | 272/8253 [08:56<4:18:20,  1.94s/it][A

  3%|▎         | 272/8253 [08:56<4:18:23,  1.94s/it][A  3%|▎         | 272/8253 [08:56<4:18:26,  1.94s/it][A
  3%|▎         | 273/8253 [08:58<4:18:09,  1.94s/it][A
  3%|▎         | 273/8253 [08:58<4:18:13,  1.94s/it][A
  3%|▎         | 273/8253 [08:58<4:18:30,  1.94s/it][A
  3%|▎         | 273/8253 [08:58<4:18:55,  1.95s/it][A
  3%|▎         | 273/8253 [08:58<4:18:51,  1.95s/it][A
  3%|▎         | 273/8253 [08:58<4:18:51,  1.95s/it][A
  3%|▎         | 274/8253 [09:00<4:19:51,  1.95s/it][A
  3%|▎         | 274/8253 [09:00<4:20:41,  1.96s/it][A
  3%|▎         | 274/8253 [09:00<4:21:06,  1.96s/it][A
  3%|▎         | 274/8253 [09:00<4:20:44,  1.96s/it][A
  3%|▎         | 274/8253 [09:00<4:20:47,  1.96s/it][A
  3%|▎         | 274/8253 [09:00<4:21:10,  1.96s/it][A
  3%|▎         | 275/8253 [09:02<4:19:18,  1.95s/it][A
  3%|▎         | 275/8253 [09:02<4:19:08,  1.95s/it][A
  3%|▎         | 275/8253 [09:02<4:19:54,  1.95s/it][A
  3%|▎         | 275/8253 [09:02<4:19:45,  1.95s/it][A
  3%|▎         | 275/8253 [09:02<4:19:50,  1.95s/it][A
  3%|▎         | 275/8253 [09:02<4:19:50,  1.95s/it][A
  3%|▎         | 276/8253 [09:04<4:19:23,  1.95s/it][A
  3%|▎         | 276/8253 [09:04<4:19:14,  1.95s/it][A
  3%|▎         | 276/8253 [09:04<4:19:46,  1.95s/it][A

  3%|▎         | 276/8253 [09:04<4:19:40,  1.95s/it][A  3%|▎         | 276/8253 [09:04<4:19:35,  1.95s/it][A
  3%|▎         | 276/8253 [09:04<4:19:54,  1.95s/it][A
  3%|▎         | 277/8253 [09:06<4:17:29,  1.94s/it][A
  3%|▎         | 277/8253 [09:06<4:17:24,  1.94s/it][A
  3%|▎         | 277/8253 [09:06<4:17:15,  1.94s/it][A
  3%|▎         | 277/8253 [09:06<4:17:30,  1.94s/it][A
  3%|▎         | 277/8253 [09:06<4:17:34,  1.94s/it][A
  3%|▎         | 277/8253 [09:06<4:17:33,  1.94s/it][A
  3%|▎         | 278/8253 [09:08<4:18:33,  1.95s/it][A
  3%|▎         | 278/8253 [09:08<4:18:48,  1.95s/it][A
  3%|▎         | 278/8253 [09:08<4:19:00,  1.95s/it][A

  3%|▎         | 278/8253 [09:08<4:19:01,  1.95s/it][A  3%|▎         | 278/8253 [09:08<4:18:54,  1.95s/it][A
  3%|▎         | 278/8253 [09:08<4:19:08,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:22,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:26,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:22,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:31,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:44,  1.95s/it][A
  3%|▎         | 279/8253 [09:10<4:19:57,  1.96s/it][A

  3%|▎         | 280/8253 [09:12<4:18:53,  1.95s/it][A  3%|▎         | 280/8253 [09:12<4:19:00,  1.95s/it][A

  3%|▎         | 280/8253 [09:12<4:19:05,  1.95s/it][A  3%|▎         | 280/8253 [09:12<4:19:13,  1.95s/it][A
  3%|▎         | 280/8253 [09:12<4:19:19,  1.95s/it][A
  3%|▎         | 280/8253 [09:12<4:19:25,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:18:36,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:18:55,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:19:06,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:19:14,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:19:10,  1.95s/it][A
  3%|▎         | 281/8253 [09:14<4:19:25,  1.95s/it][A
  3%|▎         | 282/8253 [09:16<4:20:07,  1.96s/it][A
  3%|▎         | 282/8253 [09:16<4:20:17,  1.96s/it][A
  3%|▎         | 282/8253 [09:16<4:20:15,  1.96s/it][A
  3%|▎         | 282/8253 [09:16<4:20:33,  1.96s/it][A

  3%|▎         | 282/8253 [09:16<4:20:44,  1.96s/it][A  3%|▎         | 282/8253 [09:16<4:20:39,  1.96s/it][A
  3%|▎         | 283/8253 [09:18<4:19:03,  1.95s/it][A
  3%|▎         | 283/8253 [09:18<4:19:29,  1.95s/it][A
  3%|▎         | 283/8253 [09:18<4:19:21,  1.95s/it][A
  3%|▎         | 283/8253 [09:18<4:19:31,  1.95s/it][A
  3%|▎         | 283/8253 [09:18<4:19:33,  1.95s/it][A
  3%|▎         | 283/8253 [09:18<4:19:59,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:19:57,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:20:00,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:20:12,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:20:22,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:20:38,  1.96s/it][A
  3%|▎         | 284/8253 [09:20<4:20:35,  1.96s/it][A
  3%|▎         | 285/8253 [09:22<4:19:50,  1.96s/it][A
  3%|▎         | 285/8253 [09:22<4:20:05,  1.96s/it][A
  3%|▎         | 285/8253 [09:22<4:20:06,  1.96s/it][A
  3%|▎         | 285/8253 [09:22<4:20:12,  1.96s/it][A

  3%|▎         | 285/8253 [09:22<4:20:09,  1.96s/it][A  3%|▎         | 285/8253 [09:22<4:20:24,  1.96s/it][A

  3%|▎         | 286/8253 [09:24<4:21:07,  1.97s/it][A  3%|▎         | 286/8253 [09:24<4:21:10,  1.97s/it][A
  3%|▎         | 286/8253 [09:24<4:21:11,  1.97s/it][A
  3%|▎         | 286/8253 [09:24<4:21:13,  1.97s/it][A
  3%|▎         | 286/8253 [09:24<4:21:27,  1.97s/it][A
  3%|▎         | 286/8253 [09:24<4:21:19,  1.97s/it][A
  3%|▎         | 287/8253 [09:26<4:18:20,  1.95s/it][A
  3%|▎         | 287/8253 [09:26<4:19:02,  1.95s/it][A
  3%|▎         | 287/8253 [09:26<4:19:00,  1.95s/it][A
  3%|▎         | 287/8253 [09:26<4:19:33,  1.96s/it][A
  3%|▎         | 287/8253 [09:26<4:19:37,  1.96s/it][A
  3%|▎         | 287/8253 [09:26<4:19:39,  1.96s/it][A
  3%|▎         | 288/8253 [09:28<4:20:26,  1.96s/it][A
  3%|▎         | 288/8253 [09:28<4:20:21,  1.96s/it][A
  3%|▎         | 288/8253 [09:28<4:20:49,  1.96s/it][A
  3%|▎         | 288/8253 [09:28<4:20:52,  1.97s/it][A
  3%|▎         | 288/8253 [09:28<4:21:15,  1.97s/it][A
  3%|▎         | 288/8253 [09:28<4:21:00,  1.97s/it][A
  4%|▎         | 289/8253 [09:30<4:20:50,  1.97s/it][A
  4%|▎         | 289/8253 [09:30<4:21:01,  1.97s/it][A
  4%|▎         | 289/8253 [09:30<4:20:48,  1.96s/it][A
  4%|▎         | 289/8253 [09:29<4:21:03,  1.97s/it][A
  4%|▎         | 289/8253 [09:30<4:21:01,  1.97s/it][A
  4%|▎         | 289/8253 [09:30<4:21:07,  1.97s/it][A
  4%|▎         | 290/8253 [09:32<4:20:26,  1.96s/it][A
  4%|▎         | 290/8253 [09:32<4:20:09,  1.96s/it][A
  4%|▎         | 290/8253 [09:31<4:20:58,  1.97s/it][A
  4%|▎         | 290/8253 [09:32<4:20:52,  1.97s/it][A

  4%|▎         | 290/8253 [09:32<4:21:03,  1.97s/it][A  4%|▎         | 290/8253 [09:32<4:21:09,  1.97s/it][A
  4%|▎         | 291/8253 [09:33<4:18:01,  1.94s/it][A
  4%|▎         | 291/8253 [09:33<4:18:04,  1.94s/it][A
  4%|▎         | 291/8253 [09:34<4:18:40,  1.95s/it][A
  4%|▎         | 291/8253 [09:34<4:18:35,  1.95s/it][A
  4%|▎         | 291/8253 [09:34<4:18:34,  1.95s/it][A
  4%|▎         | 291/8253 [09:34<4:18:33,  1.95s/it][A

  4%|▎         | 292/8253 [09:35<4:17:21,  1.94s/it][A  4%|▎         | 292/8253 [09:35<4:17:30,  1.94s/it][A
  4%|▎         | 292/8253 [09:35<4:17:34,  1.94s/it][A
  4%|▎         | 292/8253 [09:35<4:17:38,  1.94s/it][A

  4%|▎         | 292/8253 [09:35<4:18:01,  1.94s/it][A  4%|▎         | 292/8253 [09:35<4:17:57,  1.94s/it][A
  4%|▎         | 293/8253 [09:38<4:25:10,  2.00s/it][A
  4%|▎         | 293/8253 [09:38<4:25:06,  2.00s/it][A
  4%|▎         | 293/8253 [09:38<4:25:06,  2.00s/it][A

  4%|▎         | 293/8253 [09:38<4:25:13,  2.00s/it][A
  4%|▎         | 293/8253 [09:38<4:25:20,  2.00s/it][A  4%|▎         | 293/8253 [09:37<4:25:20,  2.00s/it][A
  4%|▎         | 294/8253 [09:39<4:22:08,  1.98s/it][A
  4%|▎         | 294/8253 [09:39<4:22:05,  1.98s/it][A
  4%|▎         | 294/8253 [09:39<4:22:18,  1.98s/it][A
  4%|▎         | 294/8253 [09:39<4:22:21,  1.98s/it][A
  4%|▎         | 294/8253 [09:39<4:22:21,  1.98s/it][A
  4%|▎         | 294/8253 [09:39<4:22:28,  1.98s/it][A
  4%|▎         | 295/8253 [09:41<4:21:56,  1.97s/it][A
  4%|▎         | 295/8253 [09:41<4:22:48,  1.98s/it][A
  4%|▎         | 295/8253 [09:41<4:22:40,  1.98s/it][A
  4%|▎         | 295/8253 [09:41<4:22:44,  1.98s/it][A
  4%|▎         | 295/8253 [09:41<4:22:56,  1.98s/it][A
  4%|▎         | 295/8253 [09:41<4:23:00,  1.98s/it][A
  4%|▎         | 296/8253 [09:43<4:22:34,  1.98s/it][A
  4%|▎         | 296/8253 [09:43<4:23:22,  1.99s/it][A
  4%|▎         | 296/8253 [09:43<4:23:28,  1.99s/it][A
  4%|▎         | 296/8253 [09:43<4:23:13,  1.98s/it][A

  4%|▎         | 296/8253 [09:43<4:23:18,  1.99s/it][A  4%|▎         | 296/8253 [09:43<4:23:22,  1.99s/it][A
  4%|▎         | 297/8253 [09:45<4:24:39,  2.00s/it][A
  4%|▎         | 297/8253 [09:45<4:24:48,  2.00s/it][A
  4%|▎         | 297/8253 [09:46<4:25:03,  2.00s/it][A
  4%|▎         | 297/8253 [09:45<4:25:04,  2.00s/it][A
  4%|▎         | 297/8253 [09:46<4:25:06,  2.00s/it][A
  4%|▎         | 297/8253 [09:46<4:25:11,  2.00s/it][A
  4%|▎         | 298/8253 [09:48<4:25:14,  2.00s/it][A
  4%|▎         | 298/8253 [09:48<4:25:33,  2.00s/it][A
  4%|▎         | 298/8253 [09:48<4:25:21,  2.00s/it][A
  4%|▎         | 298/8253 [09:48<4:25:50,  2.01s/it][A
  4%|▎         | 298/8253 [09:48<4:25:37,  2.00s/it][A
  4%|▎         | 298/8253 [09:47<4:25:37,  2.00s/it][A
  4%|▎         | 299/8253 [09:49<4:22:55,  1.98s/it][A
  4%|▎         | 299/8253 [09:49<4:23:01,  1.98s/it][A
  4%|▎         | 299/8253 [09:49<4:22:58,  1.98s/it][A
  4%|▎         | 299/8253 [09:49<4:23:23,  1.99s/it][A
  4%|▎         | 299/8253 [09:49<4:23:05,  1.98s/it][A
  4%|▎         | 299/8253 [09:49<4:23:12,  1.99s/it][A
  4%|▎         | 300/8253 [09:51<4:20:20,  1.96s/it][A
  4%|▎         | 300/8253 [09:51<4:20:56,  1.97s/it][A
  4%|▎         | 300/8253 [09:51<4:20:46,  1.97s/it][A
  4%|▎         | 300/8253 [09:51<4:20:39,  1.97s/it][A
  4%|▎         | 300/8253 [09:51<4:20:47,  1.97s/it][A
  4%|▎         | 300/8253 [09:51<4:20:49,  1.97s/it][A
  4%|▎         | 301/8253 [09:53<4:19:19,  1.96s/it][A
  4%|▎         | 301/8253 [09:53<4:19:21,  1.96s/it][A
  4%|▎         | 301/8253 [09:53<4:19:44,  1.96s/it][A
  4%|▎         | 301/8253 [09:53<4:19:29,  1.96s/it][A
  4%|▎         | 301/8253 [09:53<4:19:51,  1.96s/it][A
  4%|▎         | 301/8253 [09:53<4:19:46,  1.96s/it][A
  4%|▎         | 302/8253 [09:55<4:18:12,  1.95s/it][A
  4%|▎         | 302/8253 [09:55<4:18:31,  1.95s/it][A
  4%|▎         | 302/8253 [09:55<4:18:21,  1.95s/it][A
  4%|▎         | 302/8253 [09:55<4:18:34,  1.95s/it][A
  4%|▎         | 302/8253 [09:55<4:18:32,  1.95s/it][A
  4%|▎         | 302/8253 [09:55<4:19:00,  1.95s/it][A
  4%|▎         | 303/8253 [09:57<4:18:19,  1.95s/it][A
  4%|▎         | 303/8253 [09:57<4:18:10,  1.95s/it][A
  4%|▎         | 303/8253 [09:57<4:18:28,  1.95s/it][A
  4%|▎         | 303/8253 [09:57<4:18:30,  1.95s/it][A

  4%|▎         | 303/8253 [09:57<4:18:33,  1.95s/it][A  4%|▎         | 303/8253 [09:57<4:18:41,  1.95s/it][A

  4%|▎         | 304/8253 [09:59<4:18:35,  1.95s/it][A  4%|▎         | 304/8253 [09:59<4:18:02,  1.95s/it][A
  4%|▎         | 304/8253 [09:59<4:18:30,  1.95s/it][A
  4%|▎         | 304/8253 [09:59<4:18:40,  1.95s/it][A
  4%|▎         | 304/8253 [09:59<4:18:35,  1.95s/it][A
  4%|▎         | 304/8253 [09:59<4:18:37,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:01,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:24,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:34,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:52,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:27,  1.95s/it][A
  4%|▎         | 305/8253 [10:01<4:18:47,  1.95s/it][A
  4%|▎         | 306/8253 [10:03<4:16:43,  1.94s/it][A

  4%|▎         | 306/8253 [10:03<4:16:38,  1.94s/it][A  4%|▎         | 306/8253 [10:03<4:16:59,  1.94s/it][A
  4%|▎         | 306/8253 [10:03<4:16:56,  1.94s/it][A

  4%|▎         | 306/8253 [10:03<4:17:17,  1.94s/it][A  4%|▎         | 306/8253 [10:03<4:17:13,  1.94s/it][A
  4%|▎         | 307/8253 [10:05<4:15:26,  1.93s/it][A
  4%|▎         | 307/8253 [10:05<4:16:04,  1.93s/it][A
  4%|▎         | 307/8253 [10:05<4:15:51,  1.93s/it][A
  4%|▎         | 307/8253 [10:05<4:15:59,  1.93s/it]
[A  4%|▎         | 307/8253 [10:05<4:15:56,  1.93s/it][A
  4%|▎         | 307/8253 [10:05<4:16:09,  1.93s/it][A
  4%|▎         | 308/8253 [10:07<4:15:53,  1.93s/it][A
  4%|▎         | 308/8253 [10:07<4:16:08,  1.93s/it][A
  4%|▎         | 308/8253 [10:07<4:16:02,  1.93s/it][A
  4%|▎         | 308/8253 [10:07<4:16:08,  1.93s/it][A
  4%|▎         | 308/8253 [10:07<4:16:28,  1.94s/it][A
  4%|▎         | 308/8253 [10:07<4:16:19,  1.94s/it][A
  4%|▎         | 309/8253 [10:09<4:17:47,  1.95s/it][A
  4%|▎         | 309/8253 [10:09<4:17:41,  1.95s/it][A
  4%|▎         | 309/8253 [10:09<4:18:10,  1.95s/it][A
  4%|▎         | 309/8253 [10:09<4:18:03,  1.95s/it][A
  4%|▎         | 309/8253 [10:09<4:18:07,  1.95s/it][A
  4%|▎         | 309/8253 [10:09<4:18:22,  1.95s/it][A
  4%|▍         | 310/8253 [10:11<4:18:19,  1.95s/it][A
  4%|▍         | 310/8253 [10:11<4:18:18,  1.95s/it][A
  4%|▍         | 310/8253 [10:11<4:18:17,  1.95s/it][A
  4%|▍         | 310/8253 [10:11<4:18:53,  1.96s/it][A
  4%|▍         | 310/8253 [10:11<4:18:34,  1.95s/it][A
  4%|▍         | 310/8253 [10:11<4:18:51,  1.96s/it][A
  4%|▍         | 311/8253 [10:13<4:16:47,  1.94s/it][A
  4%|▍         | 311/8253 [10:13<4:16:50,  1.94s/it][A
  4%|▍         | 311/8253 [10:13<4:17:08,  1.94s/it][A
  4%|▍         | 311/8253 [10:13<4:17:00,  1.94s/it][A
  4%|▍         | 311/8253 [10:13<4:17:10,  1.94s/it][A
  4%|▍         | 311/8253 [10:13<4:17:08,  1.94s/it][A

  4%|▍         | 312/8253 [10:15<4:19:14,  1.96s/it][A  4%|▍         | 312/8253 [10:15<4:19:18,  1.96s/it][A
  4%|▍         | 312/8253 [10:15<4:19:13,  1.96s/it][A
  4%|▍         | 312/8253 [10:15<4:19:13,  1.96s/it][A
  4%|▍         | 312/8253 [10:15<4:19:10,  1.96s/it][A
  4%|▍         | 312/8253 [10:15<4:19:15,  1.96s/it][A
  4%|▍         | 313/8253 [10:17<4:16:23,  1.94s/it][A
  4%|▍         | 313/8253 [10:17<4:16:26,  1.94s/it][A
  4%|▍         | 313/8253 [10:17<4:17:01,  1.94s/it][A
  4%|▍         | 313/8253 [10:16<4:17:02,  1.94s/it][A

  4%|▍         | 313/8253 [10:17<4:17:02,  1.94s/it][A  4%|▍         | 313/8253 [10:17<4:17:14,  1.94s/it][A
  4%|▍         | 314/8253 [10:19<4:17:48,  1.95s/it][A
  4%|▍         | 314/8253 [10:19<4:18:21,  1.95s/it][A
  4%|▍         | 314/8253 [10:19<4:18:22,  1.95s/it][A
  4%|▍         | 314/8253 [10:19<4:18:16,  1.95s/it][A
  4%|▍         | 314/8253 [10:19<4:18:45,  1.96s/it][A
  4%|▍         | 314/8253 [10:18<4:18:38,  1.95s/it][A
  4%|▍         | 315/8253 [10:21<4:17:41,  1.95s/it][A
  4%|▍         | 315/8253 [10:21<4:18:06,  1.95s/it][A
  4%|▍         | 315/8253 [10:21<4:18:03,  1.95s/it][A
  4%|▍         | 315/8253 [10:20<4:18:09,  1.95s/it][A
  4%|▍         | 315/8253 [10:21<4:18:22,  1.95s/it][A
  4%|▍         | 315/8253 [10:21<4:18:22,  1.95s/it][A
  4%|▍         | 316/8253 [10:22<4:16:30,  1.94s/it][A

  4%|▍         | 316/8253 [10:22<4:16:54,  1.94s/it]  4%|▍         | 316/8253 [10:22<4:16:54,  1.94s/it][A[A
  4%|▍         | 316/8253 [10:22<4:16:48,  1.94s/it][A
  4%|▍         | 316/8253 [10:22<4:17:14,  1.94s/it][A
  4%|▍         | 316/8253 [10:22<4:17:06,  1.94s/it][A
  4%|▍         | 317/8253 [10:24<4:15:04,  1.93s/it][A
  4%|▍         | 317/8253 [10:24<4:15:38,  1.93s/it][A
  4%|▍         | 317/8253 [10:24<4:15:43,  1.93s/it][A
  4%|▍         | 317/8253 [10:24<4:15:59,  1.94s/it][A
  4%|▍         | 317/8253 [10:24<4:16:00,  1.94s/it][A
  4%|▍         | 317/8253 [10:24<4:16:10,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:16:45,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:16:59,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:17:02,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:17:09,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:17:10,  1.94s/it][A
  4%|▍         | 318/8253 [10:26<4:17:19,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:15,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:37,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:57,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:50,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:55,  1.95s/it][A
  4%|▍         | 319/8253 [10:28<4:17:59,  1.95s/it][A
  4%|▍         | 320/8253 [10:30<4:18:07,  1.95s/it][A
  4%|▍         | 320/8253 [10:30<4:18:09,  1.95s/it][A
  4%|▍         | 320/8253 [10:30<4:18:33,  1.96s/it][A
  4%|▍         | 320/8253 [10:30<4:18:37,  1.96s/it][A
  4%|▍         | 320/8253 [10:30<4:18:49,  1.96s/it][A
  4%|▍         | 320/8253 [10:30<4:19:12,  1.96s/it][A
  4%|▍         | 321/8253 [10:32<4:16:32,  1.94s/it][A
  4%|▍         | 321/8253 [10:32<4:16:56,  1.94s/it][A
  4%|▍         | 321/8253 [10:32<4:17:11,  1.95s/it][A
  4%|▍         | 321/8253 [10:32<4:17:17,  1.95s/it][A
  4%|▍         | 321/8253 [10:32<4:17:23,  1.95s/it][A
  4%|▍         | 321/8253 [10:32<4:17:09,  1.95s/it][A
  4%|▍         | 322/8253 [10:34<4:17:31,  1.95s/it][A
  4%|▍         | 322/8253 [10:34<4:17:49,  1.95s/it][A
  4%|▍         | 322/8253 [10:34<4:17:47,  1.95s/it][A
  4%|▍         | 322/8253 [10:34<4:18:23,  1.95s/it][A

  4%|▍         | 322/8253 [10:34<4:18:36,  1.96s/it][A  4%|▍         | 322/8253 [10:34<4:18:42,  1.96s/it][A
  4%|▍         | 323/8253 [10:36<4:16:23,  1.94s/it][A
  4%|▍         | 323/8253 [10:36<4:16:26,  1.94s/it][A
  4%|▍         | 323/8253 [10:36<4:16:44,  1.94s/it][A
  4%|▍         | 323/8253 [10:36<4:16:49,  1.94s/it][A

  4%|▍         | 323/8253 [10:36<4:16:45,  1.94s/it][A  4%|▍         | 323/8253 [10:36<4:16:50,  1.94s/it][A
  4%|▍         | 324/8253 [10:38<4:17:20,  1.95s/it][A
  4%|▍         | 324/8253 [10:38<4:17:24,  1.95s/it][A
  4%|▍         | 324/8253 [10:38<4:17:20,  1.95s/it][A
  4%|▍         | 324/8253 [10:38<4:17:26,  1.95s/it][A

  4%|▍         | 324/8253 [10:38<4:18:10,  1.95s/it][A  4%|▍         | 324/8253 [10:38<4:18:13,  1.95s/it][A
  4%|▍         | 325/8253 [10:40<4:15:50,  1.94s/it][A
  4%|▍         | 325/8253 [10:40<4:15:49,  1.94s/it][A
  4%|▍         | 325/8253 [10:40<4:16:04,  1.94s/it][A
  4%|▍         | 325/8253 [10:40<4:16:07,  1.94s/it][A
  4%|▍         | 325/8253 [10:40<4:16:13,  1.94s/it][A
  4%|▍         | 325/8253 [10:40<4:16:25,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:15:45,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:15:50,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:16:14,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:16:13,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:16:25,  1.94s/it][A
  4%|▍         | 326/8253 [10:42<4:16:24,  1.94s/it][A
  4%|▍         | 327/8253 [10:44<4:14:03,  1.92s/it][A
  4%|▍         | 327/8253 [10:44<4:14:09,  1.92s/it][A
  4%|▍         | 327/8253 [10:44<4:14:00,  1.92s/it][A
  4%|▍         | 327/8253 [10:44<4:14:15,  1.92s/it][A
  4%|▍         | 327/8253 [10:44<4:14:16,  1.92s/it][A
  4%|▍         | 327/8253 [10:44<4:14:18,  1.93s/it][A
  4%|▍         | 328/8253 [10:46<4:14:18,  1.93s/it][A
  4%|▍         | 328/8253 [10:46<4:14:32,  1.93s/it][A
  4%|▍         | 328/8253 [10:46<4:14:27,  1.93s/it][A
  4%|▍         | 328/8253 [10:46<4:14:39,  1.93s/it][A

  4%|▍         | 328/8253 [10:46<4:14:38,  1.93s/it][A  4%|▍         | 328/8253 [10:46<4:14:43,  1.93s/it][A

  4%|▍         | 329/8253 [10:48<4:14:58,  1.93s/it][A  4%|▍         | 329/8253 [10:48<4:14:55,  1.93s/it][A
  4%|▍         | 329/8253 [10:48<4:15:04,  1.93s/it][A
  4%|▍         | 329/8253 [10:48<4:15:01,  1.93s/it][A
  4%|▍         | 329/8253 [10:48<4:15:17,  1.93s/it][A
  4%|▍         | 329/8253 [10:48<4:15:42,  1.94s/it][A
  4%|▍         | 330/8253 [10:49<4:15:15,  1.93s/it][A
  4%|▍         | 330/8253 [10:50<4:15:14,  1.93s/it][A
  4%|▍         | 330/8253 [10:50<4:15:22,  1.93s/it][A
  4%|▍         | 330/8253 [10:50<4:15:32,  1.94s/it][A
  4%|▍         | 330/8253 [10:50<4:15:28,  1.93s/it][A
  4%|▍         | 330/8253 [10:50<4:15:37,  1.94s/it][A
  4%|▍         | 331/8253 [10:52<4:15:01,  1.93s/it][A
  4%|▍         | 331/8253 [10:51<4:15:45,  1.94s/it][A
  4%|▍         | 331/8253 [10:52<4:15:31,  1.94s/it][A

  4%|▍         | 331/8253 [10:52<4:15:38,  1.94s/it][A  4%|▍         | 331/8253 [10:52<4:15:51,  1.94s/it][A
  4%|▍         | 331/8253 [10:52<4:15:56,  1.94s/it][A
  4%|▍         | 332/8253 [10:53<4:14:49,  1.93s/it][A
  4%|▍         | 332/8253 [10:53<4:15:07,  1.93s/it][A
  4%|▍         | 332/8253 [10:54<4:15:16,  1.93s/it][A
  4%|▍         | 332/8253 [10:54<4:15:44,  1.94s/it][A
  4%|▍         | 332/8253 [10:53<4:15:41,  1.94s/it][A
  4%|▍         | 332/8253 [10:54<4:15:48,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:15:27,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:15:27,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:15:40,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:15:59,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:16:06,  1.94s/it][A
  4%|▍         | 333/8253 [10:55<4:16:07,  1.94s/it][A
  4%|▍         | 334/8253 [10:57<4:15:14,  1.93s/it][A
  4%|▍         | 334/8253 [10:57<4:15:26,  1.94s/it][A
  4%|▍         | 334/8253 [10:57<4:15:41,  1.94s/it][A

  4%|▍         | 334/8253 [10:57<4:15:34,  1.94s/it][A  4%|▍         | 334/8253 [10:57<4:15:24,  1.94s/it][A
  4%|▍         | 334/8253 [10:57<4:15:40,  1.94s/it][A
  4%|▍         | 335/8253 [10:59<4:14:49,  1.93s/it][A
  4%|▍         | 335/8253 [10:59<4:15:08,  1.93s/it][A
  4%|▍         | 335/8253 [10:59<4:15:14,  1.93s/it][A


  4%|▍         | 335/8253 [10:59<4:15:04,  1.93s/it][A  4%|▍         | 335/8253 [10:59<4:15:06,  1.93s/it][A  4%|▍         | 335/8253 [10:59<4:15:13,  1.93s/it][A
  4%|▍         | 336/8253 [11:01<4:15:24,  1.94s/it][A
  4%|▍         | 336/8253 [11:01<4:15:36,  1.94s/it][A
  4%|▍         | 336/8253 [11:01<4:15:28,  1.94s/it][A
  4%|▍         | 336/8253 [11:01<4:15:44,  1.94s/it][A
  4%|▍         | 336/8253 [11:01<4:15:38,  1.94s/it][A
  4%|▍         | 336/8253 [11:01<4:15:52,  1.94s/it][A
  4%|▍         | 337/8253 [11:03<4:15:36,  1.94s/it][A
  4%|▍         | 337/8253 [11:03<4:15:44,  1.94s/it][A

  4%|▍         | 337/8253 [11:03<4:16:07,  1.94s/it]
[A  4%|▍         | 337/8253 [11:03<4:15:52,  1.94s/it][A  4%|▍         | 337/8253 [11:03<4:16:07,  1.94s/it][A
  4%|▍         | 337/8253 [11:03<4:16:06,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:15:48,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:16:03,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:16:27,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:16:30,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:16:34,  1.94s/it][A
  4%|▍         | 338/8253 [11:05<4:16:31,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:15:28,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:15:42,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:15:41,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:15:51,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:15:53,  1.94s/it][A
  4%|▍         | 339/8253 [11:07<4:16:01,  1.94s/it][A
  4%|▍         | 340/8253 [11:09<4:16:50,  1.95s/it][A
  4%|▍         | 340/8253 [11:09<4:16:53,  1.95s/it][A

  4%|▍         | 340/8253 [11:09<4:17:17,  1.95s/it][A  4%|▍         | 340/8253 [11:09<4:17:15,  1.95s/it][A
  4%|▍         | 340/8253 [11:09<4:17:10,  1.95s/it][A
  4%|▍         | 340/8253 [11:09<4:17:37,  1.95s/it][A
  4%|▍         | 341/8253 [11:11<4:17:17,  1.95s/it][A
  4%|▍         | 341/8253 [11:11<4:17:34,  1.95s/it][A

  4%|▍         | 341/8253 [11:11<4:17:41,  1.95s/it][A  4%|▍         | 341/8253 [11:11<4:17:49,  1.96s/it][A
  4%|▍         | 341/8253 [11:11<4:17:49,  1.96s/it][A
  4%|▍         | 341/8253 [11:11<4:18:09,  1.96s/it][A
  4%|▍         | 342/8253 [11:13<4:16:18,  1.94s/it][A
  4%|▍         | 342/8253 [11:13<4:16:22,  1.94s/it][A
  4%|▍         | 342/8253 [11:13<4:17:35,  1.95s/it][A
  4%|▍         | 342/8253 [11:13<4:17:32,  1.95s/it][A
  4%|▍         | 342/8253 [11:13<4:17:22,  1.95s/it][A
  4%|▍         | 342/8253 [11:13<4:17:23,  1.95s/it][A
  4%|▍         | 343/8253 [11:15<4:17:53,  1.96s/it][A
  4%|▍         | 343/8253 [11:15<4:17:29,  1.95s/it][A
  4%|▍         | 343/8253 [11:15<4:17:46,  1.96s/it][A
  4%|▍         | 343/8253 [11:15<4:17:57,  1.96s/it][A
  4%|▍         | 343/8253 [11:15<4:18:16,  1.96s/it][A
  4%|▍         | 343/8253 [11:15<4:18:30,  1.96s/it][A
  4%|▍         | 344/8253 [11:17<4:16:31,  1.95s/it][A
  4%|▍         | 344/8253 [11:17<4:16:42,  1.95s/it][A
  4%|▍         | 344/8253 [11:17<4:16:54,  1.95s/it][A
  4%|▍         | 344/8253 [11:17<4:17:13,  1.95s/it][A
  4%|▍         | 344/8253 [11:17<4:17:08,  1.95s/it][A
  4%|▍         | 344/8253 [11:17<4:17:02,  1.95s/it][A
  4%|▍         | 345/8253 [11:19<4:16:08,  1.94s/it][A
  4%|▍         | 345/8253 [11:19<4:16:32,  1.95s/it][A
  4%|▍         | 345/8253 [11:19<4:16:55,  1.95s/it][A

  4%|▍         | 345/8253 [11:19<4:17:11,  1.95s/it][A  4%|▍         | 345/8253 [11:19<4:16:58,  1.95s/it][A
  4%|▍         | 345/8253 [11:19<4:17:04,  1.95s/it][A
  4%|▍         | 346/8253 [11:21<4:17:52,  1.96s/it][A
  4%|▍         | 346/8253 [11:21<4:17:51,  1.96s/it][A
  4%|▍         | 346/8253 [11:21<4:18:07,  1.96s/it][A
  4%|▍         | 346/8253 [11:21<4:18:00,  1.96s/it][A
  4%|▍         | 346/8253 [11:21<4:18:02,  1.96s/it][A
  4%|▍         | 346/8253 [11:21<4:18:05,  1.96s/it][A
  4%|▍         | 347/8253 [11:23<4:16:49,  1.95s/it][A
  4%|▍         | 347/8253 [11:23<4:16:46,  1.95s/it][A
  4%|▍         | 347/8253 [11:23<4:17:01,  1.95s/it][A
  4%|▍         | 347/8253 [11:23<4:17:13,  1.95s/it][A
  4%|▍         | 347/8253 [11:23<4:17:19,  1.95s/it][A
  4%|▍         | 347/8253 [11:23<4:17:17,  1.95s/it][A
  4%|▍         | 348/8253 [11:25<4:15:56,  1.94s/it][A

  4%|▍         | 348/8253 [11:25<4:16:11,  1.94s/it][A  4%|▍         | 348/8253 [11:25<4:15:54,  1.94s/it][A
  4%|▍         | 348/8253 [11:25<4:16:17,  1.95s/it][A
  4%|▍         | 348/8253 [11:25<4:16:03,  1.94s/it][A
  4%|▍         | 348/8253 [11:25<4:16:35,  1.95s/it][A
  4%|▍         | 349/8253 [11:27<4:17:43,  1.96s/it][A
  4%|▍         | 349/8253 [11:27<4:18:22,  1.96s/it][A
  4%|▍         | 349/8253 [11:27<4:18:13,  1.96s/it][A
  4%|▍         | 349/8253 [11:27<4:18:29,  1.96s/it][A
  4%|▍         | 349/8253 [11:27<4:18:14,  1.96s/it][A
  4%|▍         | 349/8253 [11:27<4:18:30,  1.96s/it][A
  4%|▍         | 350/8253 [11:29<4:16:45,  1.95s/it][A
  4%|▍         | 350/8253 [11:28<4:16:54,  1.95s/it][A
  4%|▍         | 350/8253 [11:29<4:17:04,  1.95s/it][A
  4%|▍         | 350/8253 [11:29<4:17:16,  1.95s/it][A
  4%|▍         | 350/8253 [11:29<4:17:24,  1.95s/it][A
  4%|▍         | 350/8253 [11:29<4:17:30,  1.96s/it][A
  4%|▍         | 351/8253 [11:31<4:15:33,  1.94s/it][A
  4%|▍         | 351/8253 [11:31<4:15:33,  1.94s/it][A
  4%|▍         | 351/8253 [11:31<4:15:46,  1.94s/it][A
  4%|▍         | 351/8253 [11:31<4:15:51,  1.94s/it][A
  4%|▍         | 351/8253 [11:31<4:16:00,  1.94s/it][A
  4%|▍         | 351/8253 [11:30<4:16:13,  1.95s/it][A
  4%|▍         | 352/8253 [11:32<4:14:57,  1.94s/it][A
  4%|▍         | 352/8253 [11:32<4:15:25,  1.94s/it][A
  4%|▍         | 352/8253 [11:32<4:15:21,  1.94s/it][A
  4%|▍         | 352/8253 [11:32<4:15:38,  1.94s/it][A
  4%|▍         | 352/8253 [11:32<4:15:37,  1.94s/it][A
  4%|▍         | 352/8253 [11:32<4:15:49,  1.94s/it][A
  4%|▍         | 353/8253 [11:34<4:14:24,  1.93s/it][A
  4%|▍         | 353/8253 [11:34<4:15:05,  1.94s/it][A
  4%|▍         | 353/8253 [11:34<4:15:02,  1.94s/it][A
  4%|▍         | 353/8253 [11:34<4:15:11,  1.94s/it][A
  4%|▍         | 353/8253 [11:34<4:15:17,  1.94s/it][A
  4%|▍         | 353/8253 [11:34<4:15:15,  1.94s/it][A
  4%|▍         | 354/8253 [11:36<4:16:45,  1.95s/it][A
  4%|▍         | 354/8253 [11:36<4:17:07,  1.95s/it][A
  4%|▍         | 354/8253 [11:36<4:17:00,  1.95s/it][A
  4%|▍         | 354/8253 [11:36<4:17:09,  1.95s/it][A
  4%|▍         | 354/8253 [11:36<4:17:11,  1.95s/it][A
  4%|▍         | 354/8253 [11:36<4:17:09,  1.95s/it][A
  4%|▍         | 355/8253 [11:38<4:22:10,  1.99s/it][A
  4%|▍         | 355/8253 [11:38<4:22:18,  1.99s/it][A
  4%|▍         | 355/8253 [11:38<4:22:18,  1.99s/it][A
  4%|▍         | 355/8253 [11:38<4:22:42,  2.00s/it][A
  4%|▍         | 355/8253 [11:38<4:22:30,  1.99s/it][A
  4%|▍         | 355/8253 [11:38<4:22:50,  2.00s/it][A
  4%|▍         | 356/8253 [11:40<4:20:12,  1.98s/it][A
  4%|▍         | 356/8253 [11:40<4:20:25,  1.98s/it][A
  4%|▍         | 356/8253 [11:40<4:20:53,  1.98s/it][A
  4%|▍         | 356/8253 [11:40<4:20:52,  1.98s/it][A
  4%|▍         | 356/8253 [11:40<4:21:10,  1.98s/it][A
  4%|▍         | 356/8253 [11:40<4:20:52,  1.98s/it][A
  4%|▍         | 357/8253 [11:42<4:19:14,  1.97s/it][A
  4%|▍         | 357/8253 [11:42<4:19:47,  1.97s/it][A
  4%|▍         | 357/8253 [11:42<4:19:51,  1.97s/it][A
  4%|▍         | 357/8253 [11:42<4:20:05,  1.98s/it][A
  4%|▍         | 357/8253 [11:42<4:19:55,  1.98s/it][A
  4%|▍         | 357/8253 [11:42<4:19:47,  1.97s/it][A
  4%|▍         | 358/8253 [11:44<4:17:33,  1.96s/it][A
  4%|▍         | 358/8253 [11:44<4:17:31,  1.96s/it][A
  4%|▍         | 358/8253 [11:44<4:17:35,  1.96s/it][A
  4%|▍         | 358/8253 [11:44<4:17:51,  1.96s/it][A

  4%|▍         | 358/8253 [11:44<4:18:14,  1.96s/it][A  4%|▍         | 358/8253 [11:44<4:17:53,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:17:56,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:17:58,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:18:01,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:17:53,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:18:00,  1.96s/it][A
  4%|▍         | 359/8253 [11:46<4:18:18,  1.96s/it][A
  4%|▍         | 360/8253 [11:48<4:16:43,  1.95s/it][A
  4%|▍         | 360/8253 [11:48<4:16:40,  1.95s/it][A
  4%|▍         | 360/8253 [11:48<4:16:45,  1.95s/it][A
  4%|▍         | 360/8253 [11:48<4:16:55,  1.95s/it][A
  4%|▍         | 360/8253 [11:48<4:16:41,  1.95s/it][A
  4%|▍         | 360/8253 [11:48<4:16:57,  1.95s/it][A
  4%|▍         | 361/8253 [11:50<4:13:17,  1.93s/it][A
  4%|▍         | 361/8253 [11:50<4:13:26,  1.93s/it][A
  4%|▍         | 361/8253 [11:50<4:13:46,  1.93s/it][A
  4%|▍         | 361/8253 [11:50<4:13:37,  1.93s/it][A

  4%|▍         | 361/8253 [11:50<4:13:34,  1.93s/it][A  4%|▍         | 361/8253 [11:50<4:13:43,  1.93s/it][A
  4%|▍         | 362/8253 [11:52<4:12:20,  1.92s/it][A

  4%|▍         | 362/8253 [11:52<4:12:23,  1.92s/it][A  4%|▍         | 362/8253 [11:52<4:12:29,  1.92s/it][A

  4%|▍         | 362/8253 [11:52<4:12:49,  1.92s/it][A  4%|▍         | 362/8253 [11:52<4:12:57,  1.92s/it][A
  4%|▍         | 362/8253 [11:52<4:13:04,  1.92s/it][A
  4%|▍         | 363/8253 [11:54<4:12:47,  1.92s/it][A
  4%|▍         | 363/8253 [11:54<4:12:38,  1.92s/it][A
  4%|▍         | 363/8253 [11:54<4:13:05,  1.92s/it][A
  4%|▍         | 363/8253 [11:54<4:13:02,  1.92s/it][A
  4%|▍         | 363/8253 [11:54<4:13:09,  1.93s/it][A
  4%|▍         | 363/8253 [11:54<4:13:14,  1.93s/it][A
  4%|▍         | 364/8253 [11:56<4:11:01,  1.91s/it][A
  4%|▍         | 364/8253 [11:56<4:11:34,  1.91s/it][A
  4%|▍         | 364/8253 [11:56<4:11:49,  1.92s/it][A
  4%|▍         | 364/8253 [11:56<4:11:47,  1.92s/it][A
  4%|▍         | 364/8253 [11:56<4:11:52,  1.92s/it][A
  4%|▍         | 364/8253 [11:56<4:12:05,  1.92s/it][A
  4%|▍         | 365/8253 [11:58<4:14:47,  1.94s/it][A
  4%|▍         | 365/8253 [11:58<4:14:59,  1.94s/it][A

  4%|▍         | 365/8253 [11:58<4:15:08,  1.94s/it][A  4%|▍         | 365/8253 [11:58<4:15:23,  1.94s/it][A
  4%|▍         | 365/8253 [11:58<4:15:10,  1.94s/it][A
  4%|▍         | 365/8253 [11:58<4:15:37,  1.94s/it][A
  4%|▍         | 366/8253 [12:00<4:15:32,  1.94s/it][A
  4%|▍         | 366/8253 [12:00<4:15:39,  1.94s/it][A
  4%|▍         | 366/8253 [12:00<4:16:10,  1.95s/it][A

  4%|▍         | 366/8253 [12:00<4:16:18,  1.95s/it][A  4%|▍         | 366/8253 [12:00<4:16:03,  1.95s/it][A
  4%|▍         | 366/8253 [12:00<4:16:10,  1.95s/it][A

  4%|▍         | 367/8253 [12:02<4:16:00,  1.95s/it][A  4%|▍         | 367/8253 [12:02<4:16:08,  1.95s/it][A
  4%|▍         | 367/8253 [12:02<4:16:05,  1.95s/it][A
  4%|▍         | 367/8253 [12:02<4:16:22,  1.95s/it][A
  4%|▍         | 367/8253 [12:02<4:16:36,  1.95s/it][A
  4%|▍         | 367/8253 [12:02<4:16:37,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:15:48,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:16:22,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:16:38,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:16:29,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:16:41,  1.95s/it][A
  4%|▍         | 368/8253 [12:04<4:16:50,  1.95s/it][A
  4%|▍         | 369/8253 [12:05<4:14:20,  1.94s/it][A
  4%|▍         | 369/8253 [12:06<4:14:48,  1.94s/it][A
  4%|▍         | 369/8253 [12:06<4:14:53,  1.94s/it][A
  4%|▍         | 369/8253 [12:06<4:14:47,  1.94s/it][A
  4%|▍         | 369/8253 [12:06<4:15:16,  1.94s/it]
[A  4%|▍         | 369/8253 [12:06<4:15:13,  1.94s/it][A
  4%|▍         | 370/8253 [12:08<4:14:57,  1.94s/it][A
  4%|▍         | 370/8253 [12:07<4:15:08,  1.94s/it][A
  4%|▍         | 370/8253 [12:08<4:15:02,  1.94s/it][A
  4%|▍         | 370/8253 [12:08<4:15:14,  1.94s/it][A
  4%|▍         | 370/8253 [12:08<4:15:42,  1.95s/it][A
  4%|▍         | 370/8253 [12:08<4:15:33,  1.95s/it][A
  4%|▍         | 371/8253 [12:10<4:18:31,  1.97s/it][A
  4%|▍         | 371/8253 [12:10<4:18:21,  1.97s/it][A
  4%|▍         | 371/8253 [12:10<4:18:55,  1.97s/it][A
  4%|▍         | 371/8253 [12:10<4:18:48,  1.97s/it][A
  4%|▍         | 371/8253 [12:09<4:19:11,  1.97s/it][A
  4%|▍         | 371/8253 [12:10<4:19:09,  1.97s/it][A

  5%|▍         | 372/8253 [12:11<4:16:29,  1.95s/it][A  5%|▍         | 372/8253 [12:11<4:16:47,  1.95s/it][A
  5%|▍         | 372/8253 [12:11<4:16:40,  1.95s/it][A
  5%|▍         | 372/8253 [12:11<4:16:50,  1.96s/it][A
  5%|▍         | 372/8253 [12:11<4:16:52,  1.96s/it][A
  5%|▍         | 372/8253 [12:11<4:16:52,  1.96s/it][A

  5%|▍         | 373/8253 [12:13<4:16:23,  1.95s/it][A
  5%|▍         | 373/8253 [12:13<4:16:36,  1.95s/it][A  5%|▍         | 373/8253 [12:13<4:16:18,  1.95s/it][A
  5%|▍         | 373/8253 [12:13<4:16:36,  1.95s/it][A
  5%|▍         | 373/8253 [12:13<4:16:36,  1.95s/it][A
  5%|▍         | 373/8253 [12:13<4:16:37,  1.95s/it][A
  5%|▍         | 374/8253 [12:15<4:15:06,  1.94s/it][A
  5%|▍         | 374/8253 [12:15<4:15:15,  1.94s/it][A

  5%|▍         | 374/8253 [12:15<4:15:19,  1.94s/it]
[A  5%|▍         | 374/8253 [12:15<4:15:32,  1.95s/it][A  5%|▍         | 374/8253 [12:15<4:15:24,  1.94s/it][A
  5%|▍         | 374/8253 [12:15<4:15:30,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:15:24,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:15:38,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:15:42,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:15:54,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:15:57,  1.95s/it][A
  5%|▍         | 375/8253 [12:17<4:16:05,  1.95s/it][A
  5%|▍         | 376/8253 [12:19<4:16:37,  1.95s/it][A
  5%|▍         | 376/8253 [12:19<4:17:06,  1.96s/it][A
  5%|▍         | 376/8253 [12:19<4:17:05,  1.96s/it][A

  5%|▍         | 376/8253 [12:19<4:17:14,  1.96s/it][A  5%|▍         | 376/8253 [12:19<4:17:25,  1.96s/it][A
  5%|▍         | 376/8253 [12:19<4:17:14,  1.96s/it][A
  5%|▍         | 377/8253 [12:21<4:17:08,  1.96s/it][A
  5%|▍         | 377/8253 [12:21<4:17:27,  1.96s/it][A

  5%|▍         | 377/8253 [12:21<4:17:10,  1.96s/it][A  5%|▍         | 377/8253 [12:21<4:17:24,  1.96s/it][A
  5%|▍         | 377/8253 [12:21<4:17:31,  1.96s/it][A
  5%|▍         | 377/8253 [12:21<4:17:29,  1.96s/it][A

  5%|▍         | 378/8253 [12:23<4:16:57,  1.96s/it][A  5%|▍         | 378/8253 [12:23<4:17:06,  1.96s/it][A
  5%|▍         | 378/8253 [12:23<4:17:10,  1.96s/it][A
  5%|▍         | 378/8253 [12:23<4:17:10,  1.96s/it][A

  5%|▍         | 378/8253 [12:23<4:17:24,  1.96s/it]  5%|▍         | 378/8253 [12:23<4:17:26,  1.96s/it][A[A
  5%|▍         | 379/8253 [12:25<4:16:42,  1.96s/it][A

  5%|▍         | 379/8253 [12:25<4:16:54,  1.96s/it][A  5%|▍         | 379/8253 [12:25<4:16:42,  1.96s/it][A
  5%|▍         | 379/8253 [12:25<4:16:54,  1.96s/it][A
  5%|▍         | 379/8253 [12:25<4:17:00,  1.96s/it][A
  5%|▍         | 379/8253 [12:25<4:17:02,  1.96s/it][A

  5%|▍         | 380/8253 [12:27<4:17:14,  1.96s/it][A  5%|▍         | 380/8253 [12:27<4:17:31,  1.96s/it][A
  5%|▍         | 380/8253 [12:27<4:17:33,  1.96s/it][A
  5%|▍         | 380/8253 [12:27<4:17:27,  1.96s/it][A
  5%|▍         | 380/8253 [12:27<4:17:54,  1.97s/it][A
  5%|▍         | 380/8253 [12:27<4:17:38,  1.96s/it][A
  5%|▍         | 381/8253 [12:29<4:15:32,  1.95s/it][A
  5%|▍         | 381/8253 [12:29<4:16:05,  1.95s/it][A
  5%|▍         | 381/8253 [12:29<4:16:04,  1.95s/it][A
  5%|▍         | 381/8253 [12:29<4:15:54,  1.95s/it][A

  5%|▍         | 381/8253 [12:29<4:15:58,  1.95s/it][A  5%|▍         | 381/8253 [12:29<4:15:58,  1.95s/it][A
  5%|▍         | 382/8253 [12:31<4:17:19,  1.96s/it][A
  5%|▍         | 382/8253 [12:31<4:17:10,  1.96s/it][A
  5%|▍         | 382/8253 [12:31<4:17:24,  1.96s/it][A
  5%|▍         | 382/8253 [12:31<4:17:40,  1.96s/it][A
  5%|▍         | 382/8253 [12:31<4:17:29,  1.96s/it][A
  5%|▍         | 382/8253 [12:31<4:17:50,  1.97s/it][A
  5%|▍         | 383/8253 [12:33<4:15:45,  1.95s/it][A
  5%|▍         | 383/8253 [12:33<4:16:04,  1.95s/it][A
  5%|▍         | 383/8253 [12:33<4:16:08,  1.95s/it][A
  5%|▍         | 383/8253 [12:33<4:16:18,  1.95s/it][A
  5%|▍         | 383/8253 [12:33<4:16:03,  1.95s/it][A
  5%|▍         | 383/8253 [12:33<4:16:13,  1.95s/it][A
  5%|▍         | 384/8253 [12:35<4:17:56,  1.97s/it][A
  5%|▍         | 384/8253 [12:35<4:17:48,  1.97s/it][A
  5%|▍         | 384/8253 [12:35<4:18:09,  1.97s/it][A
  5%|▍         | 384/8253 [12:35<4:18:04,  1.97s/it][A
  5%|▍         | 384/8253 [12:35<4:18:15,  1.97s/it][A
  5%|▍         | 384/8253 [12:35<4:18:20,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:23,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:21,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:42,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:25,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:45,  1.97s/it][A
  5%|▍         | 385/8253 [12:37<4:18:37,  1.97s/it][A
  5%|▍         | 386/8253 [12:39<4:28:12,  2.05s/it][A
  5%|▍         | 386/8253 [12:39<4:28:14,  2.05s/it][A
  5%|▍         | 386/8253 [12:39<4:28:23,  2.05s/it][A
  5%|▍         | 386/8253 [12:39<4:28:45,  2.05s/it][A
  5%|▍         | 386/8253 [12:39<4:28:51,  2.05s/it][A
  5%|▍         | 386/8253 [12:39<4:28:53,  2.05s/it][A
  5%|▍         | 387/8253 [12:41<4:25:19,  2.02s/it][A
  5%|▍         | 387/8253 [12:41<4:25:18,  2.02s/it][A
  5%|▍         | 387/8253 [12:41<4:25:37,  2.03s/it][A
  5%|▍         | 387/8253 [12:41<4:25:40,  2.03s/it][A
  5%|▍         | 387/8253 [12:41<4:25:38,  2.03s/it][A
  5%|▍         | 387/8253 [12:41<4:25:54,  2.03s/it][A
  5%|▍         | 388/8253 [12:43<4:22:25,  2.00s/it][A
  5%|▍         | 388/8253 [12:43<4:22:58,  2.01s/it][A
  5%|▍         | 388/8253 [12:43<4:22:34,  2.00s/it][A
  5%|▍         | 388/8253 [12:43<4:22:49,  2.01s/it][A
  5%|▍         | 388/8253 [12:43<4:22:53,  2.01s/it][A
  5%|▍         | 388/8253 [12:43<4:23:01,  2.01s/it][A
  5%|▍         | 389/8253 [12:45<4:19:53,  1.98s/it][A
  5%|▍         | 389/8253 [12:45<4:19:46,  1.98s/it][A
  5%|▍         | 389/8253 [12:45<4:19:53,  1.98s/it][A
  5%|▍         | 389/8253 [12:45<4:19:56,  1.98s/it][A

  5%|▍         | 389/8253 [12:45<4:20:00,  1.98s/it][A  5%|▍         | 389/8253 [12:45<4:19:53,  1.98s/it][A
  5%|▍         | 390/8253 [12:47<4:17:42,  1.97s/it][A

  5%|▍         | 390/8253 [12:47<4:17:55,  1.97s/it][A  5%|▍         | 390/8253 [12:47<4:17:50,  1.97s/it][A
  5%|▍         | 390/8253 [12:47<4:18:20,  1.97s/it][A
  5%|▍         | 390/8253 [12:47<4:18:17,  1.97s/it][A
  5%|▍         | 390/8253 [12:47<4:18:19,  1.97s/it][A
  5%|▍         | 391/8253 [12:49<4:16:25,  1.96s/it][A

  5%|▍         | 391/8253 [12:49<4:16:19,  1.96s/it][A  5%|▍         | 391/8253 [12:49<4:16:37,  1.96s/it][A

  5%|▍         | 391/8253 [12:49<4:16:31,  1.96s/it][A  5%|▍         | 391/8253 [12:49<4:16:36,  1.96s/it][A
  5%|▍         | 391/8253 [12:49<4:16:51,  1.96s/it][A
  5%|▍         | 392/8253 [12:51<4:15:16,  1.95s/it][A
  5%|▍         | 392/8253 [12:51<4:15:30,  1.95s/it][A
  5%|▍         | 392/8253 [12:51<4:15:24,  1.95s/it][A
  5%|▍         | 392/8253 [12:51<4:15:31,  1.95s/it][A
  5%|▍         | 392/8253 [12:51<4:15:45,  1.95s/it][A
  5%|▍         | 392/8253 [12:51<4:15:35,  1.95s/it][A
  5%|▍         | 393/8253 [12:53<4:15:53,  1.95s/it][A
  5%|▍         | 393/8253 [12:53<4:16:06,  1.96s/it][A
  5%|▍         | 393/8253 [12:53<4:16:10,  1.96s/it][A
  5%|▍         | 393/8253 [12:53<4:16:11,  1.96s/it][A
  5%|▍         | 393/8253 [12:53<4:16:09,  1.96s/it][A
  5%|▍         | 393/8253 [12:53<4:16:24,  1.96s/it][A
  5%|▍         | 394/8253 [12:55<4:17:16,  1.96s/it][A
  5%|▍         | 394/8253 [12:55<4:17:04,  1.96s/it][A
  5%|▍         | 394/8253 [12:55<4:17:17,  1.96s/it][A
  5%|▍         | 394/8253 [12:55<4:17:20,  1.96s/it][A
  5%|▍         | 394/8253 [12:55<4:17:25,  1.97s/it][A
  5%|▍         | 394/8253 [12:55<4:17:27,  1.97s/it][A
  5%|▍         | 395/8253 [12:57<4:16:05,  1.96s/it][A
  5%|▍         | 395/8253 [12:57<4:15:56,  1.95s/it][A
  5%|▍         | 395/8253 [12:57<4:16:04,  1.96s/it][A
  5%|▍         | 395/8253 [12:57<4:16:17,  1.96s/it][A
  5%|▍         | 395/8253 [12:57<4:16:22,  1.96s/it][A
  5%|▍         | 395/8253 [12:57<4:16:26,  1.96s/it][A
  5%|▍         | 396/8253 [12:59<4:14:44,  1.95s/it][A
  5%|▍         | 396/8253 [12:59<4:14:56,  1.95s/it][A
  5%|▍         | 396/8253 [12:59<4:14:55,  1.95s/it][A
  5%|▍         | 396/8253 [12:59<4:14:51,  1.95s/it][A
  5%|▍         | 396/8253 [12:59<4:14:53,  1.95s/it][A
  5%|▍         | 396/8253 [12:59<4:15:06,  1.95s/it][A
  5%|▍         | 397/8253 [13:01<4:15:01,  1.95s/it][A
  5%|▍         | 397/8253 [13:01<4:15:02,  1.95s/it][A
  5%|▍         | 397/8253 [13:00<4:15:07,  1.95s/it][A
  5%|▍         | 397/8253 [13:01<4:15:07,  1.95s/it][A
  5%|▍         | 397/8253 [13:01<4:15:14,  1.95s/it][A
  5%|▍         | 397/8253 [13:01<4:15:28,  1.95s/it][A
  5%|▍         | 398/8253 [13:03<4:14:08,  1.94s/it][A
  5%|▍         | 398/8253 [13:03<4:14:28,  1.94s/it][A

  5%|▍         | 398/8253 [13:03<4:14:41,  1.95s/it][A  5%|▍         | 398/8253 [13:03<4:14:30,  1.94s/it][A

  5%|▍         | 398/8253 [13:03<4:14:27,  1.94s/it][A  5%|▍         | 398/8253 [13:02<4:14:38,  1.95s/it][A
  5%|▍         | 399/8253 [13:05<4:15:24,  1.95s/it][A
  5%|▍         | 399/8253 [13:04<4:15:43,  1.95s/it][A
  5%|▍         | 399/8253 [13:05<4:15:56,  1.96s/it][A
  5%|▍         | 399/8253 [13:05<4:16:01,  1.96s/it][A

  5%|▍         | 399/8253 [13:05<4:16:02,  1.96s/it][A  5%|▍         | 399/8253 [13:05<4:16:02,  1.96s/it][A
  5%|▍         | 400/8253 [13:06<4:15:46,  1.95s/it][A
  5%|▍         | 400/8253 [13:06<4:15:45,  1.95s/it][A
  5%|▍         | 400/8253 [13:06<4:15:51,  1.95s/it][A
  5%|▍         | 400/8253 [13:06<4:16:07,  1.96s/it][A
  5%|▍         | 400/8253 [13:06<4:16:05,  1.96s/it][A
  5%|▍         | 400/8253 [13:06<4:16:17,  1.96s/it][A

  5%|▍         | 401/8253 [13:08<4:14:40,  1.95s/it][A  5%|▍         | 401/8253 [13:08<4:14:47,  1.95s/it][A
  5%|▍         | 401/8253 [13:08<4:14:53,  1.95s/it][A
  5%|▍         | 401/8253 [13:08<4:15:02,  1.95s/it][A
  5%|▍         | 401/8253 [13:08<4:15:04,  1.95s/it][A
  5%|▍         | 401/8253 [13:08<4:15:07,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:14:35,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:15:19,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:15:16,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:15:28,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:15:23,  1.95s/it][A
  5%|▍         | 402/8253 [13:10<4:15:23,  1.95s/it][A
  5%|▍         | 403/8253 [13:12<4:15:16,  1.95s/it][A
  5%|▍         | 403/8253 [13:12<4:15:37,  1.95s/it][A
  5%|▍         | 403/8253 [13:12<4:15:56,  1.96s/it][A
  5%|▍         | 403/8253 [13:12<4:15:58,  1.96s/it][A

  5%|▍         | 403/8253 [13:12<4:16:01,  1.96s/it][A  5%|▍         | 403/8253 [13:12<4:16:05,  1.96s/it][A
  5%|▍         | 404/8253 [13:14<4:14:50,  1.95s/it][A
  5%|▍         | 404/8253 [13:14<4:14:41,  1.95s/it][A
  5%|▍         | 404/8253 [13:14<4:14:50,  1.95s/it][A
  5%|▍         | 404/8253 [13:14<4:15:19,  1.95s/it][A
  5%|▍         | 404/8253 [13:14<4:15:02,  1.95s/it][A
  5%|▍         | 404/8253 [13:14<4:15:07,  1.95s/it][A
  5%|▍         | 405/8253 [13:16<4:14:02,  1.94s/it][A
  5%|▍         | 405/8253 [13:16<4:14:25,  1.95s/it][A

  5%|▍         | 405/8253 [13:16<4:14:28,  1.95s/it][A  5%|▍         | 405/8253 [13:16<4:14:27,  1.95s/it][A
  5%|▍         | 405/8253 [13:16<4:14:42,  1.95s/it][A
  5%|▍         | 405/8253 [13:16<4:14:50,  1.95s/it][A
  5%|▍         | 406/8253 [13:18<4:13:31,  1.94s/it][A
  5%|▍         | 406/8253 [13:18<4:13:50,  1.94s/it][A
  5%|▍         | 406/8253 [13:18<4:13:59,  1.94s/it][A
  5%|▍         | 406/8253 [13:18<4:13:59,  1.94s/it][A
  5%|▍         | 406/8253 [13:18<4:14:05,  1.94s/it][A
  5%|▍         | 406/8253 [13:18<4:14:16,  1.94s/it][A
  5%|▍         | 407/8253 [13:20<4:13:56,  1.94s/it][A
  5%|▍         | 407/8253 [13:20<4:14:11,  1.94s/it][A
  5%|▍         | 407/8253 [13:20<4:14:02,  1.94s/it][A
  5%|▍         | 407/8253 [13:20<4:14:27,  1.95s/it][A
  5%|▍         | 407/8253 [13:20<4:14:38,  1.95s/it][A
  5%|▍         | 407/8253 [13:20<4:14:31,  1.95s/it][A
  5%|▍         | 408/8253 [13:22<4:15:01,  1.95s/it][A
  5%|▍         | 408/8253 [13:22<4:15:09,  1.95s/it][A
  5%|▍         | 408/8253 [13:22<4:15:26,  1.95s/it][A
  5%|▍         | 408/8253 [13:22<4:15:41,  1.96s/it][A

  5%|▍         | 408/8253 [13:22<4:15:38,  1.96s/it][A  5%|▍         | 408/8253 [13:22<4:15:27,  1.95s/it][A
  5%|▍         | 409/8253 [13:24<4:15:30,  1.95s/it][A
  5%|▍         | 409/8253 [13:24<4:15:40,  1.96s/it][A
  5%|▍         | 409/8253 [13:24<4:15:52,  1.96s/it][A

  5%|▍         | 409/8253 [13:24<4:16:03,  1.96s/it][A  5%|▍         | 409/8253 [13:24<4:16:21,  1.96s/it][A
  5%|▍         | 409/8253 [13:24<4:16:16,  1.96s/it][A
  5%|▍         | 410/8253 [13:26<4:16:28,  1.96s/it][A

  5%|▍         | 410/8253 [13:26<4:17:19,  1.97s/it][A  5%|▍         | 410/8253 [13:26<4:17:30,  1.97s/it][A
  5%|▍         | 410/8253 [13:26<4:17:34,  1.97s/it][A

  5%|▍         | 410/8253 [13:26<4:17:45,  1.97s/it][A  5%|▍         | 410/8253 [13:26<4:17:44,  1.97s/it][A
  5%|▍         | 411/8253 [13:28<4:18:29,  1.98s/it][A
  5%|▍         | 411/8253 [13:28<4:18:54,  1.98s/it][A
  5%|▍         | 411/8253 [13:28<4:19:32,  1.99s/it][A


  5%|▍         | 411/8253 [13:28<4:19:09,  1.98s/it][A  5%|▍         | 411/8253 [13:28<4:19:17,  1.98s/it]  5%|▍         | 411/8253 [13:28<4:18:59,  1.98s/it][A[A
  5%|▍         | 412/8253 [13:30<4:20:46,  2.00s/it][A
  5%|▍         | 412/8253 [13:30<4:20:27,  1.99s/it][A

  5%|▍         | 412/8253 [13:30<4:20:54,  2.00s/it][A  5%|▍         | 412/8253 [13:30<4:20:42,  1.99s/it][A
  5%|▍         | 412/8253 [13:30<4:20:55,  2.00s/it][A
  5%|▍         | 412/8253 [13:30<4:20:54,  2.00s/it][A
  5%|▌         | 413/8253 [13:32<4:18:35,  1.98s/it][A
  5%|▌         | 413/8253 [13:32<4:19:22,  1.99s/it][A
  5%|▌         | 413/8253 [13:32<4:18:58,  1.98s/it][A
  5%|▌         | 413/8253 [13:32<4:19:02,  1.98s/it][A
  5%|▌         | 413/8253 [13:32<4:19:18,  1.98s/it][A
  5%|▌         | 413/8253 [13:32<4:19:12,  1.98s/it][A

  5%|▌         | 414/8253 [13:34<4:18:33,  1.98s/it][A  5%|▌         | 414/8253 [13:34<4:18:32,  1.98s/it][A
  5%|▌         | 414/8253 [13:34<4:18:56,  1.98s/it][A
  5%|▌         | 414/8253 [13:34<4:19:02,  1.98s/it][A
  5%|▌         | 414/8253 [13:34<4:19:21,  1.99s/it][A
  5%|▌         | 414/8253 [13:34<4:19:01,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:31,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:15,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:35,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:48,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:46,  1.98s/it][A
  5%|▌         | 415/8253 [13:36<4:18:58,  1.98s/it][A
  5%|▌         | 416/8253 [13:38<4:18:25,  1.98s/it][A
  5%|▌         | 416/8253 [13:38<4:18:22,  1.98s/it][A

  5%|▌         | 416/8253 [13:38<4:18:41,  1.98s/it][A  5%|▌         | 416/8253 [13:38<4:18:28,  1.98s/it][A
  5%|▌         | 416/8253 [13:38<4:18:48,  1.98s/it][A
  5%|▌         | 416/8253 [13:38<4:18:48,  1.98s/it][A
  5%|▌         | 417/8253 [13:40<4:16:58,  1.97s/it][A
  5%|▌         | 417/8253 [13:40<4:16:54,  1.97s/it][A
  5%|▌         | 417/8253 [13:40<4:17:15,  1.97s/it][A
  5%|▌         | 417/8253 [13:40<4:17:22,  1.97s/it][A
  5%|▌         | 417/8253 [13:40<4:17:22,  1.97s/it][A
  5%|▌         | 417/8253 [13:40<4:17:29,  1.97s/it][A
  5%|▌         | 418/8253 [13:42<4:16:14,  1.96s/it][A
  5%|▌         | 418/8253 [13:42<4:16:15,  1.96s/it][A
  5%|▌         | 418/8253 [13:42<4:16:34,  1.96s/it][A
  5%|▌         | 418/8253 [13:42<4:16:43,  1.97s/it][A
  5%|▌         | 418/8253 [13:42<4:16:47,  1.97s/it][A
  5%|▌         | 418/8253 [13:42<4:17:11,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:07,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:24,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:20,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:40,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:42,  1.97s/it][A
  5%|▌         | 419/8253 [13:44<4:17:57,  1.98s/it][A
  5%|▌         | 420/8253 [13:46<4:15:55,  1.96s/it][A
  5%|▌         | 420/8253 [13:46<4:16:07,  1.96s/it][A
  5%|▌         | 420/8253 [13:46<4:16:24,  1.96s/it][A
  5%|▌         | 420/8253 [13:46<4:16:33,  1.97s/it][A
  5%|▌         | 420/8253 [13:46<4:16:40,  1.97s/it][A
  5%|▌         | 420/8253 [13:46<4:16:55,  1.97s/it][A
  5%|▌         | 421/8253 [13:48<4:15:39,  1.96s/it][A
  5%|▌         | 421/8253 [13:48<4:16:06,  1.96s/it][A
  5%|▌         | 421/8253 [13:48<4:16:13,  1.96s/it][A
  5%|▌         | 421/8253 [13:48<4:16:33,  1.97s/it][A
  5%|▌         | 421/8253 [13:48<4:16:30,  1.97s/it][A
  5%|▌         | 421/8253 [13:48<4:16:27,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:15:52,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:16:11,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:16:15,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:16:23,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:16:21,  1.96s/it][A
  5%|▌         | 422/8253 [13:50<4:16:25,  1.96s/it][A
  5%|▌         | 423/8253 [13:52<4:17:33,  1.97s/it][A
  5%|▌         | 423/8253 [13:52<4:17:38,  1.97s/it][A
  5%|▌         | 423/8253 [13:52<4:17:55,  1.98s/it][A
  5%|▌         | 423/8253 [13:52<4:17:57,  1.98s/it][A
  5%|▌         | 423/8253 [13:52<4:18:26,  1.98s/it][A
  5%|▌         | 423/8253 [13:52<4:18:23,  1.98s/it][A
  5%|▌         | 424/8253 [13:54<4:16:10,  1.96s/it][A

  5%|▌         | 424/8253 [13:54<4:16:32,  1.97s/it][A  5%|▌         | 424/8253 [13:54<4:16:29,  1.97s/it][A
  5%|▌         | 424/8253 [13:54<4:16:24,  1.97s/it][A
  5%|▌         | 424/8253 [13:54<4:16:38,  1.97s/it][A
  5%|▌         | 424/8253 [13:54<4:16:28,  1.97s/it][A
  5%|▌         | 425/8253 [13:56<4:15:49,  1.96s/it][A
  5%|▌         | 425/8253 [13:55<4:15:49,  1.96s/it][A
  5%|▌         | 425/8253 [13:56<4:15:59,  1.96s/it][A
  5%|▌         | 425/8253 [13:56<4:16:09,  1.96s/it][A

  5%|▌         | 425/8253 [13:56<4:16:05,  1.96s/it][A  5%|▌         | 425/8253 [13:56<4:16:09,  1.96s/it][A
  5%|▌         | 426/8253 [13:58<4:15:52,  1.96s/it][A
  5%|▌         | 426/8253 [13:58<4:15:57,  1.96s/it][A
  5%|▌         | 426/8253 [13:58<4:16:08,  1.96s/it][A
  5%|▌         | 426/8253 [13:57<4:16:20,  1.97s/it][A
  5%|▌         | 426/8253 [13:58<4:16:08,  1.96s/it][A
  5%|▌         | 426/8253 [13:58<4:16:16,  1.96s/it][A
  5%|▌         | 427/8253 [14:00<4:15:27,  1.96s/it][A

  5%|▌         | 427/8253 [14:00<4:15:26,  1.96s/it][A  5%|▌         | 427/8253 [14:00<4:15:13,  1.96s/it][A
  5%|▌         | 427/8253 [13:59<4:15:34,  1.96s/it][A
  5%|▌         | 427/8253 [14:00<4:15:36,  1.96s/it][A
  5%|▌         | 427/8253 [14:00<4:15:32,  1.96s/it][A
  5%|▌         | 428/8253 [14:01<4:13:52,  1.95s/it][A
  5%|▌         | 428/8253 [14:01<4:14:21,  1.95s/it][A
  5%|▌         | 428/8253 [14:01<4:14:47,  1.95s/it][A

  5%|▌         | 428/8253 [14:01<4:14:43,  1.95s/it][A  5%|▌         | 428/8253 [14:01<4:14:34,  1.95s/it][A
  5%|▌         | 428/8253 [14:01<4:14:43,  1.95s/it][A
  5%|▌         | 429/8253 [14:03<4:14:16,  1.95s/it][A
  5%|▌         | 429/8253 [14:03<4:14:58,  1.96s/it][A
  5%|▌         | 429/8253 [14:03<4:14:58,  1.96s/it][A
  5%|▌         | 429/8253 [14:03<4:14:58,  1.96s/it][A
  5%|▌         | 429/8253 [14:03<4:15:02,  1.96s/it][A
  5%|▌         | 429/8253 [14:03<4:14:56,  1.96s/it][A
  5%|▌         | 430/8253 [14:05<4:14:20,  1.95s/it][A
  5%|▌         | 430/8253 [14:05<4:14:22,  1.95s/it][A
  5%|▌         | 430/8253 [14:05<4:14:26,  1.95s/it][A
  5%|▌         | 430/8253 [14:05<4:14:45,  1.95s/it][A
  5%|▌         | 430/8253 [14:05<4:14:55,  1.96s/it][A
  5%|▌         | 430/8253 [14:05<4:15:00,  1.96s/it][A
  5%|▌         | 431/8253 [14:07<4:14:52,  1.96s/it][A

  5%|▌         | 431/8253 [14:07<4:15:00,  1.96s/it][A  5%|▌         | 431/8253 [14:07<4:14:55,  1.96s/it][A
  5%|▌         | 431/8253 [14:07<4:15:20,  1.96s/it][A
  5%|▌         | 431/8253 [14:07<4:15:11,  1.96s/it][A
  5%|▌         | 431/8253 [14:07<4:15:19,  1.96s/it][A
  5%|▌         | 432/8253 [14:09<4:14:05,  1.95s/it][A
  5%|▌         | 432/8253 [14:09<4:14:13,  1.95s/it][A
  5%|▌         | 432/8253 [14:09<4:14:43,  1.95s/it][A
  5%|▌         | 432/8253 [14:09<4:14:49,  1.95s/it][A
  5%|▌         | 432/8253 [14:09<4:14:54,  1.96s/it][A
  5%|▌         | 432/8253 [14:09<4:14:59,  1.96s/it][A
  5%|▌         | 433/8253 [14:11<4:13:54,  1.95s/it][A
  5%|▌         | 433/8253 [14:11<4:13:58,  1.95s/it][A
  5%|▌         | 433/8253 [14:11<4:14:11,  1.95s/it][A
  5%|▌         | 433/8253 [14:11<4:14:12,  1.95s/it][A
  5%|▌         | 433/8253 [14:11<4:14:15,  1.95s/it][A
  5%|▌         | 433/8253 [14:11<4:14:25,  1.95s/it][A
  5%|▌         | 434/8253 [14:13<4:13:52,  1.95s/it][A
  5%|▌         | 434/8253 [14:13<4:14:01,  1.95s/it][A

  5%|▌         | 434/8253 [14:13<4:14:03,  1.95s/it][A  5%|▌         | 434/8253 [14:13<4:14:01,  1.95s/it][A
  5%|▌         | 434/8253 [14:13<4:14:07,  1.95s/it][A
  5%|▌         | 434/8253 [14:13<4:14:15,  1.95s/it][A
  5%|▌         | 435/8253 [14:15<4:12:48,  1.94s/it][A
  5%|▌         | 435/8253 [14:15<4:13:21,  1.94s/it][A

  5%|▌         | 435/8253 [14:15<4:13:21,  1.94s/it][A  5%|▌         | 435/8253 [14:15<4:13:23,  1.94s/it][A
  5%|▌         | 435/8253 [14:15<4:13:46,  1.95s/it][A
  5%|▌         | 435/8253 [14:15<4:13:54,  1.95s/it][A
  5%|▌         | 436/8253 [14:17<4:15:00,  1.96s/it][A
  5%|▌         | 436/8253 [14:17<4:15:03,  1.96s/it][A
  5%|▌         | 436/8253 [14:17<4:15:23,  1.96s/it][A
  5%|▌         | 436/8253 [14:17<4:15:23,  1.96s/it][A
  5%|▌         | 436/8253 [14:17<4:15:23,  1.96s/it][A
  5%|▌         | 436/8253 [14:17<4:15:26,  1.96s/it][A
  5%|▌         | 437/8253 [14:19<4:14:14,  1.95s/it][A

  5%|▌         | 437/8253 [14:19<4:14:55,  1.96s/it][A  5%|▌         | 437/8253 [14:19<4:14:33,  1.95s/it][A
  5%|▌         | 437/8253 [14:19<4:14:44,  1.96s/it][A
  5%|▌         | 437/8253 [14:19<4:14:38,  1.95s/it][A
  5%|▌         | 437/8253 [14:19<4:14:32,  1.95s/it][A
  5%|▌         | 438/8253 [14:21<4:12:48,  1.94s/it][A
  5%|▌         | 438/8253 [14:21<4:12:55,  1.94s/it][A

  5%|▌         | 438/8253 [14:21<4:13:08,  1.94s/it][A  5%|▌         | 438/8253 [14:21<4:12:53,  1.94s/it][A
  5%|▌         | 438/8253 [14:21<4:13:08,  1.94s/it][A
  5%|▌         | 438/8253 [14:21<4:13:14,  1.94s/it][A
  5%|▌         | 439/8253 [14:23<4:12:22,  1.94s/it][A

  5%|▌         | 439/8253 [14:23<4:12:42,  1.94s/it][A  5%|▌         | 439/8253 [14:23<4:12:38,  1.94s/it][A
  5%|▌         | 439/8253 [14:23<4:12:50,  1.94s/it][A

  5%|▌         | 439/8253 [14:23<4:12:40,  1.94s/it][A  5%|▌         | 439/8253 [14:23<4:12:48,  1.94s/it][A
  5%|▌         | 440/8253 [14:25<4:11:48,  1.93s/it][A
  5%|▌         | 440/8253 [14:25<4:11:56,  1.93s/it][A
  5%|▌         | 440/8253 [14:25<4:11:59,  1.94s/it][A
  5%|▌         | 440/8253 [14:25<4:12:01,  1.94s/it][A
  5%|▌         | 440/8253 [14:25<4:12:01,  1.94s/it][A
  5%|▌         | 440/8253 [14:25<4:12:35,  1.94s/it][A
  5%|▌         | 441/8253 [14:27<4:11:10,  1.93s/it][A
  5%|▌         | 441/8253 [14:27<4:11:26,  1.93s/it][A
  5%|▌         | 441/8253 [14:27<4:11:47,  1.93s/it][A
  5%|▌         | 441/8253 [14:27<4:12:04,  1.94s/it][A
  5%|▌         | 441/8253 [14:27<4:11:51,  1.93s/it][A
  5%|▌         | 441/8253 [14:27<4:11:58,  1.94s/it][A
  5%|▌         | 442/8253 [14:29<4:13:19,  1.95s/it][A

  5%|▌         | 442/8253 [14:29<4:13:25,  1.95s/it][A  5%|▌         | 442/8253 [14:29<4:13:30,  1.95s/it][A
  5%|▌         | 442/8253 [14:29<4:13:47,  1.95s/it][A
  5%|▌         | 442/8253 [14:29<4:13:43,  1.95s/it][A
  5%|▌         | 442/8253 [14:29<4:14:04,  1.95s/it][A
  5%|▌         | 443/8253 [14:31<4:12:33,  1.94s/it][A
  5%|▌         | 443/8253 [14:31<4:13:07,  1.94s/it][A
  5%|▌         | 443/8253 [14:31<4:13:20,  1.95s/it][A
  5%|▌         | 443/8253 [14:31<4:13:29,  1.95s/it][A
  5%|▌         | 443/8253 [14:31<4:13:19,  1.95s/it][A
  5%|▌         | 443/8253 [14:31<4:13:21,  1.95s/it][A
  5%|▌         | 444/8253 [14:33<4:13:07,  1.94s/it][A
  5%|▌         | 444/8253 [14:33<4:13:08,  1.94s/it][A
  5%|▌         | 444/8253 [14:32<4:13:48,  1.95s/it][A
  5%|▌         | 444/8253 [14:33<4:13:40,  1.95s/it][A
  5%|▌         | 444/8253 [14:33<4:13:49,  1.95s/it][A
  5%|▌         | 444/8253 [14:33<4:13:41,  1.95s/it][A
  5%|▌         | 445/8253 [14:35<4:13:02,  1.94s/it][A
  5%|▌         | 445/8253 [14:35<4:13:21,  1.95s/it][A
  5%|▌         | 445/8253 [14:35<4:13:14,  1.95s/it][A
  5%|▌         | 445/8253 [14:35<4:13:34,  1.95s/it][A
  5%|▌         | 445/8253 [14:35<4:13:43,  1.95s/it][A
  5%|▌         | 445/8253 [14:34<4:13:47,  1.95s/it][A
  5%|▌         | 446/8253 [14:37<4:13:56,  1.95s/it][A
  5%|▌         | 446/8253 [14:36<4:13:57,  1.95s/it][A
  5%|▌         | 446/8253 [14:37<4:14:01,  1.95s/it][A
  5%|▌         | 446/8253 [14:37<4:13:54,  1.95s/it][A
  5%|▌         | 446/8253 [14:37<4:14:29,  1.96s/it][A
  5%|▌         | 446/8253 [14:37<4:14:29,  1.96s/it][A
  5%|▌         | 447/8253 [14:39<4:15:17,  1.96s/it][A
  5%|▌         | 447/8253 [14:39<4:15:25,  1.96s/it][A
  5%|▌         | 447/8253 [14:39<4:15:27,  1.96s/it][A
  5%|▌         | 447/8253 [14:39<4:15:39,  1.97s/it][A
  5%|▌         | 447/8253 [14:38<4:15:54,  1.97s/it][A
  5%|▌         | 447/8253 [14:39<4:16:09,  1.97s/it][A
  5%|▌         | 448/8253 [14:41<4:24:01,  2.03s/it][A
  5%|▌         | 448/8253 [14:41<4:24:09,  2.03s/it][A
  5%|▌         | 448/8253 [14:41<4:24:41,  2.03s/it][A

  5%|▌         | 448/8253 [14:41<4:24:37,  2.03s/it][A  5%|▌         | 448/8253 [14:41<4:24:47,  2.04s/it][A
  5%|▌         | 448/8253 [14:41<4:24:37,  2.03s/it][A
  5%|▌         | 449/8253 [14:43<4:21:36,  2.01s/it][A
  5%|▌         | 449/8253 [14:43<4:21:33,  2.01s/it][A
  5%|▌         | 449/8253 [14:43<4:21:48,  2.01s/it][A
  5%|▌         | 449/8253 [14:43<4:22:15,  2.02s/it][A
  5%|▌         | 449/8253 [14:43<4:22:27,  2.02s/it][A
  5%|▌         | 449/8253 [14:43<4:22:28,  2.02s/it][A
  5%|▌         | 450/8253 [14:45<4:18:16,  1.99s/it][A
  5%|▌         | 450/8253 [14:45<4:18:25,  1.99s/it][A
  5%|▌         | 450/8253 [14:45<4:18:38,  1.99s/it][A
  5%|▌         | 450/8253 [14:45<4:19:05,  1.99s/it][A

  5%|▌         | 450/8253 [14:44<4:19:02,  1.99s/it][A  5%|▌         | 450/8253 [14:45<4:19:04,  1.99s/it][A
  5%|▌         | 451/8253 [14:47<4:17:31,  1.98s/it][A
  5%|▌         | 451/8253 [14:47<4:17:33,  1.98s/it][A
  5%|▌         | 451/8253 [14:46<4:17:28,  1.98s/it][A

  5%|▌         | 451/8253 [14:47<4:17:46,  1.98s/it][A
  5%|▌         | 451/8253 [14:47<4:17:43,  1.98s/it][A  5%|▌         | 451/8253 [14:47<4:17:48,  1.98s/it][A
  5%|▌         | 452/8253 [14:49<4:14:39,  1.96s/it][A

  5%|▌         | 452/8253 [14:49<4:14:48,  1.96s/it][A  5%|▌         | 452/8253 [14:49<4:14:47,  1.96s/it][A
  5%|▌         | 452/8253 [14:49<4:14:46,  1.96s/it][A
  5%|▌         | 452/8253 [14:49<4:15:05,  1.96s/it][A
  5%|▌         | 452/8253 [14:48<4:14:57,  1.96s/it][A
  5%|▌         | 453/8253 [14:50<4:13:45,  1.95s/it][A
  5%|▌         | 453/8253 [14:50<4:13:58,  1.95s/it][A
  5%|▌         | 453/8253 [14:50<4:13:59,  1.95s/it][A
  5%|▌         | 453/8253 [14:50<4:14:03,  1.95s/it][A
  5%|▌         | 453/8253 [14:50<4:14:23,  1.96s/it][A
  5%|▌         | 453/8253 [14:50<4:14:29,  1.96s/it][A
  6%|▌         | 454/8253 [14:52<4:13:28,  1.95s/it][A
  6%|▌         | 454/8253 [14:52<4:13:27,  1.95s/it][A
  6%|▌         | 454/8253 [14:52<4:13:49,  1.95s/it][A
  6%|▌         | 454/8253 [14:52<4:13:36,  1.95s/it][A
  6%|▌         | 454/8253 [14:52<4:13:47,  1.95s/it][A
  6%|▌         | 454/8253 [14:52<4:13:55,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:12:49,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:13:32,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:13:16,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:13:40,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:13:50,  1.95s/it][A
  6%|▌         | 455/8253 [14:54<4:13:44,  1.95s/it][A
  6%|▌         | 456/8253 [14:56<4:14:19,  1.96s/it][A
  6%|▌         | 456/8253 [14:56<4:14:33,  1.96s/it][A
  6%|▌         | 456/8253 [14:56<4:14:20,  1.96s/it][A
  6%|▌         | 456/8253 [14:56<4:14:45,  1.96s/it][A
  6%|▌         | 456/8253 [14:56<4:14:41,  1.96s/it][A
  6%|▌         | 456/8253 [14:56<4:14:51,  1.96s/it][A
  6%|▌         | 457/8253 [14:58<4:13:09,  1.95s/it][A
  6%|▌         | 457/8253 [14:58<4:13:38,  1.95s/it][A
  6%|▌         | 457/8253 [14:58<4:13:53,  1.95s/it][A
  6%|▌         | 457/8253 [14:58<4:13:49,  1.95s/it][A
  6%|▌         | 457/8253 [14:58<4:13:54,  1.95s/it][A
  6%|▌         | 457/8253 [14:58<4:13:49,  1.95s/it][A
  6%|▌         | 458/8253 [15:00<4:14:04,  1.96s/it][A
  6%|▌         | 458/8253 [15:00<4:14:00,  1.96s/it][A
  6%|▌         | 458/8253 [15:00<4:14:14,  1.96s/it][A
  6%|▌         | 458/8253 [15:00<4:14:08,  1.96s/it][A
  6%|▌         | 458/8253 [15:00<4:14:36,  1.96s/it][A
  6%|▌         | 458/8253 [15:00<4:14:46,  1.96s/it][A
  6%|▌         | 459/8253 [15:02<4:13:25,  1.95s/it][A
  6%|▌         | 459/8253 [15:02<4:13:45,  1.95s/it][A

  6%|▌         | 459/8253 [15:02<4:13:55,  1.95s/it][A  6%|▌         | 459/8253 [15:02<4:13:47,  1.95s/it][A
  6%|▌         | 459/8253 [15:02<4:14:00,  1.96s/it][A
  6%|▌         | 459/8253 [15:02<4:14:01,  1.96s/it][A
  6%|▌         | 460/8253 [15:04<4:13:13,  1.95s/it][A
  6%|▌         | 460/8253 [15:04<4:13:36,  1.95s/it][A
  6%|▌         | 460/8253 [15:04<4:13:53,  1.95s/it][A
  6%|▌         | 460/8253 [15:04<4:13:47,  1.95s/it][A
  6%|▌         | 460/8253 [15:04<4:14:04,  1.96s/it][A
  6%|▌         | 460/8253 [15:04<4:13:55,  1.95s/it][A
  6%|▌         | 461/8253 [15:06<4:12:28,  1.94s/it][A
  6%|▌         | 461/8253 [15:06<4:12:54,  1.95s/it][A
  6%|▌         | 461/8253 [15:06<4:13:15,  1.95s/it][A
  6%|▌         | 461/8253 [15:06<4:13:09,  1.95s/it][A

  6%|▌         | 461/8253 [15:06<4:13:10,  1.95s/it][A  6%|▌         | 461/8253 [15:06<4:13:22,  1.95s/it][A
  6%|▌         | 462/8253 [15:08<4:13:52,  1.96s/it][A
  6%|▌         | 462/8253 [15:08<4:13:46,  1.95s/it][A
  6%|▌         | 462/8253 [15:08<4:13:57,  1.96s/it][A
  6%|▌         | 462/8253 [15:08<4:13:59,  1.96s/it][A
  6%|▌         | 462/8253 [15:08<4:14:12,  1.96s/it][A
  6%|▌         | 462/8253 [15:08<4:13:59,  1.96s/it][A
  6%|▌         | 463/8253 [15:10<4:12:32,  1.95s/it][A
  6%|▌         | 463/8253 [15:10<4:12:39,  1.95s/it][A
  6%|▌         | 463/8253 [15:10<4:12:46,  1.95s/it][A
  6%|▌         | 463/8253 [15:10<4:12:37,  1.95s/it][A
  6%|▌         | 463/8253 [15:10<4:12:57,  1.95s/it][A
  6%|▌         | 463/8253 [15:10<4:13:07,  1.95s/it][A
  6%|▌         | 464/8253 [15:12<4:11:59,  1.94s/it][A
  6%|▌         | 464/8253 [15:12<4:11:56,  1.94s/it][A
  6%|▌         | 464/8253 [15:12<4:12:26,  1.94s/it][A
  6%|▌         | 464/8253 [15:12<4:12:21,  1.94s/it][A
  6%|▌         | 464/8253 [15:12<4:12:34,  1.95s/it][A
  6%|▌         | 464/8253 [15:12<4:12:32,  1.95s/it][A
  6%|▌         | 465/8253 [15:14<4:11:51,  1.94s/it][A
  6%|▌         | 465/8253 [15:14<4:12:06,  1.94s/it][A
  6%|▌         | 465/8253 [15:14<4:11:58,  1.94s/it][A
  6%|▌         | 465/8253 [15:14<4:12:02,  1.94s/it][A

  6%|▌         | 465/8253 [15:14<4:12:02,  1.94s/it][A  6%|▌         | 465/8253 [15:14<4:12:08,  1.94s/it][A
  6%|▌         | 466/8253 [15:16<4:13:20,  1.95s/it][A
  6%|▌         | 466/8253 [15:16<4:13:38,  1.95s/it][A
  6%|▌         | 466/8253 [15:16<4:13:45,  1.96s/it][A
  6%|▌         | 466/8253 [15:16<4:13:45,  1.96s/it][A

  6%|▌         | 466/8253 [15:16<4:13:38,  1.95s/it][A  6%|▌         | 466/8253 [15:16<4:13:42,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:27,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:39,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:33,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:48,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:43,  1.95s/it][A
  6%|▌         | 467/8253 [15:18<4:12:57,  1.95s/it][A
  6%|▌         | 468/8253 [15:20<4:12:27,  1.95s/it][A
  6%|▌         | 468/8253 [15:20<4:12:38,  1.95s/it][A
  6%|▌         | 468/8253 [15:20<4:12:35,  1.95s/it][A

  6%|▌         | 468/8253 [15:20<4:12:57,  1.95s/it][A  6%|▌         | 468/8253 [15:20<4:12:55,  1.95s/it][A
  6%|▌         | 468/8253 [15:20<4:12:59,  1.95s/it][A
  6%|▌         | 469/8253 [15:22<4:11:37,  1.94s/it][A
  6%|▌         | 469/8253 [15:22<4:11:40,  1.94s/it][A
  6%|▌         | 469/8253 [15:22<4:11:43,  1.94s/it][A
  6%|▌         | 469/8253 [15:22<4:11:52,  1.94s/it][A
  6%|▌         | 469/8253 [15:22<4:11:53,  1.94s/it][A
  6%|▌         | 469/8253 [15:21<4:11:55,  1.94s/it][A
  6%|▌         | 470/8253 [15:24<4:11:45,  1.94s/it][A
  6%|▌         | 470/8253 [15:23<4:11:49,  1.94s/it][A
  6%|▌         | 470/8253 [15:24<4:11:49,  1.94s/it][A
  6%|▌         | 470/8253 [15:24<4:11:52,  1.94s/it][A
  6%|▌         | 470/8253 [15:24<4:11:55,  1.94s/it][A
  6%|▌         | 470/8253 [15:24<4:12:09,  1.94s/it][A
  6%|▌         | 471/8253 [15:25<4:12:32,  1.95s/it][A
  6%|▌         | 471/8253 [15:26<4:12:38,  1.95s/it][A
  6%|▌         | 471/8253 [15:26<4:13:00,  1.95s/it][A

  6%|▌         | 471/8253 [15:26<4:12:59,  1.95s/it][A  6%|▌         | 471/8253 [15:26<4:13:00,  1.95s/it][A
  6%|▌         | 471/8253 [15:26<4:13:06,  1.95s/it][A
  6%|▌         | 472/8253 [15:28<4:15:04,  1.97s/it][A
  6%|▌         | 472/8253 [15:28<4:14:59,  1.97s/it][A
  6%|▌         | 472/8253 [15:28<4:14:57,  1.97s/it][A
  6%|▌         | 472/8253 [15:27<4:15:16,  1.97s/it]
[A  6%|▌         | 472/8253 [15:28<4:15:05,  1.97s/it][A
  6%|▌         | 472/8253 [15:28<4:15:10,  1.97s/it][A
  6%|▌         | 473/8253 [15:29<4:14:25,  1.96s/it][A
  6%|▌         | 473/8253 [15:29<4:14:40,  1.96s/it][A
  6%|▌         | 473/8253 [15:30<4:14:48,  1.97s/it][A
  6%|▌         | 473/8253 [15:30<4:14:44,  1.96s/it][A
  6%|▌         | 473/8253 [15:30<4:14:47,  1.96s/it][A
  6%|▌         | 473/8253 [15:30<4:15:00,  1.97s/it][A
  6%|▌         | 474/8253 [15:31<4:13:53,  1.96s/it][A
  6%|▌         | 474/8253 [15:31<4:14:01,  1.96s/it][A
  6%|▌         | 474/8253 [15:31<4:13:59,  1.96s/it][A
  6%|▌         | 474/8253 [15:31<4:14:01,  1.96s/it][A
  6%|▌         | 474/8253 [15:31<4:14:20,  1.96s/it][A
  6%|▌         | 474/8253 [15:31<4:14:11,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:13:51,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:13:58,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:14:02,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:14:04,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:14:03,  1.96s/it][A
  6%|▌         | 475/8253 [15:33<4:14:22,  1.96s/it][A
  6%|▌         | 476/8253 [15:35<4:15:16,  1.97s/it][A
  6%|▌         | 476/8253 [15:35<4:15:18,  1.97s/it][A
  6%|▌         | 476/8253 [15:35<4:15:42,  1.97s/it][A

  6%|▌         | 476/8253 [15:35<4:15:34,  1.97s/it][A  6%|▌         | 476/8253 [15:35<4:15:51,  1.97s/it][A
  6%|▌         | 476/8253 [15:35<4:15:45,  1.97s/it][A
  6%|▌         | 477/8253 [15:37<4:15:15,  1.97s/it][A
  6%|▌         | 477/8253 [15:37<4:15:49,  1.97s/it][A
  6%|▌         | 477/8253 [15:37<4:15:53,  1.97s/it][A
  6%|▌         | 477/8253 [15:37<4:16:01,  1.98s/it][A
  6%|▌         | 477/8253 [15:37<4:16:24,  1.98s/it][A
  6%|▌         | 477/8253 [15:37<4:16:26,  1.98s/it][A
  6%|▌         | 478/8253 [15:39<4:16:05,  1.98s/it][A

  6%|▌         | 478/8253 [15:39<4:16:00,  1.98s/it][A  6%|▌         | 478/8253 [15:39<4:16:07,  1.98s/it][A
  6%|▌         | 478/8253 [15:39<4:16:07,  1.98s/it][A
  6%|▌         | 478/8253 [15:39<4:16:19,  1.98s/it][A
  6%|▌         | 478/8253 [15:39<4:16:16,  1.98s/it][A
  6%|▌         | 479/8253 [15:41<4:21:38,  2.02s/it][A
  6%|▌         | 479/8253 [15:42<4:22:17,  2.02s/it][A
  6%|▌         | 479/8253 [15:42<4:22:15,  2.02s/it][A
  6%|▌         | 479/8253 [15:42<4:22:21,  2.02s/it][A
  6%|▌         | 479/8253 [15:42<4:22:20,  2.02s/it][A
  6%|▌         | 479/8253 [15:42<4:22:35,  2.03s/it][A

  6%|▌         | 480/8253 [15:43<4:22:31,  2.03s/it][A  6%|▌         | 480/8253 [15:44<4:22:40,  2.03s/it][A
  6%|▌         | 480/8253 [15:44<4:22:35,  2.03s/it][A
  6%|▌         | 480/8253 [15:44<4:22:38,  2.03s/it][A
  6%|▌         | 480/8253 [15:44<4:22:40,  2.03s/it][A
  6%|▌         | 480/8253 [15:44<4:22:52,  2.03s/it][A
  6%|▌         | 481/8253 [15:45<4:18:35,  2.00s/it][A
  6%|▌         | 481/8253 [15:45<4:18:34,  2.00s/it][A
  6%|▌         | 481/8253 [15:45<4:19:03,  2.00s/it][A
  6%|▌         | 481/8253 [15:45<4:18:58,  2.00s/it][A
  6%|▌         | 481/8253 [15:45<4:18:47,  2.00s/it][A
  6%|▌         | 481/8253 [15:45<4:19:00,  2.00s/it][A
  6%|▌         | 482/8253 [15:47<4:17:13,  1.99s/it][A
  6%|▌         | 482/8253 [15:47<4:17:17,  1.99s/it][A
  6%|▌         | 482/8253 [15:47<4:17:24,  1.99s/it][A
  6%|▌         | 482/8253 [15:47<4:17:15,  1.99s/it][A
  6%|▌         | 482/8253 [15:47<4:17:23,  1.99s/it][A
  6%|▌         | 482/8253 [15:47<4:17:44,  1.99s/it][A
  6%|▌         | 483/8253 [15:49<4:16:22,  1.98s/it][A
  6%|▌         | 483/8253 [15:49<4:16:34,  1.98s/it][A
  6%|▌         | 483/8253 [15:49<4:16:40,  1.98s/it][A
  6%|▌         | 483/8253 [15:49<4:16:26,  1.98s/it][A
  6%|▌         | 483/8253 [15:49<4:16:44,  1.98s/it][A
  6%|▌         | 483/8253 [15:49<4:16:46,  1.98s/it][A
  6%|▌         | 484/8253 [15:51<4:17:45,  1.99s/it][A
  6%|▌         | 484/8253 [15:51<4:18:08,  1.99s/it][A

  6%|▌         | 484/8253 [15:51<4:18:08,  1.99s/it][A  6%|▌         | 484/8253 [15:51<4:18:12,  1.99s/it][A
  6%|▌         | 484/8253 [15:51<4:18:11,  1.99s/it][A
  6%|▌         | 484/8253 [15:51<4:18:02,  1.99s/it][A
  6%|▌         | 485/8253 [15:53<4:19:38,  2.01s/it][A
  6%|▌         | 485/8253 [15:53<4:19:45,  2.01s/it][A
  6%|▌         | 485/8253 [15:53<4:19:55,  2.01s/it][A
  6%|▌         | 485/8253 [15:53<4:19:52,  2.01s/it][A
  6%|▌         | 485/8253 [15:53<4:19:57,  2.01s/it][A
  6%|▌         | 485/8253 [15:53<4:19:53,  2.01s/it][A
  6%|▌         | 486/8253 [15:55<4:18:19,  2.00s/it][A
  6%|▌         | 486/8253 [15:55<4:18:42,  2.00s/it][A
  6%|▌         | 486/8253 [15:55<4:18:45,  2.00s/it][A

  6%|▌         | 486/8253 [15:55<4:18:32,  2.00s/it][A  6%|▌         | 486/8253 [15:55<4:18:38,  2.00s/it][A
  6%|▌         | 486/8253 [15:55<4:18:41,  2.00s/it][A
  6%|▌         | 487/8253 [15:57<4:18:01,  1.99s/it][A
  6%|▌         | 487/8253 [15:57<4:18:21,  2.00s/it][A
  6%|▌         | 487/8253 [15:57<4:18:31,  2.00s/it][A

  6%|▌         | 487/8253 [15:57<4:18:21,  2.00s/it][A  6%|▌         | 487/8253 [15:57<4:18:17,  2.00s/it][A
  6%|▌         | 487/8253 [15:57<4:18:31,  2.00s/it][A
  6%|▌         | 488/8253 [15:59<4:17:49,  1.99s/it][A
  6%|▌         | 488/8253 [15:59<4:18:29,  2.00s/it][A
  6%|▌         | 488/8253 [15:59<4:18:26,  2.00s/it][A
  6%|▌         | 488/8253 [15:59<4:18:21,  2.00s/it][A
  6%|▌         | 488/8253 [15:59<4:18:32,  2.00s/it][A
  6%|▌         | 488/8253 [15:59<4:18:29,  2.00s/it][A
  6%|▌         | 489/8253 [16:01<4:15:52,  1.98s/it][A
  6%|▌         | 489/8253 [16:01<4:15:57,  1.98s/it][A
  6%|▌         | 489/8253 [16:01<4:16:17,  1.98s/it][A
  6%|▌         | 489/8253 [16:01<4:16:25,  1.98s/it][A
  6%|▌         | 489/8253 [16:01<4:16:42,  1.98s/it][A
  6%|▌         | 489/8253 [16:01<4:16:20,  1.98s/it][A
  6%|▌         | 490/8253 [16:03<4:14:43,  1.97s/it][A
  6%|▌         | 490/8253 [16:03<4:14:58,  1.97s/it][A
  6%|▌         | 490/8253 [16:03<4:15:15,  1.97s/it][A
  6%|▌         | 490/8253 [16:03<4:15:21,  1.97s/it][A
  6%|▌         | 490/8253 [16:03<4:15:23,  1.97s/it][A
  6%|▌         | 490/8253 [16:03<4:15:29,  1.97s/it][A
  6%|▌         | 491/8253 [16:05<4:13:53,  1.96s/it][A
  6%|▌         | 491/8253 [16:05<4:13:58,  1.96s/it][A
  6%|▌         | 491/8253 [16:05<4:14:13,  1.97s/it][A
  6%|▌         | 491/8253 [16:05<4:14:24,  1.97s/it][A
  6%|▌         | 491/8253 [16:05<4:14:28,  1.97s/it][A
  6%|▌         | 491/8253 [16:05<4:14:23,  1.97s/it][A
  6%|▌         | 492/8253 [16:07<4:16:03,  1.98s/it][A
  6%|▌         | 492/8253 [16:07<4:16:03,  1.98s/it][A

  6%|▌         | 492/8253 [16:07<4:16:29,  1.98s/it]
[A  6%|▌         | 492/8253 [16:07<4:16:29,  1.98s/it][A  6%|▌         | 492/8253 [16:07<4:16:29,  1.98s/it][A
  6%|▌         | 492/8253 [16:07<4:16:34,  1.98s/it][A
  6%|▌         | 493/8253 [16:09<4:17:21,  1.99s/it][A
  6%|▌         | 493/8253 [16:09<4:17:32,  1.99s/it][A
  6%|▌         | 493/8253 [16:09<4:17:43,  1.99s/it][A

  6%|▌         | 493/8253 [16:09<4:17:40,  1.99s/it][A  6%|▌         | 493/8253 [16:09<4:17:39,  1.99s/it][A
  6%|▌         | 493/8253 [16:09<4:17:44,  1.99s/it][A
  6%|▌         | 494/8253 [16:11<4:15:45,  1.98s/it][A
  6%|▌         | 494/8253 [16:11<4:15:46,  1.98s/it][A
  6%|▌         | 494/8253 [16:11<4:15:58,  1.98s/it][A
  6%|▌         | 494/8253 [16:11<4:16:04,  1.98s/it][A
  6%|▌         | 494/8253 [16:11<4:15:56,  1.98s/it][A
  6%|▌         | 494/8253 [16:11<4:15:51,  1.98s/it][A
  6%|▌         | 495/8253 [16:13<4:15:14,  1.97s/it][A
  6%|▌         | 495/8253 [16:13<4:15:36,  1.98s/it][A
  6%|▌         | 495/8253 [16:13<4:15:37,  1.98s/it][A
  6%|▌         | 495/8253 [16:13<4:15:43,  1.98s/it][A
  6%|▌         | 495/8253 [16:13<4:15:56,  1.98s/it][A
  6%|▌         | 495/8253 [16:13<4:16:07,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:15:45,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:15:48,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:15:50,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:15:56,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:16:10,  1.98s/it][A
  6%|▌         | 496/8253 [16:15<4:16:05,  1.98s/it][A
  6%|▌         | 497/8253 [16:17<4:17:43,  1.99s/it][A
  6%|▌         | 497/8253 [16:17<4:17:37,  1.99s/it][A
  6%|▌         | 497/8253 [16:17<4:17:51,  1.99s/it][A
  6%|▌         | 497/8253 [16:17<4:17:52,  1.99s/it][A
  6%|▌         | 497/8253 [16:17<4:18:00,  2.00s/it][A
  6%|▌         | 497/8253 [16:17<4:18:00,  2.00s/it][A
  6%|▌         | 498/8253 [16:19<4:20:14,  2.01s/it][A
  6%|▌         | 498/8253 [16:19<4:20:23,  2.01s/it][A
  6%|▌         | 498/8253 [16:19<4:20:47,  2.02s/it][A
  6%|▌         | 498/8253 [16:19<4:20:54,  2.02s/it][A
  6%|▌         | 498/8253 [16:19<4:20:44,  2.02s/it][A
  6%|▌         | 498/8253 [16:19<4:20:59,  2.02s/it][A
  6%|▌         | 499/8253 [16:21<4:19:10,  2.01s/it][A
  6%|▌         | 499/8253 [16:21<4:19:01,  2.00s/it][A
  6%|▌         | 499/8253 [16:21<4:19:35,  2.01s/it][A
  6%|▌         | 499/8253 [16:21<4:19:23,  2.01s/it][A
  6%|▌         | 499/8253 [16:21<4:19:25,  2.01s/it][A
  6%|▌         | 499/8253 [16:21<4:19:35,  2.01s/it][A
  6%|▌         | 500/8253 [16:23<4:16:32,  1.99s/it][A
  6%|▌         | 500/8253 [16:23<4:16:43,  1.99s/it][A
  6%|▌         | 500/8253 [16:23<4:17:05,  1.99s/it][A
  6%|▌         | 500/8253 [16:23<4:16:49,  1.99s/it][A
  6%|▌         | 500/8253 [16:23<4:16:57,  1.99s/it][A
  6%|▌         | 500/8253 [16:23<4:16:58,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:16:32,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:16:56,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:16:59,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:17:10,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:17:35,  1.99s/it][A
  6%|▌         | 501/8253 [16:25<4:17:51,  2.00s/it][A
  6%|▌         | 502/8253 [16:27<4:14:57,  1.97s/it][A

  6%|▌         | 502/8253 [16:27<4:15:14,  1.98s/it][A  6%|▌         | 502/8253 [16:27<4:15:12,  1.98s/it][A
  6%|▌         | 502/8253 [16:27<4:15:37,  1.98s/it][A
  6%|▌         | 502/8253 [16:27<4:15:38,  1.98s/it][A
  6%|▌         | 502/8253 [16:27<4:15:58,  1.98s/it][A
  6%|▌         | 503/8253 [16:29<4:14:25,  1.97s/it][A
  6%|▌         | 503/8253 [16:29<4:14:18,  1.97s/it][A

  6%|▌         | 503/8253 [16:29<4:14:52,  1.97s/it][A
  6%|▌         | 503/8253 [16:29<4:14:47,  1.97s/it][A  6%|▌         | 503/8253 [16:29<4:14:45,  1.97s/it][A
  6%|▌         | 503/8253 [16:29<4:15:06,  1.98s/it][A
  6%|▌         | 504/8253 [16:31<4:13:57,  1.97s/it][A
  6%|▌         | 504/8253 [16:31<4:14:12,  1.97s/it][A
  6%|▌         | 504/8253 [16:31<4:14:23,  1.97s/it][A
  6%|▌         | 504/8253 [16:31<4:14:26,  1.97s/it][A
  6%|▌         | 504/8253 [16:31<4:14:35,  1.97s/it][A
  6%|▌         | 504/8253 [16:31<4:14:46,  1.97s/it][A
  6%|▌         | 505/8253 [16:33<4:12:19,  1.95s/it][A
  6%|▌         | 505/8253 [16:33<4:12:16,  1.95s/it][A
  6%|▌         | 505/8253 [16:33<4:12:29,  1.96s/it][A
  6%|▌         | 505/8253 [16:33<4:12:41,  1.96s/it][A
  6%|▌         | 505/8253 [16:33<4:12:45,  1.96s/it][A
  6%|▌         | 505/8253 [16:33<4:12:51,  1.96s/it][A
  6%|▌         | 506/8253 [16:35<4:11:05,  1.94s/it][A
  6%|▌         | 506/8253 [16:35<4:11:20,  1.95s/it][A
  6%|▌         | 506/8253 [16:35<4:11:16,  1.95s/it][A
  6%|▌         | 506/8253 [16:35<4:11:49,  1.95s/it][A
  6%|▌         | 506/8253 [16:35<4:11:45,  1.95s/it][A
  6%|▌         | 506/8253 [16:35<4:11:59,  1.95s/it][A
  6%|▌         | 507/8253 [16:37<4:10:52,  1.94s/it][A
  6%|▌         | 507/8253 [16:37<4:10:42,  1.94s/it][A
  6%|▌         | 507/8253 [16:37<4:11:12,  1.95s/it][A
  6%|▌         | 507/8253 [16:37<4:11:00,  1.94s/it][A
  6%|▌         | 507/8253 [16:37<4:11:17,  1.95s/it][A
  6%|▌         | 507/8253 [16:37<4:11:14,  1.95s/it][A
  6%|▌         | 508/8253 [16:39<4:10:14,  1.94s/it][A
  6%|▌         | 508/8253 [16:39<4:10:24,  1.94s/it][A
  6%|▌         | 508/8253 [16:39<4:10:47,  1.94s/it][A
  6%|▌         | 508/8253 [16:39<4:10:53,  1.94s/it][A
  6%|▌         | 508/8253 [16:39<4:11:16,  1.95s/it][A
  6%|▌         | 508/8253 [16:39<4:11:01,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:09:52,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:10:21,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:10:00,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:10:24,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:10:43,  1.94s/it][A
  6%|▌         | 509/8253 [16:41<4:10:48,  1.94s/it][A
  6%|▌         | 510/8253 [16:43<4:14:34,  1.97s/it][A
  6%|▌         | 510/8253 [16:43<4:14:56,  1.98s/it][A

  6%|▌         | 510/8253 [16:43<4:15:17,  1.98s/it][A  6%|▌         | 510/8253 [16:43<4:15:43,  1.98s/it][A

  6%|▌         | 510/8253 [16:43<4:15:39,  1.98s/it][A  6%|▌         | 510/8253 [16:43<4:15:23,  1.98s/it][A
  6%|▌         | 511/8253 [16:45<4:13:13,  1.96s/it][A
  6%|▌         | 511/8253 [16:45<4:13:23,  1.96s/it][A
  6%|▌         | 511/8253 [16:45<4:13:09,  1.96s/it][A
  6%|▌         | 511/8253 [16:45<4:13:28,  1.96s/it][A
  6%|▌         | 511/8253 [16:45<4:13:49,  1.97s/it][A
  6%|▌         | 511/8253 [16:45<4:14:03,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:13:51,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:14:15,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:14:12,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:14:32,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:14:18,  1.97s/it][A
  6%|▌         | 512/8253 [16:47<4:14:22,  1.97s/it][A
  6%|▌         | 513/8253 [16:49<4:13:11,  1.96s/it][A
  6%|▌         | 513/8253 [16:49<4:13:27,  1.96s/it][A
  6%|▌         | 513/8253 [16:49<4:13:25,  1.96s/it][A
  6%|▌         | 513/8253 [16:49<4:13:41,  1.97s/it][A
  6%|▌         | 513/8253 [16:49<4:13:34,  1.97s/it][A
  6%|▌         | 513/8253 [16:49<4:13:39,  1.97s/it][A
  6%|▌         | 514/8253 [16:51<4:11:26,  1.95s/it][A
  6%|▌         | 514/8253 [16:51<4:11:18,  1.95s/it][A
  6%|▌         | 514/8253 [16:51<4:11:41,  1.95s/it][A
  6%|▌         | 514/8253 [16:51<4:11:41,  1.95s/it][A
  6%|▌         | 514/8253 [16:51<4:11:43,  1.95s/it][A
  6%|▌         | 514/8253 [16:50<4:11:52,  1.95s/it][A
  6%|▌         | 515/8253 [16:52<4:12:42,  1.96s/it][A
  6%|▌         | 515/8253 [16:53<4:13:17,  1.96s/it][A
  6%|▌         | 515/8253 [16:53<4:13:28,  1.97s/it][A
  6%|▌         | 515/8253 [16:53<4:13:22,  1.96s/it][A

  6%|▌         | 515/8253 [16:53<4:13:47,  1.97s/it][A  6%|▌         | 515/8253 [16:53<4:13:31,  1.97s/it][A
  6%|▋         | 516/8253 [16:54<4:11:54,  1.95s/it][A
  6%|▋         | 516/8253 [16:55<4:12:24,  1.96s/it][A
  6%|▋         | 516/8253 [16:55<4:12:23,  1.96s/it][A
  6%|▋         | 516/8253 [16:55<4:12:30,  1.96s/it][A
  6%|▋         | 516/8253 [16:55<4:12:53,  1.96s/it][A
  6%|▋         | 516/8253 [16:55<4:12:56,  1.96s/it][A
  6%|▋         | 517/8253 [16:56<4:10:58,  1.95s/it][A
  6%|▋         | 517/8253 [16:56<4:11:02,  1.95s/it][A
  6%|▋         | 517/8253 [16:56<4:11:03,  1.95s/it][A
  6%|▋         | 517/8253 [16:56<4:11:11,  1.95s/it][A

  6%|▋         | 517/8253 [16:57<4:11:38,  1.95s/it][A  6%|▋         | 517/8253 [16:56<4:11:25,  1.95s/it][A
  6%|▋         | 518/8253 [16:58<4:10:48,  1.95s/it][A
  6%|▋         | 518/8253 [16:58<4:10:53,  1.95s/it][A
  6%|▋         | 518/8253 [16:58<4:10:48,  1.95s/it][A
  6%|▋         | 518/8253 [16:58<4:11:01,  1.95s/it][A

  6%|▋         | 518/8253 [16:58<4:10:51,  1.95s/it][A  6%|▋         | 518/8253 [16:58<4:10:53,  1.95s/it][A
  6%|▋         | 519/8253 [17:00<4:11:21,  1.95s/it][A
  6%|▋         | 519/8253 [17:00<4:11:30,  1.95s/it][A
  6%|▋         | 519/8253 [17:00<4:12:02,  1.96s/it][A
  6%|▋         | 519/8253 [17:00<4:11:46,  1.95s/it][A
  6%|▋         | 519/8253 [17:00<4:11:39,  1.95s/it][A
  6%|▋         | 519/8253 [17:00<4:12:13,  1.96s/it][A
  6%|▋         | 520/8253 [17:02<4:11:24,  1.95s/it][A
  6%|▋         | 520/8253 [17:02<4:11:51,  1.95s/it][A
  6%|▋         | 520/8253 [17:02<4:11:30,  1.95s/it][A
  6%|▋         | 520/8253 [17:02<4:11:38,  1.95s/it][A
  6%|▋         | 520/8253 [17:02<4:11:45,  1.95s/it][A
  6%|▋         | 520/8253 [17:02<4:11:36,  1.95s/it][A
  6%|▋         | 521/8253 [17:04<4:12:10,  1.96s/it][A
  6%|▋         | 521/8253 [17:04<4:12:24,  1.96s/it][A
  6%|▋         | 521/8253 [17:04<4:12:33,  1.96s/it][A
  6%|▋         | 521/8253 [17:04<4:12:25,  1.96s/it][A

  6%|▋         | 521/8253 [17:04<4:12:35,  1.96s/it][A  6%|▋         | 521/8253 [17:04<4:12:34,  1.96s/it][A
  6%|▋         | 522/8253 [17:06<4:13:45,  1.97s/it][A
  6%|▋         | 522/8253 [17:06<4:13:47,  1.97s/it][A

  6%|▋         | 522/8253 [17:06<4:14:17,  1.97s/it][A  6%|▋         | 522/8253 [17:06<4:13:49,  1.97s/it][A
  6%|▋         | 522/8253 [17:06<4:14:01,  1.97s/it][A
  6%|▋         | 522/8253 [17:06<4:14:20,  1.97s/it][A
  6%|▋         | 523/8253 [17:08<4:12:27,  1.96s/it][A
  6%|▋         | 523/8253 [17:08<4:12:46,  1.96s/it][A
  6%|▋         | 523/8253 [17:08<4:13:01,  1.96s/it][A
  6%|▋         | 523/8253 [17:08<4:12:56,  1.96s/it][A
  6%|▋         | 523/8253 [17:08<4:13:17,  1.97s/it][A
  6%|▋         | 523/8253 [17:08<4:13:07,  1.96s/it][A
  6%|▋         | 524/8253 [17:10<4:11:15,  1.95s/it][A
  6%|▋         | 524/8253 [17:10<4:11:25,  1.95s/it][A
  6%|▋         | 524/8253 [17:10<4:11:45,  1.95s/it][A
  6%|▋         | 524/8253 [17:10<4:11:50,  1.96s/it][A
  6%|▋         | 524/8253 [17:10<4:12:02,  1.96s/it][A
  6%|▋         | 524/8253 [17:10<4:12:30,  1.96s/it][A
  6%|▋         | 525/8253 [17:12<4:11:34,  1.95s/it][A
  6%|▋         | 525/8253 [17:12<4:11:41,  1.95s/it][A
  6%|▋         | 525/8253 [17:12<4:11:34,  1.95s/it][A

  6%|▋         | 525/8253 [17:12<4:12:04,  1.96s/it][A  6%|▋         | 525/8253 [17:12<4:11:53,  1.96s/it][A
  6%|▋         | 525/8253 [17:12<4:12:06,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:11:59,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:11:59,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:12:06,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:12:35,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:12:21,  1.96s/it][A
  6%|▋         | 526/8253 [17:14<4:12:45,  1.96s/it][A
  6%|▋         | 527/8253 [17:16<4:11:19,  1.95s/it][A
  6%|▋         | 527/8253 [17:16<4:11:52,  1.96s/it][A
  6%|▋         | 527/8253 [17:16<4:11:27,  1.95s/it][A
  6%|▋         | 527/8253 [17:16<4:11:53,  1.96s/it][A
  6%|▋         | 527/8253 [17:16<4:12:02,  1.96s/it][A
  6%|▋         | 527/8253 [17:16<4:12:03,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:12:01,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:11:55,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:12:03,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:12:12,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:12:14,  1.96s/it][A
  6%|▋         | 528/8253 [17:18<4:12:11,  1.96s/it][A
  6%|▋         | 529/8253 [17:20<4:12:42,  1.96s/it][A
  6%|▋         | 529/8253 [17:20<4:13:04,  1.97s/it][A
  6%|▋         | 529/8253 [17:20<4:13:38,  1.97s/it][A

  6%|▋         | 529/8253 [17:20<4:13:28,  1.97s/it][A
  6%|▋         | 529/8253 [17:20<4:13:29,  1.97s/it][A  6%|▋         | 529/8253 [17:20<4:13:35,  1.97s/it][A
  6%|▋         | 530/8253 [17:22<4:11:01,  1.95s/it][A
  6%|▋         | 530/8253 [17:22<4:10:46,  1.95s/it][A
  6%|▋         | 530/8253 [17:22<4:11:15,  1.95s/it][A
  6%|▋         | 530/8253 [17:22<4:11:20,  1.95s/it][A
  6%|▋         | 530/8253 [17:22<4:11:15,  1.95s/it][A
  6%|▋         | 530/8253 [17:22<4:11:14,  1.95s/it][A
  6%|▋         | 531/8253 [17:24<4:10:18,  1.94s/it][A
  6%|▋         | 531/8253 [17:24<4:10:15,  1.94s/it][A
  6%|▋         | 531/8253 [17:24<4:10:37,  1.95s/it][A

  6%|▋         | 531/8253 [17:24<4:10:45,  1.95s/it][A  6%|▋         | 531/8253 [17:24<4:10:34,  1.95s/it][A
  6%|▋         | 531/8253 [17:24<4:10:41,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:35,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:26,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:25,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:47,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:58,  1.95s/it][A
  6%|▋         | 532/8253 [17:26<4:10:56,  1.95s/it][A
  6%|▋         | 533/8253 [17:28<4:08:58,  1.94s/it][A
  6%|▋         | 533/8253 [17:28<4:09:27,  1.94s/it][A
  6%|▋         | 533/8253 [17:28<4:09:13,  1.94s/it][A
  6%|▋         | 533/8253 [17:28<4:09:47,  1.94s/it][A

  6%|▋         | 533/8253 [17:28<4:09:27,  1.94s/it][A  6%|▋         | 533/8253 [17:28<4:09:39,  1.94s/it][A
  6%|▋         | 534/8253 [17:30<4:09:28,  1.94s/it][A
  6%|▋         | 534/8253 [17:30<4:10:06,  1.94s/it][A

  6%|▋         | 534/8253 [17:30<4:09:59,  1.94s/it][A  6%|▋         | 534/8253 [17:30<4:10:00,  1.94s/it][A
  6%|▋         | 534/8253 [17:30<4:09:56,  1.94s/it][A
  6%|▋         | 534/8253 [17:30<4:10:10,  1.94s/it][A
  6%|▋         | 535/8253 [17:32<4:10:16,  1.95s/it][A
  6%|▋         | 535/8253 [17:32<4:10:22,  1.95s/it][A
  6%|▋         | 535/8253 [17:32<4:10:35,  1.95s/it][A
  6%|▋         | 535/8253 [17:32<4:10:30,  1.95s/it][A
  6%|▋         | 535/8253 [17:32<4:10:36,  1.95s/it][A
  6%|▋         | 535/8253 [17:32<4:10:39,  1.95s/it][A
  6%|▋         | 536/8253 [17:34<4:12:02,  1.96s/it][A
  6%|▋         | 536/8253 [17:34<4:12:07,  1.96s/it][A
  6%|▋         | 536/8253 [17:34<4:12:29,  1.96s/it][A
  6%|▋         | 536/8253 [17:34<4:12:26,  1.96s/it][A
  6%|▋         | 536/8253 [17:34<4:12:38,  1.96s/it][A
  6%|▋         | 536/8253 [17:34<4:12:33,  1.96s/it][A
  7%|▋         | 537/8253 [17:36<4:12:45,  1.97s/it][A
  7%|▋         | 537/8253 [17:36<4:12:57,  1.97s/it][A
  7%|▋         | 537/8253 [17:36<4:13:09,  1.97s/it][A
  7%|▋         | 537/8253 [17:35<4:13:16,  1.97s/it][A
  7%|▋         | 537/8253 [17:36<4:13:23,  1.97s/it][A
  7%|▋         | 537/8253 [17:36<4:13:23,  1.97s/it][A
  7%|▋         | 538/8253 [17:38<4:11:16,  1.95s/it][A
  7%|▋         | 538/8253 [17:38<4:11:25,  1.96s/it][A
  7%|▋         | 538/8253 [17:37<4:11:28,  1.96s/it][A


  7%|▋         | 538/8253 [17:38<4:11:23,  1.96s/it][A  7%|▋         | 538/8253 [17:38<4:11:26,  1.96s/it][A  7%|▋         | 538/8253 [17:38<4:11:32,  1.96s/it][A
  7%|▋         | 539/8253 [17:39<4:09:42,  1.94s/it][A
  7%|▋         | 539/8253 [17:39<4:10:16,  1.95s/it][A
  7%|▋         | 539/8253 [17:39<4:09:56,  1.94s/it][A
  7%|▋         | 539/8253 [17:39<4:09:55,  1.94s/it][A
  7%|▋         | 539/8253 [17:39<4:10:22,  1.95s/it][A
  7%|▋         | 539/8253 [17:39<4:10:11,  1.95s/it][A
  7%|▋         | 540/8253 [17:41<4:09:59,  1.94s/it][A

  7%|▋         | 540/8253 [17:41<4:10:23,  1.95s/it][A  7%|▋         | 540/8253 [17:41<4:09:55,  1.94s/it][A
  7%|▋         | 540/8253 [17:41<4:10:22,  1.95s/it][A
  7%|▋         | 540/8253 [17:41<4:10:34,  1.95s/it][A
  7%|▋         | 540/8253 [17:41<4:10:35,  1.95s/it][A
  7%|▋         | 541/8253 [17:44<4:18:06,  2.01s/it][A
  7%|▋         | 541/8253 [17:43<4:18:08,  2.01s/it][A
  7%|▋         | 541/8253 [17:44<4:18:28,  2.01s/it][A
  7%|▋         | 541/8253 [17:44<4:18:49,  2.01s/it][A
  7%|▋         | 541/8253 [17:44<4:18:39,  2.01s/it][A
  7%|▋         | 541/8253 [17:44<4:18:49,  2.01s/it][A

  7%|▋         | 542/8253 [17:46<4:15:54,  1.99s/it][A  7%|▋         | 542/8253 [17:46<4:15:55,  1.99s/it][A

  7%|▋         | 542/8253 [17:46<4:16:20,  1.99s/it][A  7%|▋         | 542/8253 [17:45<4:16:18,  1.99s/it][A

  7%|▋         | 542/8253 [17:46<4:16:20,  1.99s/it][A  7%|▋         | 542/8253 [17:46<4:16:31,  2.00s/it][A
  7%|▋         | 543/8253 [17:47<4:14:19,  1.98s/it][A
  7%|▋         | 543/8253 [17:47<4:14:31,  1.98s/it][A
  7%|▋         | 543/8253 [17:48<4:14:41,  1.98s/it][A
  7%|▋         | 543/8253 [17:48<4:14:46,  1.98s/it][A
  7%|▋         | 543/8253 [17:48<4:14:54,  1.98s/it][A
  7%|▋         | 543/8253 [17:48<4:15:02,  1.98s/it][A
  7%|▋         | 544/8253 [17:49<4:13:43,  1.97s/it][A
  7%|▋         | 544/8253 [17:49<4:14:27,  1.98s/it][A
  7%|▋         | 544/8253 [17:49<4:14:16,  1.98s/it][A
  7%|▋         | 544/8253 [17:49<4:14:31,  1.98s/it][A
  7%|▋         | 544/8253 [17:49<4:14:31,  1.98s/it][A
  7%|▋         | 544/8253 [17:49<4:14:43,  1.98s/it][A
  7%|▋         | 545/8253 [17:51<4:12:35,  1.97s/it][A
  7%|▋         | 545/8253 [17:51<4:12:50,  1.97s/it][A
  7%|▋         | 545/8253 [17:51<4:12:59,  1.97s/it][A

  7%|▋         | 545/8253 [17:51<4:13:17,  1.97s/it][A  7%|▋         | 545/8253 [17:51<4:13:10,  1.97s/it][A
  7%|▋         | 545/8253 [17:51<4:13:25,  1.97s/it][A

  7%|▋         | 546/8253 [17:53<4:11:43,  1.96s/it][A  7%|▋         | 546/8253 [17:53<4:11:53,  1.96s/it][A
  7%|▋         | 546/8253 [17:53<4:12:07,  1.96s/it][A
  7%|▋         | 546/8253 [17:53<4:12:18,  1.96s/it][A
  7%|▋         | 546/8253 [17:53<4:12:37,  1.97s/it][A
  7%|▋         | 546/8253 [17:53<4:12:55,  1.97s/it][A
  7%|▋         | 547/8253 [17:55<4:12:02,  1.96s/it][A
  7%|▋         | 547/8253 [17:55<4:12:21,  1.96s/it][A
  7%|▋         | 547/8253 [17:55<4:12:31,  1.97s/it][A
  7%|▋         | 547/8253 [17:55<4:12:23,  1.97s/it][A
  7%|▋         | 547/8253 [17:55<4:12:30,  1.97s/it][A
  7%|▋         | 547/8253 [17:55<4:12:54,  1.97s/it][A
  7%|▋         | 548/8253 [17:57<4:11:11,  1.96s/it][A

  7%|▋         | 548/8253 [17:57<4:11:47,  1.96s/it][A  7%|▋         | 548/8253 [17:57<4:11:40,  1.96s/it][A
  7%|▋         | 548/8253 [17:57<4:11:42,  1.96s/it][A

  7%|▋         | 548/8253 [17:57<4:11:52,  1.96s/it]  7%|▋         | 548/8253 [17:57<4:11:58,  1.96s/it][A[A
  7%|▋         | 549/8253 [17:59<4:09:43,  1.94s/it][A
  7%|▋         | 549/8253 [17:59<4:09:52,  1.95s/it][A
  7%|▋         | 549/8253 [17:59<4:10:03,  1.95s/it][A
  7%|▋         | 549/8253 [17:59<4:10:08,  1.95s/it][A
  7%|▋         | 549/8253 [17:59<4:10:17,  1.95s/it][A
  7%|▋         | 549/8253 [17:59<4:10:18,  1.95s/it][A
  7%|▋         | 550/8253 [18:01<4:10:56,  1.95s/it][A
  7%|▋         | 550/8253 [18:01<4:10:42,  1.95s/it][A
  7%|▋         | 550/8253 [18:01<4:10:51,  1.95s/it][A
  7%|▋         | 550/8253 [18:01<4:11:12,  1.96s/it][A
  7%|▋         | 550/8253 [18:01<4:11:28,  1.96s/it][A
  7%|▋         | 550/8253 [18:01<4:11:20,  1.96s/it][A
  7%|▋         | 551/8253 [18:03<4:12:37,  1.97s/it][A
  7%|▋         | 551/8253 [18:03<4:13:02,  1.97s/it][A
  7%|▋         | 551/8253 [18:03<4:12:44,  1.97s/it][A
  7%|▋         | 551/8253 [18:03<4:12:54,  1.97s/it][A
  7%|▋         | 551/8253 [18:03<4:13:07,  1.97s/it][A
  7%|▋         | 551/8253 [18:03<4:13:05,  1.97s/it][A
  7%|▋         | 552/8253 [18:05<4:11:50,  1.96s/it][A
  7%|▋         | 552/8253 [18:05<4:12:18,  1.97s/it][A
  7%|▋         | 552/8253 [18:05<4:12:17,  1.97s/it][A
  7%|▋         | 552/8253 [18:05<4:12:13,  1.97s/it][A
  7%|▋         | 552/8253 [18:05<4:12:34,  1.97s/it][A
  7%|▋         | 552/8253 [18:05<4:12:31,  1.97s/it][A
  7%|▋         | 553/8253 [18:07<4:12:49,  1.97s/it][A
  7%|▋         | 553/8253 [18:07<4:13:22,  1.97s/it][A
  7%|▋         | 553/8253 [18:07<4:13:09,  1.97s/it][A

  7%|▋         | 553/8253 [18:07<4:13:12,  1.97s/it]
[A  7%|▋         | 553/8253 [18:07<4:13:27,  1.98s/it][A  7%|▋         | 553/8253 [18:07<4:13:04,  1.97s/it][A
  7%|▋         | 554/8253 [18:09<4:12:46,  1.97s/it][A
  7%|▋         | 554/8253 [18:09<4:13:11,  1.97s/it][A

  7%|▋         | 554/8253 [18:09<4:12:57,  1.97s/it][A
  7%|▋         | 554/8253 [18:09<4:13:08,  1.97s/it][A  7%|▋         | 554/8253 [18:09<4:13:14,  1.97s/it][A
  7%|▋         | 554/8253 [18:09<4:13:29,  1.98s/it][A

  7%|▋         | 555/8253 [18:11<4:11:45,  1.96s/it][A  7%|▋         | 555/8253 [18:11<4:11:36,  1.96s/it][A
  7%|▋         | 555/8253 [18:11<4:11:51,  1.96s/it][A
  7%|▋         | 555/8253 [18:11<4:11:59,  1.96s/it][A
  7%|▋         | 555/8253 [18:11<4:11:59,  1.96s/it][A
  7%|▋         | 555/8253 [18:11<4:12:17,  1.97s/it][A
  7%|▋         | 556/8253 [18:13<4:10:57,  1.96s/it][A
  7%|▋         | 556/8253 [18:13<4:10:49,  1.96s/it][A
  7%|▋         | 556/8253 [18:13<4:11:02,  1.96s/it][A
  7%|▋         | 556/8253 [18:13<4:11:09,  1.96s/it][A
  7%|▋         | 556/8253 [18:13<4:11:17,  1.96s/it][A
  7%|▋         | 556/8253 [18:13<4:11:21,  1.96s/it][A
  7%|▋         | 557/8253 [18:15<4:10:17,  1.95s/it][A
  7%|▋         | 557/8253 [18:15<4:10:26,  1.95s/it][A
  7%|▋         | 557/8253 [18:15<4:10:11,  1.95s/it][A
  7%|▋         | 557/8253 [18:15<4:10:43,  1.95s/it][A
  7%|▋         | 557/8253 [18:15<4:10:31,  1.95s/it][A
  7%|▋         | 557/8253 [18:15<4:10:40,  1.95s/it][A
  7%|▋         | 558/8253 [18:17<4:11:45,  1.96s/it][A
  7%|▋         | 558/8253 [18:17<4:11:27,  1.96s/it][A
  7%|▋         | 558/8253 [18:17<4:11:54,  1.96s/it][A
  7%|▋         | 558/8253 [18:17<4:12:02,  1.97s/it][A
  7%|▋         | 558/8253 [18:17<4:11:49,  1.96s/it][A
  7%|▋         | 558/8253 [18:17<4:11:49,  1.96s/it][A
  7%|▋         | 559/8253 [18:19<4:11:44,  1.96s/it][A
  7%|▋         | 559/8253 [18:19<4:11:55,  1.96s/it][A
  7%|▋         | 559/8253 [18:19<4:12:02,  1.97s/it][A
  7%|▋         | 559/8253 [18:19<4:12:25,  1.97s/it][A
  7%|▋         | 559/8253 [18:19<4:12:08,  1.97s/it][A
  7%|▋         | 559/8253 [18:19<4:12:29,  1.97s/it][A
  7%|▋         | 560/8253 [18:21<4:12:38,  1.97s/it][A

  7%|▋         | 560/8253 [18:21<4:12:59,  1.97s/it][A  7%|▋         | 560/8253 [18:21<4:13:02,  1.97s/it][A
  7%|▋         | 560/8253 [18:21<4:13:08,  1.97s/it][A
  7%|▋         | 560/8253 [18:21<4:13:21,  1.98s/it][A
  7%|▋         | 560/8253 [18:21<4:13:22,  1.98s/it][A
  7%|▋         | 561/8253 [18:23<4:12:56,  1.97s/it][A
  7%|▋         | 561/8253 [18:23<4:13:10,  1.97s/it][A
  7%|▋         | 561/8253 [18:23<4:13:33,  1.98s/it][A

  7%|▋         | 561/8253 [18:23<4:13:36,  1.98s/it][A  7%|▋         | 561/8253 [18:23<4:13:39,  1.98s/it][A
  7%|▋         | 561/8253 [18:23<4:13:46,  1.98s/it][A
  7%|▋         | 562/8253 [18:25<4:09:43,  1.95s/it][A
  7%|▋         | 562/8253 [18:25<4:09:49,  1.95s/it][A
  7%|▋         | 562/8253 [18:25<4:10:02,  1.95s/it][A
  7%|▋         | 562/8253 [18:25<4:10:11,  1.95s/it][A
  7%|▋         | 562/8253 [18:25<4:10:16,  1.95s/it][A
  7%|▋         | 562/8253 [18:25<4:10:14,  1.95s/it][A
  7%|▋         | 563/8253 [18:27<4:09:00,  1.94s/it][A
  7%|▋         | 563/8253 [18:27<4:09:16,  1.94s/it][A
  7%|▋         | 563/8253 [18:27<4:09:29,  1.95s/it][A
  7%|▋         | 563/8253 [18:27<4:09:44,  1.95s/it][A
  7%|▋         | 563/8253 [18:27<4:09:53,  1.95s/it][A
  7%|▋         | 563/8253 [18:27<4:09:50,  1.95s/it][A
  7%|▋         | 564/8253 [18:29<4:08:24,  1.94s/it][A
  7%|▋         | 564/8253 [18:29<4:08:40,  1.94s/it][A
  7%|▋         | 564/8253 [18:28<4:08:57,  1.94s/it][A
  7%|▋         | 564/8253 [18:29<4:09:07,  1.94s/it]
[A  7%|▋         | 564/8253 [18:29<4:08:59,  1.94s/it][A
  7%|▋         | 564/8253 [18:29<4:09:17,  1.95s/it][A
  7%|▋         | 565/8253 [18:31<4:07:22,  1.93s/it][A
  7%|▋         | 565/8253 [18:31<4:07:54,  1.93s/it][A
  7%|▋         | 565/8253 [18:31<4:07:47,  1.93s/it][A
  7%|▋         | 565/8253 [18:30<4:08:04,  1.94s/it][A
  7%|▋         | 565/8253 [18:31<4:08:08,  1.94s/it][A
  7%|▋         | 565/8253 [18:31<4:08:09,  1.94s/it][A
  7%|▋         | 566/8253 [18:33<4:08:40,  1.94s/it][A
  7%|▋         | 566/8253 [18:32<4:08:48,  1.94s/it][A
  7%|▋         | 566/8253 [18:33<4:09:00,  1.94s/it][A
  7%|▋         | 566/8253 [18:33<4:08:53,  1.94s/it][A
  7%|▋         | 566/8253 [18:33<4:09:06,  1.94s/it][A
  7%|▋         | 566/8253 [18:33<4:09:13,  1.95s/it][A
  7%|▋         | 567/8253 [18:34<4:08:31,  1.94s/it][A
  7%|▋         | 567/8253 [18:34<4:08:47,  1.94s/it][A
  7%|▋         | 567/8253 [18:34<4:08:47,  1.94s/it][A
  7%|▋         | 567/8253 [18:34<4:09:02,  1.94s/it][A
  7%|▋         | 567/8253 [18:34<4:08:55,  1.94s/it][A
  7%|▋         | 567/8253 [18:34<4:08:56,  1.94s/it][A
  7%|▋         | 568/8253 [18:36<4:08:59,  1.94s/it][A
  7%|▋         | 568/8253 [18:36<4:09:00,  1.94s/it][A


  7%|▋         | 568/8253 [18:36<4:09:04,  1.94s/it][A  7%|▋         | 568/8253 [18:36<4:09:11,  1.95s/it][A  7%|▋         | 568/8253 [18:36<4:09:04,  1.94s/it][A
  7%|▋         | 568/8253 [18:36<4:09:17,  1.95s/it][A
  7%|▋         | 569/8253 [18:38<4:08:31,  1.94s/it][A
  7%|▋         | 569/8253 [18:38<4:08:28,  1.94s/it][A

  7%|▋         | 569/8253 [18:38<4:08:40,  1.94s/it][A  7%|▋         | 569/8253 [18:38<4:08:38,  1.94s/it][A

  7%|▋         | 569/8253 [18:38<4:08:43,  1.94s/it][A  7%|▋         | 569/8253 [18:38<4:08:47,  1.94s/it][A

  7%|▋         | 570/8253 [18:40<4:09:41,  1.95s/it][A  7%|▋         | 570/8253 [18:40<4:09:39,  1.95s/it][A
  7%|▋         | 570/8253 [18:40<4:09:44,  1.95s/it][A
  7%|▋         | 570/8253 [18:40<4:09:44,  1.95s/it][A
  7%|▋         | 570/8253 [18:40<4:10:04,  1.95s/it][A
  7%|▋         | 570/8253 [18:40<4:10:11,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:09:35,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:09:39,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:09:48,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:09:51,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:09:58,  1.95s/it][A
  7%|▋         | 571/8253 [18:42<4:10:03,  1.95s/it][A
  7%|▋         | 572/8253 [18:44<4:16:56,  2.01s/it][A
  7%|▋         | 572/8253 [18:44<4:16:54,  2.01s/it][A
  7%|▋         | 572/8253 [18:44<4:17:03,  2.01s/it][A

  7%|▋         | 572/8253 [18:44<4:17:24,  2.01s/it][A  7%|▋         | 572/8253 [18:44<4:17:24,  2.01s/it][A
  7%|▋         | 572/8253 [18:44<4:17:27,  2.01s/it][A
  7%|▋         | 573/8253 [18:46<4:13:37,  1.98s/it][A
  7%|▋         | 573/8253 [18:46<4:13:46,  1.98s/it][A
  7%|▋         | 573/8253 [18:46<4:13:57,  1.98s/it]
[A  7%|▋         | 573/8253 [18:46<4:14:01,  1.98s/it][A
  7%|▋         | 573/8253 [18:46<4:14:05,  1.99s/it][A
  7%|▋         | 573/8253 [18:46<4:14:05,  1.99s/it][A
  7%|▋         | 574/8253 [18:48<4:13:07,  1.98s/it][A
  7%|▋         | 574/8253 [18:48<4:13:09,  1.98s/it][A
  7%|▋         | 574/8253 [18:48<4:13:24,  1.98s/it][A
  7%|▋         | 574/8253 [18:48<4:13:16,  1.98s/it][A

  7%|▋         | 574/8253 [18:48<4:13:39,  1.98s/it][A  7%|▋         | 574/8253 [18:48<4:13:33,  1.98s/it][A
  7%|▋         | 575/8253 [18:50<4:12:25,  1.97s/it][A
  7%|▋         | 575/8253 [18:50<4:12:36,  1.97s/it][A
  7%|▋         | 575/8253 [18:50<4:13:02,  1.98s/it][A
  7%|▋         | 575/8253 [18:50<4:13:05,  1.98s/it][A

  7%|▋         | 575/8253 [18:50<4:13:13,  1.98s/it][A  7%|▋         | 575/8253 [18:50<4:13:21,  1.98s/it][A
  7%|▋         | 576/8253 [18:52<4:12:23,  1.97s/it][A
  7%|▋         | 576/8253 [18:52<4:12:35,  1.97s/it][A
  7%|▋         | 576/8253 [18:52<4:12:49,  1.98s/it][A
  7%|▋         | 576/8253 [18:52<4:12:52,  1.98s/it][A

  7%|▋         | 576/8253 [18:52<4:12:53,  1.98s/it][A  7%|▋         | 576/8253 [18:52<4:13:02,  1.98s/it][A
  7%|▋         | 577/8253 [18:54<4:11:35,  1.97s/it][A
  7%|▋         | 577/8253 [18:54<4:11:41,  1.97s/it][A

  7%|▋         | 577/8253 [18:54<4:11:44,  1.97s/it][A  7%|▋         | 577/8253 [18:54<4:11:52,  1.97s/it][A
  7%|▋         | 577/8253 [18:54<4:12:21,  1.97s/it][A
  7%|▋         | 577/8253 [18:54<4:11:44,  1.97s/it][A
  7%|▋         | 578/8253 [18:56<4:09:39,  1.95s/it][A
  7%|▋         | 578/8253 [18:56<4:09:45,  1.95s/it][A
  7%|▋         | 578/8253 [18:56<4:09:56,  1.95s/it][A
  7%|▋         | 578/8253 [18:56<4:09:59,  1.95s/it][A
  7%|▋         | 578/8253 [18:56<4:09:50,  1.95s/it][A
  7%|▋         | 578/8253 [18:56<4:10:38,  1.96s/it][A
  7%|▋         | 579/8253 [18:58<4:08:20,  1.94s/it][A
  7%|▋         | 579/8253 [18:58<4:08:54,  1.95s/it][A
  7%|▋         | 579/8253 [18:58<4:08:49,  1.95s/it][A
  7%|▋         | 579/8253 [18:58<4:08:48,  1.95s/it][A
  7%|▋         | 579/8253 [18:58<4:09:07,  1.95s/it][A
  7%|▋         | 579/8253 [18:58<4:09:02,  1.95s/it][A
  7%|▋         | 580/8253 [19:00<4:10:15,  1.96s/it][A
  7%|▋         | 580/8253 [19:00<4:10:39,  1.96s/it][A
  7%|▋         | 580/8253 [19:00<4:10:36,  1.96s/it][A
  7%|▋         | 580/8253 [19:00<4:10:47,  1.96s/it][A
  7%|▋         | 580/8253 [19:00<4:11:04,  1.96s/it][A
  7%|▋         | 580/8253 [19:00<4:11:12,  1.96s/it][A
  7%|▋         | 581/8253 [19:02<4:12:16,  1.97s/it][A
  7%|▋         | 581/8253 [19:02<4:12:13,  1.97s/it][A
  7%|▋         | 581/8253 [19:02<4:12:13,  1.97s/it][A

  7%|▋         | 581/8253 [19:02<4:12:12,  1.97s/it][A  7%|▋         | 581/8253 [19:02<4:12:21,  1.97s/it][A
  7%|▋         | 581/8253 [19:02<4:12:26,  1.97s/it][A
  7%|▋         | 582/8253 [19:04<4:12:34,  1.98s/it][A
  7%|▋         | 582/8253 [19:04<4:12:38,  1.98s/it][A
  7%|▋         | 582/8253 [19:04<4:12:54,  1.98s/it][A
  7%|▋         | 582/8253 [19:04<4:12:45,  1.98s/it][A
  7%|▋         | 582/8253 [19:04<4:12:47,  1.98s/it][A
  7%|▋         | 582/8253 [19:04<4:13:04,  1.98s/it][A
  7%|▋         | 583/8253 [19:06<4:11:23,  1.97s/it][A
  7%|▋         | 583/8253 [19:06<4:11:49,  1.97s/it][A
  7%|▋         | 583/8253 [19:06<4:11:56,  1.97s/it][A
  7%|▋         | 583/8253 [19:06<4:11:46,  1.97s/it][A
  7%|▋         | 583/8253 [19:06<4:11:56,  1.97s/it][A
  7%|▋         | 583/8253 [19:06<4:12:02,  1.97s/it][A
  7%|▋         | 584/8253 [19:08<4:10:55,  1.96s/it][A

  7%|▋         | 584/8253 [19:08<4:11:14,  1.97s/it][A  7%|▋         | 584/8253 [19:08<4:11:16,  1.97s/it][A
  7%|▋         | 584/8253 [19:08<4:11:15,  1.97s/it][A
  7%|▋         | 584/8253 [19:08<4:11:18,  1.97s/it][A
  7%|▋         | 584/8253 [19:08<4:11:25,  1.97s/it][A
  7%|▋         | 585/8253 [19:10<4:12:12,  1.97s/it][A
  7%|▋         | 585/8253 [19:10<4:12:31,  1.98s/it][A
  7%|▋         | 585/8253 [19:10<4:12:27,  1.98s/it][A
  7%|▋         | 585/8253 [19:10<4:12:44,  1.98s/it][A
  7%|▋         | 585/8253 [19:10<4:12:33,  1.98s/it][A
  7%|▋         | 585/8253 [19:10<4:12:35,  1.98s/it][A
  7%|▋         | 586/8253 [19:12<4:11:15,  1.97s/it][A
  7%|▋         | 586/8253 [19:12<4:11:47,  1.97s/it][A
  7%|▋         | 586/8253 [19:12<4:11:49,  1.97s/it][A
  7%|▋         | 586/8253 [19:12<4:12:01,  1.97s/it][A

  7%|▋         | 586/8253 [19:12<4:11:55,  1.97s/it][A  7%|▋         | 586/8253 [19:12<4:11:49,  1.97s/it][A
  7%|▋         | 587/8253 [19:14<4:10:37,  1.96s/it][A
  7%|▋         | 587/8253 [19:14<4:11:04,  1.97s/it][A
  7%|▋         | 587/8253 [19:14<4:11:16,  1.97s/it][A
  7%|▋         | 587/8253 [19:14<4:11:01,  1.96s/it][A
  7%|▋         | 587/8253 [19:14<4:11:10,  1.97s/it][A
  7%|▋         | 587/8253 [19:14<4:11:10,  1.97s/it][A
  7%|▋         | 588/8253 [19:16<4:10:00,  1.96s/it][A
  7%|▋         | 588/8253 [19:16<4:10:01,  1.96s/it][A
  7%|▋         | 588/8253 [19:16<4:10:16,  1.96s/it][A
  7%|▋         | 588/8253 [19:16<4:09:59,  1.96s/it][A
  7%|▋         | 588/8253 [19:16<4:10:15,  1.96s/it][A
  7%|▋         | 588/8253 [19:16<4:10:17,  1.96s/it][A
  7%|▋         | 589/8253 [19:18<4:13:22,  1.98s/it][A

  7%|▋         | 589/8253 [19:18<4:13:17,  1.98s/it][A  7%|▋         | 589/8253 [19:18<4:13:31,  1.98s/it][A
  7%|▋         | 589/8253 [19:18<4:13:56,  1.99s/it][A
  7%|▋         | 589/8253 [19:18<4:13:38,  1.99s/it][A
  7%|▋         | 589/8253 [19:18<4:13:45,  1.99s/it][A
  7%|▋         | 590/8253 [19:20<4:12:20,  1.98s/it][A

  7%|▋         | 590/8253 [19:20<4:12:46,  1.98s/it][A  7%|▋         | 590/8253 [19:20<4:12:52,  1.98s/it][A
  7%|▋         | 590/8253 [19:20<4:12:39,  1.98s/it][A
  7%|▋         | 590/8253 [19:20<4:12:50,  1.98s/it][A
  7%|▋         | 590/8253 [19:20<4:12:43,  1.98s/it][A
  7%|▋         | 591/8253 [19:22<4:10:45,  1.96s/it][A
  7%|▋         | 591/8253 [19:22<4:10:54,  1.96s/it][A
  7%|▋         | 591/8253 [19:22<4:11:12,  1.97s/it][A
  7%|▋         | 591/8253 [19:22<4:11:18,  1.97s/it][A
  7%|▋         | 591/8253 [19:22<4:11:27,  1.97s/it][A
  7%|▋         | 591/8253 [19:22<4:11:28,  1.97s/it][A
  7%|▋         | 592/8253 [19:24<4:10:40,  1.96s/it][A
  7%|▋         | 592/8253 [19:24<4:10:36,  1.96s/it][A
  7%|▋         | 592/8253 [19:24<4:11:07,  1.97s/it][A
  7%|▋         | 592/8253 [19:24<4:10:59,  1.97s/it][A
  7%|▋         | 592/8253 [19:24<4:11:10,  1.97s/it][A
  7%|▋         | 592/8253 [19:24<4:11:04,  1.97s/it][A
  7%|▋         | 593/8253 [19:26<4:10:37,  1.96s/it][A
  7%|▋         | 593/8253 [19:26<4:10:57,  1.97s/it][A
  7%|▋         | 593/8253 [19:26<4:10:47,  1.96s/it][A
  7%|▋         | 593/8253 [19:26<4:11:00,  1.97s/it][A
  7%|▋         | 593/8253 [19:26<4:11:35,  1.97s/it][A
  7%|▋         | 593/8253 [19:26<4:11:35,  1.97s/it][A
  7%|▋         | 594/8253 [19:28<4:12:12,  1.98s/it][A
  7%|▋         | 594/8253 [19:28<4:12:36,  1.98s/it][A
  7%|▋         | 594/8253 [19:28<4:12:32,  1.98s/it][A
  7%|▋         | 594/8253 [19:28<4:12:36,  1.98s/it][A

  7%|▋         | 594/8253 [19:28<4:12:47,  1.98s/it][A  7%|▋         | 594/8253 [19:28<4:12:33,  1.98s/it][A
  7%|▋         | 595/8253 [19:30<4:10:28,  1.96s/it][A
  7%|▋         | 595/8253 [19:29<4:10:40,  1.96s/it][A
  7%|▋         | 595/8253 [19:30<4:10:47,  1.96s/it][A
  7%|▋         | 595/8253 [19:30<4:10:59,  1.97s/it][A
  7%|▋         | 595/8253 [19:30<4:11:07,  1.97s/it][A
  7%|▋         | 595/8253 [19:30<4:11:04,  1.97s/it][A
  7%|▋         | 596/8253 [19:31<4:13:14,  1.98s/it][A
  7%|▋         | 596/8253 [19:32<4:13:29,  1.99s/it][A
  7%|▋         | 596/8253 [19:32<4:13:51,  1.99s/it][A
  7%|▋         | 596/8253 [19:32<4:13:42,  1.99s/it][A

  7%|▋         | 596/8253 [19:32<4:14:03,  1.99s/it][A  7%|▋         | 596/8253 [19:32<4:13:44,  1.99s/it][A
  7%|▋         | 597/8253 [19:34<4:11:32,  1.97s/it][A
  7%|▋         | 597/8253 [19:34<4:11:50,  1.97s/it][A
  7%|▋         | 597/8253 [19:33<4:12:07,  1.98s/it][A
  7%|▋         | 597/8253 [19:34<4:11:57,  1.97s/it][A
  7%|▋         | 597/8253 [19:34<4:11:55,  1.97s/it][A
  7%|▋         | 597/8253 [19:34<4:12:12,  1.98s/it][A
  7%|▋         | 598/8253 [19:35<4:11:16,  1.97s/it][A
  7%|▋         | 598/8253 [19:36<4:11:08,  1.97s/it][A
  7%|▋         | 598/8253 [19:36<4:11:00,  1.97s/it][A
  7%|▋         | 598/8253 [19:36<4:11:30,  1.97s/it][A
  7%|▋         | 598/8253 [19:36<4:11:36,  1.97s/it][A
  7%|▋         | 598/8253 [19:36<4:11:27,  1.97s/it][A
  7%|▋         | 599/8253 [19:37<4:09:56,  1.96s/it][A
  7%|▋         | 599/8253 [19:37<4:09:43,  1.96s/it][A
  7%|▋         | 599/8253 [19:37<4:10:02,  1.96s/it][A
  7%|▋         | 599/8253 [19:37<4:10:14,  1.96s/it][A
  7%|▋         | 599/8253 [19:38<4:10:25,  1.96s/it][A
  7%|▋         | 599/8253 [19:38<4:10:36,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:09:29,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:09:38,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:09:41,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:09:49,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:10:12,  1.96s/it][A
  7%|▋         | 600/8253 [19:39<4:10:12,  1.96s/it][A
  7%|▋         | 601/8253 [19:41<4:08:29,  1.95s/it][A
  7%|▋         | 601/8253 [19:41<4:08:41,  1.95s/it][A
  7%|▋         | 601/8253 [19:41<4:08:44,  1.95s/it][A
  7%|▋         | 601/8253 [19:41<4:08:46,  1.95s/it][A
  7%|▋         | 601/8253 [19:41<4:08:45,  1.95s/it][A
  7%|▋         | 601/8253 [19:41<4:09:05,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:04,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:33,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:43,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:48,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:58,  1.95s/it][A
  7%|▋         | 602/8253 [19:43<4:08:53,  1.95s/it][A
  7%|▋         | 603/8253 [19:45<4:09:33,  1.96s/it][A
  7%|▋         | 603/8253 [19:45<4:09:36,  1.96s/it][A
  7%|▋         | 603/8253 [19:45<4:09:49,  1.96s/it][A
  7%|▋         | 603/8253 [19:45<4:10:04,  1.96s/it][A
  7%|▋         | 603/8253 [19:45<4:10:00,  1.96s/it][A
  7%|▋         | 603/8253 [19:45<4:10:02,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:09:41,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:09:40,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:10:09,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:10:03,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:10:09,  1.96s/it][A
  7%|▋         | 604/8253 [19:47<4:10:27,  1.96s/it][A
  7%|▋         | 605/8253 [19:49<4:10:31,  1.97s/it][A
  7%|▋         | 605/8253 [19:49<4:11:12,  1.97s/it][A
  7%|▋         | 605/8253 [19:49<4:11:10,  1.97s/it][A
  7%|▋         | 605/8253 [19:49<4:10:56,  1.97s/it][A
  7%|▋         | 605/8253 [19:49<4:11:01,  1.97s/it][A
  7%|▋         | 605/8253 [19:49<4:11:03,  1.97s/it][A
  7%|▋         | 606/8253 [19:51<4:08:53,  1.95s/it][A
  7%|▋         | 606/8253 [19:51<4:09:13,  1.96s/it][A
  7%|▋         | 606/8253 [19:51<4:09:27,  1.96s/it][A
  7%|▋         | 606/8253 [19:51<4:09:16,  1.96s/it][A
  7%|▋         | 606/8253 [19:51<4:09:34,  1.96s/it][A
  7%|▋         | 606/8253 [19:51<4:09:26,  1.96s/it][A
  7%|▋         | 607/8253 [19:53<4:08:22,  1.95s/it][A
  7%|▋         | 607/8253 [19:53<4:08:06,  1.95s/it][A
  7%|▋         | 607/8253 [19:53<4:08:22,  1.95s/it][A
  7%|▋         | 607/8253 [19:53<4:08:26,  1.95s/it][A
  7%|▋         | 607/8253 [19:53<4:08:27,  1.95s/it][A
  7%|▋         | 607/8253 [19:53<4:08:16,  1.95s/it][A
  7%|▋         | 608/8253 [19:55<4:10:20,  1.96s/it][A
  7%|▋         | 608/8253 [19:55<4:10:11,  1.96s/it][A
  7%|▋         | 608/8253 [19:55<4:10:35,  1.97s/it][A

  7%|▋         | 608/8253 [19:55<4:10:28,  1.97s/it][A  7%|▋         | 608/8253 [19:55<4:10:28,  1.97s/it][A
  7%|▋         | 608/8253 [19:55<4:10:39,  1.97s/it][A
  7%|▋         | 609/8253 [19:57<4:08:09,  1.95s/it][A
  7%|▋         | 609/8253 [19:57<4:08:07,  1.95s/it][A
  7%|▋         | 609/8253 [19:57<4:08:31,  1.95s/it][A
  7%|▋         | 609/8253 [19:57<4:08:30,  1.95s/it][A
  7%|▋         | 609/8253 [19:57<4:08:32,  1.95s/it][A
  7%|▋         | 609/8253 [19:57<4:08:31,  1.95s/it][A
  7%|▋         | 610/8253 [19:59<4:06:54,  1.94s/it][A

  7%|▋         | 610/8253 [19:59<4:07:10,  1.94s/it][A  7%|▋         | 610/8253 [19:59<4:07:18,  1.94s/it][A
  7%|▋         | 610/8253 [19:59<4:07:26,  1.94s/it][A
  7%|▋         | 610/8253 [19:59<4:07:30,  1.94s/it][A
  7%|▋         | 610/8253 [19:59<4:07:36,  1.94s/it][A
  7%|▋         | 611/8253 [20:01<4:06:17,  1.93s/it][A
  7%|▋         | 611/8253 [20:01<4:06:32,  1.94s/it][A
  7%|▋         | 611/8253 [20:01<4:06:40,  1.94s/it][A
  7%|▋         | 611/8253 [20:01<4:06:40,  1.94s/it][A
  7%|▋         | 611/8253 [20:01<4:06:45,  1.94s/it][A
  7%|▋         | 611/8253 [20:01<4:06:45,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:06:25,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:06:36,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:06:39,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:06:52,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:06:54,  1.94s/it][A
  7%|▋         | 612/8253 [20:03<4:07:06,  1.94s/it][A
  7%|▋         | 613/8253 [20:05<4:06:35,  1.94s/it][A
  7%|▋         | 613/8253 [20:05<4:07:03,  1.94s/it][A
  7%|▋         | 613/8253 [20:05<4:07:32,  1.94s/it][A

  7%|▋         | 613/8253 [20:05<4:07:56,  1.95s/it][A
  7%|▋         | 613/8253 [20:05<4:07:46,  1.95s/it][A  7%|▋         | 613/8253 [20:05<4:07:46,  1.95s/it][A
  7%|▋         | 614/8253 [20:07<4:07:12,  1.94s/it][A
  7%|▋         | 614/8253 [20:07<4:07:38,  1.95s/it][A
  7%|▋         | 614/8253 [20:07<4:07:44,  1.95s/it][A
  7%|▋         | 614/8253 [20:07<4:07:31,  1.94s/it][A
  7%|▋         | 614/8253 [20:07<4:07:35,  1.94s/it][A
  7%|▋         | 614/8253 [20:07<4:07:49,  1.95s/it][A

  7%|▋         | 615/8253 [20:09<4:06:00,  1.93s/it][A  7%|▋         | 615/8253 [20:08<4:06:04,  1.93s/it][A
  7%|▋         | 615/8253 [20:09<4:06:07,  1.93s/it][A
  7%|▋         | 615/8253 [20:09<4:06:12,  1.93s/it][A
  7%|▋         | 615/8253 [20:09<4:06:27,  1.94s/it][A
  7%|▋         | 615/8253 [20:09<4:06:14,  1.93s/it][A
  7%|▋         | 616/8253 [20:11<4:07:47,  1.95s/it][A

  7%|▋         | 616/8253 [20:11<4:08:11,  1.95s/it][A  7%|▋         | 616/8253 [20:10<4:08:14,  1.95s/it][A
  7%|▋         | 616/8253 [20:11<4:08:05,  1.95s/it][A
  7%|▋         | 616/8253 [20:11<4:08:05,  1.95s/it][A
  7%|▋         | 616/8253 [20:11<4:08:23,  1.95s/it][A
  7%|▋         | 617/8253 [20:13<4:07:40,  1.95s/it][A
  7%|▋         | 617/8253 [20:13<4:08:33,  1.95s/it][A
  7%|▋         | 617/8253 [20:12<4:08:57,  1.96s/it][A
  7%|▋         | 617/8253 [20:13<4:08:57,  1.96s/it][A
  7%|▋         | 617/8253 [20:13<4:09:10,  1.96s/it][A
  7%|▋         | 617/8253 [20:13<4:09:08,  1.96s/it][A
  7%|▋         | 618/8253 [20:15<4:09:10,  1.96s/it][A

  7%|▋         | 618/8253 [20:15<4:09:21,  1.96s/it][A  7%|▋         | 618/8253 [20:14<4:09:22,  1.96s/it][A
  7%|▋         | 618/8253 [20:15<4:09:29,  1.96s/it][A
  7%|▋         | 618/8253 [20:15<4:09:30,  1.96s/it][A
  7%|▋         | 618/8253 [20:15<4:09:27,  1.96s/it][A
  8%|▊         | 619/8253 [20:16<4:07:54,  1.95s/it][A
  8%|▊         | 619/8253 [20:16<4:07:45,  1.95s/it][A
  8%|▊         | 619/8253 [20:16<4:08:03,  1.95s/it][A
  8%|▊         | 619/8253 [20:16<4:08:07,  1.95s/it][A
  8%|▊         | 619/8253 [20:16<4:07:51,  1.95s/it][A
  8%|▊         | 619/8253 [20:16<4:08:12,  1.95s/it][A
  8%|▊         | 620/8253 [20:18<4:07:15,  1.94s/it][A
  8%|▊         | 620/8253 [20:18<4:07:58,  1.95s/it][A
  8%|▊         | 620/8253 [20:18<4:07:54,  1.95s/it][A
  8%|▊         | 620/8253 [20:18<4:07:58,  1.95s/it][A
  8%|▊         | 620/8253 [20:18<4:07:59,  1.95s/it][A
  8%|▊         | 620/8253 [20:18<4:08:01,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:07:32,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:08:16,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:08:16,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:08:11,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:08:04,  1.95s/it][A
  8%|▊         | 621/8253 [20:20<4:08:18,  1.95s/it][A
  8%|▊         | 622/8253 [20:22<4:07:13,  1.94s/it][A
  8%|▊         | 622/8253 [20:22<4:07:26,  1.95s/it][A
  8%|▊         | 622/8253 [20:22<4:07:38,  1.95s/it][A
  8%|▊         | 622/8253 [20:22<4:07:19,  1.94s/it][A
  8%|▊         | 622/8253 [20:22<4:07:42,  1.95s/it][A
  8%|▊         | 622/8253 [20:22<4:07:53,  1.95s/it][A
  8%|▊         | 623/8253 [20:24<4:05:46,  1.93s/it][A
  8%|▊         | 623/8253 [20:24<4:05:49,  1.93s/it][A
  8%|▊         | 623/8253 [20:24<4:06:06,  1.94s/it][A
  8%|▊         | 623/8253 [20:24<4:06:38,  1.94s/it][A
  8%|▊         | 623/8253 [20:24<4:06:38,  1.94s/it][A
  8%|▊         | 623/8253 [20:24<4:06:21,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:06:50,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:06:55,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:07:01,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:07:03,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:06:51,  1.94s/it][A
  8%|▊         | 624/8253 [20:26<4:07:09,  1.94s/it][A
  8%|▊         | 625/8253 [20:28<4:06:02,  1.94s/it][A
  8%|▊         | 625/8253 [20:28<4:06:46,  1.94s/it][A
  8%|▊         | 625/8253 [20:28<4:06:28,  1.94s/it][A

  8%|▊         | 625/8253 [20:28<4:06:44,  1.94s/it][A  8%|▊         | 625/8253 [20:28<4:06:47,  1.94s/it][A
  8%|▊         | 625/8253 [20:28<4:06:57,  1.94s/it][A
  8%|▊         | 626/8253 [20:30<4:05:32,  1.93s/it][A
  8%|▊         | 626/8253 [20:30<4:05:51,  1.93s/it][A
  8%|▊         | 626/8253 [20:30<4:05:55,  1.93s/it][A
  8%|▊         | 626/8253 [20:30<4:05:54,  1.93s/it][A
  8%|▊         | 626/8253 [20:30<4:06:27,  1.94s/it][A
  8%|▊         | 626/8253 [20:30<4:06:27,  1.94s/it][A
  8%|▊         | 627/8253 [20:32<4:04:34,  1.92s/it][A
  8%|▊         | 627/8253 [20:32<4:04:52,  1.93s/it][A
  8%|▊         | 627/8253 [20:32<4:04:53,  1.93s/it][A

  8%|▊         | 627/8253 [20:32<4:05:01,  1.93s/it][A  8%|▊         | 627/8253 [20:32<4:05:00,  1.93s/it][A
  8%|▊         | 627/8253 [20:32<4:05:03,  1.93s/it][A
  8%|▊         | 628/8253 [20:34<4:06:44,  1.94s/it][A
  8%|▊         | 628/8253 [20:34<4:06:57,  1.94s/it][A
  8%|▊         | 628/8253 [20:34<4:07:02,  1.94s/it][A
  8%|▊         | 628/8253 [20:34<4:07:04,  1.94s/it][A
  8%|▊         | 628/8253 [20:34<4:07:01,  1.94s/it][A
  8%|▊         | 628/8253 [20:34<4:07:07,  1.94s/it][A

  8%|▊         | 629/8253 [20:36<4:06:47,  1.94s/it][A  8%|▊         | 629/8253 [20:36<4:06:51,  1.94s/it][A
  8%|▊         | 629/8253 [20:36<4:07:25,  1.95s/it][A
  8%|▊         | 629/8253 [20:36<4:07:11,  1.95s/it][A
  8%|▊         | 629/8253 [20:36<4:07:24,  1.95s/it][A
  8%|▊         | 629/8253 [20:36<4:07:23,  1.95s/it][A
  8%|▊         | 630/8253 [20:38<4:08:13,  1.95s/it][A
  8%|▊         | 630/8253 [20:38<4:08:21,  1.95s/it][A
  8%|▊         | 630/8253 [20:38<4:08:53,  1.96s/it][A
  8%|▊         | 630/8253 [20:38<4:08:53,  1.96s/it]
[A  8%|▊         | 630/8253 [20:38<4:09:01,  1.96s/it][A
  8%|▊         | 630/8253 [20:38<4:09:00,  1.96s/it][A
  8%|▊         | 631/8253 [20:40<4:09:09,  1.96s/it][A
  8%|▊         | 631/8253 [20:40<4:09:17,  1.96s/it][A
  8%|▊         | 631/8253 [20:40<4:09:47,  1.97s/it][A
  8%|▊         | 631/8253 [20:40<4:09:45,  1.97s/it][A

  8%|▊         | 631/8253 [20:40<4:10:03,  1.97s/it][A  8%|▊         | 631/8253 [20:40<4:10:06,  1.97s/it][A
  8%|▊         | 632/8253 [20:42<4:10:15,  1.97s/it][A
  8%|▊         | 632/8253 [20:42<4:10:26,  1.97s/it][A
  8%|▊         | 632/8253 [20:42<4:10:28,  1.97s/it][A
  8%|▊         | 632/8253 [20:42<4:10:32,  1.97s/it][A

  8%|▊         | 632/8253 [20:42<4:10:49,  1.97s/it][A  8%|▊         | 632/8253 [20:42<4:10:58,  1.98s/it][A
  8%|▊         | 633/8253 [20:44<4:07:35,  1.95s/it][A
  8%|▊         | 633/8253 [20:44<4:07:45,  1.95s/it][A
  8%|▊         | 633/8253 [20:44<4:08:44,  1.96s/it][A
  8%|▊         | 633/8253 [20:44<4:08:37,  1.96s/it][A
  8%|▊         | 633/8253 [20:44<4:08:43,  1.96s/it][A
  8%|▊         | 633/8253 [20:44<4:08:50,  1.96s/it][A
  8%|▊         | 634/8253 [20:46<4:14:09,  2.00s/it][A
  8%|▊         | 634/8253 [20:46<4:14:36,  2.01s/it][A
  8%|▊         | 634/8253 [20:46<4:14:21,  2.00s/it][A
  8%|▊         | 634/8253 [20:46<4:15:06,  2.01s/it][A
  8%|▊         | 634/8253 [20:46<4:14:37,  2.01s/it][A
  8%|▊         | 634/8253 [20:46<4:15:01,  2.01s/it][A
  8%|▊         | 635/8253 [20:48<4:11:12,  1.98s/it][A
  8%|▊         | 635/8253 [20:48<4:11:06,  1.98s/it][A
  8%|▊         | 635/8253 [20:48<4:11:28,  1.98s/it][A
  8%|▊         | 635/8253 [20:48<4:11:19,  1.98s/it][A
  8%|▊         | 635/8253 [20:48<4:11:36,  1.98s/it][A
  8%|▊         | 635/8253 [20:48<4:12:01,  1.98s/it][A
  8%|▊         | 636/8253 [20:50<4:09:42,  1.97s/it][A
  8%|▊         | 636/8253 [20:50<4:09:59,  1.97s/it][A
  8%|▊         | 636/8253 [20:50<4:09:53,  1.97s/it][A
  8%|▊         | 636/8253 [20:50<4:10:13,  1.97s/it][A
  8%|▊         | 636/8253 [20:50<4:09:57,  1.97s/it][A
  8%|▊         | 636/8253 [20:50<4:10:33,  1.97s/it][A
  8%|▊         | 637/8253 [20:52<4:10:08,  1.97s/it][A

  8%|▊         | 637/8253 [20:52<4:10:16,  1.97s/it][A  8%|▊         | 637/8253 [20:52<4:10:04,  1.97s/it][A
  8%|▊         | 637/8253 [20:52<4:10:18,  1.97s/it][A
  8%|▊         | 637/8253 [20:52<4:10:17,  1.97s/it][A
  8%|▊         | 637/8253 [20:52<4:10:18,  1.97s/it][A
  8%|▊         | 638/8253 [20:54<4:08:12,  1.96s/it][A
  8%|▊         | 638/8253 [20:54<4:08:22,  1.96s/it][A
  8%|▊         | 638/8253 [20:54<4:08:37,  1.96s/it][A
  8%|▊         | 638/8253 [20:54<4:08:25,  1.96s/it][A
  8%|▊         | 638/8253 [20:54<4:08:42,  1.96s/it][A
  8%|▊         | 638/8253 [20:54<4:08:44,  1.96s/it][A
  8%|▊         | 639/8253 [20:56<4:08:48,  1.96s/it][A

  8%|▊         | 639/8253 [20:56<4:08:44,  1.96s/it][A  8%|▊         | 639/8253 [20:56<4:08:58,  1.96s/it][A
  8%|▊         | 639/8253 [20:56<4:09:15,  1.96s/it][A
  8%|▊         | 639/8253 [20:55<4:09:11,  1.96s/it][A
  8%|▊         | 639/8253 [20:56<4:09:08,  1.96s/it][A
  8%|▊         | 640/8253 [20:58<4:07:54,  1.95s/it][A
  8%|▊         | 640/8253 [20:58<4:08:10,  1.96s/it][A
  8%|▊         | 640/8253 [20:58<4:08:12,  1.96s/it][A
  8%|▊         | 640/8253 [20:58<4:08:27,  1.96s/it][A
  8%|▊         | 640/8253 [20:57<4:08:26,  1.96s/it][A
  8%|▊         | 640/8253 [20:58<4:08:38,  1.96s/it][A
  8%|▊         | 641/8253 [20:59<4:06:41,  1.94s/it][A
  8%|▊         | 641/8253 [20:59<4:06:55,  1.95s/it][A
  8%|▊         | 641/8253 [20:59<4:06:57,  1.95s/it][A
  8%|▊         | 641/8253 [20:59<4:06:54,  1.95s/it][A

  8%|▊         | 641/8253 [21:00<4:07:08,  1.95s/it][A  8%|▊         | 641/8253 [21:00<4:07:02,  1.95s/it][A
  8%|▊         | 642/8253 [21:01<4:08:49,  1.96s/it][A
  8%|▊         | 642/8253 [21:01<4:08:59,  1.96s/it][A
  8%|▊         | 642/8253 [21:02<4:09:03,  1.96s/it][A
  8%|▊         | 642/8253 [21:02<4:09:25,  1.97s/it][A
  8%|▊         | 642/8253 [21:02<4:09:22,  1.97s/it][A
  8%|▊         | 642/8253 [21:02<4:09:37,  1.97s/it][A
  8%|▊         | 643/8253 [21:03<4:06:55,  1.95s/it][A
  8%|▊         | 643/8253 [21:03<4:07:10,  1.95s/it][A
  8%|▊         | 643/8253 [21:03<4:07:17,  1.95s/it][A


  8%|▊         | 643/8253 [21:03<4:07:47,  1.95s/it][A  8%|▊         | 643/8253 [21:03<4:07:29,  1.95s/it][A  8%|▊         | 643/8253 [21:03<4:07:31,  1.95s/it][A
  8%|▊         | 644/8253 [21:05<4:07:43,  1.95s/it][A
  8%|▊         | 644/8253 [21:05<4:07:50,  1.95s/it][A
  8%|▊         | 644/8253 [21:05<4:07:55,  1.96s/it][A
  8%|▊         | 644/8253 [21:05<4:08:04,  1.96s/it][A
  8%|▊         | 644/8253 [21:05<4:08:12,  1.96s/it][A
  8%|▊         | 644/8253 [21:05<4:08:01,  1.96s/it][A
  8%|▊         | 645/8253 [21:07<4:09:13,  1.97s/it][A
  8%|▊         | 645/8253 [21:07<4:09:08,  1.96s/it][A
  8%|▊         | 645/8253 [21:07<4:09:36,  1.97s/it][A
  8%|▊         | 645/8253 [21:07<4:09:27,  1.97s/it][A
  8%|▊         | 645/8253 [21:07<4:09:35,  1.97s/it][A
  8%|▊         | 645/8253 [21:07<4:09:42,  1.97s/it][A
  8%|▊         | 646/8253 [21:09<4:09:51,  1.97s/it][A
  8%|▊         | 646/8253 [21:09<4:09:59,  1.97s/it][A
  8%|▊         | 646/8253 [21:09<4:09:54,  1.97s/it][A
  8%|▊         | 646/8253 [21:09<4:10:01,  1.97s/it][A

  8%|▊         | 646/8253 [21:09<4:10:02,  1.97s/it][A  8%|▊         | 646/8253 [21:09<4:10:05,  1.97s/it][A
  8%|▊         | 647/8253 [21:11<4:08:56,  1.96s/it][A
  8%|▊         | 647/8253 [21:11<4:08:50,  1.96s/it][A
  8%|▊         | 647/8253 [21:11<4:08:57,  1.96s/it][A
  8%|▊         | 647/8253 [21:11<4:08:58,  1.96s/it][A
  8%|▊         | 647/8253 [21:11<4:09:29,  1.97s/it][A
  8%|▊         | 647/8253 [21:11<4:09:20,  1.97s/it][A
  8%|▊         | 648/8253 [21:13<4:08:13,  1.96s/it][A
  8%|▊         | 648/8253 [21:13<4:08:28,  1.96s/it][A
  8%|▊         | 648/8253 [21:13<4:08:32,  1.96s/it][A
  8%|▊         | 648/8253 [21:13<4:08:37,  1.96s/it][A
  8%|▊         | 648/8253 [21:13<4:08:47,  1.96s/it][A
  8%|▊         | 648/8253 [21:13<4:08:40,  1.96s/it][A

  8%|▊         | 649/8253 [21:15<4:07:47,  1.96s/it][A  8%|▊         | 649/8253 [21:15<4:07:49,  1.96s/it][A
  8%|▊         | 649/8253 [21:15<4:07:54,  1.96s/it][A
  8%|▊         | 649/8253 [21:15<4:08:16,  1.96s/it][A

  8%|▊         | 649/8253 [21:15<4:08:14,  1.96s/it][A  8%|▊         | 649/8253 [21:15<4:07:59,  1.96s/it][A
  8%|▊         | 650/8253 [21:17<4:07:31,  1.95s/it][A
  8%|▊         | 650/8253 [21:17<4:07:43,  1.95s/it][A
  8%|▊         | 650/8253 [21:17<4:07:40,  1.95s/it][A
  8%|▊         | 650/8253 [21:17<4:08:00,  1.96s/it][A
  8%|▊         | 650/8253 [21:17<4:08:09,  1.96s/it][A
  8%|▊         | 650/8253 [21:17<4:08:24,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:14,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:07,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:26,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:21,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:26,  1.96s/it][A
  8%|▊         | 651/8253 [21:19<4:08:33,  1.96s/it][A
  8%|▊         | 652/8253 [21:21<4:06:44,  1.95s/it][A
  8%|▊         | 652/8253 [21:21<4:07:12,  1.95s/it][A

  8%|▊         | 652/8253 [21:21<4:07:24,  1.95s/it][A  8%|▊         | 652/8253 [21:21<4:07:17,  1.95s/it][A
  8%|▊         | 652/8253 [21:21<4:07:35,  1.95s/it][A
  8%|▊         | 652/8253 [21:21<4:07:34,  1.95s/it][A
  8%|▊         | 653/8253 [21:23<4:08:36,  1.96s/it][A
  8%|▊         | 653/8253 [21:23<4:08:36,  1.96s/it][A
  8%|▊         | 653/8253 [21:23<4:08:43,  1.96s/it][A
  8%|▊         | 653/8253 [21:23<4:08:55,  1.97s/it][A
  8%|▊         | 653/8253 [21:23<4:08:52,  1.96s/it][A
  8%|▊         | 653/8253 [21:23<4:09:03,  1.97s/it][A
  8%|▊         | 654/8253 [21:25<4:08:16,  1.96s/it][A
  8%|▊         | 654/8253 [21:25<4:08:29,  1.96s/it][A
  8%|▊         | 654/8253 [21:25<4:08:19,  1.96s/it][A
  8%|▊         | 654/8253 [21:25<4:08:31,  1.96s/it][A
  8%|▊         | 654/8253 [21:25<4:08:31,  1.96s/it][A
  8%|▊         | 654/8253 [21:25<4:08:43,  1.96s/it][A
  8%|▊         | 655/8253 [21:27<4:10:54,  1.98s/it][A
  8%|▊         | 655/8253 [21:27<4:11:06,  1.98s/it][A
  8%|▊         | 655/8253 [21:27<4:11:27,  1.99s/it][A
  8%|▊         | 655/8253 [21:27<4:11:07,  1.98s/it][A

  8%|▊         | 655/8253 [21:27<4:11:24,  1.99s/it][A  8%|▊         | 655/8253 [21:27<4:11:25,  1.99s/it][A
  8%|▊         | 656/8253 [21:29<4:08:47,  1.96s/it]
[A  8%|▊         | 656/8253 [21:29<4:08:47,  1.96s/it][A
  8%|▊         | 656/8253 [21:29<4:09:02,  1.97s/it][A
  8%|▊         | 656/8253 [21:29<4:09:19,  1.97s/it][A

  8%|▊         | 656/8253 [21:29<4:08:59,  1.97s/it][A  8%|▊         | 656/8253 [21:29<4:09:13,  1.97s/it][A
  8%|▊         | 657/8253 [21:31<4:08:39,  1.96s/it][A
  8%|▊         | 657/8253 [21:31<4:08:46,  1.97s/it][A
  8%|▊         | 657/8253 [21:31<4:09:05,  1.97s/it][A

  8%|▊         | 657/8253 [21:31<4:09:09,  1.97s/it][A
  8%|▊         | 657/8253 [21:31<4:09:17,  1.97s/it][A  8%|▊         | 657/8253 [21:31<4:09:02,  1.97s/it][A
  8%|▊         | 658/8253 [21:33<4:07:44,  1.96s/it][A
  8%|▊         | 658/8253 [21:33<4:07:45,  1.96s/it][A
  8%|▊         | 658/8253 [21:33<4:08:19,  1.96s/it][A
  8%|▊         | 658/8253 [21:33<4:08:21,  1.96s/it][A

  8%|▊         | 658/8253 [21:33<4:08:25,  1.96s/it]  8%|▊         | 658/8253 [21:33<4:08:13,  1.96s/it][A[A
  8%|▊         | 659/8253 [21:35<4:06:37,  1.95s/it][A
  8%|▊         | 659/8253 [21:35<4:06:57,  1.95s/it][A
  8%|▊         | 659/8253 [21:35<4:07:00,  1.95s/it][A
  8%|▊         | 659/8253 [21:35<4:07:11,  1.95s/it][A

  8%|▊         | 659/8253 [21:35<4:07:17,  1.95s/it][A  8%|▊         | 659/8253 [21:35<4:07:10,  1.95s/it][A
  8%|▊         | 660/8253 [21:37<4:07:52,  1.96s/it][A
  8%|▊         | 660/8253 [21:37<4:08:16,  1.96s/it][A

  8%|▊         | 660/8253 [21:37<4:08:35,  1.96s/it][A  8%|▊         | 660/8253 [21:37<4:08:35,  1.96s/it][A
  8%|▊         | 660/8253 [21:37<4:08:34,  1.96s/it][A
  8%|▊         | 660/8253 [21:37<4:08:44,  1.97s/it][A
  8%|▊         | 661/8253 [21:39<4:09:23,  1.97s/it][A
  8%|▊         | 661/8253 [21:39<4:09:33,  1.97s/it][A
  8%|▊         | 661/8253 [21:39<4:09:23,  1.97s/it][A
  8%|▊         | 661/8253 [21:39<4:09:47,  1.97s/it][A
  8%|▊         | 661/8253 [21:39<4:10:01,  1.98s/it][A
  8%|▊         | 661/8253 [21:39<4:09:51,  1.97s/it][A
  8%|▊         | 662/8253 [21:41<4:09:50,  1.97s/it][A
  8%|▊         | 662/8253 [21:41<4:10:24,  1.98s/it][A
  8%|▊         | 662/8253 [21:41<4:10:15,  1.98s/it][A
  8%|▊         | 662/8253 [21:41<4:10:27,  1.98s/it][A
  8%|▊         | 662/8253 [21:41<4:10:35,  1.98s/it][A
  8%|▊         | 662/8253 [21:41<4:10:46,  1.98s/it][A
  8%|▊         | 663/8253 [21:43<4:10:37,  1.98s/it][A
  8%|▊         | 663/8253 [21:43<4:11:05,  1.98s/it][A

  8%|▊         | 663/8253 [21:43<4:11:00,  1.98s/it][A  8%|▊         | 663/8253 [21:43<4:10:57,  1.98s/it][A
  8%|▊         | 663/8253 [21:43<4:11:18,  1.99s/it][A
  8%|▊         | 663/8253 [21:43<4:11:04,  1.98s/it][A
  8%|▊         | 664/8253 [21:45<4:08:52,  1.97s/it][A
  8%|▊         | 664/8253 [21:45<4:09:05,  1.97s/it][A
  8%|▊         | 664/8253 [21:45<4:09:15,  1.97s/it][A

  8%|▊         | 664/8253 [21:45<4:09:15,  1.97s/it]
[A  8%|▊         | 664/8253 [21:45<4:09:23,  1.97s/it][A  8%|▊         | 664/8253 [21:45<4:09:18,  1.97s/it][A
  8%|▊         | 665/8253 [21:47<4:16:52,  2.03s/it][A
  8%|▊         | 665/8253 [21:47<4:17:10,  2.03s/it][A
  8%|▊         | 665/8253 [21:47<4:17:22,  2.04s/it][A
  8%|▊         | 665/8253 [21:47<4:17:16,  2.03s/it][A
  8%|▊         | 665/8253 [21:47<4:17:24,  2.04s/it][A
  8%|▊         | 665/8253 [21:47<4:17:39,  2.04s/it][A
  8%|▊         | 666/8253 [21:49<4:15:51,  2.02s/it][A
  8%|▊         | 666/8253 [21:49<4:15:51,  2.02s/it][A

  8%|▊         | 666/8253 [21:49<4:16:05,  2.03s/it][A  8%|▊         | 666/8253 [21:49<4:15:59,  2.02s/it][A
  8%|▊         | 666/8253 [21:49<4:16:08,  2.03s/it][A
  8%|▊         | 666/8253 [21:49<4:16:08,  2.03s/it][A
  8%|▊         | 667/8253 [21:51<4:13:06,  2.00s/it][A
  8%|▊         | 667/8253 [21:51<4:13:22,  2.00s/it][A
  8%|▊         | 667/8253 [21:51<4:13:34,  2.01s/it][A
  8%|▊         | 667/8253 [21:51<4:13:39,  2.01s/it][A
  8%|▊         | 667/8253 [21:51<4:13:32,  2.01s/it][A
  8%|▊         | 667/8253 [21:51<4:13:40,  2.01s/it][A
  8%|▊         | 668/8253 [21:53<4:11:53,  1.99s/it][A
  8%|▊         | 668/8253 [21:53<4:11:55,  1.99s/it][A
  8%|▊         | 668/8253 [21:53<4:12:13,  2.00s/it][A
  8%|▊         | 668/8253 [21:53<4:12:10,  1.99s/it][A
  8%|▊         | 668/8253 [21:53<4:12:18,  2.00s/it][A
  8%|▊         | 668/8253 [21:53<4:12:18,  2.00s/it][A
  8%|▊         | 669/8253 [21:55<4:10:32,  1.98s/it][A
  8%|▊         | 669/8253 [21:55<4:10:33,  1.98s/it][A
  8%|▊         | 669/8253 [21:55<4:10:27,  1.98s/it][A
  8%|▊         | 669/8253 [21:55<4:10:37,  1.98s/it][A

  8%|▊         | 669/8253 [21:55<4:10:37,  1.98s/it][A  8%|▊         | 669/8253 [21:55<4:10:36,  1.98s/it][A
  8%|▊         | 670/8253 [21:57<4:08:50,  1.97s/it][A
  8%|▊         | 670/8253 [21:57<4:08:55,  1.97s/it][A
  8%|▊         | 670/8253 [21:57<4:08:59,  1.97s/it][A
  8%|▊         | 670/8253 [21:57<4:09:15,  1.97s/it][A
  8%|▊         | 670/8253 [21:57<4:09:08,  1.97s/it][A
  8%|▊         | 670/8253 [21:57<4:09:19,  1.97s/it][A
  8%|▊         | 671/8253 [21:59<4:10:06,  1.98s/it][A
  8%|▊         | 671/8253 [21:59<4:10:13,  1.98s/it][A
  8%|▊         | 671/8253 [21:59<4:10:40,  1.98s/it][A
  8%|▊         | 671/8253 [21:59<4:10:37,  1.98s/it][A
  8%|▊         | 671/8253 [21:59<4:10:44,  1.98s/it][A
  8%|▊         | 671/8253 [21:59<4:10:43,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:09:53,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:10:08,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:10:04,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:10:05,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:10:14,  1.98s/it][A
  8%|▊         | 672/8253 [22:01<4:10:22,  1.98s/it][A
  8%|▊         | 673/8253 [22:02<4:06:47,  1.95s/it][A
  8%|▊         | 673/8253 [22:03<4:07:16,  1.96s/it][A
  8%|▊         | 673/8253 [22:03<4:07:00,  1.96s/it][A
  8%|▊         | 673/8253 [22:03<4:07:19,  1.96s/it][A
  8%|▊         | 673/8253 [22:03<4:07:23,  1.96s/it][A
  8%|▊         | 673/8253 [22:03<4:07:20,  1.96s/it][A
  8%|▊         | 674/8253 [22:05<4:05:03,  1.94s/it][A
  8%|▊         | 674/8253 [22:05<4:04:52,  1.94s/it][A
  8%|▊         | 674/8253 [22:05<4:05:14,  1.94s/it][A
  8%|▊         | 674/8253 [22:05<4:05:07,  1.94s/it][A

  8%|▊         | 674/8253 [22:04<4:05:25,  1.94s/it][A  8%|▊         | 674/8253 [22:05<4:05:19,  1.94s/it][A
  8%|▊         | 675/8253 [22:06<4:05:15,  1.94s/it][A
  8%|▊         | 675/8253 [22:06<4:05:19,  1.94s/it][A
  8%|▊         | 675/8253 [22:06<4:05:29,  1.94s/it][A
  8%|▊         | 675/8253 [22:06<4:05:43,  1.95s/it][A
  8%|▊         | 675/8253 [22:06<4:05:40,  1.95s/it][A
  8%|▊         | 675/8253 [22:07<4:05:44,  1.95s/it][A
  8%|▊         | 676/8253 [22:08<4:04:40,  1.94s/it][A
  8%|▊         | 676/8253 [22:08<4:04:55,  1.94s/it][A
  8%|▊         | 676/8253 [22:08<4:05:03,  1.94s/it][A
  8%|▊         | 676/8253 [22:08<4:05:19,  1.94s/it][A
  8%|▊         | 676/8253 [22:08<4:05:13,  1.94s/it][A
  8%|▊         | 676/8253 [22:08<4:05:12,  1.94s/it][A
  8%|▊         | 677/8253 [22:10<4:05:11,  1.94s/it][A
  8%|▊         | 677/8253 [22:10<4:05:32,  1.94s/it][A
  8%|▊         | 677/8253 [22:10<4:05:29,  1.94s/it][A
  8%|▊         | 677/8253 [22:10<4:05:24,  1.94s/it][A

  8%|▊         | 677/8253 [22:10<4:05:41,  1.95s/it][A  8%|▊         | 677/8253 [22:10<4:05:39,  1.95s/it][A
  8%|▊         | 678/8253 [22:12<4:05:33,  1.95s/it][A

  8%|▊         | 678/8253 [22:12<4:05:33,  1.95s/it][A  8%|▊         | 678/8253 [22:12<4:05:33,  1.94s/it][A


  8%|▊         | 678/8253 [22:12<4:05:44,  1.95s/it][A  8%|▊         | 678/8253 [22:12<4:05:51,  1.95s/it][A  8%|▊         | 678/8253 [22:12<4:05:56,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:23,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:33,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:32,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:37,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:41,  1.95s/it][A
  8%|▊         | 679/8253 [22:14<4:06:57,  1.96s/it][A
  8%|▊         | 680/8253 [22:16<4:08:31,  1.97s/it][A
  8%|▊         | 680/8253 [22:16<4:08:39,  1.97s/it][A
  8%|▊         | 680/8253 [22:16<4:08:42,  1.97s/it][A
  8%|▊         | 680/8253 [22:16<4:08:44,  1.97s/it][A
  8%|▊         | 680/8253 [22:16<4:08:49,  1.97s/it][A
  8%|▊         | 680/8253 [22:16<4:08:45,  1.97s/it][A
  8%|▊         | 681/8253 [22:18<4:06:57,  1.96s/it][A
  8%|▊         | 681/8253 [22:18<4:07:02,  1.96s/it][A
  8%|▊         | 681/8253 [22:18<4:06:55,  1.96s/it][A
  8%|▊         | 681/8253 [22:18<4:07:10,  1.96s/it][A
  8%|▊         | 681/8253 [22:18<4:07:03,  1.96s/it][A
  8%|▊         | 681/8253 [22:18<4:07:23,  1.96s/it][A
  8%|▊         | 682/8253 [22:20<4:06:13,  1.95s/it][A
  8%|▊         | 682/8253 [22:20<4:06:32,  1.95s/it][A
  8%|▊         | 682/8253 [22:20<4:06:31,  1.95s/it][A
  8%|▊         | 682/8253 [22:20<4:06:25,  1.95s/it][A
  8%|▊         | 682/8253 [22:20<4:06:47,  1.96s/it][A
  8%|▊         | 682/8253 [22:20<4:06:40,  1.95s/it][A
  8%|▊         | 683/8253 [22:22<4:05:21,  1.94s/it][A
  8%|▊         | 683/8253 [22:22<4:05:13,  1.94s/it]
[A  8%|▊         | 683/8253 [22:22<4:05:12,  1.94s/it][A
  8%|▊         | 683/8253 [22:22<4:05:31,  1.95s/it][A
  8%|▊         | 683/8253 [22:22<4:05:44,  1.95s/it][A
  8%|▊         | 683/8253 [22:22<4:05:39,  1.95s/it][A
  8%|▊         | 684/8253 [22:24<4:09:22,  1.98s/it][A
  8%|▊         | 684/8253 [22:24<4:09:15,  1.98s/it][A
  8%|▊         | 684/8253 [22:24<4:09:24,  1.98s/it][A
  8%|▊         | 684/8253 [22:24<4:09:23,  1.98s/it][A
  8%|▊         | 684/8253 [22:24<4:09:31,  1.98s/it][A
  8%|▊         | 684/8253 [22:24<4:09:40,  1.98s/it][A
  8%|▊         | 685/8253 [22:26<4:07:50,  1.96s/it][A
  8%|▊         | 685/8253 [22:26<4:08:14,  1.97s/it][A
  8%|▊         | 685/8253 [22:26<4:08:23,  1.97s/it][A
  8%|▊         | 685/8253 [22:26<4:08:45,  1.97s/it][A
  8%|▊         | 685/8253 [22:26<4:08:44,  1.97s/it][A
  8%|▊         | 685/8253 [22:26<4:08:55,  1.97s/it][A
  8%|▊         | 686/8253 [22:28<4:10:02,  1.98s/it][A
  8%|▊         | 686/8253 [22:28<4:10:17,  1.98s/it][A
  8%|▊         | 686/8253 [22:28<4:10:20,  1.99s/it][A
  8%|▊         | 686/8253 [22:28<4:10:28,  1.99s/it][A

  8%|▊         | 686/8253 [22:28<4:10:27,  1.99s/it][A  8%|▊         | 686/8253 [22:28<4:10:31,  1.99s/it][A
  8%|▊         | 687/8253 [22:30<4:09:34,  1.98s/it][A
  8%|▊         | 687/8253 [22:30<4:09:56,  1.98s/it][A
  8%|▊         | 687/8253 [22:30<4:10:00,  1.98s/it][A
  8%|▊         | 687/8253 [22:30<4:10:11,  1.98s/it][A

  8%|▊         | 687/8253 [22:30<4:10:28,  1.99s/it][A  8%|▊         | 687/8253 [22:30<4:10:22,  1.99s/it][A
  8%|▊         | 688/8253 [22:32<4:08:46,  1.97s/it][A
  8%|▊         | 688/8253 [22:32<4:09:10,  1.98s/it][A
  8%|▊         | 688/8253 [22:32<4:09:25,  1.98s/it][A
  8%|▊         | 688/8253 [22:32<4:09:20,  1.98s/it][A
  8%|▊         | 688/8253 [22:32<4:09:18,  1.98s/it][A
  8%|▊         | 688/8253 [22:32<4:09:27,  1.98s/it][A
  8%|▊         | 689/8253 [22:34<4:09:03,  1.98s/it][A
  8%|▊         | 689/8253 [22:34<4:09:56,  1.98s/it][A

  8%|▊         | 689/8253 [22:34<4:10:07,  1.98s/it][A  8%|▊         | 689/8253 [22:34<4:10:16,  1.99s/it][A
  8%|▊         | 689/8253 [22:34<4:10:22,  1.99s/it][A
  8%|▊         | 689/8253 [22:34<4:10:20,  1.99s/it][A
  8%|▊         | 690/8253 [22:36<4:09:46,  1.98s/it][A
  8%|▊         | 690/8253 [22:36<4:10:10,  1.98s/it][A


  8%|▊         | 690/8253 [22:36<4:10:10,  1.98s/it][A  8%|▊         | 690/8253 [22:36<4:10:16,  1.99s/it][A  8%|▊         | 690/8253 [22:36<4:10:44,  1.99s/it][A
  8%|▊         | 690/8253 [22:36<4:10:32,  1.99s/it][A
  8%|▊         | 691/8253 [22:38<4:08:36,  1.97s/it][A
  8%|▊         | 691/8253 [22:38<4:09:01,  1.98s/it][A
  8%|▊         | 691/8253 [22:38<4:09:27,  1.98s/it][A
  8%|▊         | 691/8253 [22:38<4:09:41,  1.98s/it][A
  8%|▊         | 691/8253 [22:38<4:09:44,  1.98s/it][A
  8%|▊         | 691/8253 [22:38<4:10:05,  1.98s/it][A
  8%|▊         | 692/8253 [22:40<4:08:09,  1.97s/it][A
  8%|▊         | 692/8253 [22:40<4:08:55,  1.98s/it][A
  8%|▊         | 692/8253 [22:40<4:09:09,  1.98s/it][A
  8%|▊         | 692/8253 [22:40<4:09:25,  1.98s/it][A
  8%|▊         | 692/8253 [22:40<4:09:37,  1.98s/it][A
  8%|▊         | 692/8253 [22:40<4:09:28,  1.98s/it][A
  8%|▊         | 693/8253 [22:42<4:07:20,  1.96s/it][A
  8%|▊         | 693/8253 [22:42<4:07:42,  1.97s/it][A
  8%|▊         | 693/8253 [22:42<4:07:34,  1.96s/it][A
  8%|▊         | 693/8253 [22:42<4:07:55,  1.97s/it][A
  8%|▊         | 693/8253 [22:42<4:07:52,  1.97s/it][A
  8%|▊         | 693/8253 [22:42<4:08:02,  1.97s/it][A
  8%|▊         | 694/8253 [22:44<4:06:04,  1.95s/it][A
  8%|▊         | 694/8253 [22:44<4:05:59,  1.95s/it][A

  8%|▊         | 694/8253 [22:44<4:06:25,  1.96s/it]  8%|▊         | 694/8253 [22:44<4:06:16,  1.95s/it][A[A
  8%|▊         | 694/8253 [22:44<4:06:23,  1.96s/it][A
  8%|▊         | 694/8253 [22:44<4:06:28,  1.96s/it][A
  8%|▊         | 695/8253 [22:46<4:06:05,  1.95s/it][A
  8%|▊         | 695/8253 [22:46<4:06:31,  1.96s/it][A
  8%|▊         | 695/8253 [22:46<4:06:52,  1.96s/it][A

  8%|▊         | 695/8253 [22:46<4:07:21,  1.96s/it][A  8%|▊         | 695/8253 [22:46<4:07:11,  1.96s/it][A
  8%|▊         | 695/8253 [22:46<4:07:16,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:29,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:41,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:30,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:34,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:51,  1.96s/it][A
  8%|▊         | 696/8253 [22:48<4:06:56,  1.96s/it][A
  8%|▊         | 697/8253 [22:50<4:04:32,  1.94s/it][A
  8%|▊         | 697/8253 [22:50<4:04:24,  1.94s/it][A
  8%|▊         | 697/8253 [22:50<4:05:13,  1.95s/it][A
  8%|▊         | 697/8253 [22:50<4:05:19,  1.95s/it][A
  8%|▊         | 697/8253 [22:50<4:05:13,  1.95s/it][A
  8%|▊         | 697/8253 [22:50<4:05:27,  1.95s/it][A
  8%|▊         | 698/8253 [22:51<4:03:12,  1.93s/it][A
  8%|▊         | 698/8253 [22:52<4:03:27,  1.93s/it][A
  8%|▊         | 698/8253 [22:52<4:03:41,  1.94s/it][A
  8%|▊         | 698/8253 [22:52<4:03:37,  1.93s/it][A
  8%|▊         | 698/8253 [22:52<4:03:39,  1.94s/it][A
  8%|▊         | 698/8253 [22:52<4:03:50,  1.94s/it][A
  8%|▊         | 699/8253 [22:54<4:03:02,  1.93s/it][A
  8%|▊         | 699/8253 [22:53<4:03:32,  1.93s/it][A
  8%|▊         | 699/8253 [22:54<4:03:40,  1.94s/it][A
  8%|▊         | 699/8253 [22:54<4:03:47,  1.94s/it][A
  8%|▊         | 699/8253 [22:54<4:04:10,  1.94s/it][A
  8%|▊         | 699/8253 [22:54<4:04:09,  1.94s/it][A
  8%|▊         | 700/8253 [22:56<4:04:29,  1.94s/it][A
  8%|▊         | 700/8253 [22:56<4:04:31,  1.94s/it][A

  8%|▊         | 700/8253 [22:56<4:04:30,  1.94s/it][A  8%|▊         | 700/8253 [22:56<4:04:37,  1.94s/it][A

  8%|▊         | 700/8253 [22:55<4:04:58,  1.95s/it][A  8%|▊         | 700/8253 [22:56<4:04:48,  1.94s/it][A
  8%|▊         | 701/8253 [22:58<4:06:10,  1.96s/it][A
  8%|▊         | 701/8253 [22:57<4:06:02,  1.95s/it][A
  8%|▊         | 701/8253 [22:58<4:05:54,  1.95s/it][A
  8%|▊         | 701/8253 [22:58<4:05:56,  1.95s/it][A
  8%|▊         | 701/8253 [22:58<4:06:15,  1.96s/it][A
  8%|▊         | 701/8253 [22:58<4:06:18,  1.96s/it][A
  9%|▊         | 702/8253 [22:59<4:05:15,  1.95s/it][A
  9%|▊         | 702/8253 [22:59<4:05:12,  1.95s/it][A
  9%|▊         | 702/8253 [22:59<4:05:22,  1.95s/it][A
  9%|▊         | 702/8253 [22:59<4:05:17,  1.95s/it][A

  9%|▊         | 702/8253 [22:59<4:05:33,  1.95s/it][A  9%|▊         | 702/8253 [22:59<4:05:38,  1.95s/it][A
  9%|▊         | 703/8253 [23:01<4:06:53,  1.96s/it][A
  9%|▊         | 703/8253 [23:01<4:07:05,  1.96s/it][A
  9%|▊         | 703/8253 [23:01<4:07:34,  1.97s/it][A
  9%|▊         | 703/8253 [23:01<4:07:17,  1.97s/it][A
  9%|▊         | 703/8253 [23:01<4:07:30,  1.97s/it][A
  9%|▊         | 703/8253 [23:01<4:07:21,  1.97s/it][A
  9%|▊         | 704/8253 [23:03<4:06:51,  1.96s/it][A
  9%|▊         | 704/8253 [23:03<4:06:50,  1.96s/it][A
  9%|▊         | 704/8253 [23:03<4:07:16,  1.97s/it][A

  9%|▊         | 704/8253 [23:03<4:07:36,  1.97s/it][A  9%|▊         | 704/8253 [23:03<4:07:22,  1.97s/it][A
  9%|▊         | 704/8253 [23:03<4:07:30,  1.97s/it][A
  9%|▊         | 705/8253 [23:05<4:07:03,  1.96s/it][A
  9%|▊         | 705/8253 [23:05<4:07:11,  1.96s/it][A
  9%|▊         | 705/8253 [23:05<4:07:32,  1.97s/it][A
  9%|▊         | 705/8253 [23:05<4:07:22,  1.97s/it][A
  9%|▊         | 705/8253 [23:05<4:07:29,  1.97s/it][A
  9%|▊         | 705/8253 [23:05<4:07:25,  1.97s/it][A
  9%|▊         | 706/8253 [23:07<4:07:37,  1.97s/it][A
  9%|▊         | 706/8253 [23:07<4:07:42,  1.97s/it][A
  9%|▊         | 706/8253 [23:07<4:07:51,  1.97s/it][A
  9%|▊         | 706/8253 [23:07<4:08:08,  1.97s/it][A

  9%|▊         | 706/8253 [23:07<4:08:00,  1.97s/it][A  9%|▊         | 706/8253 [23:07<4:08:09,  1.97s/it][A
  9%|▊         | 707/8253 [23:09<4:04:45,  1.95s/it][A
  9%|▊         | 707/8253 [23:09<4:05:20,  1.95s/it][A
  9%|▊         | 707/8253 [23:09<4:05:35,  1.95s/it][A
  9%|▊         | 707/8253 [23:09<4:05:30,  1.95s/it][A
  9%|▊         | 707/8253 [23:09<4:05:35,  1.95s/it][A
  9%|▊         | 707/8253 [23:09<4:05:22,  1.95s/it][A
  9%|▊         | 708/8253 [23:11<4:05:18,  1.95s/it][A
  9%|▊         | 708/8253 [23:11<4:05:37,  1.95s/it][A
  9%|▊         | 708/8253 [23:11<4:05:55,  1.96s/it][A
  9%|▊         | 708/8253 [23:11<4:06:00,  1.96s/it][A

  9%|▊         | 708/8253 [23:11<4:05:52,  1.96s/it][A  9%|▊         | 708/8253 [23:11<4:06:00,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:05:54,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:05:59,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:06:57,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:06:47,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:06:54,  1.96s/it][A
  9%|▊         | 709/8253 [23:13<4:06:50,  1.96s/it][A
  9%|▊         | 710/8253 [23:15<4:04:29,  1.94s/it][A
  9%|▊         | 710/8253 [23:15<4:05:08,  1.95s/it][A
  9%|▊         | 710/8253 [23:15<4:05:07,  1.95s/it][A
  9%|▊         | 710/8253 [23:15<4:05:22,  1.95s/it][A
  9%|▊         | 710/8253 [23:15<4:05:53,  1.96s/it][A
  9%|▊         | 710/8253 [23:15<4:05:33,  1.95s/it][A
  9%|▊         | 711/8253 [23:17<4:06:42,  1.96s/it][A
  9%|▊         | 711/8253 [23:17<4:07:01,  1.97s/it][A
  9%|▊         | 711/8253 [23:17<4:07:33,  1.97s/it][A
  9%|▊         | 711/8253 [23:17<4:07:35,  1.97s/it][A
  9%|▊         | 711/8253 [23:17<4:07:51,  1.97s/it][A
  9%|▊         | 711/8253 [23:17<4:07:41,  1.97s/it][A
  9%|▊         | 712/8253 [23:19<4:07:50,  1.97s/it][A
  9%|▊         | 712/8253 [23:19<4:07:54,  1.97s/it][A
  9%|▊         | 712/8253 [23:19<4:08:13,  1.98s/it][A
  9%|▊         | 712/8253 [23:19<4:08:19,  1.98s/it][A
  9%|▊         | 712/8253 [23:19<4:08:35,  1.98s/it][A
  9%|▊         | 712/8253 [23:19<4:08:16,  1.98s/it][A
  9%|▊         | 713/8253 [23:21<4:05:35,  1.95s/it][A
  9%|▊         | 713/8253 [23:21<4:06:09,  1.96s/it][A
  9%|▊         | 713/8253 [23:21<4:05:53,  1.96s/it][A
  9%|▊         | 713/8253 [23:21<4:06:11,  1.96s/it][A
  9%|▊         | 713/8253 [23:21<4:06:11,  1.96s/it][A
  9%|▊         | 713/8253 [23:21<4:05:56,  1.96s/it][A
  9%|▊         | 714/8253 [23:23<4:07:34,  1.97s/it][A
  9%|▊         | 714/8253 [23:23<4:07:37,  1.97s/it][A
  9%|▊         | 714/8253 [23:23<4:07:57,  1.97s/it][A
  9%|▊         | 714/8253 [23:23<4:07:54,  1.97s/it][A
  9%|▊         | 714/8253 [23:23<4:08:02,  1.97s/it][A
  9%|▊         | 714/8253 [23:23<4:07:55,  1.97s/it][A
  9%|▊         | 715/8253 [23:25<4:06:46,  1.96s/it][A
  9%|▊         | 715/8253 [23:25<4:07:07,  1.97s/it][A
  9%|▊         | 715/8253 [23:25<4:07:20,  1.97s/it][A

  9%|▊         | 715/8253 [23:25<4:07:33,  1.97s/it][A  9%|▊         | 715/8253 [23:25<4:07:10,  1.97s/it][A
  9%|▊         | 715/8253 [23:25<4:07:27,  1.97s/it][A
  9%|▊         | 716/8253 [23:27<4:07:56,  1.97s/it][A
  9%|▊         | 716/8253 [23:27<4:07:56,  1.97s/it][A
  9%|▊         | 716/8253 [23:27<4:07:55,  1.97s/it][A
  9%|▊         | 716/8253 [23:27<4:08:14,  1.98s/it][A
  9%|▊         | 716/8253 [23:27<4:08:14,  1.98s/it][A
  9%|▊         | 716/8253 [23:27<4:08:05,  1.97s/it][A
  9%|▊         | 717/8253 [23:29<4:07:33,  1.97s/it][A
  9%|▊         | 717/8253 [23:29<4:07:15,  1.97s/it][A
  9%|▊         | 717/8253 [23:29<4:07:49,  1.97s/it][A
  9%|▊         | 717/8253 [23:29<4:07:20,  1.97s/it][A

  9%|▊         | 717/8253 [23:29<4:07:38,  1.97s/it][A  9%|▊         | 717/8253 [23:29<4:07:35,  1.97s/it][A
  9%|▊         | 718/8253 [23:31<4:07:35,  1.97s/it][A
  9%|▊         | 718/8253 [23:31<4:07:20,  1.97s/it][A
  9%|▊         | 718/8253 [23:31<4:07:33,  1.97s/it][A
  9%|▊         | 718/8253 [23:31<4:07:25,  1.97s/it][A

  9%|▊         | 718/8253 [23:31<4:07:53,  1.97s/it][A  9%|▊         | 718/8253 [23:31<4:07:41,  1.97s/it][A
  9%|▊         | 719/8253 [23:33<4:07:47,  1.97s/it][A
  9%|▊         | 719/8253 [23:33<4:08:07,  1.98s/it][A
  9%|▊         | 719/8253 [23:33<4:07:43,  1.97s/it][A
  9%|▊         | 719/8253 [23:33<4:08:00,  1.98s/it][A
  9%|▊         | 719/8253 [23:33<4:08:14,  1.98s/it][A
  9%|▊         | 719/8253 [23:33<4:08:21,  1.98s/it][A
  9%|▊         | 720/8253 [23:35<4:06:51,  1.97s/it][A
  9%|▊         | 720/8253 [23:35<4:07:17,  1.97s/it][A
  9%|▊         | 720/8253 [23:35<4:07:28,  1.97s/it][A
  9%|▊         | 720/8253 [23:35<4:07:20,  1.97s/it][A
  9%|▊         | 720/8253 [23:35<4:07:20,  1.97s/it][A
  9%|▊         | 720/8253 [23:35<4:07:24,  1.97s/it][A
  9%|▊         | 721/8253 [23:37<4:07:51,  1.97s/it][A
  9%|▊         | 721/8253 [23:37<4:07:43,  1.97s/it][A
  9%|▊         | 721/8253 [23:37<4:08:04,  1.98s/it][A
  9%|▊         | 721/8253 [23:37<4:08:01,  1.98s/it][A
  9%|▊         | 721/8253 [23:37<4:07:54,  1.97s/it][A
  9%|▊         | 721/8253 [23:37<4:08:16,  1.98s/it][A
  9%|▊         | 722/8253 [23:39<4:07:25,  1.97s/it][A
  9%|▊         | 722/8253 [23:39<4:07:40,  1.97s/it][A
  9%|▊         | 722/8253 [23:39<4:07:37,  1.97s/it][A
  9%|▊         | 722/8253 [23:39<4:07:35,  1.97s/it][A
  9%|▊         | 722/8253 [23:39<4:07:47,  1.97s/it][A
  9%|▊         | 722/8253 [23:39<4:07:51,  1.97s/it][A
  9%|▉         | 723/8253 [23:41<4:07:39,  1.97s/it][A
  9%|▉         | 723/8253 [23:41<4:08:26,  1.98s/it][A
  9%|▉         | 723/8253 [23:41<4:08:32,  1.98s/it][A
  9%|▉         | 723/8253 [23:41<4:08:26,  1.98s/it][A
  9%|▉         | 723/8253 [23:41<4:08:35,  1.98s/it][A
  9%|▉         | 723/8253 [23:41<4:08:37,  1.98s/it][A
  9%|▉         | 724/8253 [23:43<4:06:54,  1.97s/it][A
  9%|▉         | 724/8253 [23:43<4:07:30,  1.97s/it][A
  9%|▉         | 724/8253 [23:43<4:07:12,  1.97s/it][A
  9%|▉         | 724/8253 [23:43<4:07:15,  1.97s/it][A
  9%|▉         | 724/8253 [23:43<4:07:34,  1.97s/it][A
  9%|▉         | 724/8253 [23:43<4:07:44,  1.97s/it][A
  9%|▉         | 725/8253 [23:45<4:06:17,  1.96s/it][A
  9%|▉         | 725/8253 [23:45<4:06:32,  1.96s/it][A
  9%|▉         | 725/8253 [23:45<4:06:25,  1.96s/it][A
  9%|▉         | 725/8253 [23:45<4:06:54,  1.97s/it][A
  9%|▉         | 725/8253 [23:45<4:06:34,  1.97s/it][A
  9%|▉         | 725/8253 [23:45<4:06:36,  1.97s/it][A
  9%|▉         | 726/8253 [23:47<4:06:04,  1.96s/it][A
  9%|▉         | 726/8253 [23:47<4:06:36,  1.97s/it][A
  9%|▉         | 726/8253 [23:47<4:06:23,  1.96s/it][A
  9%|▉         | 726/8253 [23:47<4:06:33,  1.97s/it][A
  9%|▉         | 726/8253 [23:47<4:06:29,  1.96s/it][A
  9%|▉         | 726/8253 [23:47<4:06:29,  1.96s/it][A
  9%|▉         | 727/8253 [23:49<4:11:05,  2.00s/it][A

  9%|▉         | 727/8253 [23:49<4:11:08,  2.00s/it][A  9%|▉         | 727/8253 [23:49<4:11:02,  2.00s/it][A
  9%|▉         | 727/8253 [23:49<4:11:21,  2.00s/it][A
  9%|▉         | 727/8253 [23:49<4:11:49,  2.01s/it][A
  9%|▉         | 727/8253 [23:49<4:11:59,  2.01s/it][A
  9%|▉         | 728/8253 [23:51<4:12:26,  2.01s/it][A
  9%|▉         | 728/8253 [23:51<4:12:46,  2.02s/it][A
  9%|▉         | 728/8253 [23:51<4:13:07,  2.02s/it][A
  9%|▉         | 728/8253 [23:51<4:13:09,  2.02s/it][A

  9%|▉         | 728/8253 [23:51<4:13:27,  2.02s/it][A  9%|▉         | 728/8253 [23:51<4:13:22,  2.02s/it][A
  9%|▉         | 729/8253 [23:53<4:10:27,  2.00s/it][A

  9%|▉         | 729/8253 [23:53<4:11:04,  2.00s/it][A  9%|▉         | 729/8253 [23:53<4:10:54,  2.00s/it][A
  9%|▉         | 729/8253 [23:53<4:11:07,  2.00s/it][A

  9%|▉         | 729/8253 [23:53<4:11:18,  2.00s/it][A  9%|▉         | 729/8253 [23:53<4:11:15,  2.00s/it][A
  9%|▉         | 730/8253 [23:55<4:09:02,  1.99s/it][A
  9%|▉         | 730/8253 [23:55<4:09:17,  1.99s/it][A
  9%|▉         | 730/8253 [23:55<4:09:11,  1.99s/it][A
  9%|▉         | 730/8253 [23:55<4:09:13,  1.99s/it][A

  9%|▉         | 730/8253 [23:55<4:09:15,  1.99s/it][A  9%|▉         | 730/8253 [23:55<4:09:19,  1.99s/it][A
  9%|▉         | 731/8253 [23:57<4:06:23,  1.97s/it][A
  9%|▉         | 731/8253 [23:57<4:07:00,  1.97s/it][A
  9%|▉         | 731/8253 [23:57<4:06:58,  1.97s/it][A
  9%|▉         | 731/8253 [23:57<4:07:10,  1.97s/it][A

  9%|▉         | 731/8253 [23:57<4:07:09,  1.97s/it][A  9%|▉         | 731/8253 [23:57<4:07:10,  1.97s/it][A

  9%|▉         | 732/8253 [23:59<4:08:36,  1.98s/it][A  9%|▉         | 732/8253 [23:59<4:08:37,  1.98s/it][A
  9%|▉         | 732/8253 [23:59<4:08:53,  1.99s/it][A
  9%|▉         | 732/8253 [23:59<4:08:45,  1.98s/it][A
  9%|▉         | 732/8253 [23:59<4:08:49,  1.99s/it][A
  9%|▉         | 732/8253 [23:59<4:09:11,  1.99s/it][A
  9%|▉         | 733/8253 [24:01<4:07:44,  1.98s/it][A
  9%|▉         | 733/8253 [24:01<4:08:05,  1.98s/it][A
  9%|▉         | 733/8253 [24:01<4:08:13,  1.98s/it][A
  9%|▉         | 733/8253 [24:01<4:08:22,  1.98s/it][A
  9%|▉         | 733/8253 [24:01<4:08:35,  1.98s/it][A
  9%|▉         | 733/8253 [24:01<4:08:31,  1.98s/it][A
  9%|▉         | 734/8253 [24:03<4:08:41,  1.98s/it][A
  9%|▉         | 734/8253 [24:03<4:08:35,  1.98s/it][A
  9%|▉         | 734/8253 [24:03<4:08:45,  1.99s/it][A
  9%|▉         | 734/8253 [24:03<4:08:59,  1.99s/it][A

  9%|▉         | 734/8253 [24:03<4:09:00,  1.99s/it][A  9%|▉         | 734/8253 [24:03<4:09:01,  1.99s/it][A
  9%|▉         | 735/8253 [24:04<4:06:37,  1.97s/it][A
  9%|▉         | 735/8253 [24:05<4:06:54,  1.97s/it][A
  9%|▉         | 735/8253 [24:05<4:06:58,  1.97s/it][A
  9%|▉         | 735/8253 [24:05<4:07:23,  1.97s/it][A
  9%|▉         | 735/8253 [24:05<4:07:18,  1.97s/it][A
  9%|▉         | 735/8253 [24:05<4:07:16,  1.97s/it][A
  9%|▉         | 736/8253 [24:07<4:07:14,  1.97s/it][A
  9%|▉         | 736/8253 [24:07<4:07:35,  1.98s/it][A
  9%|▉         | 736/8253 [24:07<4:07:37,  1.98s/it][A
  9%|▉         | 736/8253 [24:07<4:07:40,  1.98s/it][A

  9%|▉         | 736/8253 [24:06<4:08:04,  1.98s/it][A  9%|▉         | 736/8253 [24:07<4:07:48,  1.98s/it][A
  9%|▉         | 737/8253 [24:09<4:06:48,  1.97s/it][A
  9%|▉         | 737/8253 [24:09<4:07:06,  1.97s/it][A
  9%|▉         | 737/8253 [24:09<4:06:54,  1.97s/it][A
  9%|▉         | 737/8253 [24:09<4:07:01,  1.97s/it][A
  9%|▉         | 737/8253 [24:08<4:07:08,  1.97s/it][A
  9%|▉         | 737/8253 [24:09<4:07:02,  1.97s/it][A
  9%|▉         | 738/8253 [24:10<4:05:21,  1.96s/it][A
  9%|▉         | 738/8253 [24:10<4:05:13,  1.96s/it][A
  9%|▉         | 738/8253 [24:10<4:05:20,  1.96s/it][A
  9%|▉         | 738/8253 [24:10<4:05:16,  1.96s/it][A
  9%|▉         | 738/8253 [24:11<4:05:37,  1.96s/it][A
  9%|▉         | 738/8253 [24:11<4:06:02,  1.96s/it][A
  9%|▉         | 739/8253 [24:12<4:05:18,  1.96s/it][A
  9%|▉         | 739/8253 [24:12<4:05:33,  1.96s/it][A
  9%|▉         | 739/8253 [24:12<4:05:46,  1.96s/it][A
  9%|▉         | 739/8253 [24:12<4:05:49,  1.96s/it][A

  9%|▉         | 739/8253 [24:12<4:05:56,  1.96s/it][A  9%|▉         | 739/8253 [24:12<4:05:52,  1.96s/it][A
  9%|▉         | 740/8253 [24:14<4:05:24,  1.96s/it][A
  9%|▉         | 740/8253 [24:14<4:05:41,  1.96s/it][A
  9%|▉         | 740/8253 [24:14<4:06:01,  1.96s/it][A
  9%|▉         | 740/8253 [24:14<4:06:04,  1.97s/it][A
  9%|▉         | 740/8253 [24:14<4:06:12,  1.97s/it][A
  9%|▉         | 740/8253 [24:14<4:05:58,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:04:54,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:04:57,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:04:52,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:05:00,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:05:05,  1.96s/it][A
  9%|▉         | 741/8253 [24:16<4:05:19,  1.96s/it][A
  9%|▉         | 742/8253 [24:18<4:04:16,  1.95s/it][A
  9%|▉         | 742/8253 [24:18<4:04:27,  1.95s/it][A
  9%|▉         | 742/8253 [24:18<4:04:38,  1.95s/it][A
  9%|▉         | 742/8253 [24:18<4:04:41,  1.95s/it][A
  9%|▉         | 742/8253 [24:18<4:04:40,  1.95s/it][A
  9%|▉         | 742/8253 [24:18<4:04:50,  1.96s/it][A
  9%|▉         | 743/8253 [24:20<4:04:02,  1.95s/it][A
  9%|▉         | 743/8253 [24:20<4:04:30,  1.95s/it][A
  9%|▉         | 743/8253 [24:20<4:05:02,  1.96s/it][A
  9%|▉         | 743/8253 [24:20<4:04:57,  1.96s/it][A
  9%|▉         | 743/8253 [24:20<4:05:22,  1.96s/it][A
  9%|▉         | 743/8253 [24:20<4:05:19,  1.96s/it][A
  9%|▉         | 744/8253 [24:22<4:05:52,  1.96s/it][A
  9%|▉         | 744/8253 [24:22<4:05:43,  1.96s/it][A
  9%|▉         | 744/8253 [24:22<4:05:40,  1.96s/it][A
  9%|▉         | 744/8253 [24:22<4:05:53,  1.96s/it][A
  9%|▉         | 744/8253 [24:22<4:06:01,  1.97s/it][A
  9%|▉         | 744/8253 [24:22<4:06:12,  1.97s/it][A
  9%|▉         | 745/8253 [24:24<4:04:29,  1.95s/it][A

  9%|▉         | 745/8253 [24:24<4:04:42,  1.96s/it][A  9%|▉         | 745/8253 [24:24<4:04:40,  1.96s/it][A
  9%|▉         | 745/8253 [24:24<4:05:04,  1.96s/it][A
  9%|▉         | 745/8253 [24:24<4:04:52,  1.96s/it][A
  9%|▉         | 745/8253 [24:24<4:05:06,  1.96s/it][A
  9%|▉         | 746/8253 [24:26<4:02:36,  1.94s/it][A
  9%|▉         | 746/8253 [24:26<4:02:47,  1.94s/it][A
  9%|▉         | 746/8253 [24:26<4:02:40,  1.94s/it][A
  9%|▉         | 746/8253 [24:26<4:02:56,  1.94s/it][A
  9%|▉         | 746/8253 [24:26<4:02:55,  1.94s/it][A
  9%|▉         | 746/8253 [24:26<4:03:17,  1.94s/it][A
  9%|▉         | 747/8253 [24:28<4:03:22,  1.95s/it][A
  9%|▉         | 747/8253 [24:28<4:03:20,  1.95s/it][A
  9%|▉         | 747/8253 [24:28<4:03:25,  1.95s/it][A
  9%|▉         | 747/8253 [24:28<4:03:25,  1.95s/it][A
  9%|▉         | 747/8253 [24:28<4:03:37,  1.95s/it][A
  9%|▉         | 747/8253 [24:28<4:03:51,  1.95s/it][A
  9%|▉         | 748/8253 [24:30<4:05:47,  1.97s/it][A
  9%|▉         | 748/8253 [24:30<4:06:09,  1.97s/it][A
  9%|▉         | 748/8253 [24:30<4:06:15,  1.97s/it][A
  9%|▉         | 748/8253 [24:30<4:06:02,  1.97s/it][A
  9%|▉         | 748/8253 [24:30<4:06:07,  1.97s/it][A
  9%|▉         | 748/8253 [24:30<4:06:07,  1.97s/it][A
  9%|▉         | 749/8253 [24:32<4:06:16,  1.97s/it][A
  9%|▉         | 749/8253 [24:32<4:06:29,  1.97s/it][A
  9%|▉         | 749/8253 [24:32<4:06:29,  1.97s/it][A
  9%|▉         | 749/8253 [24:32<4:06:42,  1.97s/it][A

  9%|▉         | 749/8253 [24:32<4:06:34,  1.97s/it][A  9%|▉         | 749/8253 [24:32<4:06:41,  1.97s/it][A
  9%|▉         | 750/8253 [24:34<4:04:12,  1.95s/it][A
  9%|▉         | 750/8253 [24:34<4:04:44,  1.96s/it][A
  9%|▉         | 750/8253 [24:34<4:04:45,  1.96s/it][A
  9%|▉         | 750/8253 [24:34<4:04:42,  1.96s/it][A
  9%|▉         | 750/8253 [24:34<4:04:47,  1.96s/it][A
  9%|▉         | 750/8253 [24:34<4:04:58,  1.96s/it][A
  9%|▉         | 751/8253 [24:36<4:06:28,  1.97s/it][A
  9%|▉         | 751/8253 [24:36<4:07:02,  1.98s/it][A
  9%|▉         | 751/8253 [24:36<4:06:58,  1.98s/it][A
  9%|▉         | 751/8253 [24:36<4:07:16,  1.98s/it][A
  9%|▉         | 751/8253 [24:36<4:07:14,  1.98s/it][A
  9%|▉         | 751/8253 [24:36<4:07:23,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:15,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:11,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:29,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:28,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:43,  1.98s/it][A
  9%|▉         | 752/8253 [24:38<4:07:50,  1.98s/it][A
  9%|▉         | 753/8253 [24:40<4:06:39,  1.97s/it][A
  9%|▉         | 753/8253 [24:40<4:06:36,  1.97s/it][A
  9%|▉         | 753/8253 [24:40<4:06:38,  1.97s/it][A
  9%|▉         | 753/8253 [24:40<4:06:53,  1.98s/it][A
  9%|▉         | 753/8253 [24:40<4:06:43,  1.97s/it][A
  9%|▉         | 753/8253 [24:40<4:06:51,  1.97s/it][A
  9%|▉         | 754/8253 [24:42<4:05:31,  1.96s/it][A
  9%|▉         | 754/8253 [24:42<4:05:19,  1.96s/it][A
  9%|▉         | 754/8253 [24:42<4:05:13,  1.96s/it][A
  9%|▉         | 754/8253 [24:42<4:05:20,  1.96s/it][A

  9%|▉         | 754/8253 [24:42<4:05:32,  1.96s/it][A  9%|▉         | 754/8253 [24:42<4:05:17,  1.96s/it][A
  9%|▉         | 755/8253 [24:44<4:05:44,  1.97s/it][A

  9%|▉         | 755/8253 [24:44<4:05:40,  1.97s/it][A  9%|▉         | 755/8253 [24:44<4:05:42,  1.97s/it][A
  9%|▉         | 755/8253 [24:44<4:05:55,  1.97s/it][A

  9%|▉         | 755/8253 [24:44<4:06:18,  1.97s/it][A  9%|▉         | 755/8253 [24:44<4:05:58,  1.97s/it][A
  9%|▉         | 756/8253 [24:46<4:06:57,  1.98s/it][A
  9%|▉         | 756/8253 [24:46<4:06:43,  1.97s/it][A
  9%|▉         | 756/8253 [24:46<4:06:59,  1.98s/it][A
  9%|▉         | 756/8253 [24:46<4:07:00,  1.98s/it][A
  9%|▉         | 756/8253 [24:46<4:07:12,  1.98s/it][A
  9%|▉         | 756/8253 [24:46<4:07:22,  1.98s/it][A
  9%|▉         | 757/8253 [24:48<4:05:46,  1.97s/it][A
  9%|▉         | 757/8253 [24:48<4:05:54,  1.97s/it][A
  9%|▉         | 757/8253 [24:48<4:06:05,  1.97s/it][A
  9%|▉         | 757/8253 [24:48<4:06:12,  1.97s/it][A
  9%|▉         | 757/8253 [24:48<4:06:03,  1.97s/it][A
  9%|▉         | 757/8253 [24:48<4:06:24,  1.97s/it][A
  9%|▉         | 758/8253 [24:50<4:13:17,  2.03s/it][A
  9%|▉         | 758/8253 [24:50<4:13:28,  2.03s/it][A
  9%|▉         | 758/8253 [24:50<4:13:42,  2.03s/it][A
  9%|▉         | 758/8253 [24:50<4:13:39,  2.03s/it][A
  9%|▉         | 758/8253 [24:50<4:13:49,  2.03s/it][A
  9%|▉         | 758/8253 [24:50<4:13:46,  2.03s/it][A
  9%|▉         | 759/8253 [24:52<4:10:56,  2.01s/it][A
  9%|▉         | 759/8253 [24:52<4:11:05,  2.01s/it][A
  9%|▉         | 759/8253 [24:52<4:11:00,  2.01s/it][A
  9%|▉         | 759/8253 [24:52<4:11:23,  2.01s/it][A

  9%|▉         | 759/8253 [24:52<4:11:10,  2.01s/it][A  9%|▉         | 759/8253 [24:52<4:11:15,  2.01s/it][A
  9%|▉         | 760/8253 [24:54<4:08:30,  1.99s/it][A
  9%|▉         | 760/8253 [24:54<4:08:43,  1.99s/it][A
  9%|▉         | 760/8253 [24:54<4:08:40,  1.99s/it][A
  9%|▉         | 760/8253 [24:54<4:08:42,  1.99s/it][A
  9%|▉         | 760/8253 [24:54<4:08:57,  1.99s/it][A
  9%|▉         | 760/8253 [24:54<4:09:04,  1.99s/it][A
  9%|▉         | 761/8253 [24:56<4:04:41,  1.96s/it][A
  9%|▉         | 761/8253 [24:56<4:04:54,  1.96s/it][A


  9%|▉         | 761/8253 [24:56<4:05:06,  1.96s/it][A  9%|▉         | 761/8253 [24:56<4:05:00,  1.96s/it][A  9%|▉         | 761/8253 [24:56<4:05:11,  1.96s/it][A
  9%|▉         | 761/8253 [24:56<4:05:05,  1.96s/it][A
  9%|▉         | 762/8253 [24:58<4:05:27,  1.97s/it][A
  9%|▉         | 762/8253 [24:58<4:05:40,  1.97s/it][A
  9%|▉         | 762/8253 [24:58<4:05:43,  1.97s/it][A
  9%|▉         | 762/8253 [24:58<4:06:06,  1.97s/it][A

  9%|▉         | 762/8253 [24:58<4:06:00,  1.97s/it][A  9%|▉         | 762/8253 [24:58<4:05:53,  1.97s/it][A
  9%|▉         | 763/8253 [25:00<4:05:03,  1.96s/it][A
  9%|▉         | 763/8253 [25:00<4:05:19,  1.97s/it][A
  9%|▉         | 763/8253 [25:00<4:05:15,  1.96s/it][A
  9%|▉         | 763/8253 [25:00<4:05:21,  1.97s/it][A

  9%|▉         | 763/8253 [25:00<4:05:31,  1.97s/it][A  9%|▉         | 763/8253 [25:00<4:05:21,  1.97s/it][A
  9%|▉         | 764/8253 [25:02<4:04:09,  1.96s/it][A
  9%|▉         | 764/8253 [25:02<4:04:22,  1.96s/it][A
  9%|▉         | 764/8253 [25:02<4:04:20,  1.96s/it][A
  9%|▉         | 764/8253 [25:02<4:04:42,  1.96s/it][A

  9%|▉         | 764/8253 [25:02<4:04:51,  1.96s/it][A  9%|▉         | 764/8253 [25:02<4:04:48,  1.96s/it][A
  9%|▉         | 765/8253 [25:04<4:02:54,  1.95s/it][A
  9%|▉         | 765/8253 [25:04<4:03:05,  1.95s/it][A
  9%|▉         | 765/8253 [25:04<4:03:12,  1.95s/it][A
  9%|▉         | 765/8253 [25:04<4:03:14,  1.95s/it][A
  9%|▉         | 765/8253 [25:03<4:03:25,  1.95s/it][A
  9%|▉         | 765/8253 [25:04<4:03:26,  1.95s/it][A
  9%|▉         | 766/8253 [25:06<4:05:06,  1.96s/it][A
  9%|▉         | 766/8253 [25:06<4:05:19,  1.97s/it][A
  9%|▉         | 766/8253 [25:06<4:05:30,  1.97s/it][A
  9%|▉         | 766/8253 [25:06<4:05:32,  1.97s/it][A

  9%|▉         | 766/8253 [25:05<4:05:44,  1.97s/it][A  9%|▉         | 766/8253 [25:06<4:05:50,  1.97s/it][A
  9%|▉         | 767/8253 [25:08<4:05:31,  1.97s/it][A
  9%|▉         | 767/8253 [25:08<4:05:46,  1.97s/it][A
  9%|▉         | 767/8253 [25:08<4:06:01,  1.97s/it][A
  9%|▉         | 767/8253 [25:07<4:05:56,  1.97s/it][A
  9%|▉         | 767/8253 [25:08<4:05:55,  1.97s/it][A
  9%|▉         | 767/8253 [25:08<4:06:02,  1.97s/it][A
  9%|▉         | 768/8253 [25:10<4:06:21,  1.97s/it][A
  9%|▉         | 768/8253 [25:10<4:06:26,  1.98s/it][A
  9%|▉         | 768/8253 [25:10<4:06:38,  1.98s/it][A
  9%|▉         | 768/8253 [25:09<4:06:44,  1.98s/it][A

  9%|▉         | 768/8253 [25:10<4:06:50,  1.98s/it][A  9%|▉         | 768/8253 [25:10<4:06:52,  1.98s/it][A
  9%|▉         | 769/8253 [25:12<4:07:10,  1.98s/it][A
  9%|▉         | 769/8253 [25:11<4:07:19,  1.98s/it][A
  9%|▉         | 769/8253 [25:12<4:07:23,  1.98s/it][A
  9%|▉         | 769/8253 [25:12<4:07:28,  1.98s/it][A
  9%|▉         | 769/8253 [25:12<4:07:36,  1.99s/it][A
  9%|▉         | 769/8253 [25:12<4:07:42,  1.99s/it][A
  9%|▉         | 770/8253 [25:14<4:06:04,  1.97s/it][A
  9%|▉         | 770/8253 [25:14<4:05:57,  1.97s/it][A
  9%|▉         | 770/8253 [25:14<4:06:12,  1.97s/it][A
  9%|▉         | 770/8253 [25:13<4:06:15,  1.97s/it][A
  9%|▉         | 770/8253 [25:14<4:06:34,  1.98s/it][A
  9%|▉         | 770/8253 [25:14<4:06:37,  1.98s/it][A
  9%|▉         | 771/8253 [25:16<4:07:20,  1.98s/it][A
  9%|▉         | 771/8253 [25:16<4:07:06,  1.98s/it][A
  9%|▉         | 771/8253 [25:16<4:07:21,  1.98s/it][A
  9%|▉         | 771/8253 [25:16<4:07:19,  1.98s/it][A
  9%|▉         | 771/8253 [25:15<4:07:29,  1.98s/it][A
  9%|▉         | 771/8253 [25:16<4:07:34,  1.99s/it][A
  9%|▉         | 772/8253 [25:18<4:07:19,  1.98s/it][A
  9%|▉         | 772/8253 [25:18<4:07:11,  1.98s/it][A
  9%|▉         | 772/8253 [25:17<4:07:16,  1.98s/it][A
  9%|▉         | 772/8253 [25:18<4:07:20,  1.98s/it][A
  9%|▉         | 772/8253 [25:18<4:07:30,  1.99s/it][A
  9%|▉         | 772/8253 [25:18<4:07:38,  1.99s/it][A
  9%|▉         | 773/8253 [25:19<4:05:59,  1.97s/it][A
  9%|▉         | 773/8253 [25:19<4:06:18,  1.98s/it][A
  9%|▉         | 773/8253 [25:19<4:06:14,  1.98s/it][A
  9%|▉         | 773/8253 [25:19<4:06:16,  1.98s/it][A
  9%|▉         | 773/8253 [25:19<4:06:28,  1.98s/it]
[A  9%|▉         | 773/8253 [25:19<4:06:29,  1.98s/it][A
  9%|▉         | 774/8253 [25:21<4:03:06,  1.95s/it][A
  9%|▉         | 774/8253 [25:21<4:03:39,  1.95s/it][A
  9%|▉         | 774/8253 [25:21<4:03:29,  1.95s/it][A
  9%|▉         | 774/8253 [25:21<4:03:33,  1.95s/it][A
  9%|▉         | 774/8253 [25:21<4:03:39,  1.95s/it][A
  9%|▉         | 774/8253 [25:21<4:03:47,  1.96s/it][A
  9%|▉         | 775/8253 [25:23<4:04:57,  1.97s/it][A
  9%|▉         | 775/8253 [25:23<4:05:14,  1.97s/it][A
  9%|▉         | 775/8253 [25:23<4:05:17,  1.97s/it][A
  9%|▉         | 775/8253 [25:23<4:05:22,  1.97s/it][A
  9%|▉         | 775/8253 [25:23<4:05:28,  1.97s/it][A
  9%|▉         | 775/8253 [25:23<4:05:42,  1.97s/it][A
  9%|▉         | 776/8253 [25:25<4:04:04,  1.96s/it][A
  9%|▉         | 776/8253 [25:25<4:04:03,  1.96s/it][A
  9%|▉         | 776/8253 [25:25<4:04:04,  1.96s/it][A
  9%|▉         | 776/8253 [25:25<4:04:12,  1.96s/it]
[A  9%|▉         | 776/8253 [25:25<4:04:10,  1.96s/it][A
  9%|▉         | 776/8253 [25:25<4:04:14,  1.96s/it][A
  9%|▉         | 777/8253 [25:27<4:03:02,  1.95s/it][A
  9%|▉         | 777/8253 [25:27<4:03:31,  1.95s/it][A
  9%|▉         | 777/8253 [25:27<4:03:43,  1.96s/it][A
  9%|▉         | 777/8253 [25:27<4:03:42,  1.96s/it][A
  9%|▉         | 777/8253 [25:27<4:03:48,  1.96s/it][A
  9%|▉         | 777/8253 [25:27<4:04:00,  1.96s/it][A
  9%|▉         | 778/8253 [25:29<4:02:56,  1.95s/it][A
  9%|▉         | 778/8253 [25:29<4:03:04,  1.95s/it][A
  9%|▉         | 778/8253 [25:29<4:03:13,  1.95s/it][A
  9%|▉         | 778/8253 [25:29<4:03:15,  1.95s/it][A
  9%|▉         | 778/8253 [25:29<4:03:14,  1.95s/it][A
  9%|▉         | 778/8253 [25:29<4:03:17,  1.95s/it][A

  9%|▉         | 779/8253 [25:31<4:01:56,  1.94s/it][A  9%|▉         | 779/8253 [25:31<4:02:09,  1.94s/it][A
  9%|▉         | 779/8253 [25:31<4:02:08,  1.94s/it][A
  9%|▉         | 779/8253 [25:31<4:01:54,  1.94s/it][A
  9%|▉         | 779/8253 [25:31<4:01:58,  1.94s/it][A
  9%|▉         | 779/8253 [25:31<4:02:15,  1.94s/it][A
  9%|▉         | 780/8253 [25:33<4:01:59,  1.94s/it][A
  9%|▉         | 780/8253 [25:33<4:02:01,  1.94s/it][A
  9%|▉         | 780/8253 [25:33<4:02:49,  1.95s/it][A
  9%|▉         | 780/8253 [25:33<4:02:36,  1.95s/it][A
  9%|▉         | 780/8253 [25:33<4:02:45,  1.95s/it][A
  9%|▉         | 780/8253 [25:33<4:02:45,  1.95s/it][A
  9%|▉         | 781/8253 [25:35<4:03:18,  1.95s/it][A
  9%|▉         | 781/8253 [25:35<4:03:25,  1.95s/it][A
  9%|▉         | 781/8253 [25:35<4:03:29,  1.96s/it][A
  9%|▉         | 781/8253 [25:35<4:03:42,  1.96s/it][A
  9%|▉         | 781/8253 [25:35<4:03:46,  1.96s/it][A
  9%|▉         | 781/8253 [25:35<4:03:43,  1.96s/it][A
  9%|▉         | 782/8253 [25:37<4:02:15,  1.95s/it][A

  9%|▉         | 782/8253 [25:37<4:02:25,  1.95s/it][A  9%|▉         | 782/8253 [25:37<4:02:53,  1.95s/it][A
  9%|▉         | 782/8253 [25:37<4:02:34,  1.95s/it][A
  9%|▉         | 782/8253 [25:37<4:02:47,  1.95s/it][A
  9%|▉         | 782/8253 [25:37<4:02:45,  1.95s/it][A

  9%|▉         | 783/8253 [25:39<4:04:50,  1.97s/it][A  9%|▉         | 783/8253 [25:39<4:05:08,  1.97s/it][A
  9%|▉         | 783/8253 [25:39<4:05:20,  1.97s/it][A
  9%|▉         | 783/8253 [25:39<4:05:23,  1.97s/it][A
  9%|▉         | 783/8253 [25:39<4:05:28,  1.97s/it][A
  9%|▉         | 783/8253 [25:39<4:05:34,  1.97s/it][A
  9%|▉         | 784/8253 [25:41<4:06:26,  1.98s/it][A
  9%|▉         | 784/8253 [25:41<4:06:50,  1.98s/it][A
  9%|▉         | 784/8253 [25:41<4:06:57,  1.98s/it][A
  9%|▉         | 784/8253 [25:41<4:06:49,  1.98s/it][A

  9%|▉         | 784/8253 [25:41<4:07:08,  1.99s/it][A  9%|▉         | 784/8253 [25:41<4:07:14,  1.99s/it][A

 10%|▉         | 785/8253 [25:43<4:03:24,  1.96s/it] 10%|▉         | 785/8253 [25:43<4:03:06,  1.95s/it][A[A
 10%|▉         | 785/8253 [25:43<4:03:18,  1.95s/it][A
 10%|▉         | 785/8253 [25:43<4:03:29,  1.96s/it][A
 10%|▉         | 785/8253 [25:43<4:03:51,  1.96s/it][A
 10%|▉         | 785/8253 [25:43<4:03:50,  1.96s/it][A
 10%|▉         | 786/8253 [25:45<4:02:08,  1.95s/it][A
 10%|▉         | 786/8253 [25:45<4:01:57,  1.94s/it][A

 10%|▉         | 786/8253 [25:45<4:02:01,  1.94s/it][A 10%|▉         | 786/8253 [25:45<4:01:50,  1.94s/it][A
 10%|▉         | 786/8253 [25:45<4:02:09,  1.95s/it][A
 10%|▉         | 786/8253 [25:45<4:02:14,  1.95s/it][A
 10%|▉         | 787/8253 [25:47<4:01:58,  1.94s/it][A
 10%|▉         | 787/8253 [25:47<4:02:31,  1.95s/it][A
 10%|▉         | 787/8253 [25:47<4:02:47,  1.95s/it][A

 10%|▉         | 787/8253 [25:47<4:02:30,  1.95s/it][A 10%|▉         | 787/8253 [25:47<4:02:44,  1.95s/it][A
 10%|▉         | 787/8253 [25:47<4:02:47,  1.95s/it][A
 10%|▉         | 788/8253 [25:49<4:00:58,  1.94s/it][A
 10%|▉         | 788/8253 [25:49<4:00:50,  1.94s/it][A
 10%|▉         | 788/8253 [25:49<4:01:08,  1.94s/it][A
 10%|▉         | 788/8253 [25:49<4:01:20,  1.94s/it][A
 10%|▉         | 788/8253 [25:49<4:01:26,  1.94s/it][A
 10%|▉         | 788/8253 [25:49<4:01:28,  1.94s/it][A
 10%|▉         | 789/8253 [25:51<4:02:34,  1.95s/it][A
 10%|▉         | 789/8253 [25:51<4:02:38,  1.95s/it][A
 10%|▉         | 789/8253 [25:51<4:02:37,  1.95s/it][A
 10%|▉         | 789/8253 [25:51<4:02:49,  1.95s/it][A
 10%|▉         | 789/8253 [25:51<4:03:09,  1.95s/it][A
 10%|▉         | 789/8253 [25:51<4:03:11,  1.95s/it][A

 10%|▉         | 790/8253 [25:53<4:04:05,  1.96s/it][A 10%|▉         | 790/8253 [25:53<4:03:59,  1.96s/it][A
 10%|▉         | 790/8253 [25:53<4:04:21,  1.96s/it][A


 10%|▉         | 790/8253 [25:53<4:04:27,  1.97s/it][A 10%|▉         | 790/8253 [25:53<4:04:27,  1.97s/it][A 10%|▉         | 790/8253 [25:53<4:04:46,  1.97s/it][A
 10%|▉         | 791/8253 [25:55<4:02:52,  1.95s/it][A
 10%|▉         | 791/8253 [25:55<4:03:26,  1.96s/it][A
 10%|▉         | 791/8253 [25:55<4:03:41,  1.96s/it][A
 10%|▉         | 791/8253 [25:55<4:03:43,  1.96s/it][A
 10%|▉         | 791/8253 [25:55<4:03:53,  1.96s/it][A
 10%|▉         | 791/8253 [25:55<4:03:49,  1.96s/it][A
 10%|▉         | 792/8253 [25:57<4:05:00,  1.97s/it][A
 10%|▉         | 792/8253 [25:57<4:05:03,  1.97s/it][A
 10%|▉         | 792/8253 [25:57<4:04:58,  1.97s/it][A
 10%|▉         | 792/8253 [25:57<4:05:11,  1.97s/it][A
 10%|▉         | 792/8253 [25:57<4:05:07,  1.97s/it][A
 10%|▉         | 792/8253 [25:57<4:05:15,  1.97s/it][A
 10%|▉         | 793/8253 [25:59<4:03:44,  1.96s/it][A
 10%|▉         | 793/8253 [25:58<4:03:50,  1.96s/it][A
 10%|▉         | 793/8253 [25:59<4:04:12,  1.96s/it][A
 10%|▉         | 793/8253 [25:59<4:04:11,  1.96s/it][A
 10%|▉         | 793/8253 [25:59<4:04:11,  1.96s/it][A
 10%|▉         | 793/8253 [25:59<4:04:27,  1.97s/it][A
 10%|▉         | 794/8253 [26:01<4:04:22,  1.97s/it][A
 10%|▉         | 794/8253 [26:00<4:04:44,  1.97s/it][A
 10%|▉         | 794/8253 [26:01<4:04:39,  1.97s/it][A
 10%|▉         | 794/8253 [26:01<4:04:48,  1.97s/it][A
 10%|▉         | 794/8253 [26:01<4:05:02,  1.97s/it][A
 10%|▉         | 794/8253 [26:01<4:04:54,  1.97s/it][A
 10%|▉         | 795/8253 [26:03<4:06:05,  1.98s/it][A
 10%|▉         | 795/8253 [26:03<4:05:52,  1.98s/it][A
 10%|▉         | 795/8253 [26:03<4:06:09,  1.98s/it][A
 10%|▉         | 795/8253 [26:03<4:06:08,  1.98s/it][A
 10%|▉         | 795/8253 [26:03<4:06:22,  1.98s/it][A
 10%|▉         | 795/8253 [26:02<4:06:40,  1.98s/it][A
 10%|▉         | 796/8253 [26:05<4:06:16,  1.98s/it][A
 10%|▉         | 796/8253 [26:05<4:06:13,  1.98s/it][A
 10%|▉         | 796/8253 [26:05<4:06:23,  1.98s/it][A
 10%|▉         | 796/8253 [26:05<4:06:23,  1.98s/it][A
 10%|▉         | 796/8253 [26:04<4:06:29,  1.98s/it][A
 10%|▉         | 796/8253 [26:05<4:06:31,  1.98s/it][A


 10%|▉         | 797/8253 [26:06<4:04:49,  1.97s/it][A 10%|▉         | 797/8253 [26:07<4:05:19,  1.97s/it][A 10%|▉         | 797/8253 [26:07<4:04:56,  1.97s/it][A
 10%|▉         | 797/8253 [26:07<4:05:11,  1.97s/it][A
 10%|▉         | 797/8253 [26:07<4:05:26,  1.98s/it][A
 10%|▉         | 797/8253 [26:07<4:05:20,  1.97s/it][A
 10%|▉         | 798/8253 [26:08<4:04:49,  1.97s/it][A
 10%|▉         | 798/8253 [26:09<4:05:12,  1.97s/it][A
 10%|▉         | 798/8253 [26:09<4:05:16,  1.97s/it][A
 10%|▉         | 798/8253 [26:09<4:05:16,  1.97s/it][A
 10%|▉         | 798/8253 [26:09<4:05:50,  1.98s/it][A
 10%|▉         | 798/8253 [26:09<4:05:23,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:09,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:13,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:11,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:14,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:34,  1.97s/it][A
 10%|▉         | 799/8253 [26:10<4:04:20,  1.97s/it][A
 10%|▉         | 800/8253 [26:12<4:03:02,  1.96s/it][A
 10%|▉         | 800/8253 [26:12<4:03:13,  1.96s/it][A
 10%|▉         | 800/8253 [26:12<4:03:07,  1.96s/it][A
 10%|▉         | 800/8253 [26:12<4:03:24,  1.96s/it][A

 10%|▉         | 800/8253 [26:12<4:03:37,  1.96s/it][A 10%|▉         | 800/8253 [26:12<4:03:14,  1.96s/it][A
 10%|▉         | 801/8253 [26:14<4:05:29,  1.98s/it][A
 10%|▉         | 801/8253 [26:14<4:05:27,  1.98s/it][A
 10%|▉         | 801/8253 [26:14<4:05:22,  1.98s/it][A
 10%|▉         | 801/8253 [26:14<4:05:49,  1.98s/it][A
 10%|▉         | 801/8253 [26:14<4:05:48,  1.98s/it][A
 10%|▉         | 801/8253 [26:14<4:05:51,  1.98s/it][A
 10%|▉         | 802/8253 [26:16<4:03:48,  1.96s/it][A
 10%|▉         | 802/8253 [26:16<4:04:14,  1.97s/it][A


 10%|▉         | 802/8253 [26:16<4:04:19,  1.97s/it] 10%|▉         | 802/8253 [26:16<4:04:10,  1.97s/it][A[A 10%|▉         | 802/8253 [26:16<4:03:58,  1.96s/it][A
 10%|▉         | 802/8253 [26:16<4:04:00,  1.96s/it][A
 10%|▉         | 803/8253 [26:18<4:04:09,  1.97s/it][A
 10%|▉         | 803/8253 [26:18<4:04:10,  1.97s/it][A
 10%|▉         | 803/8253 [26:18<4:04:28,  1.97s/it][A
 10%|▉         | 803/8253 [26:18<4:04:35,  1.97s/it][A
 10%|▉         | 803/8253 [26:18<4:04:26,  1.97s/it][A
 10%|▉         | 803/8253 [26:18<4:04:58,  1.97s/it][A
 10%|▉         | 804/8253 [26:20<4:05:20,  1.98s/it][A

 10%|▉         | 804/8253 [26:20<4:05:01,  1.97s/it][A 10%|▉         | 804/8253 [26:20<4:05:13,  1.98s/it][A
 10%|▉         | 804/8253 [26:20<4:05:18,  1.98s/it][A
 10%|▉         | 804/8253 [26:20<4:05:11,  1.97s/it][A
 10%|▉         | 804/8253 [26:20<4:05:32,  1.98s/it][A
 10%|▉         | 805/8253 [26:22<4:02:05,  1.95s/it][A
 10%|▉         | 805/8253 [26:22<4:02:10,  1.95s/it][A
 10%|▉         | 805/8253 [26:22<4:02:27,  1.95s/it][A
 10%|▉         | 805/8253 [26:22<4:02:37,  1.95s/it][A
 10%|▉         | 805/8253 [26:22<4:02:34,  1.95s/it][A
 10%|▉         | 805/8253 [26:22<4:02:39,  1.95s/it][A
 10%|▉         | 806/8253 [26:24<4:02:46,  1.96s/it][A
 10%|▉         | 806/8253 [26:24<4:02:54,  1.96s/it][A
 10%|▉         | 806/8253 [26:24<4:03:16,  1.96s/it][A
 10%|▉         | 806/8253 [26:24<4:03:15,  1.96s/it][A
 10%|▉         | 806/8253 [26:24<4:03:22,  1.96s/it][A
 10%|▉         | 806/8253 [26:24<4:03:29,  1.96s/it][A
 10%|▉         | 807/8253 [26:26<4:02:38,  1.96s/it][A

 10%|▉         | 807/8253 [26:26<4:03:08,  1.96s/it][A 10%|▉         | 807/8253 [26:26<4:03:18,  1.96s/it][A
 10%|▉         | 807/8253 [26:26<4:03:06,  1.96s/it][A
 10%|▉         | 807/8253 [26:26<4:03:11,  1.96s/it][A
 10%|▉         | 807/8253 [26:26<4:03:14,  1.96s/it][A

 10%|▉         | 808/8253 [26:28<4:02:15,  1.95s/it][A 10%|▉         | 808/8253 [26:28<4:02:26,  1.95s/it][A
 10%|▉         | 808/8253 [26:28<4:02:36,  1.96s/it][A
 10%|▉         | 808/8253 [26:28<4:02:26,  1.95s/it][A
 10%|▉         | 808/8253 [26:28<4:02:41,  1.96s/it][A
 10%|▉         | 808/8253 [26:28<4:02:42,  1.96s/it][A
 10%|▉         | 809/8253 [26:30<4:04:40,  1.97s/it][A
 10%|▉         | 809/8253 [26:30<4:05:06,  1.98s/it][A
 10%|▉         | 809/8253 [26:30<4:05:08,  1.98s/it][A
 10%|▉         | 809/8253 [26:30<4:05:06,  1.98s/it][A

 10%|▉         | 809/8253 [26:30<4:05:09,  1.98s/it][A 10%|▉         | 809/8253 [26:30<4:05:17,  1.98s/it][A
 10%|▉         | 810/8253 [26:32<4:04:17,  1.97s/it][A
 10%|▉         | 810/8253 [26:32<4:04:17,  1.97s/it][A
 10%|▉         | 810/8253 [26:32<4:04:25,  1.97s/it][A
 10%|▉         | 810/8253 [26:32<4:04:55,  1.97s/it][A
 10%|▉         | 810/8253 [26:32<4:05:06,  1.98s/it][A
 10%|▉         | 810/8253 [26:32<4:04:50,  1.97s/it][A
 10%|▉         | 811/8253 [26:34<4:02:01,  1.95s/it][A
 10%|▉         | 811/8253 [26:34<4:02:37,  1.96s/it][A
 10%|▉         | 811/8253 [26:34<4:02:47,  1.96s/it][A

 10%|▉         | 811/8253 [26:34<4:02:48,  1.96s/it][A 10%|▉         | 811/8253 [26:34<4:02:46,  1.96s/it][A
 10%|▉         | 811/8253 [26:34<4:02:35,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:02:54,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:02:54,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:03:02,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:03:16,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:02:58,  1.96s/it][A
 10%|▉         | 812/8253 [26:36<4:03:18,  1.96s/it][A
 10%|▉         | 813/8253 [26:38<4:02:00,  1.95s/it][A
 10%|▉         | 813/8253 [26:38<4:02:15,  1.95s/it][A
 10%|▉         | 813/8253 [26:38<4:02:18,  1.95s/it][A
 10%|▉         | 813/8253 [26:38<4:02:16,  1.95s/it][A

 10%|▉         | 813/8253 [26:38<4:02:28,  1.96s/it][A 10%|▉         | 813/8253 [26:38<4:02:16,  1.95s/it][A
 10%|▉         | 814/8253 [26:40<4:04:44,  1.97s/it][A
 10%|▉         | 814/8253 [26:40<4:04:54,  1.98s/it][A


 10%|▉         | 814/8253 [26:40<4:05:19,  1.98s/it][A 10%|▉         | 814/8253 [26:40<4:05:15,  1.98s/it][A 10%|▉         | 814/8253 [26:40<4:05:10,  1.98s/it][A
 10%|▉         | 814/8253 [26:40<4:05:34,  1.98s/it][A
 10%|▉         | 815/8253 [26:42<4:04:50,  1.98s/it][A
 10%|▉         | 815/8253 [26:42<4:04:47,  1.97s/it][A
 10%|▉         | 815/8253 [26:42<4:05:02,  1.98s/it][A
 10%|▉         | 815/8253 [26:42<4:05:00,  1.98s/it][A
 10%|▉         | 815/8253 [26:42<4:05:11,  1.98s/it][A
 10%|▉         | 815/8253 [26:42<4:05:14,  1.98s/it][A
 10%|▉         | 816/8253 [26:44<4:04:46,  1.97s/it][A
 10%|▉         | 816/8253 [26:44<4:04:46,  1.97s/it][A
 10%|▉         | 816/8253 [26:44<4:05:05,  1.98s/it][A
 10%|▉         | 816/8253 [26:44<4:05:11,  1.98s/it][A

 10%|▉         | 816/8253 [26:44<4:05:02,  1.98s/it][A 10%|▉         | 816/8253 [26:44<4:05:02,  1.98s/it][A
 10%|▉         | 817/8253 [26:46<4:01:43,  1.95s/it][A
 10%|▉         | 817/8253 [26:46<4:02:02,  1.95s/it][A
 10%|▉         | 817/8253 [26:46<4:02:11,  1.95s/it][A
 10%|▉         | 817/8253 [26:46<4:02:07,  1.95s/it][A
 10%|▉         | 817/8253 [26:46<4:02:14,  1.95s/it][A
 10%|▉         | 817/8253 [26:46<4:02:17,  1.96s/it][A
 10%|▉         | 818/8253 [26:48<4:02:58,  1.96s/it][A
 10%|▉         | 818/8253 [26:48<4:02:59,  1.96s/it][A

 10%|▉         | 818/8253 [26:48<4:03:12,  1.96s/it][A 10%|▉         | 818/8253 [26:48<4:03:11,  1.96s/it][A
 10%|▉         | 818/8253 [26:48<4:03:26,  1.96s/it][A
 10%|▉         | 818/8253 [26:48<4:03:27,  1.96s/it][A
 10%|▉         | 819/8253 [26:50<4:02:22,  1.96s/it][A
 10%|▉         | 819/8253 [26:50<4:02:31,  1.96s/it][A

 10%|▉         | 819/8253 [26:50<4:02:36,  1.96s/it][A 10%|▉         | 819/8253 [26:50<4:02:31,  1.96s/it][A
 10%|▉         | 819/8253 [26:50<4:02:53,  1.96s/it][A
 10%|▉         | 819/8253 [26:50<4:03:00,  1.96s/it][A
 10%|▉         | 820/8253 [26:52<4:08:59,  2.01s/it][A
 10%|▉         | 820/8253 [26:52<4:09:06,  2.01s/it][A
 10%|▉         | 820/8253 [26:52<4:09:16,  2.01s/it][A
 10%|▉         | 820/8253 [26:52<4:09:19,  2.01s/it][A
 10%|▉         | 820/8253 [26:52<4:09:30,  2.01s/it][A
 10%|▉         | 820/8253 [26:52<4:09:26,  2.01s/it][A
 10%|▉         | 821/8253 [26:54<4:06:49,  1.99s/it][A
 10%|▉         | 821/8253 [26:54<4:07:11,  2.00s/it][A

 10%|▉         | 821/8253 [26:54<4:07:11,  2.00s/it][A 10%|▉         | 821/8253 [26:54<4:07:16,  2.00s/it][A
 10%|▉         | 821/8253 [26:54<4:07:21,  2.00s/it][A
 10%|▉         | 821/8253 [26:54<4:07:31,  2.00s/it][A
 10%|▉         | 822/8253 [26:56<4:06:41,  1.99s/it][A
 10%|▉         | 822/8253 [26:56<4:06:43,  1.99s/it][A
 10%|▉         | 822/8253 [26:56<4:06:47,  1.99s/it][A
 10%|▉         | 822/8253 [26:56<4:07:14,  2.00s/it][A
 10%|▉         | 822/8253 [26:56<4:06:56,  1.99s/it][A
 10%|▉         | 822/8253 [26:56<4:07:04,  1.99s/it][A
 10%|▉         | 823/8253 [26:58<4:06:03,  1.99s/it][A
 10%|▉         | 823/8253 [26:58<4:06:15,  1.99s/it][A
 10%|▉         | 823/8253 [26:58<4:06:18,  1.99s/it][A
 10%|▉         | 823/8253 [26:58<4:06:29,  1.99s/it][A

 10%|▉         | 823/8253 [26:58<4:06:36,  1.99s/it][A 10%|▉         | 823/8253 [26:58<4:06:39,  1.99s/it][A
 10%|▉         | 824/8253 [27:00<4:04:29,  1.97s/it][A
 10%|▉         | 824/8253 [27:00<4:04:12,  1.97s/it][A
 10%|▉         | 824/8253 [27:00<4:04:20,  1.97s/it][A
 10%|▉         | 824/8253 [27:00<4:04:12,  1.97s/it][A
 10%|▉         | 824/8253 [27:00<4:04:20,  1.97s/it][A
 10%|▉         | 824/8253 [27:00<4:04:43,  1.98s/it][A
 10%|▉         | 825/8253 [27:02<4:02:03,  1.96s/it][A
 10%|▉         | 825/8253 [27:02<4:02:00,  1.95s/it][A
 10%|▉         | 825/8253 [27:02<4:02:21,  1.96s/it][A
 10%|▉         | 825/8253 [27:02<4:02:19,  1.96s/it][A
 10%|▉         | 825/8253 [27:02<4:02:19,  1.96s/it][A
 10%|▉         | 825/8253 [27:02<4:02:34,  1.96s/it][A
 10%|█         | 826/8253 [27:04<4:03:21,  1.97s/it][A
 10%|█         | 826/8253 [27:04<4:03:24,  1.97s/it][A
 10%|█         | 826/8253 [27:04<4:03:17,  1.97s/it][A
 10%|█         | 826/8253 [27:04<4:03:27,  1.97s/it][A

 10%|█         | 826/8253 [27:04<4:03:35,  1.97s/it] 10%|█         | 826/8253 [27:04<4:03:40,  1.97s/it][A[A
 10%|█         | 827/8253 [27:06<4:03:01,  1.96s/it][A
 10%|█         | 827/8253 [27:06<4:03:20,  1.97s/it][A
 10%|█         | 827/8253 [27:06<4:03:31,  1.97s/it][A
 10%|█         | 827/8253 [27:05<4:03:23,  1.97s/it][A
 10%|█         | 827/8253 [27:06<4:03:53,  1.97s/it][A
 10%|█         | 827/8253 [27:06<4:03:29,  1.97s/it][A
 10%|█         | 828/8253 [27:08<4:03:11,  1.97s/it][A
 10%|█         | 828/8253 [27:07<4:03:06,  1.96s/it][A
 10%|█         | 828/8253 [27:08<4:03:24,  1.97s/it][A

 10%|█         | 828/8253 [27:08<4:03:10,  1.97s/it][A 10%|█         | 828/8253 [27:08<4:03:21,  1.97s/it][A
 10%|█         | 828/8253 [27:08<4:03:23,  1.97s/it][A
 10%|█         | 829/8253 [27:10<4:03:27,  1.97s/it][A
 10%|█         | 829/8253 [27:10<4:03:24,  1.97s/it][A

 10%|█         | 829/8253 [27:10<4:03:44,  1.97s/it][A 10%|█         | 829/8253 [27:09<4:03:40,  1.97s/it][A
 10%|█         | 829/8253 [27:10<4:03:56,  1.97s/it][A
 10%|█         | 829/8253 [27:10<4:03:47,  1.97s/it][A
 10%|█         | 830/8253 [27:11<4:03:00,  1.96s/it][A
 10%|█         | 830/8253 [27:12<4:03:33,  1.97s/it][A
 10%|█         | 830/8253 [27:12<4:03:36,  1.97s/it][A
 10%|█         | 830/8253 [27:12<4:03:47,  1.97s/it][A
 10%|█         | 830/8253 [27:12<4:04:02,  1.97s/it][A
 10%|█         | 830/8253 [27:12<4:04:03,  1.97s/it][A
 10%|█         | 831/8253 [27:13<4:05:32,  1.99s/it][A
 10%|█         | 831/8253 [27:14<4:05:51,  1.99s/it][A

 10%|█         | 831/8253 [27:14<4:05:51,  1.99s/it][A 10%|█         | 831/8253 [27:14<4:05:49,  1.99s/it][A
 10%|█         | 831/8253 [27:14<4:05:56,  1.99s/it][A
 10%|█         | 831/8253 [27:14<4:05:54,  1.99s/it][A
 10%|█         | 832/8253 [27:16<4:05:15,  1.98s/it][A
 10%|█         | 832/8253 [27:16<4:05:17,  1.98s/it][A
 10%|█         | 832/8253 [27:16<4:05:38,  1.99s/it][A

 10%|█         | 832/8253 [27:16<4:05:42,  1.99s/it][A 10%|█         | 832/8253 [27:15<4:06:04,  1.99s/it][A
 10%|█         | 832/8253 [27:16<4:05:53,  1.99s/it][A
 10%|█         | 833/8253 [27:17<4:04:20,  1.98s/it][A
 10%|█         | 833/8253 [27:17<4:04:24,  1.98s/it][A
 10%|█         | 833/8253 [27:17<4:04:24,  1.98s/it][A
 10%|█         | 833/8253 [27:17<4:04:42,  1.98s/it][A
 10%|█         | 833/8253 [27:17<4:04:33,  1.98s/it][A
 10%|█         | 833/8253 [27:17<4:04:45,  1.98s/it][A
 10%|█         | 834/8253 [27:20<4:06:38,  1.99s/it][A
 10%|█         | 834/8253 [27:20<4:06:48,  2.00s/it][A
 10%|█         | 834/8253 [27:19<4:06:47,  2.00s/it][A
 10%|█         | 834/8253 [27:20<4:06:40,  1.99s/it][A
 10%|█         | 834/8253 [27:20<4:06:40,  1.99s/it][A
 10%|█         | 834/8253 [27:20<4:06:42,  2.00s/it][A
 10%|█         | 835/8253 [27:21<4:03:34,  1.97s/it][A
 10%|█         | 835/8253 [27:21<4:04:06,  1.97s/it][A
 10%|█         | 835/8253 [27:21<4:04:17,  1.98s/it][A

 10%|█         | 835/8253 [27:21<4:04:02,  1.97s/it][A 10%|█         | 835/8253 [27:21<4:04:04,  1.97s/it][A
 10%|█         | 835/8253 [27:21<4:04:23,  1.98s/it][A
 10%|█         | 836/8253 [27:23<4:01:47,  1.96s/it][A
 10%|█         | 836/8253 [27:23<4:02:18,  1.96s/it][A
 10%|█         | 836/8253 [27:23<4:02:28,  1.96s/it][A
 10%|█         | 836/8253 [27:23<4:02:29,  1.96s/it][A
 10%|█         | 836/8253 [27:23<4:02:29,  1.96s/it][A
 10%|█         | 836/8253 [27:23<4:02:38,  1.96s/it][A
 10%|█         | 837/8253 [27:25<4:00:39,  1.95s/it][A
 10%|█         | 837/8253 [27:25<4:00:49,  1.95s/it][A
 10%|█         | 837/8253 [27:25<4:00:46,  1.95s/it][A
 10%|█         | 837/8253 [27:25<4:01:00,  1.95s/it][A
 10%|█         | 837/8253 [27:25<4:01:15,  1.95s/it][A
 10%|█         | 837/8253 [27:25<4:01:08,  1.95s/it][A
 10%|█         | 838/8253 [27:27<4:00:04,  1.94s/it][A
 10%|█         | 838/8253 [27:27<4:00:31,  1.95s/it][A
 10%|█         | 838/8253 [27:27<4:00:21,  1.94s/it][A
 10%|█         | 838/8253 [27:27<4:00:28,  1.95s/it][A

 10%|█         | 838/8253 [27:27<4:00:44,  1.95s/it][A 10%|█         | 838/8253 [27:27<4:00:36,  1.95s/it][A
 10%|█         | 839/8253 [27:29<3:59:23,  1.94s/it][A
 10%|█         | 839/8253 [27:29<4:00:08,  1.94s/it][A
 10%|█         | 839/8253 [27:29<4:00:15,  1.94s/it][A
 10%|█         | 839/8253 [27:29<4:00:12,  1.94s/it][A
 10%|█         | 839/8253 [27:29<4:00:14,  1.94s/it][A
 10%|█         | 839/8253 [27:29<4:00:24,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:00:59,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:00:47,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:00:55,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:01:01,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:01:06,  1.95s/it][A
 10%|█         | 840/8253 [27:31<4:01:03,  1.95s/it][A
 10%|█         | 841/8253 [27:33<4:00:12,  1.94s/it][A
 10%|█         | 841/8253 [27:33<4:00:23,  1.95s/it][A
 10%|█         | 841/8253 [27:33<4:00:17,  1.95s/it][A
 10%|█         | 841/8253 [27:33<4:00:24,  1.95s/it][A
 10%|█         | 841/8253 [27:33<4:01:05,  1.95s/it][A
 10%|█         | 841/8253 [27:33<4:00:51,  1.95s/it][A
 10%|█         | 842/8253 [27:35<3:59:30,  1.94s/it][A
 10%|█         | 842/8253 [27:35<3:59:36,  1.94s/it][A
 10%|█         | 842/8253 [27:35<3:59:51,  1.94s/it][A
 10%|█         | 842/8253 [27:35<4:00:01,  1.94s/it][A
 10%|█         | 842/8253 [27:35<4:00:03,  1.94s/it][A
 10%|█         | 842/8253 [27:35<4:00:01,  1.94s/it][A
 10%|█         | 843/8253 [27:37<3:59:36,  1.94s/it][A
 10%|█         | 843/8253 [27:37<3:59:43,  1.94s/it][A
 10%|█         | 843/8253 [27:37<3:59:44,  1.94s/it][A
 10%|█         | 843/8253 [27:37<3:59:55,  1.94s/it][A
 10%|█         | 843/8253 [27:37<3:59:41,  1.94s/it][A
 10%|█         | 843/8253 [27:37<4:00:07,  1.94s/it][A
 10%|█         | 844/8253 [27:39<3:58:35,  1.93s/it][A
 10%|█         | 844/8253 [27:39<3:58:44,  1.93s/it][A
 10%|█         | 844/8253 [27:39<3:58:59,  1.94s/it][A
 10%|█         | 844/8253 [27:39<3:59:09,  1.94s/it][A

 10%|█         | 844/8253 [27:39<3:59:11,  1.94s/it][A 10%|█         | 844/8253 [27:39<3:59:01,  1.94s/it][A
 10%|█         | 845/8253 [27:41<3:59:03,  1.94s/it][A
 10%|█         | 845/8253 [27:41<3:58:51,  1.93s/it][A
 10%|█         | 845/8253 [27:41<3:58:55,  1.94s/it][A
 10%|█         | 845/8253 [27:41<3:59:17,  1.94s/it][A
 10%|█         | 845/8253 [27:41<3:59:17,  1.94s/it][A
 10%|█         | 845/8253 [27:41<3:59:12,  1.94s/it][A
 10%|█         | 846/8253 [27:43<3:58:06,  1.93s/it][A
 10%|█         | 846/8253 [27:43<3:58:35,  1.93s/it][A
 10%|█         | 846/8253 [27:43<3:58:45,  1.93s/it][A

 10%|█         | 846/8253 [27:43<3:58:48,  1.93s/it][A 10%|█         | 846/8253 [27:43<3:58:52,  1.94s/it][A
 10%|█         | 846/8253 [27:43<3:58:39,  1.93s/it][A
 10%|█         | 847/8253 [27:45<3:59:11,  1.94s/it][A
 10%|█         | 847/8253 [27:45<3:59:28,  1.94s/it][A
 10%|█         | 847/8253 [27:45<3:59:49,  1.94s/it][A
 10%|█         | 847/8253 [27:45<3:59:41,  1.94s/it][A

 10%|█         | 847/8253 [27:45<3:59:39,  1.94s/it][A 10%|█         | 847/8253 [27:45<3:59:42,  1.94s/it][A

 10%|█         | 848/8253 [27:47<3:57:07,  1.92s/it][A 10%|█         | 848/8253 [27:47<3:57:07,  1.92s/it][A
 10%|█         | 848/8253 [27:47<3:57:20,  1.92s/it][A
 10%|█         | 848/8253 [27:47<3:57:13,  1.92s/it][A
 10%|█         | 848/8253 [27:47<3:57:28,  1.92s/it][A
 10%|█         | 848/8253 [27:46<3:57:21,  1.92s/it][A
 10%|█         | 849/8253 [27:49<3:58:32,  1.93s/it][A
 10%|█         | 849/8253 [27:48<3:58:39,  1.93s/it][A
 10%|█         | 849/8253 [27:49<3:58:44,  1.93s/it][A
 10%|█         | 849/8253 [27:49<3:59:01,  1.94s/it][A
 10%|█         | 849/8253 [27:49<3:59:00,  1.94s/it][A
 10%|█         | 849/8253 [27:49<3:59:02,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:02,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:34,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:25,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:28,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:28,  1.94s/it][A
 10%|█         | 850/8253 [27:50<3:59:29,  1.94s/it][A
 10%|█         | 851/8253 [27:53<4:05:38,  1.99s/it][A
 10%|█         | 851/8253 [27:53<4:05:30,  1.99s/it][A

 10%|█         | 851/8253 [27:53<4:05:45,  1.99s/it][A 10%|█         | 851/8253 [27:52<4:05:42,  1.99s/it][A

 10%|█         | 851/8253 [27:53<4:05:49,  1.99s/it][A 10%|█         | 851/8253 [27:53<4:05:57,  1.99s/it][A
 10%|█         | 852/8253 [27:55<4:04:12,  1.98s/it][A
 10%|█         | 852/8253 [27:55<4:04:04,  1.98s/it][A

 10%|█         | 852/8253 [27:55<4:04:12,  1.98s/it][A 10%|█         | 852/8253 [27:54<4:04:09,  1.98s/it][A
 10%|█         | 852/8253 [27:55<4:04:16,  1.98s/it][A
 10%|█         | 852/8253 [27:55<4:04:36,  1.98s/it][A
 10%|█         | 853/8253 [27:56<4:02:11,  1.96s/it][A
 10%|█         | 853/8253 [27:56<4:02:17,  1.96s/it][A
 10%|█         | 853/8253 [27:56<4:02:22,  1.97s/it][A
 10%|█         | 853/8253 [27:56<4:02:27,  1.97s/it][A

 10%|█         | 853/8253 [27:56<4:02:31,  1.97s/it][A 10%|█         | 853/8253 [27:56<4:02:40,  1.97s/it][A
 10%|█         | 854/8253 [27:58<4:01:04,  1.95s/it][A

 10%|█         | 854/8253 [27:58<4:01:17,  1.96s/it][A 10%|█         | 854/8253 [27:58<4:01:25,  1.96s/it][A
 10%|█         | 854/8253 [27:58<4:01:31,  1.96s/it][A
 10%|█         | 854/8253 [27:58<4:01:59,  1.96s/it][A
 10%|█         | 854/8253 [27:58<4:01:52,  1.96s/it][A
 10%|█         | 855/8253 [28:00<4:02:04,  1.96s/it][A
 10%|█         | 855/8253 [28:00<4:02:22,  1.97s/it][A
 10%|█         | 855/8253 [28:00<4:02:11,  1.96s/it][A
 10%|█         | 855/8253 [28:00<4:02:26,  1.97s/it][A
 10%|█         | 855/8253 [28:00<4:02:22,  1.97s/it][A
 10%|█         | 855/8253 [28:00<4:02:34,  1.97s/it][A
 10%|█         | 856/8253 [28:02<3:59:46,  1.94s/it][A
 10%|█         | 856/8253 [28:02<4:00:08,  1.95s/it][A
 10%|█         | 856/8253 [28:02<4:00:19,  1.95s/it][A
 10%|█         | 856/8253 [28:02<4:00:33,  1.95s/it][A
 10%|█         | 856/8253 [28:02<4:00:25,  1.95s/it][A
 10%|█         | 856/8253 [28:02<4:00:31,  1.95s/it][A
 10%|█         | 857/8253 [28:04<3:59:38,  1.94s/it][A
 10%|█         | 857/8253 [28:04<4:00:00,  1.95s/it][A
 10%|█         | 857/8253 [28:04<4:00:06,  1.95s/it][A
 10%|█         | 857/8253 [28:04<4:00:06,  1.95s/it][A
 10%|█         | 857/8253 [28:04<4:00:20,  1.95s/it][A
 10%|█         | 857/8253 [28:04<4:00:11,  1.95s/it][A
 10%|█         | 858/8253 [28:06<4:01:44,  1.96s/it][A
 10%|█         | 858/8253 [28:06<4:02:08,  1.96s/it][A
 10%|█         | 858/8253 [28:06<4:02:19,  1.97s/it][A
 10%|█         | 858/8253 [28:06<4:02:28,  1.97s/it][A
 10%|█         | 858/8253 [28:06<4:02:33,  1.97s/it][A
 10%|█         | 858/8253 [28:06<4:02:36,  1.97s/it][A
 10%|█         | 859/8253 [28:08<4:04:59,  1.99s/it][A
 10%|█         | 859/8253 [28:08<4:05:08,  1.99s/it][A
 10%|█         | 859/8253 [28:08<4:05:04,  1.99s/it][A
 10%|█         | 859/8253 [28:08<4:05:12,  1.99s/it][A
 10%|█         | 859/8253 [28:08<4:05:13,  1.99s/it][A
 10%|█         | 859/8253 [28:08<4:05:24,  1.99s/it][A
 10%|█         | 860/8253 [28:10<4:01:54,  1.96s/it][A
 10%|█         | 860/8253 [28:10<4:02:10,  1.97s/it][A
 10%|█         | 860/8253 [28:10<4:02:06,  1.96s/it][A
 10%|█         | 860/8253 [28:10<4:02:31,  1.97s/it][A
 10%|█         | 860/8253 [28:10<4:02:26,  1.97s/it][A
 10%|█         | 860/8253 [28:10<4:02:25,  1.97s/it][A
 10%|█         | 861/8253 [28:12<3:59:24,  1.94s/it][A
 10%|█         | 861/8253 [28:12<3:59:40,  1.95s/it][A
 10%|█         | 861/8253 [28:12<3:59:49,  1.95s/it][A

 10%|█         | 861/8253 [28:12<4:00:09,  1.95s/it][A 10%|█         | 861/8253 [28:12<3:59:54,  1.95s/it][A
 10%|█         | 861/8253 [28:12<3:59:49,  1.95s/it][A
 10%|█         | 862/8253 [28:14<3:59:35,  1.95s/it][A
 10%|█         | 862/8253 [28:14<3:59:52,  1.95s/it][A
 10%|█         | 862/8253 [28:14<4:00:05,  1.95s/it][A
 10%|█         | 862/8253 [28:14<3:59:50,  1.95s/it][A

 10%|█         | 862/8253 [28:14<4:00:08,  1.95s/it][A 10%|█         | 862/8253 [28:14<4:00:14,  1.95s/it][A

 10%|█         | 863/8253 [28:16<4:00:05,  1.95s/it][A 10%|█         | 863/8253 [28:16<4:00:00,  1.95s/it][A
 10%|█         | 863/8253 [28:16<4:00:26,  1.95s/it][A
 10%|█         | 863/8253 [28:16<4:00:20,  1.95s/it][A

 10%|█         | 863/8253 [28:16<4:00:42,  1.95s/it][A 10%|█         | 863/8253 [28:16<4:00:42,  1.95s/it][A
 10%|█         | 864/8253 [28:18<3:58:46,  1.94s/it][A

 10%|█         | 864/8253 [28:18<3:59:20,  1.94s/it][A 10%|█         | 864/8253 [28:18<3:59:19,  1.94s/it][A
 10%|█         | 864/8253 [28:18<3:59:19,  1.94s/it][A

 10%|█         | 864/8253 [28:18<3:59:28,  1.94s/it][A 10%|█         | 864/8253 [28:18<3:59:40,  1.95s/it][A
 10%|█         | 865/8253 [28:20<3:58:31,  1.94s/it][A
 10%|█         | 865/8253 [28:20<3:58:53,  1.94s/it][A
 10%|█         | 865/8253 [28:20<3:58:52,  1.94s/it][A
 10%|█         | 865/8253 [28:20<3:59:08,  1.94s/it][A
 10%|█         | 865/8253 [28:20<3:59:19,  1.94s/it][A
 10%|█         | 865/8253 [28:20<3:59:14,  1.94s/it][A
 10%|█         | 866/8253 [28:22<4:01:25,  1.96s/it][A
 10%|█         | 866/8253 [28:22<4:01:47,  1.96s/it][A
 10%|█         | 866/8253 [28:22<4:01:49,  1.96s/it][A
 10%|█         | 866/8253 [28:22<4:01:46,  1.96s/it][A
 10%|█         | 866/8253 [28:22<4:02:13,  1.97s/it][A
 10%|█         | 866/8253 [28:22<4:01:50,  1.96s/it][A
 11%|█         | 867/8253 [28:24<3:59:05,  1.94s/it][A
 11%|█         | 867/8253 [28:24<3:59:23,  1.94s/it][A
 11%|█         | 867/8253 [28:24<3:59:31,  1.95s/it][A
 11%|█         | 867/8253 [28:24<3:59:33,  1.95s/it][A
 11%|█         | 867/8253 [28:24<3:59:13,  1.94s/it][A
 11%|█         | 867/8253 [28:24<3:59:29,  1.95s/it][A
 11%|█         | 868/8253 [28:26<3:58:49,  1.94s/it][A


 11%|█         | 868/8253 [28:26<3:59:12,  1.94s/it][A 11%|█         | 868/8253 [28:26<3:59:12,  1.94s/it][A 11%|█         | 868/8253 [28:26<3:59:10,  1.94s/it][A
 11%|█         | 868/8253 [28:26<3:59:04,  1.94s/it][A
 11%|█         | 868/8253 [28:26<3:59:20,  1.94s/it][A
 11%|█         | 869/8253 [28:28<4:00:40,  1.96s/it][A
 11%|█         | 869/8253 [28:28<4:00:57,  1.96s/it][A
 11%|█         | 869/8253 [28:28<4:01:20,  1.96s/it][A
 11%|█         | 869/8253 [28:28<4:01:15,  1.96s/it][A
 11%|█         | 869/8253 [28:28<4:01:30,  1.96s/it][A
 11%|█         | 869/8253 [28:28<4:01:20,  1.96s/it][A
 11%|█         | 870/8253 [28:30<4:00:25,  1.95s/it]
[A 11%|█         | 870/8253 [28:30<4:00:45,  1.96s/it][A
 11%|█         | 870/8253 [28:30<4:00:35,  1.96s/it][A
 11%|█         | 870/8253 [28:30<4:00:44,  1.96s/it][A

 11%|█         | 870/8253 [28:30<4:01:02,  1.96s/it][A 11%|█         | 870/8253 [28:30<4:00:52,  1.96s/it][A
 11%|█         | 871/8253 [28:32<3:58:22,  1.94s/it][A
 11%|█         | 871/8253 [28:32<3:58:29,  1.94s/it][A

 11%|█         | 871/8253 [28:32<3:58:38,  1.94s/it][A 11%|█         | 871/8253 [28:31<3:58:45,  1.94s/it][A
 11%|█         | 871/8253 [28:32<3:58:54,  1.94s/it][A
 11%|█         | 871/8253 [28:32<3:58:51,  1.94s/it][A
 11%|█         | 872/8253 [28:34<3:59:46,  1.95s/it][A
 11%|█         | 872/8253 [28:33<3:59:53,  1.95s/it][A
 11%|█         | 872/8253 [28:34<3:59:48,  1.95s/it][A
 11%|█         | 872/8253 [28:34<4:00:00,  1.95s/it][A
 11%|█         | 872/8253 [28:34<4:00:00,  1.95s/it][A
 11%|█         | 872/8253 [28:34<4:00:11,  1.95s/it][A
 11%|█         | 873/8253 [28:35<3:57:50,  1.93s/it][A
 11%|█         | 873/8253 [28:35<3:57:47,  1.93s/it][A
 11%|█         | 873/8253 [28:35<3:57:51,  1.93s/it][A
 11%|█         | 873/8253 [28:35<3:57:59,  1.93s/it][A
 11%|█         | 873/8253 [28:35<3:57:58,  1.93s/it][A
 11%|█         | 873/8253 [28:35<3:58:01,  1.94s/it][A
 11%|█         | 874/8253 [28:37<3:57:16,  1.93s/it][A
 11%|█         | 874/8253 [28:37<3:57:04,  1.93s/it][A
 11%|█         | 874/8253 [28:37<3:57:23,  1.93s/it][A
 11%|█         | 874/8253 [28:37<3:57:28,  1.93s/it][A
 11%|█         | 874/8253 [28:37<3:57:40,  1.93s/it][A
 11%|█         | 874/8253 [28:37<3:57:39,  1.93s/it][A
 11%|█         | 875/8253 [28:39<3:57:53,  1.93s/it][A
 11%|█         | 875/8253 [28:39<3:57:52,  1.93s/it][A
 11%|█         | 875/8253 [28:39<3:57:51,  1.93s/it][A
 11%|█         | 875/8253 [28:39<3:58:01,  1.94s/it][A

 11%|█         | 875/8253 [28:39<3:58:01,  1.94s/it][A 11%|█         | 875/8253 [28:39<3:58:04,  1.94s/it][A
 11%|█         | 876/8253 [28:41<3:59:43,  1.95s/it][A
 11%|█         | 876/8253 [28:41<3:59:46,  1.95s/it][A
 11%|█         | 876/8253 [28:41<4:00:05,  1.95s/it][A
 11%|█         | 876/8253 [28:41<4:00:24,  1.96s/it][A
 11%|█         | 876/8253 [28:41<4:00:09,  1.95s/it][A
 11%|█         | 876/8253 [28:41<4:00:25,  1.96s/it][A
 11%|█         | 877/8253 [28:43<3:58:33,  1.94s/it][A
 11%|█         | 877/8253 [28:43<3:58:33,  1.94s/it][A
 11%|█         | 877/8253 [28:43<3:58:48,  1.94s/it][A
 11%|█         | 877/8253 [28:43<3:58:57,  1.94s/it][A
 11%|█         | 877/8253 [28:43<3:58:46,  1.94s/it][A
 11%|█         | 877/8253 [28:43<3:58:54,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:29,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:24,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:23,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:15,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:21,  1.94s/it][A
 11%|█         | 878/8253 [28:45<3:58:28,  1.94s/it][A
 11%|█         | 879/8253 [28:47<3:57:35,  1.93s/it][A
 11%|█         | 879/8253 [28:47<3:57:36,  1.93s/it][A
 11%|█         | 879/8253 [28:47<3:57:45,  1.93s/it][A
 11%|█         | 879/8253 [28:47<3:57:56,  1.94s/it][A
 11%|█         | 879/8253 [28:47<3:58:03,  1.94s/it][A
 11%|█         | 879/8253 [28:47<3:58:08,  1.94s/it][A
 11%|█         | 880/8253 [28:49<3:58:40,  1.94s/it][A
 11%|█         | 880/8253 [28:49<3:58:37,  1.94s/it][A
 11%|█         | 880/8253 [28:49<3:58:50,  1.94s/it][A

 11%|█         | 880/8253 [28:49<3:59:02,  1.95s/it][A 11%|█         | 880/8253 [28:49<3:59:03,  1.95s/it][A
 11%|█         | 880/8253 [28:49<3:59:08,  1.95s/it][A
 11%|█         | 881/8253 [28:51<3:59:44,  1.95s/it][A
 11%|█         | 881/8253 [28:51<3:59:35,  1.95s/it][A
 11%|█         | 881/8253 [28:51<4:00:11,  1.95s/it][A

 11%|█         | 881/8253 [28:51<4:00:08,  1.95s/it][A 11%|█         | 881/8253 [28:51<4:00:12,  1.96s/it][A
 11%|█         | 881/8253 [28:51<4:00:17,  1.96s/it][A
 11%|█         | 882/8253 [28:53<4:01:27,  1.97s/it][A
 11%|█         | 882/8253 [28:53<4:01:57,  1.97s/it][A
 11%|█         | 882/8253 [28:53<4:01:51,  1.97s/it][A
 11%|█         | 882/8253 [28:53<4:01:57,  1.97s/it][A

 11%|█         | 882/8253 [28:53<4:02:02,  1.97s/it][A 11%|█         | 882/8253 [28:53<4:02:08,  1.97s/it][A



 11%|█         | 883/8253 [28:55<4:02:44,  1.98s/it]
[A
 11%|█         | 883/8253 [28:55<4:02:34,  1.97s/it] 11%|█         | 883/8253 [28:55<4:02:36,  1.98s/it][A 11%|█         | 883/8253 [28:55<4:02:55,  1.98s/it][A[A 11%|█         | 883/8253 [28:55<4:03:09,  1.98s/it][A 11%|█         | 883/8253 [28:55<4:02:52,  1.98s/it][A
 11%|█         | 884/8253 [28:57<3:59:40,  1.95s/it][A
 11%|█         | 884/8253 [28:57<3:59:34,  1.95s/it][A
 11%|█         | 884/8253 [28:57<3:59:52,  1.95s/it][A
 11%|█         | 884/8253 [28:57<4:00:09,  1.96s/it][A
 11%|█         | 884/8253 [28:57<4:00:15,  1.96s/it][A
 11%|█         | 884/8253 [28:57<4:00:30,  1.96s/it][A
 11%|█         | 885/8253 [28:59<3:59:25,  1.95s/it][A
 11%|█         | 885/8253 [28:59<3:59:54,  1.95s/it][A
 11%|█         | 885/8253 [28:59<3:59:32,  1.95s/it][A
 11%|█         | 885/8253 [28:59<3:59:53,  1.95s/it][A
 11%|█         | 885/8253 [28:59<3:59:42,  1.95s/it][A
 11%|█         | 885/8253 [28:59<3:59:55,  1.95s/it][A
 11%|█         | 886/8253 [29:01<3:58:50,  1.95s/it][A
 11%|█         | 886/8253 [29:01<3:58:45,  1.94s/it][A
 11%|█         | 886/8253 [29:01<3:58:50,  1.95s/it][A
 11%|█         | 886/8253 [29:01<3:59:02,  1.95s/it][A
 11%|█         | 886/8253 [29:01<3:59:32,  1.95s/it][A
 11%|█         | 886/8253 [29:01<3:59:27,  1.95s/it][A
 11%|█         | 887/8253 [29:03<3:58:38,  1.94s/it][A
 11%|█         | 887/8253 [29:03<3:58:30,  1.94s/it][A

 11%|█         | 887/8253 [29:03<3:58:57,  1.95s/it][A 11%|█         | 887/8253 [29:03<3:58:52,  1.95s/it][A
 11%|█         | 887/8253 [29:03<3:58:50,  1.95s/it][A
 11%|█         | 887/8253 [29:03<3:58:54,  1.95s/it][A
 11%|█         | 888/8253 [29:05<3:56:39,  1.93s/it][A
 11%|█         | 888/8253 [29:05<3:56:38,  1.93s/it][A
 11%|█         | 888/8253 [29:05<3:56:55,  1.93s/it][A
 11%|█         | 888/8253 [29:05<3:56:55,  1.93s/it][A
 11%|█         | 888/8253 [29:05<3:57:14,  1.93s/it][A
 11%|█         | 888/8253 [29:05<3:57:07,  1.93s/it][A
 11%|█         | 889/8253 [29:07<3:58:15,  1.94s/it][A
 11%|█         | 889/8253 [29:07<3:58:22,  1.94s/it][A
 11%|█         | 889/8253 [29:07<3:58:47,  1.95s/it][A
 11%|█         | 889/8253 [29:07<3:58:35,  1.94s/it][A
 11%|█         | 889/8253 [29:07<3:58:50,  1.95s/it][A
 11%|█         | 889/8253 [29:07<3:58:59,  1.95s/it][A
 11%|█         | 890/8253 [29:09<3:59:07,  1.95s/it][A
 11%|█         | 890/8253 [29:09<3:59:05,  1.95s/it][A
 11%|█         | 890/8253 [29:08<3:59:19,  1.95s/it][A
 11%|█         | 890/8253 [29:09<3:59:25,  1.95s/it][A
 11%|█         | 890/8253 [29:09<3:59:28,  1.95s/it][A
 11%|█         | 890/8253 [29:09<3:59:35,  1.95s/it][A
 11%|█         | 891/8253 [29:11<4:01:23,  1.97s/it][A
 11%|█         | 891/8253 [29:11<4:01:22,  1.97s/it][A
 11%|█         | 891/8253 [29:11<4:01:24,  1.97s/it][A
 11%|█         | 891/8253 [29:10<4:01:44,  1.97s/it][A
 11%|█         | 891/8253 [29:11<4:01:48,  1.97s/it][A
 11%|█         | 891/8253 [29:11<4:01:44,  1.97s/it][A
 11%|█         | 892/8253 [29:13<4:01:31,  1.97s/it][A
 11%|█         | 892/8253 [29:13<4:02:07,  1.97s/it][A
 11%|█         | 892/8253 [29:13<4:02:01,  1.97s/it][A
 11%|█         | 892/8253 [29:13<4:02:10,  1.97s/it][A
 11%|█         | 892/8253 [29:13<4:02:06,  1.97s/it][A
 11%|█         | 892/8253 [29:12<4:02:23,  1.98s/it][A
 11%|█         | 893/8253 [29:15<4:02:00,  1.97s/it][A
 11%|█         | 893/8253 [29:15<4:02:15,  1.97s/it][A
 11%|█         | 893/8253 [29:15<4:02:04,  1.97s/it][A
 11%|█         | 893/8253 [29:14<4:02:07,  1.97s/it][A
 11%|█         | 893/8253 [29:15<4:02:09,  1.97s/it][A
 11%|█         | 893/8253 [29:15<4:02:06,  1.97s/it][A
 11%|█         | 894/8253 [29:16<4:02:32,  1.98s/it][A
 11%|█         | 894/8253 [29:17<4:02:36,  1.98s/it][A
 11%|█         | 894/8253 [29:17<4:03:05,  1.98s/it][A
 11%|█         | 894/8253 [29:17<4:02:58,  1.98s/it][A
 11%|█         | 894/8253 [29:17<4:03:05,  1.98s/it][A
 11%|█         | 894/8253 [29:17<4:03:16,  1.98s/it][A
 11%|█         | 895/8253 [29:18<4:01:03,  1.97s/it][A
 11%|█         | 895/8253 [29:19<4:01:11,  1.97s/it][A
 11%|█         | 895/8253 [29:19<4:01:23,  1.97s/it][A
 11%|█         | 895/8253 [29:19<4:01:34,  1.97s/it][A
 11%|█         | 895/8253 [29:19<4:01:27,  1.97s/it][A
 11%|█         | 895/8253 [29:19<4:01:33,  1.97s/it][A
 11%|█         | 896/8253 [29:20<4:00:26,  1.96s/it][A
 11%|█         | 896/8253 [29:20<4:00:29,  1.96s/it][A
 11%|█         | 896/8253 [29:20<4:00:24,  1.96s/it][A

 11%|█         | 896/8253 [29:20<4:00:56,  1.97s/it][A 11%|█         | 896/8253 [29:20<4:00:46,  1.96s/it][A
 11%|█         | 896/8253 [29:20<4:00:43,  1.96s/it][A
 11%|█         | 897/8253 [29:22<4:00:27,  1.96s/it][A
 11%|█         | 897/8253 [29:22<4:00:49,  1.96s/it][A
 11%|█         | 897/8253 [29:22<4:00:44,  1.96s/it][A

 11%|█         | 897/8253 [29:22<4:00:41,  1.96s/it][A 11%|█         | 897/8253 [29:22<4:00:54,  1.97s/it][A
 11%|█         | 897/8253 [29:22<4:01:07,  1.97s/it][A
 11%|█         | 898/8253 [29:24<3:58:46,  1.95s/it][A
 11%|█         | 898/8253 [29:24<3:59:11,  1.95s/it][A


 11%|█         | 898/8253 [29:24<3:59:00,  1.95s/it][A 11%|█         | 898/8253 [29:24<3:59:06,  1.95s/it][A 11%|█         | 898/8253 [29:24<3:59:03,  1.95s/it][A
 11%|█         | 898/8253 [29:24<3:59:22,  1.95s/it][A
 11%|█         | 899/8253 [29:26<3:58:49,  1.95s/it][A
 11%|█         | 899/8253 [29:26<3:58:45,  1.95s/it][A
 11%|█         | 899/8253 [29:26<3:58:51,  1.95s/it][A

 11%|█         | 899/8253 [29:26<3:59:04,  1.95s/it][A 11%|█         | 899/8253 [29:26<3:59:06,  1.95s/it][A
 11%|█         | 899/8253 [29:26<3:58:52,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:58:47,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:58:57,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:59:17,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:59:32,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:59:25,  1.95s/it][A
 11%|█         | 900/8253 [29:28<3:59:25,  1.95s/it][A
 11%|█         | 901/8253 [29:30<4:00:15,  1.96s/it][A
 11%|█         | 901/8253 [29:30<4:00:24,  1.96s/it][A
 11%|█         | 901/8253 [29:30<4:00:34,  1.96s/it][A

 11%|█         | 901/8253 [29:30<4:00:43,  1.96s/it][A 11%|█         | 901/8253 [29:30<4:00:55,  1.97s/it][A
 11%|█         | 901/8253 [29:30<4:00:52,  1.97s/it][A
 11%|█         | 902/8253 [29:32<4:01:13,  1.97s/it][A
 11%|█         | 902/8253 [29:32<4:01:19,  1.97s/it][A

 11%|█         | 902/8253 [29:32<4:01:12,  1.97s/it][A 11%|█         | 902/8253 [29:32<4:01:17,  1.97s/it][A
 11%|█         | 902/8253 [29:32<4:01:31,  1.97s/it][A
 11%|█         | 902/8253 [29:32<4:01:49,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:01:17,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:01:16,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:01:45,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:01:45,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:01:47,  1.97s/it][A
 11%|█         | 903/8253 [29:34<4:02:03,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:01:59,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:02:04,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:02:03,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:02:12,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:02:18,  1.98s/it][A
 11%|█         | 904/8253 [29:36<4:02:20,  1.98s/it][A
 11%|█         | 905/8253 [29:38<4:00:21,  1.96s/it][A
 11%|█         | 905/8253 [29:38<4:00:52,  1.97s/it][A
 11%|█         | 905/8253 [29:38<4:01:07,  1.97s/it][A
 11%|█         | 905/8253 [29:38<4:01:09,  1.97s/it][A

 11%|█         | 905/8253 [29:38<4:01:36,  1.97s/it] 11%|█         | 905/8253 [29:38<4:01:17,  1.97s/it][A[A
 11%|█         | 906/8253 [29:40<3:58:35,  1.95s/it][A
 11%|█         | 906/8253 [29:40<3:58:44,  1.95s/it][A
 11%|█         | 906/8253 [29:40<3:59:21,  1.95s/it][A

 11%|█         | 906/8253 [29:40<3:59:11,  1.95s/it][A 11%|█         | 906/8253 [29:40<3:59:20,  1.95s/it][A
 11%|█         | 906/8253 [29:40<3:59:31,  1.96s/it][A
 11%|█         | 907/8253 [29:42<3:59:44,  1.96s/it][A
 11%|█         | 907/8253 [29:42<4:00:06,  1.96s/it][A
 11%|█         | 907/8253 [29:42<4:00:15,  1.96s/it][A
 11%|█         | 907/8253 [29:42<4:00:11,  1.96s/it][A
 11%|█         | 907/8253 [29:42<4:00:24,  1.96s/it][A
 11%|█         | 907/8253 [29:42<4:00:33,  1.96s/it][A
 11%|█         | 908/8253 [29:44<4:00:32,  1.96s/it]
[A 11%|█         | 908/8253 [29:44<4:00:49,  1.97s/it][A
 11%|█         | 908/8253 [29:44<4:00:57,  1.97s/it][A
 11%|█         | 908/8253 [29:44<4:00:41,  1.97s/it][A
 11%|█         | 908/8253 [29:44<4:00:46,  1.97s/it][A
 11%|█         | 908/8253 [29:44<4:00:58,  1.97s/it][A
 11%|█         | 909/8253 [29:46<4:02:16,  1.98s/it][A
 11%|█         | 909/8253 [29:46<4:02:38,  1.98s/it][A
 11%|█         | 909/8253 [29:46<4:02:31,  1.98s/it][A
 11%|█         | 909/8253 [29:46<4:02:47,  1.98s/it][A
 11%|█         | 909/8253 [29:46<4:02:32,  1.98s/it][A
 11%|█         | 909/8253 [29:46<4:02:39,  1.98s/it][A
 11%|█         | 910/8253 [29:48<4:02:00,  1.98s/it][A
 11%|█         | 910/8253 [29:48<4:01:51,  1.98s/it][A
 11%|█         | 910/8253 [29:48<4:02:05,  1.98s/it][A
 11%|█         | 910/8253 [29:48<4:01:59,  1.98s/it][A

 11%|█         | 910/8253 [29:48<4:02:39,  1.98s/it][A 11%|█         | 910/8253 [29:48<4:02:31,  1.98s/it][A
 11%|█         | 911/8253 [29:50<4:02:30,  1.98s/it][A
 11%|█         | 911/8253 [29:50<4:02:51,  1.98s/it][A
 11%|█         | 911/8253 [29:50<4:02:59,  1.99s/it][A
 11%|█         | 911/8253 [29:50<4:03:02,  1.99s/it][A
 11%|█         | 911/8253 [29:50<4:03:01,  1.99s/it][A
 11%|█         | 911/8253 [29:50<4:03:05,  1.99s/it][A
 11%|█         | 912/8253 [29:52<4:02:56,  1.99s/it][A
 11%|█         | 912/8253 [29:52<4:03:06,  1.99s/it][A
 11%|█         | 912/8253 [29:52<4:03:13,  1.99s/it][A


 11%|█         | 912/8253 [29:52<4:03:07,  1.99s/it][A 11%|█         | 912/8253 [29:52<4:03:16,  1.99s/it][A 11%|█         | 912/8253 [29:52<4:03:17,  1.99s/it][A
 11%|█         | 913/8253 [29:54<4:11:18,  2.05s/it][A
 11%|█         | 913/8253 [29:54<4:11:25,  2.06s/it][A
 11%|█         | 913/8253 [29:54<4:11:43,  2.06s/it][A
 11%|█         | 913/8253 [29:54<4:12:06,  2.06s/it][A
 11%|█         | 913/8253 [29:54<4:12:10,  2.06s/it][A
 11%|█         | 913/8253 [29:54<4:11:53,  2.06s/it][A
 11%|█         | 914/8253 [29:56<4:09:06,  2.04s/it][A
 11%|█         | 914/8253 [29:56<4:09:17,  2.04s/it][A
 11%|█         | 914/8253 [29:56<4:09:42,  2.04s/it][A
 11%|█         | 914/8253 [29:56<4:09:57,  2.04s/it][A
 11%|█         | 914/8253 [29:56<4:09:41,  2.04s/it][A
 11%|█         | 914/8253 [29:56<4:09:59,  2.04s/it][A
 11%|█         | 915/8253 [29:58<4:07:31,  2.02s/it][A
 11%|█         | 915/8253 [29:58<4:07:34,  2.02s/it][A
 11%|█         | 915/8253 [29:58<4:07:47,  2.03s/it][A
 11%|█         | 915/8253 [29:58<4:07:40,  2.03s/it][A

 11%|█         | 915/8253 [29:58<4:07:35,  2.02s/it][A 11%|█         | 915/8253 [29:58<4:07:48,  2.03s/it][A
 11%|█         | 916/8253 [30:00<4:04:21,  2.00s/it][A
 11%|█         | 916/8253 [30:00<4:04:42,  2.00s/it][A
 11%|█         | 916/8253 [30:00<4:04:28,  2.00s/it][A
 11%|█         | 916/8253 [30:00<4:04:44,  2.00s/it][A
 11%|█         | 916/8253 [30:00<4:04:33,  2.00s/it][A
 11%|█         | 916/8253 [30:00<4:04:47,  2.00s/it][A
 11%|█         | 917/8253 [30:02<4:03:37,  1.99s/it][A
 11%|█         | 917/8253 [30:02<4:03:35,  1.99s/it][A
 11%|█         | 917/8253 [30:02<4:04:04,  2.00s/it][A
 11%|█         | 917/8253 [30:02<4:04:19,  2.00s/it][A
 11%|█         | 917/8253 [30:02<4:04:27,  2.00s/it][A
 11%|█         | 917/8253 [30:02<4:04:41,  2.00s/it][A
 11%|█         | 918/8253 [30:04<4:02:38,  1.98s/it][A
 11%|█         | 918/8253 [30:04<4:02:45,  1.99s/it][A
 11%|█         | 918/8253 [30:04<4:02:44,  1.99s/it][A

 11%|█         | 918/8253 [30:04<4:02:52,  1.99s/it][A 11%|█         | 918/8253 [30:04<4:02:51,  1.99s/it][A
 11%|█         | 918/8253 [30:04<4:03:05,  1.99s/it][A
 11%|█         | 919/8253 [30:06<3:59:52,  1.96s/it][A


 11%|█         | 919/8253 [30:06<4:00:36,  1.97s/it][A 11%|█         | 919/8253 [30:06<4:00:23,  1.97s/it][A 11%|█         | 919/8253 [30:06<4:00:31,  1.97s/it]
[A 11%|█         | 919/8253 [30:06<4:00:28,  1.97s/it][A
 11%|█         | 919/8253 [30:06<4:00:28,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:00:46,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:00:52,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:01:16,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:01:05,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:01:04,  1.97s/it][A
 11%|█         | 920/8253 [30:08<4:01:12,  1.97s/it][A
 11%|█         | 921/8253 [30:10<4:00:32,  1.97s/it][A
 11%|█         | 921/8253 [30:10<4:00:32,  1.97s/it][A
 11%|█         | 921/8253 [30:10<4:00:42,  1.97s/it][A
 11%|█         | 921/8253 [30:10<4:00:56,  1.97s/it][A

 11%|█         | 921/8253 [30:10<4:01:01,  1.97s/it][A 11%|█         | 921/8253 [30:10<4:01:12,  1.97s/it][A
 11%|█         | 922/8253 [30:12<4:02:35,  1.99s/it][A
 11%|█         | 922/8253 [30:12<4:02:54,  1.99s/it][A
 11%|█         | 922/8253 [30:12<4:02:36,  1.99s/it][A
 11%|█         | 922/8253 [30:12<4:02:44,  1.99s/it][A
 11%|█         | 922/8253 [30:12<4:02:55,  1.99s/it][A
 11%|█         | 922/8253 [30:12<4:03:08,  1.99s/it][A
 11%|█         | 923/8253 [30:14<4:00:08,  1.97s/it][A
 11%|█         | 923/8253 [30:14<4:00:24,  1.97s/it][A
 11%|█         | 923/8253 [30:14<4:00:28,  1.97s/it][A
 11%|█         | 923/8253 [30:14<4:00:53,  1.97s/it][A
 11%|█         | 923/8253 [30:14<4:00:42,  1.97s/it][A
 11%|█         | 923/8253 [30:14<4:00:50,  1.97s/it][A
 11%|█         | 924/8253 [30:16<3:59:32,  1.96s/it][A
 11%|█         | 924/8253 [30:16<3:59:48,  1.96s/it][A
 11%|█         | 924/8253 [30:16<3:59:57,  1.96s/it][A

 11%|█         | 924/8253 [30:16<4:00:17,  1.97s/it][A 11%|█         | 924/8253 [30:16<4:00:10,  1.97s/it][A
 11%|█         | 924/8253 [30:16<4:00:00,  1.96s/it][A
 11%|█         | 925/8253 [30:18<3:58:21,  1.95s/it][A
 11%|█         | 925/8253 [30:18<3:58:31,  1.95s/it][A
 11%|█         | 925/8253 [30:18<3:58:54,  1.96s/it][A
 11%|█         | 925/8253 [30:18<3:58:55,  1.96s/it][A
 11%|█         | 925/8253 [30:18<3:58:56,  1.96s/it][A
 11%|█         | 925/8253 [30:18<3:58:59,  1.96s/it][A
 11%|█         | 926/8253 [30:20<3:59:01,  1.96s/it][A
 11%|█         | 926/8253 [30:20<3:59:17,  1.96s/it][A
 11%|█         | 926/8253 [30:20<3:59:11,  1.96s/it][A

 11%|█         | 926/8253 [30:20<3:59:07,  1.96s/it][A 11%|█         | 926/8253 [30:20<3:59:09,  1.96s/it][A
 11%|█         | 926/8253 [30:20<3:59:36,  1.96s/it][A
 11%|█         | 927/8253 [30:22<4:00:05,  1.97s/it][A
 11%|█         | 927/8253 [30:22<4:00:21,  1.97s/it][A
 11%|█         | 927/8253 [30:22<4:00:37,  1.97s/it][A
 11%|█         | 927/8253 [30:22<4:00:46,  1.97s/it][A

 11%|█         | 927/8253 [30:22<4:00:58,  1.97s/it][A 11%|█         | 927/8253 [30:22<4:00:56,  1.97s/it][A
 11%|█         | 928/8253 [30:24<4:01:38,  1.98s/it][A

 11%|█         | 928/8253 [30:24<4:01:45,  1.98s/it][A 11%|█         | 928/8253 [30:24<4:01:40,  1.98s/it][A
 11%|█         | 928/8253 [30:24<4:01:53,  1.98s/it][A
 11%|█         | 928/8253 [30:24<4:01:57,  1.98s/it][A
 11%|█         | 928/8253 [30:24<4:01:57,  1.98s/it][A
 11%|█▏        | 929/8253 [30:26<3:59:58,  1.97s/it][A
 11%|█▏        | 929/8253 [30:26<3:59:39,  1.96s/it][A
 11%|█▏        | 929/8253 [30:26<3:59:57,  1.97s/it][A
 11%|█▏        | 929/8253 [30:26<4:00:07,  1.97s/it][A
 11%|█▏        | 929/8253 [30:26<4:00:02,  1.97s/it][A
 11%|█▏        | 929/8253 [30:26<3:59:59,  1.97s/it][A
 11%|█▏        | 930/8253 [30:28<3:59:05,  1.96s/it][A
 11%|█▏        | 930/8253 [30:28<3:58:54,  1.96s/it][A
 11%|█▏        | 930/8253 [30:28<3:59:07,  1.96s/it][A
 11%|█▏        | 930/8253 [30:28<3:59:21,  1.96s/it][A
 11%|█▏        | 930/8253 [30:28<3:59:20,  1.96s/it][A
 11%|█▏        | 930/8253 [30:28<3:59:22,  1.96s/it][A
 11%|█▏        | 931/8253 [30:29<3:58:16,  1.95s/it][A
 11%|█▏        | 931/8253 [30:30<3:58:31,  1.95s/it][A
 11%|█▏        | 931/8253 [30:30<3:58:23,  1.95s/it][A
 11%|█▏        | 931/8253 [30:30<3:58:23,  1.95s/it][A
 11%|█▏        | 931/8253 [30:30<3:58:39,  1.96s/it][A
 11%|█▏        | 931/8253 [30:30<3:58:40,  1.96s/it][A
 11%|█▏        | 932/8253 [30:32<3:57:38,  1.95s/it][A
 11%|█▏        | 932/8253 [30:32<3:57:40,  1.95s/it][A
 11%|█▏        | 932/8253 [30:32<3:57:54,  1.95s/it][A
 11%|█▏        | 932/8253 [30:31<3:58:06,  1.95s/it][A
 11%|█▏        | 932/8253 [30:32<3:58:23,  1.95s/it][A
 11%|█▏        | 932/8253 [30:32<3:58:06,  1.95s/it][A
 11%|█▏        | 933/8253 [30:34<3:58:30,  1.95s/it][A
 11%|█▏        | 933/8253 [30:33<3:58:55,  1.96s/it][A
 11%|█▏        | 933/8253 [30:34<3:59:06,  1.96s/it][A
 11%|█▏        | 933/8253 [30:34<3:59:14,  1.96s/it][A
 11%|█▏        | 933/8253 [30:34<3:59:25,  1.96s/it][A
 11%|█▏        | 933/8253 [30:34<3:59:26,  1.96s/it][A
 11%|█▏        | 934/8253 [30:36<3:59:07,  1.96s/it][A
 11%|█▏        | 934/8253 [30:36<3:59:13,  1.96s/it][A
 11%|█▏        | 934/8253 [30:35<3:59:24,  1.96s/it][A
 11%|█▏        | 934/8253 [30:36<3:59:23,  1.96s/it][A
 11%|█▏        | 934/8253 [30:36<3:59:24,  1.96s/it][A
 11%|█▏        | 934/8253 [30:36<3:59:36,  1.96s/it][A
 11%|█▏        | 935/8253 [30:37<3:58:18,  1.95s/it][A
 11%|█▏        | 935/8253 [30:37<3:59:05,  1.96s/it][A
 11%|█▏        | 935/8253 [30:37<3:59:16,  1.96s/it][A

 11%|█▏        | 935/8253 [30:37<3:59:36,  1.96s/it][A 11%|█▏        | 935/8253 [30:37<3:59:29,  1.96s/it][A
 11%|█▏        | 935/8253 [30:37<3:59:49,  1.97s/it][A
 11%|█▏        | 936/8253 [30:39<4:01:08,  1.98s/it][A
 11%|█▏        | 936/8253 [30:39<4:00:41,  1.97s/it][A
 11%|█▏        | 936/8253 [30:39<4:01:01,  1.98s/it][A
 11%|█▏        | 936/8253 [30:39<4:01:00,  1.98s/it][A
 11%|█▏        | 936/8253 [30:39<4:01:14,  1.98s/it][A
 11%|█▏        | 936/8253 [30:39<4:01:25,  1.98s/it][A

 11%|█▏        | 937/8253 [30:41<4:01:12,  1.98s/it][A 11%|█▏        | 937/8253 [30:41<4:01:38,  1.98s/it][A
 11%|█▏        | 937/8253 [30:41<4:01:29,  1.98s/it][A
 11%|█▏        | 937/8253 [30:41<4:01:31,  1.98s/it][A
 11%|█▏        | 937/8253 [30:41<4:01:34,  1.98s/it][A
 11%|█▏        | 937/8253 [30:41<4:01:44,  1.98s/it][A
 11%|█▏        | 938/8253 [30:43<4:02:32,  1.99s/it][A
 11%|█▏        | 938/8253 [30:43<4:02:19,  1.99s/it][A
 11%|█▏        | 938/8253 [30:43<4:02:31,  1.99s/it][A
 11%|█▏        | 938/8253 [30:43<4:02:47,  1.99s/it][A
 11%|█▏        | 938/8253 [30:43<4:02:52,  1.99s/it]
[A 11%|█▏        | 938/8253 [30:43<4:02:51,  1.99s/it][A
 11%|█▏        | 939/8253 [30:45<3:59:58,  1.97s/it][A
 11%|█▏        | 939/8253 [30:45<4:00:22,  1.97s/it][A
 11%|█▏        | 939/8253 [30:45<4:00:12,  1.97s/it][A
 11%|█▏        | 939/8253 [30:45<4:00:21,  1.97s/it][A
 11%|█▏        | 939/8253 [30:45<4:00:21,  1.97s/it][A
 11%|█▏        | 939/8253 [30:45<4:00:32,  1.97s/it][A

 11%|█▏        | 940/8253 [30:47<4:01:32,  1.98s/it][A 11%|█▏        | 940/8253 [30:47<4:01:49,  1.98s/it][A
 11%|█▏        | 940/8253 [30:47<4:01:27,  1.98s/it][A
 11%|█▏        | 940/8253 [30:47<4:01:28,  1.98s/it][A

 11%|█▏        | 940/8253 [30:47<4:01:38,  1.98s/it][A 11%|█▏        | 940/8253 [30:47<4:01:44,  1.98s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:05,  1.96s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:09,  1.96s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:06,  1.96s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:18,  1.96s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:38,  1.97s/it][A
 11%|█▏        | 941/8253 [30:49<3:59:34,  1.97s/it][A
 11%|█▏        | 942/8253 [30:51<3:58:18,  1.96s/it][A
 11%|█▏        | 942/8253 [30:51<3:58:36,  1.96s/it][A
 11%|█▏        | 942/8253 [30:51<3:58:42,  1.96s/it][A
 11%|█▏        | 942/8253 [30:51<3:58:36,  1.96s/it][A

 11%|█▏        | 942/8253 [30:51<3:58:46,  1.96s/it][A 11%|█▏        | 942/8253 [30:51<3:58:47,  1.96s/it][A
 11%|█▏        | 943/8253 [30:53<3:58:00,  1.95s/it][A
 11%|█▏        | 943/8253 [30:53<3:57:58,  1.95s/it][A
 11%|█▏        | 943/8253 [30:53<3:57:49,  1.95s/it][A
 11%|█▏        | 943/8253 [30:53<3:58:02,  1.95s/it][A
 11%|█▏        | 943/8253 [30:53<3:58:03,  1.95s/it][A
 11%|█▏        | 943/8253 [30:53<3:58:12,  1.96s/it][A
 11%|█▏        | 944/8253 [30:55<4:05:42,  2.02s/it][A
 11%|█▏        | 944/8253 [30:55<4:05:25,  2.01s/it][A
 11%|█▏        | 944/8253 [30:55<4:05:56,  2.02s/it][A
 11%|█▏        | 944/8253 [30:55<4:05:51,  2.02s/it][A
 11%|█▏        | 944/8253 [30:55<4:06:10,  2.02s/it][A
 11%|█▏        | 944/8253 [30:55<4:06:16,  2.02s/it][A
 11%|█▏        | 945/8253 [30:57<4:01:25,  1.98s/it][A
 11%|█▏        | 945/8253 [30:57<4:02:10,  1.99s/it][A
 11%|█▏        | 945/8253 [30:57<4:01:53,  1.99s/it][A
 11%|█▏        | 945/8253 [30:57<4:02:19,  1.99s/it][A
 11%|█▏        | 945/8253 [30:57<4:02:23,  1.99s/it][A
 11%|█▏        | 945/8253 [30:57<4:02:18,  1.99s/it][A
 11%|█▏        | 946/8253 [30:59<4:03:23,  2.00s/it][A
 11%|█▏        | 946/8253 [30:59<4:03:36,  2.00s/it][A
 11%|█▏        | 946/8253 [30:59<4:03:36,  2.00s/it][A
 11%|█▏        | 946/8253 [30:59<4:04:05,  2.00s/it][A
 11%|█▏        | 946/8253 [30:59<4:03:44,  2.00s/it][A
 11%|█▏        | 946/8253 [30:59<4:04:02,  2.00s/it][A
 11%|█▏        | 947/8253 [31:01<4:03:35,  2.00s/it][A
 11%|█▏        | 947/8253 [31:01<4:03:48,  2.00s/it][A
 11%|█▏        | 947/8253 [31:01<4:03:58,  2.00s/it][A

 11%|█▏        | 947/8253 [31:01<4:04:13,  2.01s/it][A 11%|█▏        | 947/8253 [31:01<4:04:13,  2.01s/it][A
 11%|█▏        | 947/8253 [31:01<4:04:20,  2.01s/it][A
 11%|█▏        | 948/8253 [31:03<4:03:47,  2.00s/it][A
 11%|█▏        | 948/8253 [31:03<4:04:03,  2.00s/it][A

 11%|█▏        | 948/8253 [31:03<4:04:26,  2.01s/it][A 11%|█▏        | 948/8253 [31:03<4:04:36,  2.01s/it][A

 11%|█▏        | 948/8253 [31:03<4:04:32,  2.01s/it][A 11%|█▏        | 948/8253 [31:03<4:04:32,  2.01s/it][A
 11%|█▏        | 949/8253 [31:05<4:01:38,  1.98s/it][A
 11%|█▏        | 949/8253 [31:05<4:01:48,  1.99s/it][A
 11%|█▏        | 949/8253 [31:05<4:02:12,  1.99s/it][A
 11%|█▏        | 949/8253 [31:05<4:02:13,  1.99s/it][A
 11%|█▏        | 949/8253 [31:05<4:02:22,  1.99s/it][A
 11%|█▏        | 949/8253 [31:05<4:02:12,  1.99s/it][A
 12%|█▏        | 950/8253 [31:07<4:02:09,  1.99s/it][A
 12%|█▏        | 950/8253 [31:07<4:02:31,  1.99s/it][A

 12%|█▏        | 950/8253 [31:07<4:02:34,  1.99s/it][A 12%|█▏        | 950/8253 [31:07<4:02:29,  1.99s/it][A
 12%|█▏        | 950/8253 [31:07<4:02:39,  1.99s/it][A
 12%|█▏        | 950/8253 [31:07<4:02:37,  1.99s/it][A
 12%|█▏        | 951/8253 [31:09<4:03:54,  2.00s/it][A
 12%|█▏        | 951/8253 [31:09<4:03:59,  2.00s/it][A
 12%|█▏        | 951/8253 [31:09<4:03:57,  2.00s/it][A
 12%|█▏        | 951/8253 [31:09<4:03:59,  2.00s/it][A
 12%|█▏        | 951/8253 [31:09<4:04:10,  2.01s/it][A
 12%|█▏        | 951/8253 [31:09<4:04:06,  2.01s/it][A
 12%|█▏        | 952/8253 [31:11<4:01:06,  1.98s/it][A
 12%|█▏        | 952/8253 [31:11<4:01:18,  1.98s/it][A

 12%|█▏        | 952/8253 [31:11<4:01:53,  1.99s/it][A 12%|█▏        | 952/8253 [31:11<4:01:53,  1.99s/it][A
 12%|█▏        | 952/8253 [31:11<4:01:56,  1.99s/it][A
 12%|█▏        | 952/8253 [31:11<4:01:42,  1.99s/it][A
 12%|█▏        | 953/8253 [31:13<4:00:41,  1.98s/it][A
 12%|█▏        | 953/8253 [31:13<4:00:46,  1.98s/it][A
 12%|█▏        | 953/8253 [31:13<4:01:02,  1.98s/it][A
 12%|█▏        | 953/8253 [31:13<4:00:50,  1.98s/it][A
 12%|█▏        | 953/8253 [31:13<4:01:13,  1.98s/it][A
 12%|█▏        | 953/8253 [31:13<4:00:57,  1.98s/it][A
 12%|█▏        | 954/8253 [31:15<3:59:22,  1.97s/it][A
 12%|█▏        | 954/8253 [31:15<3:59:39,  1.97s/it][A
 12%|█▏        | 954/8253 [31:15<3:59:27,  1.97s/it][A
 12%|█▏        | 954/8253 [31:15<3:59:42,  1.97s/it][A
 12%|█▏        | 954/8253 [31:15<4:00:08,  1.97s/it][A
 12%|█▏        | 954/8253 [31:15<4:00:02,  1.97s/it][A
 12%|█▏        | 955/8253 [31:17<4:00:35,  1.98s/it][A
 12%|█▏        | 955/8253 [31:17<4:00:41,  1.98s/it][A
 12%|█▏        | 955/8253 [31:17<4:00:40,  1.98s/it][A
 12%|█▏        | 955/8253 [31:17<4:01:02,  1.98s/it][A

 12%|█▏        | 955/8253 [31:17<4:00:51,  1.98s/it][A 12%|█▏        | 955/8253 [31:17<4:01:10,  1.98s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:36,  1.96s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:38,  1.96s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:45,  1.96s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:39,  1.96s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:53,  1.96s/it][A
 12%|█▏        | 956/8253 [31:19<3:58:50,  1.96s/it][A
 12%|█▏        | 957/8253 [31:21<3:58:32,  1.96s/it][A

 12%|█▏        | 957/8253 [31:21<3:58:46,  1.96s/it][A 12%|█▏        | 957/8253 [31:21<3:58:54,  1.96s/it][A
 12%|█▏        | 957/8253 [31:21<3:58:49,  1.96s/it][A
 12%|█▏        | 957/8253 [31:21<3:58:53,  1.96s/it][A
 12%|█▏        | 957/8253 [31:21<3:58:56,  1.96s/it][A
 12%|█▏        | 958/8253 [31:23<4:00:40,  1.98s/it][A
 12%|█▏        | 958/8253 [31:23<4:00:41,  1.98s/it][A
 12%|█▏        | 958/8253 [31:23<4:00:54,  1.98s/it][A
 12%|█▏        | 958/8253 [31:23<4:01:08,  1.98s/it][A
 12%|█▏        | 958/8253 [31:23<4:00:57,  1.98s/it][A
 12%|█▏        | 958/8253 [31:23<4:00:52,  1.98s/it][A
 12%|█▏        | 959/8253 [31:25<3:58:49,  1.96s/it][A
 12%|█▏        | 959/8253 [31:25<3:58:54,  1.97s/it][A
 12%|█▏        | 959/8253 [31:25<3:58:56,  1.97s/it][A
 12%|█▏        | 959/8253 [31:25<3:59:14,  1.97s/it][A
 12%|█▏        | 959/8253 [31:25<3:58:59,  1.97s/it][A
 12%|█▏        | 959/8253 [31:25<3:59:36,  1.97s/it][A
 12%|█▏        | 960/8253 [31:27<3:56:44,  1.95s/it][A
 12%|█▏        | 960/8253 [31:27<3:56:44,  1.95s/it][A
 12%|█▏        | 960/8253 [31:27<3:57:03,  1.95s/it][A

 12%|█▏        | 960/8253 [31:27<3:57:24,  1.95s/it][A 12%|█▏        | 960/8253 [31:27<3:57:15,  1.95s/it][A
 12%|█▏        | 960/8253 [31:27<3:57:34,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:56:51,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:57:08,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:57:06,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:57:18,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:57:29,  1.95s/it][A
 12%|█▏        | 961/8253 [31:29<3:57:19,  1.95s/it][A
 12%|█▏        | 962/8253 [31:31<3:59:08,  1.97s/it][A
 12%|█▏        | 962/8253 [31:31<3:59:15,  1.97s/it][A
 12%|█▏        | 962/8253 [31:31<3:59:10,  1.97s/it][A

 12%|█▏        | 962/8253 [31:31<3:59:24,  1.97s/it][A 12%|█▏        | 962/8253 [31:31<3:59:31,  1.97s/it][A
 12%|█▏        | 962/8253 [31:31<3:59:46,  1.97s/it][A
 12%|█▏        | 963/8253 [31:33<3:59:45,  1.97s/it][A
 12%|█▏        | 963/8253 [31:33<4:00:04,  1.98s/it][A
 12%|█▏        | 963/8253 [31:33<4:00:12,  1.98s/it][A
 12%|█▏        | 963/8253 [31:33<4:00:09,  1.98s/it][A
 12%|█▏        | 963/8253 [31:33<4:00:23,  1.98s/it][A
 12%|█▏        | 963/8253 [31:33<4:00:32,  1.98s/it][A
 12%|█▏        | 964/8253 [31:35<3:58:26,  1.96s/it][A

 12%|█▏        | 964/8253 [31:35<3:58:25,  1.96s/it]
[A 12%|█▏        | 964/8253 [31:35<3:58:22,  1.96s/it][A 12%|█▏        | 964/8253 [31:35<3:58:25,  1.96s/it][A
 12%|█▏        | 964/8253 [31:35<3:58:42,  1.96s/it][A
 12%|█▏        | 964/8253 [31:35<3:58:37,  1.96s/it][A
 12%|█▏        | 965/8253 [31:37<4:00:52,  1.98s/it][A
 12%|█▏        | 965/8253 [31:37<4:01:03,  1.98s/it][A
 12%|█▏        | 965/8253 [31:37<4:01:05,  1.98s/it][A
 12%|█▏        | 965/8253 [31:37<4:01:27,  1.99s/it][A
 12%|█▏        | 965/8253 [31:37<4:01:30,  1.99s/it][A
 12%|█▏        | 965/8253 [31:37<4:01:38,  1.99s/it][A
 12%|█▏        | 966/8253 [31:39<4:02:53,  2.00s/it][A
 12%|█▏        | 966/8253 [31:39<4:02:48,  2.00s/it][A
 12%|█▏        | 966/8253 [31:39<4:03:13,  2.00s/it][A
 12%|█▏        | 966/8253 [31:39<4:03:17,  2.00s/it][A
 12%|█▏        | 966/8253 [31:39<4:03:21,  2.00s/it][A
 12%|█▏        | 966/8253 [31:39<4:03:25,  2.00s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:04,  1.99s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:10,  1.99s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:30,  1.99s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:33,  1.99s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:21,  1.99s/it][A
 12%|█▏        | 967/8253 [31:41<4:01:31,  1.99s/it][A
 12%|█▏        | 968/8253 [31:43<4:00:57,  1.98s/it][A
 12%|█▏        | 968/8253 [31:43<4:01:01,  1.99s/it][A
 12%|█▏        | 968/8253 [31:43<4:01:16,  1.99s/it][A
 12%|█▏        | 968/8253 [31:43<4:01:29,  1.99s/it][A
 12%|█▏        | 968/8253 [31:43<4:01:24,  1.99s/it][A
 12%|█▏        | 968/8253 [31:43<4:01:37,  1.99s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:15,  1.98s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:30,  1.98s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:16,  1.98s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:31,  1.98s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:48,  1.98s/it][A
 12%|█▏        | 969/8253 [31:45<4:00:52,  1.98s/it][A
 12%|█▏        | 970/8253 [31:47<3:59:30,  1.97s/it][A
 12%|█▏        | 970/8253 [31:47<3:59:32,  1.97s/it][A

 12%|█▏        | 970/8253 [31:47<3:59:57,  1.98s/it][A 12%|█▏        | 970/8253 [31:47<4:00:06,  1.98s/it][A
 12%|█▏        | 970/8253 [31:47<3:59:56,  1.98s/it][A
 12%|█▏        | 970/8253 [31:47<4:00:01,  1.98s/it][A
 12%|█▏        | 971/8253 [31:49<3:58:34,  1.97s/it][A
 12%|█▏        | 971/8253 [31:49<3:58:58,  1.97s/it][A
 12%|█▏        | 971/8253 [31:49<3:59:00,  1.97s/it][A
 12%|█▏        | 971/8253 [31:49<3:59:07,  1.97s/it][A
 12%|█▏        | 971/8253 [31:49<3:58:52,  1.97s/it][A
 12%|█▏        | 971/8253 [31:49<3:59:11,  1.97s/it][A
 12%|█▏        | 972/8253 [31:51<3:57:41,  1.96s/it][A
 12%|█▏        | 972/8253 [31:51<3:57:47,  1.96s/it][A
 12%|█▏        | 972/8253 [31:51<3:58:43,  1.97s/it][A
 12%|█▏        | 972/8253 [31:51<3:58:36,  1.97s/it][A
 12%|█▏        | 972/8253 [31:51<3:58:22,  1.96s/it][A
 12%|█▏        | 972/8253 [31:51<3:58:41,  1.97s/it][A
 12%|█▏        | 973/8253 [31:53<3:57:13,  1.96s/it][A
 12%|█▏        | 973/8253 [31:53<3:57:58,  1.96s/it][A
 12%|█▏        | 973/8253 [31:53<3:58:04,  1.96s/it][A
 12%|█▏        | 973/8253 [31:53<3:58:35,  1.97s/it][A
 12%|█▏        | 973/8253 [31:53<3:58:11,  1.96s/it][A
 12%|█▏        | 973/8253 [31:53<3:58:10,  1.96s/it][A
 12%|█▏        | 974/8253 [31:55<3:58:46,  1.97s/it][A
 12%|█▏        | 974/8253 [31:55<3:59:22,  1.97s/it][A
 12%|█▏        | 974/8253 [31:55<3:59:09,  1.97s/it][A
 12%|█▏        | 974/8253 [31:55<3:59:03,  1.97s/it][A
 12%|█▏        | 974/8253 [31:55<3:59:36,  1.98s/it][A
 12%|█▏        | 974/8253 [31:55<3:59:20,  1.97s/it][A
 12%|█▏        | 975/8253 [31:57<3:57:51,  1.96s/it][A
 12%|█▏        | 975/8253 [31:56<3:58:31,  1.97s/it][A
 12%|█▏        | 975/8253 [31:57<3:58:42,  1.97s/it][A
 12%|█▏        | 975/8253 [31:57<3:58:51,  1.97s/it][A

 12%|█▏        | 975/8253 [31:57<3:58:41,  1.97s/it][A 12%|█▏        | 975/8253 [31:57<3:58:46,  1.97s/it][A
 12%|█▏        | 976/8253 [31:59<3:58:10,  1.96s/it][A
 12%|█▏        | 976/8253 [31:59<3:58:06,  1.96s/it][A
 12%|█▏        | 976/8253 [31:59<3:58:31,  1.97s/it][A
 12%|█▏        | 976/8253 [31:59<3:58:44,  1.97s/it][A
 12%|█▏        | 976/8253 [31:58<3:58:44,  1.97s/it][A
 12%|█▏        | 976/8253 [31:59<3:58:35,  1.97s/it][A
 12%|█▏        | 977/8253 [32:01<3:56:42,  1.95s/it][A
 12%|█▏        | 977/8253 [32:00<3:56:43,  1.95s/it][A
 12%|█▏        | 977/8253 [32:01<3:57:07,  1.96s/it][A
 12%|█▏        | 977/8253 [32:01<3:56:47,  1.95s/it][A
 12%|█▏        | 977/8253 [32:01<3:57:09,  1.96s/it][A
 12%|█▏        | 977/8253 [32:01<3:57:11,  1.96s/it][A
 12%|█▏        | 978/8253 [32:02<3:55:34,  1.94s/it][A
 12%|█▏        | 978/8253 [32:02<3:55:52,  1.95s/it][A
 12%|█▏        | 978/8253 [32:02<3:55:51,  1.95s/it][A
 12%|█▏        | 978/8253 [32:02<3:56:04,  1.95s/it][A

 12%|█▏        | 978/8253 [32:02<3:56:13,  1.95s/it][A 12%|█▏        | 978/8253 [32:02<3:56:08,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:55:56,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:56:04,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:56:00,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:56:09,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:56:24,  1.95s/it][A
 12%|█▏        | 979/8253 [32:04<3:56:17,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:56:03,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:55:54,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:56:03,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:56:03,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:56:13,  1.95s/it][A
 12%|█▏        | 980/8253 [32:06<3:56:16,  1.95s/it][A
 12%|█▏        | 981/8253 [32:08<3:54:30,  1.93s/it][A
 12%|█▏        | 981/8253 [32:08<3:54:27,  1.93s/it][A
 12%|█▏        | 981/8253 [32:08<3:54:24,  1.93s/it][A
 12%|█▏        | 981/8253 [32:08<3:54:43,  1.94s/it][A
 12%|█▏        | 981/8253 [32:08<3:55:00,  1.94s/it][A
 12%|█▏        | 981/8253 [32:08<3:54:51,  1.94s/it][A
 12%|█▏        | 982/8253 [32:10<3:55:22,  1.94s/it][A
 12%|█▏        | 982/8253 [32:10<3:55:29,  1.94s/it][A
 12%|█▏        | 982/8253 [32:10<3:55:29,  1.94s/it][A
 12%|█▏        | 982/8253 [32:10<3:55:43,  1.95s/it][A

 12%|█▏        | 982/8253 [32:10<3:56:04,  1.95s/it][A 12%|█▏        | 982/8253 [32:10<3:55:59,  1.95s/it][A
 12%|█▏        | 983/8253 [32:12<3:56:51,  1.95s/it][A
 12%|█▏        | 983/8253 [32:12<3:56:46,  1.95s/it][A
 12%|█▏        | 983/8253 [32:12<3:57:02,  1.96s/it][A
 12%|█▏        | 983/8253 [32:12<3:57:05,  1.96s/it][A
 12%|█▏        | 983/8253 [32:12<3:57:06,  1.96s/it][A
 12%|█▏        | 983/8253 [32:12<3:57:13,  1.96s/it][A
 12%|█▏        | 984/8253 [32:14<3:56:20,  1.95s/it][A
 12%|█▏        | 984/8253 [32:14<3:56:44,  1.95s/it][A
 12%|█▏        | 984/8253 [32:14<3:56:49,  1.95s/it][A
 12%|█▏        | 984/8253 [32:14<3:57:06,  1.96s/it][A
 12%|█▏        | 984/8253 [32:14<3:56:50,  1.95s/it][A
 12%|█▏        | 984/8253 [32:14<3:56:56,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:56:51,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:56:59,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:56:54,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:57:13,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:57:24,  1.96s/it][A
 12%|█▏        | 985/8253 [32:16<3:57:13,  1.96s/it][A
 12%|█▏        | 986/8253 [32:18<3:59:08,  1.97s/it][A
 12%|█▏        | 986/8253 [32:18<3:58:59,  1.97s/it][A
 12%|█▏        | 986/8253 [32:18<3:59:28,  1.98s/it][A
 12%|█▏        | 986/8253 [32:18<3:59:12,  1.98s/it][A
 12%|█▏        | 986/8253 [32:18<3:59:16,  1.98s/it][A
 12%|█▏        | 986/8253 [32:18<3:59:15,  1.98s/it][A
 12%|█▏        | 987/8253 [32:20<3:56:18,  1.95s/it][A
 12%|█▏        | 987/8253 [32:20<3:56:55,  1.96s/it][A
 12%|█▏        | 987/8253 [32:20<3:56:52,  1.96s/it][A
 12%|█▏        | 987/8253 [32:20<3:56:45,  1.96s/it][A
 12%|█▏        | 987/8253 [32:20<3:56:59,  1.96s/it][A
 12%|█▏        | 987/8253 [32:20<3:57:00,  1.96s/it][A
 12%|█▏        | 988/8253 [32:22<3:56:52,  1.96s/it][A
 12%|█▏        | 988/8253 [32:22<3:56:49,  1.96s/it][A
 12%|█▏        | 988/8253 [32:22<3:57:01,  1.96s/it][A

 12%|█▏        | 988/8253 [32:22<3:57:05,  1.96s/it][A 12%|█▏        | 988/8253 [32:22<3:57:01,  1.96s/it][A
 12%|█▏        | 988/8253 [32:22<3:57:27,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:57:25,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:57:34,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:57:45,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:57:53,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:57:36,  1.96s/it][A
 12%|█▏        | 989/8253 [32:24<3:58:10,  1.97s/it][A
 12%|█▏        | 990/8253 [32:26<3:56:48,  1.96s/it][A
 12%|█▏        | 990/8253 [32:26<3:56:47,  1.96s/it][A
 12%|█▏        | 990/8253 [32:26<3:57:00,  1.96s/it][A
 12%|█▏        | 990/8253 [32:26<3:57:00,  1.96s/it][A
 12%|█▏        | 990/8253 [32:26<3:57:13,  1.96s/it][A
 12%|█▏        | 990/8253 [32:26<3:57:02,  1.96s/it][A
 12%|█▏        | 991/8253 [32:28<3:53:16,  1.93s/it][A
 12%|█▏        | 991/8253 [32:28<3:53:46,  1.93s/it][A
 12%|█▏        | 991/8253 [32:28<3:53:44,  1.93s/it][A
 12%|█▏        | 991/8253 [32:28<3:54:00,  1.93s/it][A
 12%|█▏        | 991/8253 [32:28<3:53:54,  1.93s/it][A
 12%|█▏        | 991/8253 [32:28<3:54:01,  1.93s/it][A
 12%|█▏        | 992/8253 [32:30<3:54:51,  1.94s/it][A
 12%|█▏        | 992/8253 [32:30<3:54:53,  1.94s/it][A
 12%|█▏        | 992/8253 [32:30<3:55:01,  1.94s/it][A
 12%|█▏        | 992/8253 [32:30<3:55:10,  1.94s/it][A
 12%|█▏        | 992/8253 [32:30<3:55:29,  1.95s/it][A
 12%|█▏        | 992/8253 [32:30<3:55:32,  1.95s/it][A
 12%|█▏        | 993/8253 [32:32<3:55:08,  1.94s/it][A

 12%|█▏        | 993/8253 [32:32<3:55:21,  1.95s/it][A
 12%|█▏        | 993/8253 [32:32<3:55:20,  1.94s/it][A 12%|█▏        | 993/8253 [32:32<3:55:28,  1.95s/it][A
 12%|█▏        | 993/8253 [32:32<3:55:32,  1.95s/it][A
 12%|█▏        | 993/8253 [32:32<3:55:37,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:20,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:24,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:39,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:35,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:37,  1.95s/it][A
 12%|█▏        | 994/8253 [32:34<3:55:51,  1.95s/it][A
 12%|█▏        | 995/8253 [32:36<3:54:19,  1.94s/it][A

 12%|█▏        | 995/8253 [32:35<3:54:21,  1.94s/it][A 12%|█▏        | 995/8253 [32:36<3:54:27,  1.94s/it][A
 12%|█▏        | 995/8253 [32:36<3:54:37,  1.94s/it][A
 12%|█▏        | 995/8253 [32:36<3:54:40,  1.94s/it][A
 12%|█▏        | 995/8253 [32:36<3:54:48,  1.94s/it][A

 12%|█▏        | 996/8253 [32:38<3:56:53,  1.96s/it][A 12%|█▏        | 996/8253 [32:38<3:56:43,  1.96s/it][A
 12%|█▏        | 996/8253 [32:38<3:57:01,  1.96s/it][A
 12%|█▏        | 996/8253 [32:38<3:56:47,  1.96s/it][A
 12%|█▏        | 996/8253 [32:37<3:57:05,  1.96s/it][A
 12%|█▏        | 996/8253 [32:38<3:57:00,  1.96s/it][A
 12%|█▏        | 997/8253 [32:39<3:56:43,  1.96s/it][A
 12%|█▏        | 997/8253 [32:40<3:56:51,  1.96s/it][A
 12%|█▏        | 997/8253 [32:40<3:56:58,  1.96s/it][A
 12%|█▏        | 997/8253 [32:40<3:57:04,  1.96s/it][A

 12%|█▏        | 997/8253 [32:40<3:57:16,  1.96s/it][A 12%|█▏        | 997/8253 [32:40<3:57:15,  1.96s/it][A
 12%|█▏        | 998/8253 [32:42<4:00:40,  1.99s/it][A
 12%|█▏        | 998/8253 [32:42<4:00:45,  1.99s/it][A
 12%|█▏        | 998/8253 [32:41<4:00:51,  1.99s/it][A

 12%|█▏        | 998/8253 [32:42<4:00:56,  1.99s/it][A 12%|█▏        | 998/8253 [32:42<4:01:01,  1.99s/it][A
 12%|█▏        | 998/8253 [32:42<4:00:58,  1.99s/it][A
 12%|█▏        | 999/8253 [32:44<3:59:30,  1.98s/it][A
 12%|█▏        | 999/8253 [32:44<3:59:26,  1.98s/it][A

 12%|█▏        | 999/8253 [32:44<3:59:35,  1.98s/it][A 12%|█▏        | 999/8253 [32:44<3:59:53,  1.98s/it][A
 12%|█▏        | 999/8253 [32:43<3:59:55,  1.98s/it][A
 12%|█▏        | 999/8253 [32:44<3:59:47,  1.98s/it][A
 12%|█▏        | 1000/8253 [32:46<3:59:39,  1.98s/it][A
 12%|█▏        | 1000/8253 [32:46<3:59:20,  1.98s/it][A
 12%|█▏        | 1000/8253 [32:46<3:59:56,  1.98s/it][A
 12%|█▏        | 1000/8253 [32:46<4:00:16,  1.99s/it][A
 12%|█▏        | 1000/8253 [32:45<4:00:20,  1.99s/it][A
 12%|█▏        | 1000/8253 [32:46<4:00:12,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:48<4:00:12,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:48<4:00:22,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:47<4:00:33,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:48<4:01:00,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:48<4:00:55,  1.99s/it][A
 12%|█▏        | 1001/8253 [32:48<4:00:45,  1.99s/it][A
 12%|█▏        | 1002/8253 [32:50<3:59:35,  1.98s/it][A
 12%|█▏        | 1002/8253 [32:50<3:59:56,  1.99s/it][A
 12%|█▏        | 1002/8253 [32:50<4:00:12,  1.99s/it][A
 12%|█▏        | 1002/8253 [32:50<4:00:23,  1.99s/it][A

 12%|█▏        | 1002/8253 [32:50<4:00:19,  1.99s/it][A 12%|█▏        | 1002/8253 [32:49<4:00:22,  1.99s/it][A
 12%|█▏        | 1003/8253 [32:51<3:57:22,  1.96s/it][A
 12%|█▏        | 1003/8253 [32:51<3:57:23,  1.96s/it][A
 12%|█▏        | 1003/8253 [32:51<3:57:47,  1.97s/it][A
 12%|█▏        | 1003/8253 [32:51<3:57:37,  1.97s/it][A
 12%|█▏        | 1003/8253 [32:51<3:57:42,  1.97s/it][A
 12%|█▏        | 1003/8253 [32:51<3:58:01,  1.97s/it][A
 12%|█▏        | 1004/8253 [32:53<3:57:16,  1.96s/it][A
 12%|█▏        | 1004/8253 [32:53<3:57:26,  1.97s/it][A

 12%|█▏        | 1004/8253 [32:53<3:57:20,  1.96s/it][A 12%|█▏        | 1004/8253 [32:53<3:57:42,  1.97s/it][A
 12%|█▏        | 1004/8253 [32:53<3:57:35,  1.97s/it][A
 12%|█▏        | 1004/8253 [32:53<3:57:51,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:57:23,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:57:47,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:58:04,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:58:13,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:58:05,  1.97s/it][A
 12%|█▏        | 1005/8253 [32:55<3:58:05,  1.97s/it][A
 12%|█▏        | 1006/8253 [32:57<3:58:52,  1.98s/it][A
 12%|█▏        | 1006/8253 [32:57<3:58:56,  1.98s/it][A
 12%|█▏        | 1006/8253 [32:57<3:59:07,  1.98s/it][A
 12%|█▏        | 1006/8253 [32:57<3:59:23,  1.98s/it][A
 12%|█▏        | 1006/8253 [32:57<3:59:28,  1.98s/it][A
 12%|█▏        | 1006/8253 [32:57<3:59:33,  1.98s/it][A
 12%|█▏        | 1007/8253 [32:59<3:56:57,  1.96s/it][A
 12%|█▏        | 1007/8253 [32:59<3:56:44,  1.96s/it][A
 12%|█▏        | 1007/8253 [32:59<3:57:00,  1.96s/it][A

 12%|█▏        | 1007/8253 [32:59<3:56:58,  1.96s/it][A 12%|█▏        | 1007/8253 [32:59<3:57:01,  1.96s/it][A
 12%|█▏        | 1007/8253 [32:59<3:57:07,  1.96s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:18,  1.94s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:30,  1.94s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:43,  1.94s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:52,  1.95s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:45,  1.94s/it][A
 12%|█▏        | 1008/8253 [33:01<3:54:53,  1.95s/it][A
 12%|█▏        | 1009/8253 [33:03<3:54:47,  1.94s/it][A
 12%|█▏        | 1009/8253 [33:03<3:55:07,  1.95s/it][A
 12%|█▏        | 1009/8253 [33:03<3:55:02,  1.95s/it][A
 12%|█▏        | 1009/8253 [33:03<3:55:31,  1.95s/it][A

 12%|█▏        | 1009/8253 [33:03<3:55:32,  1.95s/it][A 12%|█▏        | 1009/8253 [33:03<3:55:39,  1.95s/it][A
 12%|█▏        | 1010/8253 [33:05<3:55:59,  1.95s/it][A
 12%|█▏        | 1010/8253 [33:05<3:56:00,  1.96s/it][A
 12%|█▏        | 1010/8253 [33:05<3:56:05,  1.96s/it][A
 12%|█▏        | 1010/8253 [33:05<3:56:15,  1.96s/it][A
 12%|█▏        | 1010/8253 [33:05<3:56:13,  1.96s/it][A
 12%|█▏        | 1010/8253 [33:05<3:56:13,  1.96s/it][A
 12%|█▏        | 1011/8253 [33:07<3:56:44,  1.96s/it][A
 12%|█▏        | 1011/8253 [33:07<3:56:51,  1.96s/it][A
 12%|█▏        | 1011/8253 [33:07<3:57:06,  1.96s/it][A
 12%|█▏        | 1011/8253 [33:07<3:56:51,  1.96s/it][A
 12%|█▏        | 1011/8253 [33:07<3:57:11,  1.97s/it][A
 12%|█▏        | 1011/8253 [33:07<3:57:23,  1.97s/it][A
 12%|█▏        | 1012/8253 [33:09<3:57:40,  1.97s/it][A
 12%|█▏        | 1012/8253 [33:09<3:57:52,  1.97s/it][A
 12%|█▏        | 1012/8253 [33:09<3:58:00,  1.97s/it][A
 12%|█▏        | 1012/8253 [33:09<3:58:18,  1.97s/it][A

 12%|█▏        | 1012/8253 [33:09<3:58:06,  1.97s/it][A 12%|█▏        | 1012/8253 [33:09<3:58:26,  1.98s/it][A
 12%|█▏        | 1013/8253 [33:11<3:57:56,  1.97s/it][A
 12%|█▏        | 1013/8253 [33:11<3:58:13,  1.97s/it][A
 12%|█▏        | 1013/8253 [33:11<3:58:19,  1.98s/it][A
 12%|█▏        | 1013/8253 [33:11<3:58:36,  1.98s/it][A
 12%|█▏        | 1013/8253 [33:11<3:58:35,  1.98s/it][A
 12%|█▏        | 1013/8253 [33:11<3:58:34,  1.98s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:09,  1.98s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:18,  1.98s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:16,  1.98s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:44,  1.99s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:33,  1.99s/it][A
 12%|█▏        | 1014/8253 [33:13<3:59:52,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<3:59:56,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<4:00:12,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<4:00:28,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<4:00:23,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<4:00:26,  1.99s/it][A
 12%|█▏        | 1015/8253 [33:15<4:00:30,  1.99s/it][A

 12%|█▏        | 1016/8253 [33:17<4:00:45,  2.00s/it][A 12%|█▏        | 1016/8253 [33:17<4:00:37,  1.99s/it][A
 12%|█▏        | 1016/8253 [33:17<4:00:48,  2.00s/it][A
 12%|█▏        | 1016/8253 [33:17<4:00:50,  2.00s/it][A
 12%|█▏        | 1016/8253 [33:17<4:00:52,  2.00s/it][A
 12%|█▏        | 1016/8253 [33:17<4:01:00,  2.00s/it][A
 12%|█▏        | 1017/8253 [33:19<3:58:06,  1.97s/it][A
 12%|█▏        | 1017/8253 [33:19<3:58:52,  1.98s/it][A
 12%|█▏        | 1017/8253 [33:19<3:59:10,  1.98s/it][A
 12%|█▏        | 1017/8253 [33:19<3:59:00,  1.98s/it][A
 12%|█▏        | 1017/8253 [33:19<3:59:01,  1.98s/it][A
 12%|█▏        | 1017/8253 [33:19<3:59:13,  1.98s/it][A
 12%|█▏        | 1018/8253 [33:21<3:57:58,  1.97s/it][A
 12%|█▏        | 1018/8253 [33:21<3:58:10,  1.98s/it][A

 12%|█▏        | 1018/8253 [33:21<3:58:09,  1.98s/it][A 12%|█▏        | 1018/8253 [33:21<3:58:10,  1.98s/it][A
 12%|█▏        | 1018/8253 [33:21<3:58:39,  1.98s/it][A
 12%|█▏        | 1018/8253 [33:21<3:58:52,  1.98s/it][A
 12%|█▏        | 1019/8253 [33:23<3:56:51,  1.96s/it][A
 12%|█▏        | 1019/8253 [33:23<3:57:11,  1.97s/it][A
 12%|█▏        | 1019/8253 [33:23<3:57:25,  1.97s/it][A
 12%|█▏        | 1019/8253 [33:23<3:57:22,  1.97s/it][A

 12%|█▏        | 1019/8253 [33:23<3:57:36,  1.97s/it][A 12%|█▏        | 1019/8253 [33:23<3:57:35,  1.97s/it][A
 12%|█▏        | 1020/8253 [33:25<3:56:34,  1.96s/it][A
 12%|█▏        | 1020/8253 [33:25<3:56:57,  1.97s/it][A
 12%|█▏        | 1020/8253 [33:25<3:56:46,  1.96s/it][A
 12%|█▏        | 1020/8253 [33:25<3:57:01,  1.97s/it][A
 12%|█▏        | 1020/8253 [33:25<3:57:10,  1.97s/it][A
 12%|█▏        | 1020/8253 [33:25<3:57:10,  1.97s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:18,  1.96s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:04,  1.96s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:39,  1.96s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:37,  1.96s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:41,  1.96s/it][A
 12%|█▏        | 1021/8253 [33:27<3:56:50,  1.96s/it][A
 12%|█▏        | 1022/8253 [33:29<3:54:29,  1.95s/it][A
 12%|█▏        | 1022/8253 [33:29<3:55:08,  1.95s/it][A
 12%|█▏        | 1022/8253 [33:29<3:55:03,  1.95s/it][A
 12%|█▏        | 1022/8253 [33:29<3:55:08,  1.95s/it][A
 12%|█▏        | 1022/8253 [33:29<3:55:19,  1.95s/it][A
 12%|█▏        | 1022/8253 [33:29<3:55:20,  1.95s/it][A
 12%|█▏        | 1023/8253 [33:31<3:55:29,  1.95s/it][A
 12%|█▏        | 1023/8253 [33:31<3:55:13,  1.95s/it][A
 12%|█▏        | 1023/8253 [33:31<3:55:21,  1.95s/it][A

 12%|█▏        | 1023/8253 [33:31<3:55:16,  1.95s/it][A 12%|█▏        | 1023/8253 [33:31<3:55:22,  1.95s/it][A
 12%|█▏        | 1023/8253 [33:31<3:55:17,  1.95s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:21,  1.97s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:53,  1.97s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:45,  1.97s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:44,  1.97s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:49,  1.97s/it][A
 12%|█▏        | 1024/8253 [33:33<3:57:59,  1.98s/it][A
 12%|█▏        | 1025/8253 [33:35<3:57:30,  1.97s/it][A
 12%|█▏        | 1025/8253 [33:35<3:57:32,  1.97s/it][A
 12%|█▏        | 1025/8253 [33:35<3:57:40,  1.97s/it][A
 12%|█▏        | 1025/8253 [33:35<3:57:39,  1.97s/it][A
 12%|█▏        | 1025/8253 [33:35<3:58:00,  1.98s/it][A
 12%|█▏        | 1025/8253 [33:35<3:57:52,  1.97s/it][A
 12%|█▏        | 1026/8253 [33:37<3:57:39,  1.97s/it][A
 12%|█▏        | 1026/8253 [33:37<3:58:12,  1.98s/it][A
 12%|█▏        | 1026/8253 [33:37<3:58:03,  1.98s/it][A
 12%|█▏        | 1026/8253 [33:37<3:58:13,  1.98s/it][A
 12%|█▏        | 1026/8253 [33:37<3:58:14,  1.98s/it][A
 12%|█▏        | 1026/8253 [33:37<3:58:20,  1.98s/it][A
 12%|█▏        | 1027/8253 [33:39<3:55:34,  1.96s/it][A
 12%|█▏        | 1027/8253 [33:39<3:55:38,  1.96s/it][A
 12%|█▏        | 1027/8253 [33:39<3:56:02,  1.96s/it]
[A 12%|█▏        | 1027/8253 [33:39<3:55:43,  1.96s/it][A
 12%|█▏        | 1027/8253 [33:39<3:55:45,  1.96s/it][A
 12%|█▏        | 1027/8253 [33:39<3:55:57,  1.96s/it][A
 12%|█▏        | 1028/8253 [33:41<3:57:50,  1.98s/it][A
 12%|█▏        | 1028/8253 [33:41<3:58:12,  1.98s/it][A
 12%|█▏        | 1028/8253 [33:41<3:57:58,  1.98s/it][A
 12%|█▏        | 1028/8253 [33:41<3:58:21,  1.98s/it][A
 12%|█▏        | 1028/8253 [33:41<3:58:26,  1.98s/it][A
 12%|█▏        | 1028/8253 [33:41<3:58:33,  1.98s/it][A
 12%|█▏        | 1029/8253 [33:43<3:56:27,  1.96s/it][A
 12%|█▏        | 1029/8253 [33:43<3:56:30,  1.96s/it][A
 12%|█▏        | 1029/8253 [33:43<3:56:43,  1.97s/it][A
 12%|█▏        | 1029/8253 [33:43<3:56:44,  1.97s/it][A
 12%|█▏        | 1029/8253 [33:43<3:56:57,  1.97s/it][A
 12%|█▏        | 1029/8253 [33:43<3:57:01,  1.97s/it][A
 12%|█▏        | 1030/8253 [33:45<3:57:46,  1.98s/it][A
 12%|█▏        | 1030/8253 [33:45<3:57:53,  1.98s/it][A
 12%|█▏        | 1030/8253 [33:45<3:57:52,  1.98s/it][A
 12%|█▏        | 1030/8253 [33:45<3:57:56,  1.98s/it][A

 12%|█▏        | 1030/8253 [33:45<3:58:00,  1.98s/it][A 12%|█▏        | 1030/8253 [33:45<3:57:59,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:25,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:21,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:12,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:20,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:34,  1.98s/it][A
 12%|█▏        | 1031/8253 [33:47<3:58:45,  1.98s/it][A
 13%|█▎        | 1032/8253 [33:49<3:57:10,  1.97s/it][A
 13%|█▎        | 1032/8253 [33:49<3:57:49,  1.98s/it][A
 13%|█▎        | 1032/8253 [33:49<3:57:26,  1.97s/it][A
 13%|█▎        | 1032/8253 [33:48<3:57:41,  1.97s/it][A
 13%|█▎        | 1032/8253 [33:49<3:58:01,  1.98s/it][A
 13%|█▎        | 1032/8253 [33:49<3:57:38,  1.97s/it][A
 13%|█▎        | 1033/8253 [33:51<3:58:35,  1.98s/it][A
 13%|█▎        | 1033/8253 [33:51<3:58:57,  1.99s/it][A
 13%|█▎        | 1033/8253 [33:50<3:58:55,  1.99s/it][A
 13%|█▎        | 1033/8253 [33:51<3:58:50,  1.98s/it][A
 13%|█▎        | 1033/8253 [33:51<3:59:00,  1.99s/it][A
 13%|█▎        | 1033/8253 [33:51<3:59:09,  1.99s/it][A
 13%|█▎        | 1034/8253 [33:53<3:58:09,  1.98s/it][A
 13%|█▎        | 1034/8253 [33:53<3:58:04,  1.98s/it][A
 13%|█▎        | 1034/8253 [33:53<3:58:12,  1.98s/it][A
 13%|█▎        | 1034/8253 [33:53<3:58:47,  1.98s/it][A
 13%|█▎        | 1034/8253 [33:53<3:58:41,  1.98s/it][A
 13%|█▎        | 1034/8253 [33:52<3:58:35,  1.98s/it][A
 13%|█▎        | 1035/8253 [33:54<3:59:04,  1.99s/it][A
 13%|█▎        | 1035/8253 [33:55<3:59:32,  1.99s/it][A
 13%|█▎        | 1035/8253 [33:55<3:59:37,  1.99s/it][A
 13%|█▎        | 1035/8253 [33:55<3:59:36,  1.99s/it][A
 13%|█▎        | 1035/8253 [33:55<3:59:44,  1.99s/it][A
 13%|█▎        | 1035/8253 [33:55<3:59:49,  1.99s/it][A
 13%|█▎        | 1036/8253 [33:57<3:58:45,  1.98s/it][A
 13%|█▎        | 1036/8253 [33:57<3:59:05,  1.99s/it][A
 13%|█▎        | 1036/8253 [33:57<3:59:15,  1.99s/it][A
 13%|█▎        | 1036/8253 [33:57<3:59:04,  1.99s/it][A
 13%|█▎        | 1036/8253 [33:57<3:59:22,  1.99s/it][A
 13%|█▎        | 1036/8253 [33:56<3:59:20,  1.99s/it][A
 13%|█▎        | 1037/8253 [33:59<4:01:23,  2.01s/it][A
 13%|█▎        | 1037/8253 [33:59<4:01:32,  2.01s/it][A

 13%|█▎        | 1037/8253 [33:59<4:01:38,  2.01s/it][A 13%|█▎        | 1037/8253 [33:59<4:01:39,  2.01s/it][A
 13%|█▎        | 1037/8253 [33:59<4:01:34,  2.01s/it][A
 13%|█▎        | 1037/8253 [33:59<4:01:40,  2.01s/it][A
 13%|█▎        | 1038/8253 [34:01<3:59:36,  1.99s/it][A
 13%|█▎        | 1038/8253 [34:01<3:59:44,  1.99s/it][A
 13%|█▎        | 1038/8253 [34:01<3:59:50,  1.99s/it][A
 13%|█▎        | 1038/8253 [34:01<3:59:56,  2.00s/it][A

 13%|█▎        | 1038/8253 [34:01<4:00:15,  2.00s/it][A 13%|█▎        | 1038/8253 [34:00<4:00:07,  2.00s/it][A
 13%|█▎        | 1039/8253 [34:03<3:58:44,  1.99s/it][A
 13%|█▎        | 1039/8253 [34:03<3:58:58,  1.99s/it][A
 13%|█▎        | 1039/8253 [34:03<3:58:52,  1.99s/it][A
 13%|█▎        | 1039/8253 [34:03<3:59:03,  1.99s/it][A
 13%|█▎        | 1039/8253 [34:02<3:59:02,  1.99s/it][A
 13%|█▎        | 1039/8253 [34:03<3:59:07,  1.99s/it][A
 13%|█▎        | 1040/8253 [34:04<3:59:46,  1.99s/it][A
 13%|█▎        | 1040/8253 [34:05<4:00:08,  2.00s/it][A
 13%|█▎        | 1040/8253 [34:05<4:00:09,  2.00s/it][A
 13%|█▎        | 1040/8253 [34:05<4:00:15,  2.00s/it][A
 13%|█▎        | 1040/8253 [34:05<4:00:35,  2.00s/it][A
 13%|█▎        | 1040/8253 [34:05<4:00:21,  2.00s/it][A
 13%|█▎        | 1041/8253 [34:07<3:57:52,  1.98s/it][A
 13%|█▎        | 1041/8253 [34:07<3:57:55,  1.98s/it][A
 13%|█▎        | 1041/8253 [34:07<3:58:06,  1.98s/it][A
 13%|█▎        | 1041/8253 [34:07<3:58:12,  1.98s/it][A
 13%|█▎        | 1041/8253 [34:06<3:58:11,  1.98s/it][A
 13%|█▎        | 1041/8253 [34:07<3:58:14,  1.98s/it][A
 13%|█▎        | 1042/8253 [34:09<3:56:43,  1.97s/it][A
 13%|█▎        | 1042/8253 [34:09<3:57:20,  1.97s/it][A
 13%|█▎        | 1042/8253 [34:08<3:57:01,  1.97s/it][A

 13%|█▎        | 1042/8253 [34:09<3:57:16,  1.97s/it][A 13%|█▎        | 1042/8253 [34:09<3:57:18,  1.97s/it][A
 13%|█▎        | 1042/8253 [34:09<3:57:24,  1.98s/it][A
 13%|█▎        | 1043/8253 [34:10<3:55:20,  1.96s/it][A
 13%|█▎        | 1043/8253 [34:10<3:55:48,  1.96s/it][A
 13%|█▎        | 1043/8253 [34:10<3:55:45,  1.96s/it][A
 13%|█▎        | 1043/8253 [34:10<3:55:45,  1.96s/it][A

 13%|█▎        | 1043/8253 [34:10<3:55:53,  1.96s/it][A 13%|█▎        | 1043/8253 [34:10<3:55:51,  1.96s/it][A
 13%|█▎        | 1044/8253 [34:12<3:51:59,  1.93s/it][A
 13%|█▎        | 1044/8253 [34:12<3:51:51,  1.93s/it][A
 13%|█▎        | 1044/8253 [34:12<3:52:04,  1.93s/it][A
 13%|█▎        | 1044/8253 [34:12<3:52:15,  1.93s/it][A
 13%|█▎        | 1044/8253 [34:12<3:52:37,  1.94s/it][A
 13%|█▎        | 1044/8253 [34:12<3:52:24,  1.93s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:09,  1.92s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:25,  1.93s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:47,  1.93s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:42,  1.93s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:38,  1.93s/it][A
 13%|█▎        | 1045/8253 [34:14<3:51:43,  1.93s/it][A
 13%|█▎        | 1046/8253 [34:16<3:53:27,  1.94s/it][A

 13%|█▎        | 1046/8253 [34:16<3:53:22,  1.94s/it][A 13%|█▎        | 1046/8253 [34:16<3:53:31,  1.94s/it][A

 13%|█▎        | 1046/8253 [34:16<3:53:33,  1.94s/it][A 13%|█▎        | 1046/8253 [34:16<3:53:47,  1.95s/it][A
 13%|█▎        | 1046/8253 [34:16<3:53:52,  1.95s/it][A
 13%|█▎        | 1047/8253 [34:18<3:53:39,  1.95s/it][A
 13%|█▎        | 1047/8253 [34:18<3:53:39,  1.95s/it][A

 13%|█▎        | 1047/8253 [34:18<3:54:06,  1.95s/it] 13%|█▎        | 1047/8253 [34:18<3:54:13,  1.95s/it][A[A
 13%|█▎        | 1047/8253 [34:18<3:54:01,  1.95s/it][A
 13%|█▎        | 1047/8253 [34:18<3:54:13,  1.95s/it][A

 13%|█▎        | 1048/8253 [34:20<3:55:16,  1.96s/it][A 13%|█▎        | 1048/8253 [34:20<3:55:30,  1.96s/it][A
 13%|█▎        | 1048/8253 [34:20<3:55:29,  1.96s/it][A

 13%|█▎        | 1048/8253 [34:20<3:55:52,  1.96s/it][A 13%|█▎        | 1048/8253 [34:20<3:55:49,  1.96s/it][A
 13%|█▎        | 1048/8253 [34:20<3:55:54,  1.96s/it][A
 13%|█▎        | 1049/8253 [34:22<3:55:33,  1.96s/it][A
 13%|█▎        | 1049/8253 [34:22<3:56:03,  1.97s/it][A
 13%|█▎        | 1049/8253 [34:22<3:55:55,  1.96s/it][A
 13%|█▎        | 1049/8253 [34:22<3:55:59,  1.97s/it][A
 13%|█▎        | 1049/8253 [34:22<3:56:02,  1.97s/it][A
 13%|█▎        | 1049/8253 [34:22<3:56:20,  1.97s/it][A
 13%|█▎        | 1050/8253 [34:24<3:55:56,  1.97s/it][A
 13%|█▎        | 1050/8253 [34:24<3:55:48,  1.96s/it][A
 13%|█▎        | 1050/8253 [34:24<3:56:01,  1.97s/it][A
 13%|█▎        | 1050/8253 [34:24<3:56:10,  1.97s/it][A
 13%|█▎        | 1050/8253 [34:24<3:56:08,  1.97s/it][A
 13%|█▎        | 1050/8253 [34:24<3:56:15,  1.97s/it][A
 13%|█▎        | 1051/8253 [34:26<3:54:38,  1.95s/it][A
 13%|█▎        | 1051/8253 [34:26<3:54:59,  1.96s/it][A
 13%|█▎        | 1051/8253 [34:26<3:55:16,  1.96s/it][A
 13%|█▎        | 1051/8253 [34:26<3:55:22,  1.96s/it][A
 13%|█▎        | 1051/8253 [34:26<3:55:37,  1.96s/it][A
 13%|█▎        | 1051/8253 [34:26<3:55:33,  1.96s/it][A
 13%|█▎        | 1052/8253 [34:28<3:55:15,  1.96s/it][A
 13%|█▎        | 1052/8253 [34:28<3:55:38,  1.96s/it][A
 13%|█▎        | 1052/8253 [34:28<3:55:42,  1.96s/it][A

 13%|█▎        | 1052/8253 [34:28<3:55:51,  1.97s/it][A 13%|█▎        | 1052/8253 [34:28<3:55:50,  1.97s/it][A
 13%|█▎        | 1052/8253 [34:28<3:56:20,  1.97s/it][A
 13%|█▎        | 1053/8253 [34:30<3:52:57,  1.94s/it][A
 13%|█▎        | 1053/8253 [34:30<3:53:18,  1.94s/it][A
 13%|█▎        | 1053/8253 [34:30<3:53:31,  1.95s/it][A
 13%|█▎        | 1053/8253 [34:30<3:53:56,  1.95s/it][A
 13%|█▎        | 1053/8253 [34:30<3:53:43,  1.95s/it][A
 13%|█▎        | 1053/8253 [34:30<3:53:56,  1.95s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:02,  1.94s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:08,  1.94s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:47,  1.95s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:44,  1.95s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:49,  1.95s/it][A
 13%|█▎        | 1054/8253 [34:32<3:53:43,  1.95s/it][A
 13%|█▎        | 1055/8253 [34:34<3:52:42,  1.94s/it][A
 13%|█▎        | 1055/8253 [34:34<3:53:11,  1.94s/it][A
 13%|█▎        | 1055/8253 [34:34<3:53:06,  1.94s/it][A
 13%|█▎        | 1055/8253 [34:34<3:52:54,  1.94s/it][A
 13%|█▎        | 1055/8253 [34:34<3:53:19,  1.94s/it][A
 13%|█▎        | 1055/8253 [34:34<3:53:21,  1.95s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:04,  1.96s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:09,  1.96s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:07,  1.96s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:18,  1.96s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:13,  1.96s/it][A
 13%|█▎        | 1056/8253 [34:36<3:55:34,  1.96s/it][A
 13%|█▎        | 1057/8253 [34:38<3:56:10,  1.97s/it][A
 13%|█▎        | 1057/8253 [34:38<3:56:11,  1.97s/it][A

 13%|█▎        | 1057/8253 [34:38<3:56:10,  1.97s/it][A 13%|█▎        | 1057/8253 [34:38<3:56:18,  1.97s/it][A
 13%|█▎        | 1057/8253 [34:38<3:56:44,  1.97s/it][A
 13%|█▎        | 1057/8253 [34:38<3:56:35,  1.97s/it][A
 13%|█▎        | 1058/8253 [34:40<3:55:20,  1.96s/it][A
 13%|█▎        | 1058/8253 [34:40<3:55:40,  1.97s/it][A

 13%|█▎        | 1058/8253 [34:40<3:55:52,  1.97s/it][A 13%|█▎        | 1058/8253 [34:40<3:55:53,  1.97s/it][A
 13%|█▎        | 1058/8253 [34:40<3:56:05,  1.97s/it][A
 13%|█▎        | 1058/8253 [34:40<3:56:05,  1.97s/it][A
 13%|█▎        | 1059/8253 [34:42<3:56:43,  1.97s/it][A
 13%|█▎        | 1059/8253 [34:42<3:56:42,  1.97s/it][A
 13%|█▎        | 1059/8253 [34:42<3:56:38,  1.97s/it][A
 13%|█▎        | 1059/8253 [34:42<3:56:39,  1.97s/it][A
 13%|█▎        | 1059/8253 [34:42<3:57:00,  1.98s/it][A
 13%|█▎        | 1059/8253 [34:42<3:56:54,  1.98s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:04,  1.95s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:09,  1.95s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:22,  1.96s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:14,  1.95s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:15,  1.95s/it][A
 13%|█▎        | 1060/8253 [34:44<3:54:27,  1.96s/it][A
 13%|█▎        | 1061/8253 [34:46<3:54:17,  1.95s/it][A

 13%|█▎        | 1061/8253 [34:45<3:54:36,  1.96s/it][A 13%|█▎        | 1061/8253 [34:46<3:54:26,  1.96s/it][A
 13%|█▎        | 1061/8253 [34:46<3:54:42,  1.96s/it][A
 13%|█▎        | 1061/8253 [34:46<3:54:44,  1.96s/it][A
 13%|█▎        | 1061/8253 [34:46<3:54:47,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:48<3:54:43,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:48<3:54:50,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:47<3:54:55,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:48<3:54:50,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:48<3:55:08,  1.96s/it][A
 13%|█▎        | 1062/8253 [34:48<3:55:12,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:50<3:55:18,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:49<3:55:15,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:50<3:55:22,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:50<3:55:16,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:50<3:55:23,  1.96s/it][A
 13%|█▎        | 1063/8253 [34:50<3:55:30,  1.97s/it][A
 13%|█▎        | 1064/8253 [34:51<3:54:37,  1.96s/it][A
 13%|█▎        | 1064/8253 [34:52<3:55:02,  1.96s/it][A

 13%|█▎        | 1064/8253 [34:52<3:54:57,  1.96s/it][A 13%|█▎        | 1064/8253 [34:52<3:54:51,  1.96s/it][A
 13%|█▎        | 1064/8253 [34:52<3:54:53,  1.96s/it][A
 13%|█▎        | 1064/8253 [34:52<3:55:16,  1.96s/it][A
 13%|█▎        | 1065/8253 [34:53<3:55:41,  1.97s/it][A
 13%|█▎        | 1065/8253 [34:54<3:55:36,  1.97s/it][A
 13%|█▎        | 1065/8253 [34:54<3:55:57,  1.97s/it][A
 13%|█▎        | 1065/8253 [34:54<3:55:53,  1.97s/it][A

 13%|█▎        | 1065/8253 [34:54<3:56:03,  1.97s/it][A 13%|█▎        | 1065/8253 [34:54<3:56:15,  1.97s/it][A
 13%|█▎        | 1066/8253 [34:56<3:56:38,  1.98s/it][A
 13%|█▎        | 1066/8253 [34:56<3:57:04,  1.98s/it][A
 13%|█▎        | 1066/8253 [34:55<3:57:12,  1.98s/it][A
 13%|█▎        | 1066/8253 [34:56<3:56:52,  1.98s/it][A
 13%|█▎        | 1066/8253 [34:56<3:57:26,  1.98s/it][A
 13%|█▎        | 1066/8253 [34:56<3:57:16,  1.98s/it][A
 13%|█▎        | 1067/8253 [34:57<3:56:58,  1.98s/it][A
 13%|█▎        | 1067/8253 [34:57<3:57:18,  1.98s/it][A
 13%|█▎        | 1067/8253 [34:58<3:57:06,  1.98s/it][A

 13%|█▎        | 1067/8253 [34:57<3:57:42,  1.98s/it][A 13%|█▎        | 1067/8253 [34:58<3:57:38,  1.98s/it][A
 13%|█▎        | 1067/8253 [34:58<3:57:25,  1.98s/it][A
 13%|█▎        | 1068/8253 [34:59<3:55:08,  1.96s/it][A
 13%|█▎        | 1068/8253 [34:59<3:55:09,  1.96s/it][A
 13%|█▎        | 1068/8253 [34:59<3:55:16,  1.96s/it][A

 13%|█▎        | 1068/8253 [34:59<3:55:08,  1.96s/it][A 13%|█▎        | 1068/8253 [34:59<3:55:11,  1.96s/it][A
 13%|█▎        | 1068/8253 [34:59<3:55:19,  1.97s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:34,  1.98s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:36,  1.98s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:51,  1.98s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:47,  1.98s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:42,  1.98s/it][A
 13%|█▎        | 1069/8253 [35:01<3:56:59,  1.98s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:36,  1.95s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:34,  1.95s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:39,  1.95s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:41,  1.95s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:48,  1.95s/it][A
 13%|█▎        | 1070/8253 [35:03<3:53:58,  1.95s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:13,  1.96s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:16,  1.96s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:24,  1.96s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:35,  1.96s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:30,  1.96s/it][A
 13%|█▎        | 1071/8253 [35:05<3:54:32,  1.96s/it][A
 13%|█▎        | 1072/8253 [35:07<3:53:21,  1.95s/it][A
 13%|█▎        | 1072/8253 [35:07<3:53:24,  1.95s/it][A
 13%|█▎        | 1072/8253 [35:07<3:53:32,  1.95s/it][A
 13%|█▎        | 1072/8253 [35:07<3:53:36,  1.95s/it][A
 13%|█▎        | 1072/8253 [35:07<3:53:48,  1.95s/it][A
 13%|█▎        | 1072/8253 [35:07<3:54:00,  1.96s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:24,  1.95s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:32,  1.95s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:26,  1.95s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:39,  1.95s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:36,  1.95s/it][A
 13%|█▎        | 1073/8253 [35:09<3:53:46,  1.95s/it][A
 13%|█▎        | 1074/8253 [35:11<3:52:47,  1.95s/it][A

 13%|█▎        | 1074/8253 [35:11<3:53:04,  1.95s/it][A 13%|█▎        | 1074/8253 [35:11<3:53:05,  1.95s/it][A
 13%|█▎        | 1074/8253 [35:11<3:53:01,  1.95s/it][A
 13%|█▎        | 1074/8253 [35:11<3:53:07,  1.95s/it][A
 13%|█▎        | 1074/8253 [35:11<3:53:17,  1.95s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:03,  1.94s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:14,  1.94s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:15,  1.94s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:32,  1.94s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:28,  1.94s/it][A
 13%|█▎        | 1075/8253 [35:13<3:52:39,  1.94s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:30,  1.96s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:29,  1.96s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:38,  1.96s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:47,  1.96s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:53,  1.96s/it][A
 13%|█▎        | 1076/8253 [35:15<3:54:57,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:13,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:16,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:33,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:41,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:48,  1.96s/it][A
 13%|█▎        | 1077/8253 [35:17<3:54:57,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:15,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:33,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:44,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:24,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:33,  1.96s/it][A
 13%|█▎        | 1078/8253 [35:19<3:54:42,  1.96s/it][A
 13%|█▎        | 1079/8253 [35:21<3:56:08,  1.98s/it][A
 13%|█▎        | 1079/8253 [35:21<3:56:25,  1.98s/it][A
 13%|█▎        | 1079/8253 [35:21<3:56:25,  1.98s/it][A
 13%|█▎        | 1079/8253 [35:21<3:56:33,  1.98s/it][A
 13%|█▎        | 1079/8253 [35:21<3:56:42,  1.98s/it][A
 13%|█▎        | 1079/8253 [35:21<3:57:02,  1.98s/it][A
 13%|█▎        | 1080/8253 [35:23<3:57:21,  1.99s/it][A

 13%|█▎        | 1080/8253 [35:23<3:57:51,  1.99s/it][A 13%|█▎        | 1080/8253 [35:23<3:57:40,  1.99s/it][A
 13%|█▎        | 1080/8253 [35:23<3:57:46,  1.99s/it][A
 13%|█▎        | 1080/8253 [35:23<3:57:56,  1.99s/it][A
 13%|█▎        | 1080/8253 [35:23<3:57:53,  1.99s/it][A
 13%|█▎        | 1081/8253 [35:25<3:55:51,  1.97s/it][A
 13%|█▎        | 1081/8253 [35:25<3:55:50,  1.97s/it][A
 13%|█▎        | 1081/8253 [35:25<3:56:11,  1.98s/it][A
 13%|█▎        | 1081/8253 [35:25<3:56:03,  1.97s/it][A
 13%|█▎        | 1081/8253 [35:25<3:56:21,  1.98s/it][A
 13%|█▎        | 1081/8253 [35:25<3:56:24,  1.98s/it][A
 13%|█▎        | 1082/8253 [35:27<3:54:47,  1.96s/it][A
 13%|█▎        | 1082/8253 [35:27<3:54:55,  1.97s/it][A
 13%|█▎        | 1082/8253 [35:27<3:55:14,  1.97s/it][A
 13%|█▎        | 1082/8253 [35:27<3:54:58,  1.97s/it][A
 13%|█▎        | 1082/8253 [35:27<3:55:11,  1.97s/it][A
 13%|█▎        | 1082/8253 [35:27<3:55:21,  1.97s/it][A
 13%|█▎        | 1083/8253 [35:29<3:52:51,  1.95s/it][A
 13%|█▎        | 1083/8253 [35:29<3:53:21,  1.95s/it][A
 13%|█▎        | 1083/8253 [35:29<3:53:17,  1.95s/it][A
 13%|█▎        | 1083/8253 [35:29<3:53:32,  1.95s/it][A
 13%|█▎        | 1083/8253 [35:29<3:53:42,  1.96s/it][A
 13%|█▎        | 1083/8253 [35:29<3:53:44,  1.96s/it][A
 13%|█▎        | 1084/8253 [35:31<3:52:29,  1.95s/it][A
 13%|█▎        | 1084/8253 [35:31<3:52:41,  1.95s/it][A
 13%|█▎        | 1084/8253 [35:31<3:52:44,  1.95s/it][A
 13%|█▎        | 1084/8253 [35:31<3:53:06,  1.95s/it][A

 13%|█▎        | 1084/8253 [35:31<3:52:50,  1.95s/it][A 13%|█▎        | 1084/8253 [35:31<3:52:50,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:52:46,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:52:32,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:52:49,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:52:37,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:53:07,  1.95s/it][A
 13%|█▎        | 1085/8253 [35:33<3:52:50,  1.95s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:02,  1.94s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:11,  1.94s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:22,  1.95s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:26,  1.95s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:43,  1.95s/it][A
 13%|█▎        | 1086/8253 [35:35<3:52:40,  1.95s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:16,  1.97s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:31,  1.97s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:32,  1.97s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:54,  1.98s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:58,  1.98s/it][A
 13%|█▎        | 1087/8253 [35:37<3:55:59,  1.98s/it][A
 13%|█▎        | 1088/8253 [35:39<3:56:58,  1.98s/it][A
 13%|█▎        | 1088/8253 [35:39<3:57:03,  1.99s/it][A
 13%|█▎        | 1088/8253 [35:39<3:57:21,  1.99s/it][A
 13%|█▎        | 1088/8253 [35:39<3:57:33,  1.99s/it][A
 13%|█▎        | 1088/8253 [35:39<3:57:22,  1.99s/it][A
 13%|█▎        | 1088/8253 [35:39<3:57:28,  1.99s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:12,  1.98s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:16,  1.98s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:22,  1.98s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:16,  1.98s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:38,  1.98s/it][A
 13%|█▎        | 1089/8253 [35:41<3:56:30,  1.98s/it][A
 13%|█▎        | 1090/8253 [35:43<3:52:42,  1.95s/it][A
 13%|█▎        | 1090/8253 [35:43<3:52:48,  1.95s/it][A
 13%|█▎        | 1090/8253 [35:43<3:53:13,  1.95s/it][A
 13%|█▎        | 1090/8253 [35:43<3:53:18,  1.95s/it][A
 13%|█▎        | 1090/8253 [35:43<3:53:22,  1.95s/it][A
 13%|█▎        | 1090/8253 [35:42<3:53:26,  1.96s/it][A
 13%|█▎        | 1091/8253 [35:45<3:54:33,  1.97s/it][A
 13%|█▎        | 1091/8253 [35:44<3:54:28,  1.96s/it][A

 13%|█▎        | 1091/8253 [35:45<3:55:03,  1.97s/it][A 13%|█▎        | 1091/8253 [35:45<3:55:01,  1.97s/it][A

 13%|█▎        | 1091/8253 [35:45<3:55:05,  1.97s/it][A 13%|█▎        | 1091/8253 [35:45<3:55:12,  1.97s/it][A
 13%|█▎        | 1092/8253 [35:47<3:55:00,  1.97s/it][A
 13%|█▎        | 1092/8253 [35:47<3:55:32,  1.97s/it][A
 13%|█▎        | 1092/8253 [35:46<3:55:28,  1.97s/it][A

 13%|█▎        | 1092/8253 [35:47<3:55:30,  1.97s/it][A 13%|█▎        | 1092/8253 [35:47<3:55:26,  1.97s/it][A
 13%|█▎        | 1092/8253 [35:47<3:55:34,  1.97s/it][A
 13%|█▎        | 1093/8253 [35:48<3:53:43,  1.96s/it][A
 13%|█▎        | 1093/8253 [35:48<3:53:58,  1.96s/it][A
 13%|█▎        | 1093/8253 [35:48<3:54:05,  1.96s/it][A
 13%|█▎        | 1093/8253 [35:48<3:54:04,  1.96s/it][A
 13%|█▎        | 1093/8253 [35:48<3:53:53,  1.96s/it][A
 13%|█▎        | 1093/8253 [35:48<3:53:58,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:53:21,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:53:23,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:53:39,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:53:47,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:54:05,  1.96s/it][A
 13%|█▎        | 1094/8253 [35:50<3:53:58,  1.96s/it][A
 13%|█▎        | 1095/8253 [35:52<3:53:26,  1.96s/it][A
 13%|█▎        | 1095/8253 [35:52<3:53:41,  1.96s/it][A

 13%|█▎        | 1095/8253 [35:52<3:53:30,  1.96s/it][A 13%|█▎        | 1095/8253 [35:52<3:53:40,  1.96s/it][A
 13%|█▎        | 1095/8253 [35:52<3:53:49,  1.96s/it][A
 13%|█▎        | 1095/8253 [35:52<3:53:54,  1.96s/it][A
 13%|█▎        | 1096/8253 [35:54<3:52:18,  1.95s/it][A
 13%|█▎        | 1096/8253 [35:54<3:52:20,  1.95s/it][A
 13%|█▎        | 1096/8253 [35:54<3:52:29,  1.95s/it][A
 13%|█▎        | 1096/8253 [35:54<3:52:30,  1.95s/it][A
 13%|█▎        | 1096/8253 [35:54<3:52:41,  1.95s/it][A
 13%|█▎        | 1096/8253 [35:54<3:53:02,  1.95s/it][A
 13%|█▎        | 1097/8253 [35:56<3:53:52,  1.96s/it][A

 13%|█▎        | 1097/8253 [35:56<3:54:06,  1.96s/it][A 13%|█▎        | 1097/8253 [35:56<3:54:17,  1.96s/it][A
 13%|█▎        | 1097/8253 [35:56<3:54:22,  1.97s/it][A
 13%|█▎        | 1097/8253 [35:56<3:54:23,  1.97s/it][A
 13%|█▎        | 1097/8253 [35:56<3:54:29,  1.97s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:02,  1.96s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:16,  1.96s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:35,  1.97s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:23,  1.97s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:38,  1.97s/it][A
 13%|█▎        | 1098/8253 [35:58<3:54:38,  1.97s/it][A
 13%|█▎        | 1099/8253 [36:01<4:04:15,  2.05s/it][A
 13%|█▎        | 1099/8253 [36:01<4:04:33,  2.05s/it][A
 13%|█▎        | 1099/8253 [36:00<4:04:28,  2.05s/it][A
 13%|█▎        | 1099/8253 [36:01<4:04:41,  2.05s/it][A
 13%|█▎        | 1099/8253 [36:01<4:04:31,  2.05s/it][A
 13%|█▎        | 1099/8253 [36:01<4:04:42,  2.05s/it][A
 13%|█▎        | 1100/8253 [36:02<4:00:43,  2.02s/it][A
 13%|█▎        | 1100/8253 [36:02<4:01:08,  2.02s/it][A

 13%|█▎        | 1100/8253 [36:03<4:01:24,  2.02s/it][A 13%|█▎        | 1100/8253 [36:03<4:01:20,  2.02s/it][A
 13%|█▎        | 1100/8253 [36:03<4:01:14,  2.02s/it][A
 13%|█▎        | 1100/8253 [36:02<4:01:20,  2.02s/it][A
 13%|█▎        | 1101/8253 [36:04<3:57:09,  1.99s/it][A
 13%|█▎        | 1101/8253 [36:04<3:57:07,  1.99s/it][A
 13%|█▎        | 1101/8253 [36:04<3:56:53,  1.99s/it][A
 13%|█▎        | 1101/8253 [36:04<3:57:21,  1.99s/it][A
 13%|█▎        | 1101/8253 [36:04<3:57:27,  1.99s/it][A
 13%|█▎        | 1101/8253 [36:04<3:57:19,  1.99s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:08,  1.98s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:27,  1.98s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:33,  1.98s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:26,  1.98s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:24,  1.98s/it][A
 13%|█▎        | 1102/8253 [36:06<3:56:36,  1.99s/it][A
 13%|█▎        | 1103/8253 [36:08<3:53:47,  1.96s/it][A
 13%|█▎        | 1103/8253 [36:08<3:54:15,  1.97s/it][A

 13%|█▎        | 1103/8253 [36:08<3:54:23,  1.97s/it][A 13%|█▎        | 1103/8253 [36:08<3:54:12,  1.97s/it][A
 13%|█▎        | 1103/8253 [36:08<3:54:28,  1.97s/it][A
 13%|█▎        | 1103/8253 [36:08<3:54:16,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:54:23,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:54:38,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:54:43,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:55:04,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:54:57,  1.97s/it][A
 13%|█▎        | 1104/8253 [36:10<3:55:16,  1.97s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:25,  1.98s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:18,  1.98s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:13,  1.98s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:30,  1.99s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:28,  1.98s/it][A
 13%|█▎        | 1105/8253 [36:12<3:56:46,  1.99s/it][A
 13%|█▎        | 1106/8253 [36:14<3:53:45,  1.96s/it][A
 13%|█▎        | 1106/8253 [36:14<3:53:53,  1.96s/it][A
 13%|█▎        | 1106/8253 [36:14<3:54:32,  1.97s/it][A
 13%|█▎        | 1106/8253 [36:14<3:54:26,  1.97s/it][A
 13%|█▎        | 1106/8253 [36:14<3:54:30,  1.97s/it][A
 13%|█▎        | 1106/8253 [36:14<3:54:43,  1.97s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:05,  1.95s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:06,  1.95s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:16,  1.95s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:16,  1.95s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:07,  1.95s/it][A
 13%|█▎        | 1107/8253 [36:16<3:52:21,  1.95s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:05,  1.94s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:08,  1.94s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:01,  1.94s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:17,  1.94s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:31,  1.94s/it][A
 13%|█▎        | 1108/8253 [36:18<3:51:38,  1.95s/it][A
 13%|█▎        | 1109/8253 [36:20<3:49:27,  1.93s/it][A
 13%|█▎        | 1109/8253 [36:20<3:49:45,  1.93s/it][A
 13%|█▎        | 1109/8253 [36:20<3:50:03,  1.93s/it][A
 13%|█▎        | 1109/8253 [36:20<3:50:00,  1.93s/it][A
 13%|█▎        | 1109/8253 [36:20<3:50:03,  1.93s/it][A
 13%|█▎        | 1109/8253 [36:20<3:50:00,  1.93s/it][A
 13%|█▎        | 1110/8253 [36:22<3:50:42,  1.94s/it][A
 13%|█▎        | 1110/8253 [36:22<3:50:30,  1.94s/it][A

 13%|█▎        | 1110/8253 [36:22<3:50:49,  1.94s/it][A 13%|█▎        | 1110/8253 [36:22<3:51:03,  1.94s/it][A
 13%|█▎        | 1110/8253 [36:22<3:51:03,  1.94s/it][A
 13%|█▎        | 1110/8253 [36:22<3:50:54,  1.94s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:08,  1.93s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:19,  1.93s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:25,  1.94s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:12,  1.93s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:21,  1.94s/it][A
 13%|█▎        | 1111/8253 [36:24<3:50:21,  1.94s/it][A
 13%|█▎        | 1112/8253 [36:26<3:51:48,  1.95s/it][A
 13%|█▎        | 1112/8253 [36:26<3:52:03,  1.95s/it][A
 13%|█▎        | 1112/8253 [36:26<3:51:57,  1.95s/it][A
 13%|█▎        | 1112/8253 [36:26<3:52:20,  1.95s/it][A
 13%|█▎        | 1112/8253 [36:26<3:52:20,  1.95s/it][A
 13%|█▎        | 1112/8253 [36:26<3:52:12,  1.95s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:13,  1.95s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:27,  1.95s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:37,  1.95s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:37,  1.95s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:56,  1.96s/it][A
 13%|█▎        | 1113/8253 [36:28<3:52:47,  1.96s/it][A
 13%|█▎        | 1114/8253 [36:30<3:50:59,  1.94s/it][A
 13%|█▎        | 1114/8253 [36:30<3:51:08,  1.94s/it][A
 13%|█▎        | 1114/8253 [36:30<3:51:08,  1.94s/it][A
 13%|█▎        | 1114/8253 [36:30<3:51:01,  1.94s/it][A

 13%|█▎        | 1114/8253 [36:30<3:51:27,  1.95s/it][A 13%|█▎        | 1114/8253 [36:30<3:51:21,  1.94s/it][A
 14%|█▎        | 1115/8253 [36:32<3:53:55,  1.97s/it][A
 14%|█▎        | 1115/8253 [36:32<3:54:11,  1.97s/it][A
 14%|█▎        | 1115/8253 [36:32<3:54:06,  1.97s/it][A
 14%|█▎        | 1115/8253 [36:32<3:54:18,  1.97s/it][A
 14%|█▎        | 1115/8253 [36:32<3:54:08,  1.97s/it][A
 14%|█▎        | 1115/8253 [36:32<3:54:36,  1.97s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:24,  1.96s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:12,  1.96s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:32,  1.96s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:34,  1.96s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:38,  1.96s/it][A
 14%|█▎        | 1116/8253 [36:34<3:53:35,  1.96s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:23,  1.96s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:41,  1.96s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:28,  1.96s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:39,  1.96s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:47,  1.97s/it][A
 14%|█▎        | 1117/8253 [36:36<3:53:55,  1.97s/it][A
 14%|█▎        | 1118/8253 [36:38<3:54:16,  1.97s/it][A
 14%|█▎        | 1118/8253 [36:38<3:54:26,  1.97s/it]
[A 14%|█▎        | 1118/8253 [36:38<3:54:19,  1.97s/it][A
 14%|█▎        | 1118/8253 [36:38<3:54:41,  1.97s/it][A
 14%|█▎        | 1118/8253 [36:38<3:54:35,  1.97s/it][A
 14%|█▎        | 1118/8253 [36:38<3:54:36,  1.97s/it][A
 14%|█▎        | 1119/8253 [36:40<3:52:33,  1.96s/it][A
 14%|█▎        | 1119/8253 [36:40<3:52:59,  1.96s/it][A
 14%|█▎        | 1119/8253 [36:40<3:53:04,  1.96s/it][A
 14%|█▎        | 1119/8253 [36:40<3:53:07,  1.96s/it][A
 14%|█▎        | 1119/8253 [36:40<3:53:13,  1.96s/it][A
 14%|█▎        | 1119/8253 [36:39<3:53:20,  1.96s/it][A
 14%|█▎        | 1120/8253 [36:42<3:51:33,  1.95s/it][A
 14%|█▎        | 1120/8253 [36:42<3:51:59,  1.95s/it][A
 14%|█▎        | 1120/8253 [36:41<3:51:54,  1.95s/it][A
 14%|█▎        | 1120/8253 [36:42<3:52:00,  1.95s/it][A
 14%|█▎        | 1120/8253 [36:42<3:51:58,  1.95s/it][A
 14%|█▎        | 1120/8253 [36:42<3:52:12,  1.95s/it][A
 14%|█▎        | 1121/8253 [36:43<3:50:08,  1.94s/it][A
 14%|█▎        | 1121/8253 [36:43<3:50:14,  1.94s/it][A
 14%|█▎        | 1121/8253 [36:43<3:50:22,  1.94s/it][A

 14%|█▎        | 1121/8253 [36:43<3:50:31,  1.94s/it][A 14%|█▎        | 1121/8253 [36:43<3:50:15,  1.94s/it][A
 14%|█▎        | 1121/8253 [36:43<3:50:22,  1.94s/it][A
 14%|█▎        | 1122/8253 [36:45<3:51:42,  1.95s/it][A
 14%|█▎        | 1122/8253 [36:45<3:52:05,  1.95s/it][A
 14%|█▎        | 1122/8253 [36:45<3:51:57,  1.95s/it][A
 14%|█▎        | 1122/8253 [36:45<3:52:09,  1.95s/it][A
 14%|█▎        | 1122/8253 [36:45<3:52:16,  1.95s/it][A
 14%|█▎        | 1122/8253 [36:45<3:52:30,  1.96s/it][A
 14%|█▎        | 1123/8253 [36:47<3:51:09,  1.95s/it][A

 14%|█▎        | 1123/8253 [36:47<3:51:38,  1.95s/it][A 14%|█▎        | 1123/8253 [36:47<3:51:38,  1.95s/it][A
 14%|█▎        | 1123/8253 [36:47<3:51:38,  1.95s/it][A
 14%|█▎        | 1123/8253 [36:47<3:51:40,  1.95s/it][A
 14%|█▎        | 1123/8253 [36:47<3:51:43,  1.95s/it][A
 14%|█▎        | 1124/8253 [36:49<3:50:42,  1.94s/it][A
 14%|█▎        | 1124/8253 [36:49<3:50:48,  1.94s/it][A
 14%|█▎        | 1124/8253 [36:49<3:51:10,  1.95s/it][A
 14%|█▎        | 1124/8253 [36:49<3:51:08,  1.95s/it][A
 14%|█▎        | 1124/8253 [36:49<3:51:17,  1.95s/it][A
 14%|█▎        | 1124/8253 [36:49<3:51:28,  1.95s/it][A
 14%|█▎        | 1125/8253 [36:51<3:53:51,  1.97s/it][A
 14%|█▎        | 1125/8253 [36:51<3:53:55,  1.97s/it][A
 14%|█▎        | 1125/8253 [36:51<3:54:03,  1.97s/it][A
 14%|█▎        | 1125/8253 [36:51<3:54:02,  1.97s/it][A
 14%|█▎        | 1125/8253 [36:51<3:54:10,  1.97s/it][A
 14%|█▎        | 1125/8253 [36:51<3:54:15,  1.97s/it][A
 14%|█▎        | 1126/8253 [36:53<3:51:28,  1.95s/it][A

 14%|█▎        | 1126/8253 [36:53<3:51:19,  1.95s/it][A 14%|█▎        | 1126/8253 [36:53<3:51:22,  1.95s/it][A
 14%|█▎        | 1126/8253 [36:53<3:51:22,  1.95s/it][A
 14%|█▎        | 1126/8253 [36:53<3:51:24,  1.95s/it][A
 14%|█▎        | 1126/8253 [36:53<3:51:26,  1.95s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:11,  1.94s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:03,  1.94s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:09,  1.94s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:15,  1.94s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:22,  1.94s/it][A
 14%|█▎        | 1127/8253 [36:55<3:50:29,  1.94s/it][A
 14%|█▎        | 1128/8253 [36:57<3:50:39,  1.94s/it][A
 14%|█▎        | 1128/8253 [36:57<3:51:04,  1.95s/it][A
 14%|█▎        | 1128/8253 [36:57<3:50:53,  1.94s/it][A
 14%|█▎        | 1128/8253 [36:57<3:50:58,  1.95s/it][A
 14%|█▎        | 1128/8253 [36:57<3:51:06,  1.95s/it][A
 14%|█▎        | 1128/8253 [36:57<3:51:11,  1.95s/it][A
 14%|█▎        | 1129/8253 [36:59<3:50:04,  1.94s/it][A
 14%|█▎        | 1129/8253 [36:59<3:50:34,  1.94s/it][A
 14%|█▎        | 1129/8253 [36:59<3:50:22,  1.94s/it][A

 14%|█▎        | 1129/8253 [36:59<3:50:22,  1.94s/it][A 14%|█▎        | 1129/8253 [36:59<3:50:21,  1.94s/it][A
 14%|█▎        | 1129/8253 [36:59<3:50:29,  1.94s/it][A
 14%|█▎        | 1130/8253 [37:01<3:54:28,  1.98s/it][A
 14%|█▎        | 1130/8253 [37:01<3:54:47,  1.98s/it][A
 14%|█▎        | 1130/8253 [37:01<3:54:55,  1.98s/it][A
 14%|█▎        | 1130/8253 [37:01<3:54:47,  1.98s/it][A
 14%|█▎        | 1130/8253 [37:01<3:55:06,  1.98s/it][A
 14%|█▎        | 1130/8253 [37:01<3:55:00,  1.98s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:21,  1.97s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:24,  1.97s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:46,  1.98s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:48,  1.98s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:48,  1.98s/it][A
 14%|█▎        | 1131/8253 [37:03<3:54:44,  1.98s/it][A
 14%|█▎        | 1132/8253 [37:05<3:52:29,  1.96s/it][A
 14%|█▎        | 1132/8253 [37:05<3:53:18,  1.97s/it][A


 14%|█▎        | 1132/8253 [37:05<3:53:19,  1.97s/it][A 14%|█▎        | 1132/8253 [37:05<3:53:18,  1.97s/it][A 14%|█▎        | 1132/8253 [37:05<3:53:17,  1.97s/it][A
 14%|█▎        | 1132/8253 [37:05<3:53:20,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:53:24,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:53:39,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:53:42,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:53:49,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:53:59,  1.97s/it][A
 14%|█▎        | 1133/8253 [37:07<3:54:04,  1.97s/it][A
 14%|█▎        | 1134/8253 [37:09<3:54:04,  1.97s/it][A
 14%|█▎        | 1134/8253 [37:09<3:54:27,  1.98s/it][A

 14%|█▎        | 1134/8253 [37:09<3:54:27,  1.98s/it]
[A 14%|█▎        | 1134/8253 [37:09<3:54:25,  1.98s/it][A 14%|█▎        | 1134/8253 [37:09<3:54:21,  1.98s/it][A
 14%|█▎        | 1134/8253 [37:09<3:54:25,  1.98s/it][A
 14%|█▍        | 1135/8253 [37:11<3:53:49,  1.97s/it][A
 14%|█▍        | 1135/8253 [37:11<3:54:02,  1.97s/it][A
 14%|█▍        | 1135/8253 [37:11<3:54:14,  1.97s/it][A
 14%|█▍        | 1135/8253 [37:11<3:54:16,  1.97s/it][A

 14%|█▍        | 1135/8253 [37:11<3:54:25,  1.98s/it][A 14%|█▍        | 1135/8253 [37:11<3:54:38,  1.98s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:04,  1.98s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:22,  1.98s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:38,  1.99s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:40,  1.99s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:51,  1.99s/it][A
 14%|█▍        | 1136/8253 [37:13<3:55:56,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:55:43,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:55:55,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:55:56,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:56:18,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:56:14,  1.99s/it][A
 14%|█▍        | 1137/8253 [37:15<3:56:26,  1.99s/it][A
 14%|█▍        | 1138/8253 [37:17<3:54:22,  1.98s/it][A
 14%|█▍        | 1138/8253 [37:17<3:54:32,  1.98s/it][A

 14%|█▍        | 1138/8253 [37:17<3:54:30,  1.98s/it][A 14%|█▍        | 1138/8253 [37:17<3:54:27,  1.98s/it][A
 14%|█▍        | 1138/8253 [37:17<3:54:30,  1.98s/it][A
 14%|█▍        | 1138/8253 [37:17<3:54:51,  1.98s/it][A

 14%|█▍        | 1139/8253 [37:19<3:53:43,  1.97s/it][A 14%|█▍        | 1139/8253 [37:19<3:53:56,  1.97s/it][A
 14%|█▍        | 1139/8253 [37:19<3:54:07,  1.97s/it][A
 14%|█▍        | 1139/8253 [37:19<3:54:18,  1.98s/it][A
 14%|█▍        | 1139/8253 [37:19<3:54:10,  1.98s/it][A
 14%|█▍        | 1139/8253 [37:19<3:54:17,  1.98s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:24,  1.96s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:33,  1.96s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:37,  1.96s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:28,  1.96s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:51,  1.96s/it][A
 14%|█▍        | 1140/8253 [37:21<3:52:33,  1.96s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:42,  1.96s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:46,  1.96s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:52,  1.96s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:59,  1.97s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:58,  1.97s/it][A
 14%|█▍        | 1141/8253 [37:23<3:52:58,  1.97s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:33,  1.98s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:19,  1.98s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:43,  1.98s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:49,  1.98s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:39,  1.98s/it][A
 14%|█▍        | 1142/8253 [37:25<3:54:52,  1.98s/it][A
 14%|█▍        | 1143/8253 [37:27<3:53:49,  1.97s/it][A
 14%|█▍        | 1143/8253 [37:27<3:53:53,  1.97s/it][A
 14%|█▍        | 1143/8253 [37:27<3:53:56,  1.97s/it][A
 14%|█▍        | 1143/8253 [37:27<3:54:07,  1.98s/it][A
 14%|█▍        | 1143/8253 [37:27<3:54:21,  1.98s/it][A
 14%|█▍        | 1143/8253 [37:27<3:54:03,  1.98s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:50,  1.96s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:51,  1.96s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:58,  1.96s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:51,  1.96s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:54,  1.96s/it][A
 14%|█▍        | 1144/8253 [37:29<3:51:48,  1.96s/it][A
 14%|█▍        | 1145/8253 [37:31<3:51:45,  1.96s/it][A
 14%|█▍        | 1145/8253 [37:30<3:51:48,  1.96s/it][A
 14%|█▍        | 1145/8253 [37:31<3:51:59,  1.96s/it][A

 14%|█▍        | 1145/8253 [37:31<3:52:07,  1.96s/it][A 14%|█▍        | 1145/8253 [37:31<3:51:53,  1.96s/it][A
 14%|█▍        | 1145/8253 [37:31<3:52:01,  1.96s/it][A
 14%|█▍        | 1146/8253 [37:33<3:50:04,  1.94s/it][A
 14%|█▍        | 1146/8253 [37:33<3:50:27,  1.95s/it][A
 14%|█▍        | 1146/8253 [37:33<3:50:32,  1.95s/it][A
 14%|█▍        | 1146/8253 [37:33<3:50:42,  1.95s/it][A
 14%|█▍        | 1146/8253 [37:32<3:50:49,  1.95s/it][A
 14%|█▍        | 1146/8253 [37:33<3:50:44,  1.95s/it][A
 14%|█▍        | 1147/8253 [37:34<3:50:27,  1.95s/it][A
 14%|█▍        | 1147/8253 [37:34<3:50:17,  1.94s/it][A

 14%|█▍        | 1147/8253 [37:35<3:50:59,  1.95s/it][A 14%|█▍        | 1147/8253 [37:35<3:50:41,  1.95s/it][A
 14%|█▍        | 1147/8253 [37:35<3:50:49,  1.95s/it][A
 14%|█▍        | 1147/8253 [37:35<3:51:07,  1.95s/it][A
 14%|█▍        | 1148/8253 [37:36<3:51:37,  1.96s/it][A
 14%|█▍        | 1148/8253 [37:36<3:51:41,  1.96s/it][A
 14%|█▍        | 1148/8253 [37:36<3:51:55,  1.96s/it][A
 14%|█▍        | 1148/8253 [37:36<3:52:08,  1.96s/it][A
 14%|█▍        | 1148/8253 [37:36<3:52:24,  1.96s/it][A
 14%|█▍        | 1148/8253 [37:36<3:52:38,  1.96s/it][A
 14%|█▍        | 1149/8253 [37:38<3:53:09,  1.97s/it][A
 14%|█▍        | 1149/8253 [37:38<3:53:16,  1.97s/it][A
 14%|█▍        | 1149/8253 [37:38<3:53:28,  1.97s/it][A
 14%|█▍        | 1149/8253 [37:38<3:53:17,  1.97s/it][A

 14%|█▍        | 1149/8253 [37:38<3:53:18,  1.97s/it][A 14%|█▍        | 1149/8253 [37:38<3:53:27,  1.97s/it][A
 14%|█▍        | 1150/8253 [37:40<3:51:19,  1.95s/it][A
 14%|█▍        | 1150/8253 [37:40<3:51:39,  1.96s/it][A
 14%|█▍        | 1150/8253 [37:40<3:51:57,  1.96s/it][A
 14%|█▍        | 1150/8253 [37:40<3:51:48,  1.96s/it][A
 14%|█▍        | 1150/8253 [37:40<3:51:55,  1.96s/it][A
 14%|█▍        | 1150/8253 [37:40<3:52:19,  1.96s/it][A
 14%|█▍        | 1151/8253 [37:42<3:52:42,  1.97s/it][A
 14%|█▍        | 1151/8253 [37:42<3:52:57,  1.97s/it][A
 14%|█▍        | 1151/8253 [37:42<3:53:18,  1.97s/it][A
 14%|█▍        | 1151/8253 [37:42<3:53:13,  1.97s/it][A
 14%|█▍        | 1151/8253 [37:42<3:53:21,  1.97s/it][A
 14%|█▍        | 1151/8253 [37:42<3:53:15,  1.97s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:19,  1.97s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:34,  1.97s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:52,  1.98s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:42,  1.97s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:53,  1.98s/it][A
 14%|█▍        | 1152/8253 [37:44<3:53:57,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:07,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:27,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:41,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:30,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:30,  1.98s/it][A
 14%|█▍        | 1153/8253 [37:46<3:54:42,  1.98s/it][A
 14%|█▍        | 1154/8253 [37:48<3:52:15,  1.96s/it][A
 14%|█▍        | 1154/8253 [37:48<3:52:52,  1.97s/it][A
 14%|█▍        | 1154/8253 [37:48<3:52:45,  1.97s/it][A
 14%|█▍        | 1154/8253 [37:48<3:52:49,  1.97s/it][A
 14%|█▍        | 1154/8253 [37:48<3:53:00,  1.97s/it][A
 14%|█▍        | 1154/8253 [37:48<3:53:11,  1.97s/it][A
 14%|█▍        | 1155/8253 [37:50<3:54:58,  1.99s/it][A
 14%|█▍        | 1155/8253 [37:50<3:54:52,  1.99s/it][A
 14%|█▍        | 1155/8253 [37:50<3:55:20,  1.99s/it][A
 14%|█▍        | 1155/8253 [37:50<3:55:04,  1.99s/it][A
 14%|█▍        | 1155/8253 [37:50<3:54:59,  1.99s/it][A
 14%|█▍        | 1155/8253 [37:50<3:55:13,  1.99s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:05,  2.00s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:28,  2.00s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:30,  2.00s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:51,  2.00s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:35,  2.00s/it][A
 14%|█▍        | 1156/8253 [37:52<3:56:47,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:00,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:12,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:23,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:28,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:42,  2.00s/it][A
 14%|█▍        | 1157/8253 [37:54<3:56:33,  2.00s/it][A
 14%|█▍        | 1158/8253 [37:56<3:53:37,  1.98s/it][A
 14%|█▍        | 1158/8253 [37:56<3:53:52,  1.98s/it][A
 14%|█▍        | 1158/8253 [37:56<3:53:52,  1.98s/it][A
 14%|█▍        | 1158/8253 [37:56<3:53:55,  1.98s/it][A
 14%|█▍        | 1158/8253 [37:56<3:54:16,  1.98s/it][A
 14%|█▍        | 1158/8253 [37:56<3:54:14,  1.98s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:21,  1.97s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:40,  1.98s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:25,  1.97s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:29,  1.97s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:33,  1.98s/it][A
 14%|█▍        | 1159/8253 [37:58<3:53:36,  1.98s/it][A

 14%|█▍        | 1160/8253 [38:00<3:51:09,  1.96s/it] 14%|█▍        | 1160/8253 [38:00<3:51:24,  1.96s/it][A[A
 14%|█▍        | 1160/8253 [38:00<3:51:14,  1.96s/it][A
 14%|█▍        | 1160/8253 [38:00<3:51:17,  1.96s/it][A

 14%|█▍        | 1160/8253 [38:00<3:51:20,  1.96s/it][A 14%|█▍        | 1160/8253 [38:00<3:51:34,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:51:41,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:51:53,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:51:52,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:51:54,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:52:06,  1.96s/it][A
 14%|█▍        | 1161/8253 [38:02<3:52:04,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:51:58,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:51:45,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:51:56,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:51:50,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:52:08,  1.96s/it][A
 14%|█▍        | 1162/8253 [38:04<3:52:10,  1.96s/it][A
 14%|█▍        | 1163/8253 [38:06<3:51:19,  1.96s/it][A
 14%|█▍        | 1163/8253 [38:06<3:51:41,  1.96s/it][A
 14%|█▍        | 1163/8253 [38:06<3:51:40,  1.96s/it][A
 14%|█▍        | 1163/8253 [38:06<3:51:58,  1.96s/it][A

 14%|█▍        | 1163/8253 [38:06<3:51:41,  1.96s/it][A 14%|█▍        | 1163/8253 [38:06<3:51:50,  1.96s/it][A
 14%|█▍        | 1164/8253 [38:08<3:51:44,  1.96s/it][A
 14%|█▍        | 1164/8253 [38:08<3:51:57,  1.96s/it][A
 14%|█▍        | 1164/8253 [38:08<3:52:13,  1.97s/it][A
 14%|█▍        | 1164/8253 [38:08<3:52:11,  1.97s/it][A
 14%|█▍        | 1164/8253 [38:08<3:52:13,  1.97s/it][A
 14%|█▍        | 1164/8253 [38:08<3:52:20,  1.97s/it][A
 14%|█▍        | 1165/8253 [38:10<3:49:59,  1.95s/it][A
 14%|█▍        | 1165/8253 [38:10<3:50:44,  1.95s/it][A
 14%|█▍        | 1165/8253 [38:10<3:50:35,  1.95s/it][A
 14%|█▍        | 1165/8253 [38:10<3:50:58,  1.96s/it][A
 14%|█▍        | 1165/8253 [38:10<3:50:47,  1.95s/it][A
 14%|█▍        | 1165/8253 [38:10<3:50:50,  1.95s/it][A
 14%|█▍        | 1166/8253 [38:12<3:52:44,  1.97s/it][A
 14%|█▍        | 1166/8253 [38:12<3:53:17,  1.98s/it][A
 14%|█▍        | 1166/8253 [38:12<3:53:08,  1.97s/it][A
 14%|█▍        | 1166/8253 [38:12<3:53:17,  1.98s/it][A
 14%|█▍        | 1166/8253 [38:12<3:53:34,  1.98s/it][A
 14%|█▍        | 1166/8253 [38:12<3:53:45,  1.98s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:29,  1.96s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:32,  1.96s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:16,  1.96s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:38,  1.96s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:44,  1.96s/it][A
 14%|█▍        | 1167/8253 [38:14<3:51:45,  1.96s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:20,  1.95s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:15,  1.95s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:13,  1.95s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:31,  1.95s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:45,  1.95s/it][A
 14%|█▍        | 1168/8253 [38:16<3:50:41,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:17,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:26,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:44,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:34,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:45,  1.95s/it][A
 14%|█▍        | 1169/8253 [38:18<3:50:41,  1.95s/it][A
 14%|█▍        | 1170/8253 [38:20<3:49:57,  1.95s/it][A
 14%|█▍        | 1170/8253 [38:20<3:50:28,  1.95s/it][A

 14%|█▍        | 1170/8253 [38:20<3:50:28,  1.95s/it][A 14%|█▍        | 1170/8253 [38:20<3:50:37,  1.95s/it][A
 14%|█▍        | 1170/8253 [38:20<3:50:19,  1.95s/it][A
 14%|█▍        | 1170/8253 [38:20<3:50:20,  1.95s/it][A
 14%|█▍        | 1171/8253 [38:22<3:50:46,  1.96s/it][A
 14%|█▍        | 1171/8253 [38:22<3:51:09,  1.96s/it][A
 14%|█▍        | 1171/8253 [38:22<3:51:05,  1.96s/it][A
 14%|█▍        | 1171/8253 [38:22<3:51:14,  1.96s/it][A

 14%|█▍        | 1171/8253 [38:22<3:51:09,  1.96s/it][A 14%|█▍        | 1171/8253 [38:22<3:51:22,  1.96s/it][A
 14%|█▍        | 1172/8253 [38:24<3:50:30,  1.95s/it][A
 14%|█▍        | 1172/8253 [38:24<3:50:09,  1.95s/it][A

 14%|█▍        | 1172/8253 [38:24<3:50:26,  1.95s/it][A 14%|█▍        | 1172/8253 [38:24<3:50:31,  1.95s/it][A

 14%|█▍        | 1172/8253 [38:24<3:50:35,  1.95s/it][A 14%|█▍        | 1172/8253 [38:24<3:50:30,  1.95s/it][A
 14%|█▍        | 1173/8253 [38:26<3:50:48,  1.96s/it][A
 14%|█▍        | 1173/8253 [38:26<3:50:57,  1.96s/it][A
 14%|█▍        | 1173/8253 [38:26<3:51:07,  1.96s/it][A
 14%|█▍        | 1173/8253 [38:26<3:51:11,  1.96s/it][A
 14%|█▍        | 1173/8253 [38:26<3:51:30,  1.96s/it][A
 14%|█▍        | 1173/8253 [38:26<3:51:16,  1.96s/it][A
 14%|█▍        | 1174/8253 [38:28<3:51:23,  1.96s/it][A
 14%|█▍        | 1174/8253 [38:27<3:51:45,  1.96s/it][A
 14%|█▍        | 1174/8253 [38:28<3:51:41,  1.96s/it][A

 14%|█▍        | 1174/8253 [38:28<3:52:02,  1.97s/it][A 14%|█▍        | 1174/8253 [38:28<3:51:41,  1.96s/it][A
 14%|█▍        | 1174/8253 [38:28<3:51:42,  1.96s/it][A
 14%|█▍        | 1175/8253 [38:30<3:50:14,  1.95s/it][A
 14%|█▍        | 1175/8253 [38:30<3:50:27,  1.95s/it][A
 14%|█▍        | 1175/8253 [38:29<3:50:32,  1.95s/it][A
 14%|█▍        | 1175/8253 [38:30<3:50:29,  1.95s/it][A
 14%|█▍        | 1175/8253 [38:30<3:50:31,  1.95s/it][A
 14%|█▍        | 1175/8253 [38:30<3:50:52,  1.96s/it][A
 14%|█▍        | 1176/8253 [38:31<3:49:08,  1.94s/it][A
 14%|█▍        | 1176/8253 [38:31<3:49:01,  1.94s/it][A
 14%|█▍        | 1176/8253 [38:31<3:49:29,  1.95s/it][A
 14%|█▍        | 1176/8253 [38:32<3:49:44,  1.95s/it][A
 14%|█▍        | 1176/8253 [38:32<3:49:38,  1.95s/it][A
 14%|█▍        | 1176/8253 [38:31<3:49:53,  1.95s/it][A
 14%|█▍        | 1177/8253 [38:33<3:50:44,  1.96s/it][A
 14%|█▍        | 1177/8253 [38:33<3:50:51,  1.96s/it][A
 14%|█▍        | 1177/8253 [38:33<3:51:05,  1.96s/it][A
 14%|█▍        | 1177/8253 [38:33<3:50:51,  1.96s/it][A

 14%|█▍        | 1177/8253 [38:33<3:51:11,  1.96s/it][A 14%|█▍        | 1177/8253 [38:33<3:51:21,  1.96s/it][A
 14%|█▍        | 1178/8253 [38:35<3:50:18,  1.95s/it][A
 14%|█▍        | 1178/8253 [38:35<3:50:18,  1.95s/it][A

 14%|█▍        | 1178/8253 [38:35<3:50:07,  1.95s/it][A 14%|█▍        | 1178/8253 [38:35<3:50:28,  1.95s/it][A

 14%|█▍        | 1178/8253 [38:35<3:50:09,  1.95s/it][A 14%|█▍        | 1178/8253 [38:35<3:50:15,  1.95s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:26,  1.94s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:32,  1.94s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:41,  1.94s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:33,  1.94s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:56,  1.94s/it][A
 14%|█▍        | 1179/8253 [38:37<3:48:54,  1.94s/it][A
 14%|█▍        | 1180/8253 [38:39<3:49:58,  1.95s/it][A
 14%|█▍        | 1180/8253 [38:39<3:49:55,  1.95s/it][A
 14%|█▍        | 1180/8253 [38:39<3:49:59,  1.95s/it][A
 14%|█▍        | 1180/8253 [38:39<3:50:08,  1.95s/it][A
 14%|█▍        | 1180/8253 [38:39<3:50:10,  1.95s/it][A
 14%|█▍        | 1180/8253 [38:39<3:50:21,  1.95s/it][A
 14%|█▍        | 1181/8253 [38:41<3:51:17,  1.96s/it][A

 14%|█▍        | 1181/8253 [38:41<3:51:15,  1.96s/it][A 14%|█▍        | 1181/8253 [38:41<3:51:23,  1.96s/it][A
 14%|█▍        | 1181/8253 [38:41<3:51:28,  1.96s/it][A
 14%|█▍        | 1181/8253 [38:41<3:51:22,  1.96s/it][A
 14%|█▍        | 1181/8253 [38:41<3:51:27,  1.96s/it][A
 14%|█▍        | 1182/8253 [38:43<3:50:09,  1.95s/it][A
 14%|█▍        | 1182/8253 [38:43<3:50:37,  1.96s/it][A
 14%|█▍        | 1182/8253 [38:43<3:50:40,  1.96s/it][A

 14%|█▍        | 1182/8253 [38:43<3:50:41,  1.96s/it][A 14%|█▍        | 1182/8253 [38:43<3:50:44,  1.96s/it][A
 14%|█▍        | 1182/8253 [38:43<3:50:40,  1.96s/it][A
 14%|█▍        | 1183/8253 [38:45<3:49:50,  1.95s/it][A
 14%|█▍        | 1183/8253 [38:45<3:50:12,  1.95s/it][A
 14%|█▍        | 1183/8253 [38:45<3:50:08,  1.95s/it][A
 14%|█▍        | 1183/8253 [38:45<3:50:18,  1.95s/it][A
 14%|█▍        | 1183/8253 [38:45<3:50:16,  1.95s/it][A
 14%|█▍        | 1183/8253 [38:45<3:50:31,  1.96s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:06,  1.96s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:18,  1.96s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:34,  1.97s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:36,  1.97s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:26,  1.96s/it][A
 14%|█▍        | 1184/8253 [38:47<3:51:37,  1.97s/it][A
 14%|█▍        | 1185/8253 [38:49<3:49:36,  1.95s/it][A
 14%|█▍        | 1185/8253 [38:49<3:49:55,  1.95s/it][A
 14%|█▍        | 1185/8253 [38:49<3:49:59,  1.95s/it][A
 14%|█▍        | 1185/8253 [38:49<3:50:06,  1.95s/it][A
 14%|█▍        | 1185/8253 [38:49<3:50:08,  1.95s/it][A
 14%|█▍        | 1185/8253 [38:49<3:50:05,  1.95s/it][A
 14%|█▍        | 1186/8253 [38:51<3:49:59,  1.95s/it][A
 14%|█▍        | 1186/8253 [38:51<3:50:01,  1.95s/it][A
 14%|█▍        | 1186/8253 [38:51<3:50:25,  1.96s/it][A
 14%|█▍        | 1186/8253 [38:51<3:50:19,  1.96s/it][A
 14%|█▍        | 1186/8253 [38:51<3:50:36,  1.96s/it][A
 14%|█▍        | 1186/8253 [38:51<3:50:25,  1.96s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:07,  1.94s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:29,  1.94s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:34,  1.94s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:27,  1.94s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:33,  1.94s/it][A
 14%|█▍        | 1187/8253 [38:53<3:48:42,  1.94s/it][A
 14%|█▍        | 1188/8253 [38:55<3:49:48,  1.95s/it][A
 14%|█▍        | 1188/8253 [38:55<3:49:47,  1.95s/it][A
 14%|█▍        | 1188/8253 [38:55<3:50:18,  1.96s/it][A
 14%|█▍        | 1188/8253 [38:55<3:50:14,  1.96s/it][A
 14%|█▍        | 1188/8253 [38:55<3:50:05,  1.95s/it][A
 14%|█▍        | 1188/8253 [38:55<3:50:10,  1.95s/it][A
 14%|█▍        | 1189/8253 [38:57<3:48:48,  1.94s/it][A
 14%|█▍        | 1189/8253 [38:57<3:49:19,  1.95s/it][A
 14%|█▍        | 1189/8253 [38:57<3:49:14,  1.95s/it][A
 14%|█▍        | 1189/8253 [38:57<3:49:21,  1.95s/it][A
 14%|█▍        | 1189/8253 [38:57<3:49:18,  1.95s/it][A
 14%|█▍        | 1189/8253 [38:57<3:49:35,  1.95s/it][A
 14%|█▍        | 1190/8253 [38:59<3:49:59,  1.95s/it][A
 14%|█▍        | 1190/8253 [38:59<3:50:18,  1.96s/it][A
 14%|█▍        | 1190/8253 [38:59<3:50:27,  1.96s/it][A

 14%|█▍        | 1190/8253 [38:59<3:50:40,  1.96s/it][A 14%|█▍        | 1190/8253 [38:59<3:50:30,  1.96s/it][A
 14%|█▍        | 1190/8253 [38:59<3:50:37,  1.96s/it][A
 14%|█▍        | 1191/8253 [39:01<3:49:46,  1.95s/it][A
 14%|█▍        | 1191/8253 [39:01<3:49:55,  1.95s/it][A
 14%|█▍        | 1191/8253 [39:01<3:50:15,  1.96s/it][A
 14%|█▍        | 1191/8253 [39:01<3:50:33,  1.96s/it][A
 14%|█▍        | 1191/8253 [39:01<3:50:21,  1.96s/it][A
 14%|█▍        | 1191/8253 [39:01<3:50:25,  1.96s/it][A
 14%|█▍        | 1192/8253 [39:03<3:55:20,  2.00s/it][A
 14%|█▍        | 1192/8253 [39:03<3:55:48,  2.00s/it][A
 14%|█▍        | 1192/8253 [39:03<3:55:46,  2.00s/it][A
 14%|█▍        | 1192/8253 [39:03<3:55:59,  2.01s/it][A
 14%|█▍        | 1192/8253 [39:03<3:55:45,  2.00s/it][A
 14%|█▍        | 1192/8253 [39:03<3:56:03,  2.01s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:01,  2.00s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:15,  2.00s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:37,  2.00s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:21,  2.00s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:35,  2.00s/it][A
 14%|█▍        | 1193/8253 [39:05<3:55:44,  2.00s/it][A
 14%|█▍        | 1194/8253 [39:07<3:53:04,  1.98s/it][A
 14%|█▍        | 1194/8253 [39:07<3:53:11,  1.98s/it][A
 14%|█▍        | 1194/8253 [39:07<3:53:29,  1.98s/it][A
 14%|█▍        | 1194/8253 [39:07<3:53:39,  1.99s/it][A

 14%|█▍        | 1194/8253 [39:07<3:53:38,  1.99s/it][A 14%|█▍        | 1194/8253 [39:07<3:53:34,  1.99s/it][A
 14%|█▍        | 1195/8253 [39:09<3:51:15,  1.97s/it][A
 14%|█▍        | 1195/8253 [39:09<3:51:42,  1.97s/it][A
 14%|█▍        | 1195/8253 [39:09<3:51:38,  1.97s/it][A
 14%|█▍        | 1195/8253 [39:09<3:51:47,  1.97s/it][A

 14%|█▍        | 1195/8253 [39:09<3:51:58,  1.97s/it][A 14%|█▍        | 1195/8253 [39:09<3:51:54,  1.97s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:37,  1.98s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:36,  1.98s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:47,  1.98s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:48,  1.98s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:56,  1.98s/it][A
 14%|█▍        | 1196/8253 [39:11<3:52:53,  1.98s/it][A
 15%|█▍        | 1197/8253 [39:13<3:49:39,  1.95s/it][A
 15%|█▍        | 1197/8253 [39:13<3:49:52,  1.95s/it][A
 15%|█▍        | 1197/8253 [39:13<3:50:04,  1.96s/it][A
 15%|█▍        | 1197/8253 [39:13<3:50:03,  1.96s/it][A
 15%|█▍        | 1197/8253 [39:13<3:50:19,  1.96s/it][A
 15%|█▍        | 1197/8253 [39:13<3:50:38,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:49:56,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:50:04,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:50:12,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:50:16,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:50:22,  1.96s/it][A
 15%|█▍        | 1198/8253 [39:15<3:50:34,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:49:59,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:50:05,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:50:10,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:50:20,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:50:24,  1.96s/it][A
 15%|█▍        | 1199/8253 [39:17<3:50:33,  1.96s/it][A
 15%|█▍        | 1200/8253 [39:19<3:50:49,  1.96s/it][A
 15%|█▍        | 1200/8253 [39:19<3:50:46,  1.96s/it][A
 15%|█▍        | 1200/8253 [39:18<3:50:54,  1.96s/it][A
 15%|█▍        | 1200/8253 [39:19<3:51:09,  1.97s/it][A
 15%|█▍        | 1200/8253 [39:19<3:51:14,  1.97s/it][A
 15%|█▍        | 1200/8253 [39:19<3:51:11,  1.97s/it][A
 15%|█▍        | 1201/8253 [39:21<3:50:09,  1.96s/it][A
 15%|█▍        | 1201/8253 [39:20<3:50:09,  1.96s/it][A

 15%|█▍        | 1201/8253 [39:21<3:50:20,  1.96s/it][A 15%|█▍        | 1201/8253 [39:21<3:50:16,  1.96s/it][A
 15%|█▍        | 1201/8253 [39:21<3:50:34,  1.96s/it][A
 15%|█▍        | 1201/8253 [39:21<3:50:43,  1.96s/it][A
 15%|█▍        | 1202/8253 [39:23<3:50:00,  1.96s/it][A

 15%|█▍        | 1202/8253 [39:23<3:49:45,  1.96s/it][A 15%|█▍        | 1202/8253 [39:23<3:49:48,  1.96s/it][A
 15%|█▍        | 1202/8253 [39:22<3:49:58,  1.96s/it][A
 15%|█▍        | 1202/8253 [39:23<3:50:04,  1.96s/it][A
 15%|█▍        | 1202/8253 [39:23<3:49:57,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:03,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:07,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:16,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:12,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:11,  1.96s/it][A
 15%|█▍        | 1203/8253 [39:24<3:50:19,  1.96s/it][A
 15%|█▍        | 1204/8253 [39:26<3:51:19,  1.97s/it][A

 15%|█▍        | 1204/8253 [39:26<3:51:41,  1.97s/it] 15%|█▍        | 1204/8253 [39:26<3:51:43,  1.97s/it][A[A
 15%|█▍        | 1204/8253 [39:26<3:51:42,  1.97s/it][A
 15%|█▍        | 1204/8253 [39:26<3:51:58,  1.97s/it][A
 15%|█▍        | 1204/8253 [39:26<3:51:57,  1.97s/it][A
 15%|█▍        | 1205/8253 [39:28<3:49:48,  1.96s/it][A
 15%|█▍        | 1205/8253 [39:28<3:49:58,  1.96s/it][A

 15%|█▍        | 1205/8253 [39:28<3:50:02,  1.96s/it] 15%|█▍        | 1205/8253 [39:28<3:50:11,  1.96s/it][A[A

 15%|█▍        | 1205/8253 [39:28<3:50:00,  1.96s/it][A 15%|█▍        | 1205/8253 [39:28<3:50:15,  1.96s/it][A
 15%|█▍        | 1206/8253 [39:30<3:48:44,  1.95s/it][A
 15%|█▍        | 1206/8253 [39:30<3:48:49,  1.95s/it][A
 15%|█▍        | 1206/8253 [39:30<3:48:57,  1.95s/it][A
 15%|█▍        | 1206/8253 [39:30<3:49:04,  1.95s/it][A
 15%|█▍        | 1206/8253 [39:30<3:49:13,  1.95s/it][A
 15%|█▍        | 1206/8253 [39:30<3:49:17,  1.95s/it][A
 15%|█▍        | 1207/8253 [39:32<3:49:36,  1.96s/it][A
 15%|█▍        | 1207/8253 [39:32<3:49:46,  1.96s/it][A
 15%|█▍        | 1207/8253 [39:32<3:49:32,  1.95s/it][A

 15%|█▍        | 1207/8253 [39:32<3:50:05,  1.96s/it][A 15%|█▍        | 1207/8253 [39:32<3:50:05,  1.96s/it][A
 15%|█▍        | 1207/8253 [39:32<3:50:09,  1.96s/it][A
 15%|█▍        | 1208/8253 [39:34<3:47:59,  1.94s/it][A
 15%|█▍        | 1208/8253 [39:34<3:48:04,  1.94s/it][A

 15%|█▍        | 1208/8253 [39:34<3:48:11,  1.94s/it][A 15%|█▍        | 1208/8253 [39:34<3:48:02,  1.94s/it][A
 15%|█▍        | 1208/8253 [39:34<3:48:12,  1.94s/it][A
 15%|█▍        | 1208/8253 [39:34<3:48:18,  1.94s/it][A
 15%|█▍        | 1209/8253 [39:36<3:47:35,  1.94s/it][A
 15%|█▍        | 1209/8253 [39:36<3:47:47,  1.94s/it][A
 15%|█▍        | 1209/8253 [39:36<3:47:55,  1.94s/it][A
 15%|█▍        | 1209/8253 [39:36<3:48:20,  1.94s/it][A

 15%|█▍        | 1209/8253 [39:36<3:48:13,  1.94s/it][A 15%|█▍        | 1209/8253 [39:36<3:48:28,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:21,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:34,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:44,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:36,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:49,  1.95s/it][A
 15%|█▍        | 1210/8253 [39:38<3:48:51,  1.95s/it][A
 15%|█▍        | 1211/8253 [39:40<3:46:37,  1.93s/it][A
 15%|█▍        | 1211/8253 [39:40<3:46:56,  1.93s/it][A
 15%|█▍        | 1211/8253 [39:40<3:47:07,  1.94s/it][A
 15%|█▍        | 1211/8253 [39:40<3:47:13,  1.94s/it][A
 15%|█▍        | 1211/8253 [39:40<3:47:11,  1.94s/it][A
 15%|█▍        | 1211/8253 [39:40<3:47:24,  1.94s/it][A
 15%|█▍        | 1212/8253 [39:42<3:48:02,  1.94s/it][A
 15%|█▍        | 1212/8253 [39:42<3:48:11,  1.94s/it][A

 15%|█▍        | 1212/8253 [39:42<3:48:13,  1.94s/it][A 15%|█▍        | 1212/8253 [39:42<3:48:16,  1.95s/it][A
 15%|█▍        | 1212/8253 [39:42<3:48:45,  1.95s/it][A
 15%|█▍        | 1212/8253 [39:42<3:48:55,  1.95s/it][A
 15%|█▍        | 1213/8253 [39:44<3:49:37,  1.96s/it][A
 15%|█▍        | 1213/8253 [39:44<3:49:53,  1.96s/it][A
 15%|█▍        | 1213/8253 [39:44<3:49:51,  1.96s/it][A
 15%|█▍        | 1213/8253 [39:44<3:49:45,  1.96s/it][A
 15%|█▍        | 1213/8253 [39:44<3:50:03,  1.96s/it][A
 15%|█▍        | 1213/8253 [39:44<3:49:55,  1.96s/it][A
 15%|█▍        | 1214/8253 [39:46<3:48:53,  1.95s/it][A
 15%|█▍        | 1214/8253 [39:46<3:49:00,  1.95s/it][A
 15%|█▍        | 1214/8253 [39:46<3:49:18,  1.95s/it][A
 15%|█▍        | 1214/8253 [39:46<3:49:09,  1.95s/it][A
 15%|█▍        | 1214/8253 [39:46<3:49:19,  1.95s/it][A
 15%|█▍        | 1214/8253 [39:46<3:49:14,  1.95s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:25,  1.96s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:35,  1.96s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:46,  1.96s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:49,  1.96s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:48,  1.96s/it][A
 15%|█▍        | 1215/8253 [39:48<3:49:49,  1.96s/it][A
 15%|█▍        | 1216/8253 [39:50<3:49:28,  1.96s/it][A
 15%|█▍        | 1216/8253 [39:50<3:49:20,  1.96s/it][A
 15%|█▍        | 1216/8253 [39:50<3:49:30,  1.96s/it][A
 15%|█▍        | 1216/8253 [39:50<3:49:32,  1.96s/it][A

 15%|█▍        | 1216/8253 [39:50<3:49:52,  1.96s/it] 15%|█▍        | 1216/8253 [39:50<3:49:46,  1.96s/it][A[A

 15%|█▍        | 1217/8253 [39:52<3:49:29,  1.96s/it][A 15%|█▍        | 1217/8253 [39:52<3:49:24,  1.96s/it][A
 15%|█▍        | 1217/8253 [39:52<3:49:47,  1.96s/it][A

 15%|█▍        | 1217/8253 [39:52<3:49:56,  1.96s/it][A 15%|█▍        | 1217/8253 [39:52<3:49:49,  1.96s/it][A
 15%|█▍        | 1217/8253 [39:52<3:49:53,  1.96s/it][A
 15%|█▍        | 1218/8253 [39:54<3:49:31,  1.96s/it][A
 15%|█▍        | 1218/8253 [39:54<3:49:42,  1.96s/it][A

 15%|█▍        | 1218/8253 [39:54<3:49:49,  1.96s/it][A 15%|█▍        | 1218/8253 [39:54<3:49:48,  1.96s/it][A

 15%|█▍        | 1218/8253 [39:54<3:49:56,  1.96s/it][A 15%|█▍        | 1218/8253 [39:54<3:50:03,  1.96s/it][A
 15%|█▍        | 1219/8253 [39:56<3:52:01,  1.98s/it][A
 15%|█▍        | 1219/8253 [39:56<3:52:11,  1.98s/it][A

 15%|█▍        | 1219/8253 [39:56<3:52:18,  1.98s/it][A 15%|█▍        | 1219/8253 [39:56<3:52:19,  1.98s/it][A
 15%|█▍        | 1219/8253 [39:56<3:52:20,  1.98s/it][A
 15%|█▍        | 1219/8253 [39:56<3:52:19,  1.98s/it][A
 15%|█▍        | 1220/8253 [39:58<3:52:48,  1.99s/it][A
 15%|█▍        | 1220/8253 [39:58<3:53:10,  1.99s/it][A
 15%|█▍        | 1220/8253 [39:58<3:53:10,  1.99s/it][A

 15%|█▍        | 1220/8253 [39:58<3:53:18,  1.99s/it][A 15%|█▍        | 1220/8253 [39:58<3:53:05,  1.99s/it][A
 15%|█▍        | 1220/8253 [39:58<3:53:20,  1.99s/it][A
 15%|█▍        | 1221/8253 [40:00<3:52:53,  1.99s/it][A
 15%|█▍        | 1221/8253 [40:00<3:53:03,  1.99s/it][A
 15%|█▍        | 1221/8253 [40:00<3:53:10,  1.99s/it][A
 15%|█▍        | 1221/8253 [40:00<3:53:13,  1.99s/it][A
 15%|█▍        | 1221/8253 [40:00<3:53:38,  1.99s/it]
[A 15%|█▍        | 1221/8253 [40:00<3:53:37,  1.99s/it][A
 15%|█▍        | 1222/8253 [40:02<3:53:23,  1.99s/it][A

 15%|█▍        | 1222/8253 [40:02<3:53:27,  1.99s/it][A 15%|█▍        | 1222/8253 [40:02<3:53:24,  1.99s/it][A
 15%|█▍        | 1222/8253 [40:02<3:53:30,  1.99s/it][A
 15%|█▍        | 1222/8253 [40:02<3:53:33,  1.99s/it][A
 15%|█▍        | 1222/8253 [40:02<3:53:42,  1.99s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:10,  2.05s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:14,  2.05s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:25,  2.05s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:28,  2.05s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:40,  2.05s/it][A
 15%|█▍        | 1223/8253 [40:04<4:00:34,  2.05s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:29,  2.04s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:33,  2.04s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:24,  2.04s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:26,  2.04s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:37,  2.04s/it][A
 15%|█▍        | 1224/8253 [40:06<3:58:34,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:59:00,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:58:57,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:59:17,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:59:24,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:59:29,  2.04s/it][A
 15%|█▍        | 1225/8253 [40:08<3:59:37,  2.05s/it][A
 15%|█▍        | 1226/8253 [40:10<3:57:33,  2.03s/it][A

 15%|█▍        | 1226/8253 [40:10<3:57:50,  2.03s/it][A 15%|█▍        | 1226/8253 [40:10<3:57:50,  2.03s/it][A
 15%|█▍        | 1226/8253 [40:10<3:57:48,  2.03s/it][A
 15%|█▍        | 1226/8253 [40:10<3:58:02,  2.03s/it][A
 15%|█▍        | 1226/8253 [40:10<3:58:04,  2.03s/it][A
 15%|█▍        | 1227/8253 [40:12<3:54:55,  2.01s/it][A
 15%|█▍        | 1227/8253 [40:12<3:54:54,  2.01s/it][A
 15%|█▍        | 1227/8253 [40:12<3:55:00,  2.01s/it][A

 15%|█▍        | 1227/8253 [40:12<3:54:56,  2.01s/it][A 15%|█▍        | 1227/8253 [40:12<3:55:05,  2.01s/it][A
 15%|█▍        | 1227/8253 [40:12<3:55:04,  2.01s/it][A
 15%|█▍        | 1228/8253 [40:14<3:52:00,  1.98s/it][A
 15%|█▍        | 1228/8253 [40:14<3:51:54,  1.98s/it][A
 15%|█▍        | 1228/8253 [40:14<3:52:05,  1.98s/it][A
 15%|█▍        | 1228/8253 [40:14<3:52:16,  1.98s/it][A
 15%|█▍        | 1228/8253 [40:14<3:52:15,  1.98s/it][A
 15%|█▍        | 1228/8253 [40:14<3:52:13,  1.98s/it][A
 15%|█▍        | 1229/8253 [40:16<3:51:47,  1.98s/it][A
 15%|█▍        | 1229/8253 [40:16<3:52:02,  1.98s/it][A
 15%|█▍        | 1229/8253 [40:16<3:52:06,  1.98s/it][A
 15%|█▍        | 1229/8253 [40:16<3:52:08,  1.98s/it][A
 15%|█▍        | 1229/8253 [40:16<3:52:24,  1.99s/it][A
 15%|█▍        | 1229/8253 [40:16<3:52:21,  1.98s/it][A
 15%|█▍        | 1230/8253 [40:18<3:52:00,  1.98s/it][A

 15%|█▍        | 1230/8253 [40:18<3:52:16,  1.98s/it][A 15%|█▍        | 1230/8253 [40:18<3:52:23,  1.99s/it][A
 15%|█▍        | 1230/8253 [40:18<3:52:15,  1.98s/it][A

 15%|█▍        | 1230/8253 [40:18<3:52:13,  1.98s/it][A 15%|█▍        | 1230/8253 [40:18<3:52:19,  1.98s/it][A
 15%|█▍        | 1231/8253 [40:20<3:52:17,  1.98s/it][A
 15%|█▍        | 1231/8253 [40:20<3:52:09,  1.98s/it][A

 15%|█▍        | 1231/8253 [40:20<3:52:23,  1.99s/it][A 15%|█▍        | 1231/8253 [40:20<3:52:29,  1.99s/it][A
 15%|█▍        | 1231/8253 [40:20<3:52:35,  1.99s/it][A
 15%|█▍        | 1231/8253 [40:20<3:52:44,  1.99s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:15,  1.98s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:11,  1.98s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:31,  1.98s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:28,  1.98s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:36,  1.98s/it][A
 15%|█▍        | 1232/8253 [40:22<3:51:46,  1.98s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:21,  1.99s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:40,  1.99s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:28,  1.99s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:28,  1.99s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:59,  1.99s/it][A
 15%|█▍        | 1233/8253 [40:24<3:52:49,  1.99s/it][A
 15%|█▍        | 1234/8253 [40:26<3:53:11,  1.99s/it][A
 15%|█▍        | 1234/8253 [40:26<3:53:24,  2.00s/it][A
 15%|█▍        | 1234/8253 [40:26<3:53:35,  2.00s/it][A

 15%|█▍        | 1234/8253 [40:26<3:53:24,  2.00s/it][A 15%|█▍        | 1234/8253 [40:26<3:53:49,  2.00s/it][A
 15%|█▍        | 1234/8253 [40:26<3:53:44,  2.00s/it][A
 15%|█▍        | 1235/8253 [40:28<3:51:50,  1.98s/it][A
 15%|█▍        | 1235/8253 [40:28<3:52:37,  1.99s/it][A
 15%|█▍        | 1235/8253 [40:28<3:52:33,  1.99s/it][A
 15%|█▍        | 1235/8253 [40:28<3:52:29,  1.99s/it][A
 15%|█▍        | 1235/8253 [40:28<3:52:43,  1.99s/it][A
 15%|█▍        | 1235/8253 [40:28<3:52:44,  1.99s/it][A
 15%|█▍        | 1236/8253 [40:30<3:51:56,  1.98s/it][A
 15%|█▍        | 1236/8253 [40:30<3:52:01,  1.98s/it][A
 15%|█▍        | 1236/8253 [40:30<3:52:21,  1.99s/it][A
 15%|█▍        | 1236/8253 [40:30<3:52:23,  1.99s/it][A
 15%|█▍        | 1236/8253 [40:30<3:52:31,  1.99s/it][A
 15%|█▍        | 1236/8253 [40:30<3:52:39,  1.99s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:11,  1.97s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:17,  1.97s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:13,  1.97s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:21,  1.97s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:31,  1.97s/it][A
 15%|█▍        | 1237/8253 [40:32<3:50:22,  1.97s/it][A
 15%|█▌        | 1238/8253 [40:34<3:50:23,  1.97s/it][A

 15%|█▌        | 1238/8253 [40:34<3:50:22,  1.97s/it][A 15%|█▌        | 1238/8253 [40:34<3:50:17,  1.97s/it][A
 15%|█▌        | 1238/8253 [40:34<3:50:40,  1.97s/it][A
 15%|█▌        | 1238/8253 [40:34<3:50:43,  1.97s/it][A
 15%|█▌        | 1238/8253 [40:34<3:50:38,  1.97s/it][A
 15%|█▌        | 1239/8253 [40:36<3:51:20,  1.98s/it][A
 15%|█▌        | 1239/8253 [40:36<3:51:47,  1.98s/it][A
 15%|█▌        | 1239/8253 [40:36<3:51:48,  1.98s/it][A
 15%|█▌        | 1239/8253 [40:36<3:51:48,  1.98s/it][A
 15%|█▌        | 1239/8253 [40:36<3:51:56,  1.98s/it][A
 15%|█▌        | 1239/8253 [40:36<3:52:00,  1.98s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:12,  1.97s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:07,  1.97s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:00,  1.97s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:23,  1.97s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:20,  1.97s/it][A
 15%|█▌        | 1240/8253 [40:38<3:50:25,  1.97s/it][A
 15%|█▌        | 1241/8253 [40:40<3:49:24,  1.96s/it][A
 15%|█▌        | 1241/8253 [40:40<3:49:15,  1.96s/it]
[A 15%|█▌        | 1241/8253 [40:40<3:49:13,  1.96s/it][A
 15%|█▌        | 1241/8253 [40:40<3:49:11,  1.96s/it][A
 15%|█▌        | 1241/8253 [40:40<3:49:21,  1.96s/it][A
 15%|█▌        | 1241/8253 [40:40<3:49:29,  1.96s/it][A
 15%|█▌        | 1242/8253 [40:42<3:48:14,  1.95s/it][A
 15%|█▌        | 1242/8253 [40:41<3:48:14,  1.95s/it][A
 15%|█▌        | 1242/8253 [40:42<3:48:34,  1.96s/it][A
 15%|█▌        | 1242/8253 [40:42<3:48:35,  1.96s/it][A
 15%|█▌        | 1242/8253 [40:42<3:48:45,  1.96s/it][A
 15%|█▌        | 1242/8253 [40:42<3:48:49,  1.96s/it][A
 15%|█▌        | 1243/8253 [40:43<3:47:36,  1.95s/it][A
 15%|█▌        | 1243/8253 [40:44<3:48:06,  1.95s/it][A
 15%|█▌        | 1243/8253 [40:44<3:48:05,  1.95s/it][A

 15%|█▌        | 1243/8253 [40:44<3:48:09,  1.95s/it][A 15%|█▌        | 1243/8253 [40:44<3:48:20,  1.95s/it][A
 15%|█▌        | 1243/8253 [40:44<3:48:06,  1.95s/it][A
 15%|█▌        | 1244/8253 [40:45<3:47:07,  1.94s/it][A
 15%|█▌        | 1244/8253 [40:45<3:47:11,  1.94s/it][A
 15%|█▌        | 1244/8253 [40:45<3:47:11,  1.94s/it][A
 15%|█▌        | 1244/8253 [40:45<3:47:23,  1.95s/it][A

 15%|█▌        | 1244/8253 [40:45<3:47:23,  1.95s/it][A 15%|█▌        | 1244/8253 [40:45<3:47:18,  1.95s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:19,  1.94s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:26,  1.94s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:41,  1.94s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:31,  1.94s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:52,  1.94s/it][A
 15%|█▌        | 1245/8253 [40:47<3:46:48,  1.94s/it][A
 15%|█▌        | 1246/8253 [40:49<3:44:32,  1.92s/it][A
 15%|█▌        | 1246/8253 [40:49<3:44:42,  1.92s/it][A
 15%|█▌        | 1246/8253 [40:49<3:45:06,  1.93s/it][A
 15%|█▌        | 1246/8253 [40:49<3:45:00,  1.93s/it][A
 15%|█▌        | 1246/8253 [40:49<3:45:06,  1.93s/it][A
 15%|█▌        | 1246/8253 [40:49<3:45:16,  1.93s/it][A

 15%|█▌        | 1247/8253 [40:51<3:46:21,  1.94s/it][A 15%|█▌        | 1247/8253 [40:51<3:46:17,  1.94s/it][A
 15%|█▌        | 1247/8253 [40:51<3:46:22,  1.94s/it][A
 15%|█▌        | 1247/8253 [40:51<3:46:39,  1.94s/it][A
 15%|█▌        | 1247/8253 [40:51<3:46:34,  1.94s/it][A
 15%|█▌        | 1247/8253 [40:51<3:46:33,  1.94s/it][A
 15%|█▌        | 1248/8253 [40:53<3:46:56,  1.94s/it][A

 15%|█▌        | 1248/8253 [40:53<3:47:10,  1.95s/it][A 15%|█▌        | 1248/8253 [40:53<3:47:23,  1.95s/it][A
 15%|█▌        | 1248/8253 [40:53<3:47:28,  1.95s/it][A
 15%|█▌        | 1248/8253 [40:53<3:47:30,  1.95s/it][A
 15%|█▌        | 1248/8253 [40:53<3:47:30,  1.95s/it][A
 15%|█▌        | 1249/8253 [40:55<3:46:34,  1.94s/it][A
 15%|█▌        | 1249/8253 [40:55<3:46:47,  1.94s/it][A
 15%|█▌        | 1249/8253 [40:55<3:46:56,  1.94s/it][A
 15%|█▌        | 1249/8253 [40:55<3:46:47,  1.94s/it][A
 15%|█▌        | 1249/8253 [40:55<3:46:57,  1.94s/it][A
 15%|█▌        | 1249/8253 [40:55<3:47:01,  1.94s/it][A
 15%|█▌        | 1250/8253 [40:57<3:46:39,  1.94s/it][A
 15%|█▌        | 1250/8253 [40:57<3:47:15,  1.95s/it][A
 15%|█▌        | 1250/8253 [40:57<3:47:14,  1.95s/it][A
 15%|█▌        | 1250/8253 [40:57<3:47:23,  1.95s/it][A
 15%|█▌        | 1250/8253 [40:57<3:47:13,  1.95s/it][A
 15%|█▌        | 1250/8253 [40:57<3:47:27,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:25,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:14,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:36,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:42,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:43,  1.95s/it][A
 15%|█▌        | 1251/8253 [40:59<3:47:51,  1.95s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:19,  1.97s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:40,  1.97s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:40,  1.97s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:59,  1.97s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:46,  1.97s/it][A
 15%|█▌        | 1252/8253 [41:01<3:49:45,  1.97s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:03,  1.95s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:25,  1.96s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:26,  1.96s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:27,  1.96s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:29,  1.96s/it][A
 15%|█▌        | 1253/8253 [41:03<3:48:45,  1.96s/it][A
 15%|█▌        | 1254/8253 [41:05<3:47:23,  1.95s/it][A
 15%|█▌        | 1254/8253 [41:05<3:47:31,  1.95s/it][A

 15%|█▌        | 1254/8253 [41:05<3:47:38,  1.95s/it][A 15%|█▌        | 1254/8253 [41:05<3:47:44,  1.95s/it][A

 15%|█▌        | 1254/8253 [41:05<3:47:55,  1.95s/it][A 15%|█▌        | 1254/8253 [41:05<3:47:46,  1.95s/it][A
 15%|█▌        | 1255/8253 [41:07<3:48:26,  1.96s/it][A
 15%|█▌        | 1255/8253 [41:07<3:48:37,  1.96s/it][A
 15%|█▌        | 1255/8253 [41:07<3:49:01,  1.96s/it][A
 15%|█▌        | 1255/8253 [41:07<3:48:56,  1.96s/it][A
 15%|█▌        | 1255/8253 [41:07<3:49:05,  1.96s/it][A
 15%|█▌        | 1255/8253 [41:07<3:49:22,  1.97s/it][A
 15%|█▌        | 1256/8253 [41:09<3:47:38,  1.95s/it][A
 15%|█▌        | 1256/8253 [41:09<3:47:55,  1.95s/it][A
 15%|█▌        | 1256/8253 [41:09<3:48:10,  1.96s/it][A
 15%|█▌        | 1256/8253 [41:09<3:48:08,  1.96s/it][A

 15%|█▌        | 1256/8253 [41:09<3:48:05,  1.96s/it][A 15%|█▌        | 1256/8253 [41:09<3:48:24,  1.96s/it][A
 15%|█▌        | 1257/8253 [41:11<3:47:27,  1.95s/it][A
 15%|█▌        | 1257/8253 [41:11<3:48:03,  1.96s/it][A
 15%|█▌        | 1257/8253 [41:11<3:48:07,  1.96s/it][A
 15%|█▌        | 1257/8253 [41:11<3:48:21,  1.96s/it][A
 15%|█▌        | 1257/8253 [41:11<3:48:33,  1.96s/it][A
 15%|█▌        | 1257/8253 [41:11<3:48:21,  1.96s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:17,  1.95s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:22,  1.95s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:38,  1.95s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:20,  1.95s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:37,  1.95s/it][A
 15%|█▌        | 1258/8253 [41:13<3:47:54,  1.95s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:23,  1.96s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:21,  1.96s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:34,  1.96s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:44,  1.96s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:41,  1.96s/it][A
 15%|█▌        | 1259/8253 [41:15<3:48:35,  1.96s/it][A
 15%|█▌        | 1260/8253 [41:17<3:49:51,  1.97s/it][A
 15%|█▌        | 1260/8253 [41:17<3:50:10,  1.97s/it][A
 15%|█▌        | 1260/8253 [41:17<3:49:54,  1.97s/it][A
 15%|█▌        | 1260/8253 [41:17<3:50:09,  1.97s/it][A
 15%|█▌        | 1260/8253 [41:17<3:50:18,  1.98s/it][A
 15%|█▌        | 1260/8253 [41:17<3:50:25,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:15,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:12,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:21,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:14,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:25,  1.98s/it][A
 15%|█▌        | 1261/8253 [41:19<3:50:31,  1.98s/it][A
 15%|█▌        | 1262/8253 [41:21<3:49:51,  1.97s/it][A
 15%|█▌        | 1262/8253 [41:21<3:50:08,  1.98s/it][A
 15%|█▌        | 1262/8253 [41:21<3:50:27,  1.98s/it][A
 15%|█▌        | 1262/8253 [41:21<3:50:17,  1.98s/it][A
 15%|█▌        | 1262/8253 [41:21<3:50:14,  1.98s/it][A
 15%|█▌        | 1262/8253 [41:21<3:50:27,  1.98s/it][A
 15%|█▌        | 1263/8253 [41:23<3:51:05,  1.98s/it][A
 15%|█▌        | 1263/8253 [41:23<3:51:07,  1.98s/it][A
 15%|█▌        | 1263/8253 [41:23<3:51:06,  1.98s/it][A


 15%|█▌        | 1263/8253 [41:23<3:51:42,  1.99s/it][A 15%|█▌        | 1263/8253 [41:23<3:51:33,  1.99s/it][A 15%|█▌        | 1263/8253 [41:23<3:51:36,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:21,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:20,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:42,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:43,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:51,  1.99s/it][A
 15%|█▌        | 1264/8253 [41:25<3:51:56,  1.99s/it][A
 15%|█▌        | 1265/8253 [41:27<3:50:02,  1.98s/it][A
 15%|█▌        | 1265/8253 [41:27<3:50:05,  1.98s/it][A
 15%|█▌        | 1265/8253 [41:27<3:50:20,  1.98s/it][A
 15%|█▌        | 1265/8253 [41:27<3:50:20,  1.98s/it][A

 15%|█▌        | 1265/8253 [41:27<3:50:37,  1.98s/it][A 15%|█▌        | 1265/8253 [41:27<3:50:28,  1.98s/it][A
 15%|█▌        | 1266/8253 [41:29<3:48:04,  1.96s/it][A
 15%|█▌        | 1266/8253 [41:29<3:48:14,  1.96s/it][A
 15%|█▌        | 1266/8253 [41:28<3:48:17,  1.96s/it][A
 15%|█▌        | 1266/8253 [41:29<3:48:23,  1.96s/it][A
 15%|█▌        | 1266/8253 [41:29<3:48:48,  1.96s/it][A
 15%|█▌        | 1266/8253 [41:29<3:48:30,  1.96s/it][A
 15%|█▌        | 1267/8253 [41:31<3:46:31,  1.95s/it][A
 15%|█▌        | 1267/8253 [41:31<3:46:31,  1.95s/it][A
 15%|█▌        | 1267/8253 [41:31<3:46:41,  1.95s/it][A
 15%|█▌        | 1267/8253 [41:31<3:47:08,  1.95s/it][A
 15%|█▌        | 1267/8253 [41:30<3:47:04,  1.95s/it][A
 15%|█▌        | 1267/8253 [41:31<3:47:15,  1.95s/it][A

 15%|█▌        | 1268/8253 [41:32<3:45:19,  1.94s/it][A 15%|█▌        | 1268/8253 [41:32<3:45:18,  1.94s/it][A
 15%|█▌        | 1268/8253 [41:32<3:45:33,  1.94s/it][A

 15%|█▌        | 1268/8253 [41:32<3:45:21,  1.94s/it][A 15%|█▌        | 1268/8253 [41:32<3:45:24,  1.94s/it][A
 15%|█▌        | 1268/8253 [41:32<3:45:36,  1.94s/it][A
 15%|█▌        | 1269/8253 [41:34<3:43:50,  1.92s/it][A
 15%|█▌        | 1269/8253 [41:34<3:43:56,  1.92s/it][A
 15%|█▌        | 1269/8253 [41:34<3:44:11,  1.93s/it][A
 15%|█▌        | 1269/8253 [41:34<3:44:13,  1.93s/it][A
 15%|█▌        | 1269/8253 [41:34<3:44:29,  1.93s/it][A
 15%|█▌        | 1269/8253 [41:34<3:44:18,  1.93s/it][A
 15%|█▌        | 1270/8253 [41:36<3:45:57,  1.94s/it][A
 15%|█▌        | 1270/8253 [41:36<3:46:01,  1.94s/it][A
 15%|█▌        | 1270/8253 [41:36<3:45:56,  1.94s/it][A
 15%|█▌        | 1270/8253 [41:36<3:46:20,  1.94s/it][A
 15%|█▌        | 1270/8253 [41:36<3:46:24,  1.95s/it][A
 15%|█▌        | 1270/8253 [41:36<3:46:20,  1.94s/it][A
 15%|█▌        | 1271/8253 [41:38<3:44:28,  1.93s/it][A
 15%|█▌        | 1271/8253 [41:38<3:44:32,  1.93s/it][A
 15%|█▌        | 1271/8253 [41:38<3:45:02,  1.93s/it][A
 15%|█▌        | 1271/8253 [41:38<3:45:04,  1.93s/it][A
 15%|█▌        | 1271/8253 [41:38<3:45:03,  1.93s/it][A
 15%|█▌        | 1271/8253 [41:38<3:45:08,  1.93s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:17,  1.94s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:33,  1.94s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:25,  1.94s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:29,  1.94s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:52,  1.94s/it][A
 15%|█▌        | 1272/8253 [41:40<3:45:45,  1.94s/it][A
 15%|█▌        | 1273/8253 [41:42<3:44:44,  1.93s/it][A
 15%|█▌        | 1273/8253 [41:42<3:45:09,  1.94s/it][A
 15%|█▌        | 1273/8253 [41:42<3:45:14,  1.94s/it][A
 15%|█▌        | 1273/8253 [41:42<3:45:33,  1.94s/it][A
 15%|█▌        | 1273/8253 [41:42<3:45:22,  1.94s/it][A
 15%|█▌        | 1273/8253 [41:42<3:45:20,  1.94s/it][A
 15%|█▌        | 1274/8253 [41:44<3:45:51,  1.94s/it][A
 15%|█▌        | 1274/8253 [41:44<3:45:41,  1.94s/it][A
 15%|█▌        | 1274/8253 [41:44<3:45:40,  1.94s/it][A
 15%|█▌        | 1274/8253 [41:44<3:45:53,  1.94s/it][A
 15%|█▌        | 1274/8253 [41:44<3:46:15,  1.95s/it][A
 15%|█▌        | 1274/8253 [41:44<3:46:19,  1.95s/it][A
 15%|█▌        | 1275/8253 [41:46<3:45:39,  1.94s/it][A
 15%|█▌        | 1275/8253 [41:46<3:45:56,  1.94s/it][A
 15%|█▌        | 1275/8253 [41:46<3:46:07,  1.94s/it][A

 15%|█▌        | 1275/8253 [41:46<3:46:11,  1.94s/it][A 15%|█▌        | 1275/8253 [41:46<3:46:23,  1.95s/it][A
 15%|█▌        | 1275/8253 [41:46<3:46:17,  1.95s/it][A
 15%|█▌        | 1276/8253 [41:48<3:45:27,  1.94s/it][A
 15%|█▌        | 1276/8253 [41:48<3:45:36,  1.94s/it][A
 15%|█▌        | 1276/8253 [41:48<3:46:04,  1.94s/it][A
 15%|█▌        | 1276/8253 [41:48<3:45:58,  1.94s/it][A
 15%|█▌        | 1276/8253 [41:48<3:46:11,  1.95s/it][A
 15%|█▌        | 1276/8253 [41:48<3:46:16,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:30,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:25,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:27,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:34,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:35,  1.95s/it][A
 15%|█▌        | 1277/8253 [41:50<3:46:47,  1.95s/it][A
 15%|█▌        | 1278/8253 [41:52<3:45:55,  1.94s/it][A
 15%|█▌        | 1278/8253 [41:52<3:46:07,  1.95s/it][A
 15%|█▌        | 1278/8253 [41:52<3:46:19,  1.95s/it][A
 15%|█▌        | 1278/8253 [41:52<3:46:20,  1.95s/it][A
 15%|█▌        | 1278/8253 [41:52<3:46:22,  1.95s/it][A
 15%|█▌        | 1278/8253 [41:52<3:46:24,  1.95s/it][A

 15%|█▌        | 1279/8253 [41:54<3:47:08,  1.95s/it][A 15%|█▌        | 1279/8253 [41:54<3:47:03,  1.95s/it][A
 15%|█▌        | 1279/8253 [41:54<3:47:17,  1.96s/it][A
 15%|█▌        | 1279/8253 [41:54<3:47:22,  1.96s/it][A
 15%|█▌        | 1279/8253 [41:54<3:47:21,  1.96s/it][A
 15%|█▌        | 1279/8253 [41:54<3:47:23,  1.96s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:11,  1.95s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:04,  1.95s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:24,  1.96s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:30,  1.96s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:40,  1.96s/it][A
 16%|█▌        | 1280/8253 [41:56<3:47:47,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:47:51,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:47:49,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:47:53,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:47:56,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:48:02,  1.96s/it][A
 16%|█▌        | 1281/8253 [41:58<3:48:01,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:10,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:22,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:28,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:31,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:44,  1.96s/it][A
 16%|█▌        | 1282/8253 [42:00<3:47:46,  1.96s/it][A
 16%|█▌        | 1283/8253 [42:02<3:46:42,  1.95s/it][A
 16%|█▌        | 1283/8253 [42:02<3:46:48,  1.95s/it][A
 16%|█▌        | 1283/8253 [42:02<3:47:16,  1.96s/it][A
 16%|█▌        | 1283/8253 [42:02<3:47:21,  1.96s/it][A
 16%|█▌        | 1283/8253 [42:02<3:47:27,  1.96s/it][A
 16%|█▌        | 1283/8253 [42:02<3:47:24,  1.96s/it][A
 16%|█▌        | 1284/8253 [42:04<3:49:08,  1.97s/it][A

 16%|█▌        | 1284/8253 [42:04<3:49:17,  1.97s/it][A 16%|█▌        | 1284/8253 [42:04<3:49:31,  1.98s/it][A
 16%|█▌        | 1284/8253 [42:04<3:49:31,  1.98s/it][A
 16%|█▌        | 1284/8253 [42:04<3:49:22,  1.97s/it][A
 16%|█▌        | 1284/8253 [42:04<3:49:31,  1.98s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:26,  2.01s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:34,  2.01s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:36,  2.01s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:36,  2.01s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:53,  2.01s/it][A
 16%|█▌        | 1285/8253 [42:06<3:53:43,  2.01s/it][A
 16%|█▌        | 1286/8253 [42:08<3:51:21,  1.99s/it][A

 16%|█▌        | 1286/8253 [42:08<3:52:01,  2.00s/it][A 16%|█▌        | 1286/8253 [42:08<3:51:47,  2.00s/it][A
 16%|█▌        | 1286/8253 [42:08<3:51:52,  2.00s/it][A
 16%|█▌        | 1286/8253 [42:08<3:52:06,  2.00s/it][A
 16%|█▌        | 1286/8253 [42:08<3:51:50,  2.00s/it][A
 16%|█▌        | 1287/8253 [42:10<3:49:34,  1.98s/it][A
 16%|█▌        | 1287/8253 [42:10<3:49:48,  1.98s/it][A
 16%|█▌        | 1287/8253 [42:10<3:49:33,  1.98s/it][A
 16%|█▌        | 1287/8253 [42:10<3:50:05,  1.98s/it][A
 16%|█▌        | 1287/8253 [42:10<3:50:08,  1.98s/it][A
 16%|█▌        | 1287/8253 [42:10<3:50:08,  1.98s/it][A
 16%|█▌        | 1288/8253 [42:11<3:48:23,  1.97s/it][A

 16%|█▌        | 1288/8253 [42:12<3:48:55,  1.97s/it][A 16%|█▌        | 1288/8253 [42:12<3:48:56,  1.97s/it][A
 16%|█▌        | 1288/8253 [42:12<3:48:47,  1.97s/it][A
 16%|█▌        | 1288/8253 [42:12<3:48:49,  1.97s/it][A
 16%|█▌        | 1288/8253 [42:12<3:48:49,  1.97s/it][A
 16%|█▌        | 1289/8253 [42:14<3:46:14,  1.95s/it][A
 16%|█▌        | 1289/8253 [42:14<3:46:20,  1.95s/it][A
 16%|█▌        | 1289/8253 [42:14<3:46:16,  1.95s/it][A
 16%|█▌        | 1289/8253 [42:13<3:46:28,  1.95s/it][A
 16%|█▌        | 1289/8253 [42:14<3:46:14,  1.95s/it][A
 16%|█▌        | 1289/8253 [42:14<3:46:21,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:41,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:43,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:51,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:52,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:45,  1.95s/it][A
 16%|█▌        | 1290/8253 [42:15<3:46:51,  1.95s/it][A
 16%|█▌        | 1291/8253 [42:17<3:44:13,  1.93s/it][A
 16%|█▌        | 1291/8253 [42:17<3:44:48,  1.94s/it][A
 16%|█▌        | 1291/8253 [42:17<3:44:54,  1.94s/it][A
 16%|█▌        | 1291/8253 [42:17<3:44:44,  1.94s/it][A
 16%|█▌        | 1291/8253 [42:17<3:45:07,  1.94s/it][A
 16%|█▌        | 1291/8253 [42:17<3:44:53,  1.94s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:23,  1.95s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:20,  1.95s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:27,  1.95s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:28,  1.95s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:25,  1.95s/it][A
 16%|█▌        | 1292/8253 [42:19<3:46:42,  1.95s/it][A
 16%|█▌        | 1293/8253 [42:21<3:43:42,  1.93s/it][A
 16%|█▌        | 1293/8253 [42:21<3:44:00,  1.93s/it][A
 16%|█▌        | 1293/8253 [42:21<3:44:21,  1.93s/it][A
 16%|█▌        | 1293/8253 [42:21<3:44:08,  1.93s/it][A
 16%|█▌        | 1293/8253 [42:21<3:44:17,  1.93s/it][A
 16%|█▌        | 1293/8253 [42:21<3:44:23,  1.93s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:07,  1.93s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:36,  1.94s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:36,  1.94s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:34,  1.94s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:53,  1.94s/it][A
 16%|█▌        | 1294/8253 [42:23<3:44:55,  1.94s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:07,  1.94s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:17,  1.94s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:11,  1.94s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:19,  1.94s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:33,  1.95s/it][A
 16%|█▌        | 1295/8253 [42:25<3:45:30,  1.94s/it][A
 16%|█▌        | 1296/8253 [42:27<3:44:02,  1.93s/it][A
 16%|█▌        | 1296/8253 [42:27<3:44:03,  1.93s/it][A
 16%|█▌        | 1296/8253 [42:27<3:44:13,  1.93s/it][A
 16%|█▌        | 1296/8253 [42:27<3:44:34,  1.94s/it][A

 16%|█▌        | 1296/8253 [42:27<3:44:48,  1.94s/it] 16%|█▌        | 1296/8253 [42:27<3:44:49,  1.94s/it][A[A
 16%|█▌        | 1297/8253 [42:29<3:46:17,  1.95s/it][A
 16%|█▌        | 1297/8253 [42:29<3:46:28,  1.95s/it][A
 16%|█▌        | 1297/8253 [42:29<3:46:25,  1.95s/it][A
 16%|█▌        | 1297/8253 [42:29<3:46:30,  1.95s/it][A

 16%|█▌        | 1297/8253 [42:29<3:46:30,  1.95s/it][A 16%|█▌        | 1297/8253 [42:29<3:46:24,  1.95s/it][A
 16%|█▌        | 1298/8253 [42:31<3:46:20,  1.95s/it][A
 16%|█▌        | 1298/8253 [42:31<3:46:33,  1.95s/it][A
 16%|█▌        | 1298/8253 [42:31<3:47:10,  1.96s/it][A
 16%|█▌        | 1298/8253 [42:31<3:47:23,  1.96s/it][A
 16%|█▌        | 1298/8253 [42:31<3:47:28,  1.96s/it][A
 16%|█▌        | 1298/8253 [42:31<3:47:18,  1.96s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:10,  1.94s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:12,  1.94s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:09,  1.94s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:17,  1.94s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:25,  1.95s/it][A
 16%|█▌        | 1299/8253 [42:33<3:45:33,  1.95s/it][A
 16%|█▌        | 1300/8253 [42:35<3:45:17,  1.94s/it][A
 16%|█▌        | 1300/8253 [42:35<3:44:47,  1.94s/it][A
 16%|█▌        | 1300/8253 [42:35<3:45:08,  1.94s/it][A
 16%|█▌        | 1300/8253 [42:35<3:45:21,  1.94s/it][A

 16%|█▌        | 1300/8253 [42:35<3:45:13,  1.94s/it][A 16%|█▌        | 1300/8253 [42:35<3:45:09,  1.94s/it][A
 16%|█▌        | 1301/8253 [42:37<3:48:06,  1.97s/it][A

 16%|█▌        | 1301/8253 [42:37<3:47:56,  1.97s/it][A 16%|█▌        | 1301/8253 [42:37<3:48:05,  1.97s/it][A
 16%|█▌        | 1301/8253 [42:37<3:48:09,  1.97s/it][A
 16%|█▌        | 1301/8253 [42:37<3:48:08,  1.97s/it][A
 16%|█▌        | 1301/8253 [42:37<3:48:11,  1.97s/it][A
 16%|█▌        | 1302/8253 [42:39<3:47:31,  1.96s/it][A
 16%|█▌        | 1302/8253 [42:39<3:48:00,  1.97s/it][A
 16%|█▌        | 1302/8253 [42:39<3:47:45,  1.97s/it][A
 16%|█▌        | 1302/8253 [42:39<3:47:50,  1.97s/it][A
 16%|█▌        | 1302/8253 [42:39<3:47:54,  1.97s/it][A
 16%|█▌        | 1302/8253 [42:39<3:47:50,  1.97s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:20,  1.95s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:11,  1.95s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:24,  1.95s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:31,  1.96s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:35,  1.96s/it][A
 16%|█▌        | 1303/8253 [42:41<3:46:58,  1.96s/it][A
 16%|█▌        | 1304/8253 [42:43<3:45:54,  1.95s/it][A
 16%|█▌        | 1304/8253 [42:43<3:46:09,  1.95s/it][A
 16%|█▌        | 1304/8253 [42:43<3:46:28,  1.96s/it][A
 16%|█▌        | 1304/8253 [42:43<3:46:18,  1.95s/it][A
 16%|█▌        | 1304/8253 [42:43<3:46:21,  1.95s/it][A
 16%|█▌        | 1304/8253 [42:43<3:46:33,  1.96s/it][A

 16%|█▌        | 1305/8253 [42:45<3:45:20,  1.95s/it][A 16%|█▌        | 1305/8253 [42:45<3:45:23,  1.95s/it][A
 16%|█▌        | 1305/8253 [42:45<3:45:22,  1.95s/it][A
 16%|█▌        | 1305/8253 [42:45<3:45:34,  1.95s/it][A
 16%|█▌        | 1305/8253 [42:45<3:45:44,  1.95s/it][A
 16%|█▌        | 1305/8253 [42:45<3:45:41,  1.95s/it][A
 16%|█▌        | 1306/8253 [42:47<3:44:39,  1.94s/it][A
 16%|█▌        | 1306/8253 [42:47<3:45:12,  1.95s/it][A

 16%|█▌        | 1306/8253 [42:47<3:45:12,  1.95s/it][A 16%|█▌        | 1306/8253 [42:47<3:45:12,  1.95s/it][A
 16%|█▌        | 1306/8253 [42:46<3:45:11,  1.94s/it][A
 16%|█▌        | 1306/8253 [42:47<3:45:19,  1.95s/it][A
 16%|█▌        | 1307/8253 [42:49<3:44:10,  1.94s/it][A


 16%|█▌        | 1307/8253 [42:49<3:44:11,  1.94s/it][A 16%|█▌        | 1307/8253 [42:49<3:44:12,  1.94s/it][A 16%|█▌        | 1307/8253 [42:48<3:44:08,  1.94s/it][A
 16%|█▌        | 1307/8253 [42:49<3:44:15,  1.94s/it][A
 16%|█▌        | 1307/8253 [42:49<3:44:14,  1.94s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:09,  1.93s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:20,  1.93s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:24,  1.93s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:25,  1.93s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:29,  1.93s/it][A
 16%|█▌        | 1308/8253 [42:50<3:43:29,  1.93s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:33,  1.93s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:31,  1.93s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:40,  1.93s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:59,  1.94s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:57,  1.94s/it][A
 16%|█▌        | 1309/8253 [42:52<3:43:59,  1.94s/it][A
 16%|█▌        | 1310/8253 [42:54<3:43:47,  1.93s/it][A
 16%|█▌        | 1310/8253 [42:54<3:44:03,  1.94s/it][A
 16%|█▌        | 1310/8253 [42:54<3:44:20,  1.94s/it][A

 16%|█▌        | 1310/8253 [42:54<3:44:25,  1.94s/it][A 16%|█▌        | 1310/8253 [42:54<3:44:24,  1.94s/it][A
 16%|█▌        | 1310/8253 [42:54<3:44:34,  1.94s/it][A

 16%|█▌        | 1311/8253 [42:56<3:43:51,  1.93s/it][A 16%|█▌        | 1311/8253 [42:56<3:43:52,  1.93s/it][A
 16%|█▌        | 1311/8253 [42:56<3:44:08,  1.94s/it][A
 16%|█▌        | 1311/8253 [42:56<3:44:11,  1.94s/it][A
 16%|█▌        | 1311/8253 [42:56<3:44:13,  1.94s/it][A
 16%|█▌        | 1311/8253 [42:56<3:44:13,  1.94s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:00,  1.93s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:14,  1.93s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:26,  1.93s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:25,  1.93s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:37,  1.93s/it][A
 16%|█▌        | 1312/8253 [42:58<3:43:38,  1.93s/it][A
 16%|█▌        | 1313/8253 [43:00<3:42:31,  1.92s/it][A
 16%|█▌        | 1313/8253 [43:00<3:42:37,  1.92s/it][A
 16%|█▌        | 1313/8253 [43:00<3:42:38,  1.92s/it][A
 16%|█▌        | 1313/8253 [43:00<3:42:50,  1.93s/it][A
 16%|█▌        | 1313/8253 [43:00<3:43:00,  1.93s/it][A
 16%|█▌        | 1313/8253 [43:00<3:42:57,  1.93s/it][A
 16%|█▌        | 1314/8253 [43:02<3:42:06,  1.92s/it][A
 16%|█▌        | 1314/8253 [43:02<3:42:58,  1.93s/it][A
 16%|█▌        | 1314/8253 [43:02<3:43:07,  1.93s/it][A
 16%|█▌        | 1314/8253 [43:02<3:43:18,  1.93s/it][A
 16%|█▌        | 1314/8253 [43:02<3:43:21,  1.93s/it][A
 16%|█▌        | 1314/8253 [43:02<3:43:29,  1.93s/it][A
 16%|█▌        | 1315/8253 [43:04<3:43:04,  1.93s/it][A
 16%|█▌        | 1315/8253 [43:04<3:43:09,  1.93s/it][A
 16%|█▌        | 1315/8253 [43:04<3:43:34,  1.93s/it][A

 16%|█▌        | 1315/8253 [43:04<3:43:50,  1.94s/it][A 16%|█▌        | 1315/8253 [43:04<3:43:22,  1.93s/it][A
 16%|█▌        | 1315/8253 [43:04<3:43:18,  1.93s/it][A
 16%|█▌        | 1316/8253 [43:06<3:51:54,  2.01s/it][A
 16%|█▌        | 1316/8253 [43:06<3:51:41,  2.00s/it][A

 16%|█▌        | 1316/8253 [43:06<3:52:08,  2.01s/it][A 16%|█▌        | 1316/8253 [43:06<3:51:59,  2.01s/it][A

 16%|█▌        | 1316/8253 [43:06<3:52:32,  2.01s/it][A 16%|█▌        | 1316/8253 [43:06<3:52:12,  2.01s/it][A
 16%|█▌        | 1317/8253 [43:08<3:50:33,  1.99s/it][A

 16%|█▌        | 1317/8253 [43:08<3:50:35,  1.99s/it][A
 16%|█▌        | 1317/8253 [43:08<3:50:39,  2.00s/it]
[A 16%|█▌        | 1317/8253 [43:08<3:50:50,  2.00s/it][A 16%|█▌        | 1317/8253 [43:08<3:50:45,  2.00s/it][A
 16%|█▌        | 1317/8253 [43:08<3:50:53,  2.00s/it][A
 16%|█▌        | 1318/8253 [43:10<3:47:52,  1.97s/it][A
 16%|█▌        | 1318/8253 [43:10<3:48:29,  1.98s/it][A
 16%|█▌        | 1318/8253 [43:10<3:48:30,  1.98s/it][A
 16%|█▌        | 1318/8253 [43:10<3:48:21,  1.98s/it][A
 16%|█▌        | 1318/8253 [43:10<3:48:25,  1.98s/it][A
 16%|█▌        | 1318/8253 [43:10<3:48:34,  1.98s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:36,  1.97s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:30,  1.97s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:25,  1.97s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:38,  1.97s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:36,  1.97s/it][A
 16%|█▌        | 1319/8253 [43:12<3:47:42,  1.97s/it][A