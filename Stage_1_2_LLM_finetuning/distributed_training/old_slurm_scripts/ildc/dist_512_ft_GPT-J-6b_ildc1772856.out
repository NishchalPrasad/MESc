+ module load python
+ unset _mlshdbg
+ '[' 0 = 1 ']'
+ unset _mlre _mlIFS
+ '[' -n x ']'
+ _mlIFS=' 	
'
+ IFS=' '
+ for _mlv in ${MODULES_RUN_QUARANTINE:-}
+ '[' LD_LIBRARY_PATH = LD_LIBRARY_PATH -a LD_LIBRARY_PATH = LD_LIBRARY_PATH ']'
++ eval 'echo ${LD_LIBRARY_PATH+x}'
+++ echo x
+ '[' -n x ']'
++ eval 'echo ${LD_LIBRARY_PATH}'
+++ echo /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' '
+ _mlrv=MODULES_RUNENV_LD_LIBRARY_PATH
++ eval 'echo ${MODULES_RUNENV_LD_LIBRARY_PATH:-}'
+++ echo
+ _mlre='LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' '
+ '[' -n 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\'' LD_LIBRARY_PATH='\'''\'' ' ']'
++ eval 'LD_LIBRARY_PATH_modquar='\''/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib'\''' 'LD_LIBRARY_PATH='\'''\''' /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash '"$@"'
+++ LD_LIBRARY_PATH_modquar=/gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
+++ LD_LIBRARY_PATH=
+++ /gpfslocalsup/spack_soft/tcl/8.6.8/gcc-4.8.5-5nqkfcnctewdheju62zvqbsonnzszr6m/bin/tclsh /gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/libexec/modulecmd.tcl bash load python
+ eval '_LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1;' export '_LMFILES__modshare;
LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1;' export 'LOADEDMODULES_modshare;
PYTHONUNBUFFERED=1;' export 'PYTHONUNBUFFERED;
MODULES_LMCONFLICT_modshare=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu:1;' export 'MODULES_LMCONFLICT_modshare;
_LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4;' export '_LMFILES_;
LOADEDMODULES=cpuarch/amd:python/3.10.4;' export 'LOADEDMODULES;
MODULES_LMCONFLICT=python/3.10.4\&anaconda-py3\&anaconda-py2\&python\&tensorflow-gpu\&pytorch-gpu;' export 'MODULES_LMCONFLICT;
.' '/gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh;
conda' activate 'python-3.10.4;
test' '0;'
++ _LMFILES__modshare=/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4:1:/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:1
++ export _LMFILES__modshare
++ LOADEDMODULES_modshare=python/3.10.4:1:cpuarch/amd:1
++ export LOADEDMODULES_modshare
++ PYTHONUNBUFFERED=1
++ export PYTHONUNBUFFERED
++ MODULES_LMCONFLICT_modshare='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu:1'
++ export MODULES_LMCONFLICT_modshare
++ _LMFILES_=/gpfslocalsup/pub/module-rh/modulefiles/cpuarch/amd:/gpfslocalsup/pub/modules-idris-env4/modulefiles/linux-rhel8-x86_64/python/3.10.4
++ export _LMFILES_
++ LOADEDMODULES=cpuarch/amd:python/3.10.4
++ export LOADEDMODULES
++ MODULES_LMCONFLICT='python/3.10.4&anaconda-py3&anaconda-py2&python&tensorflow-gpu&pytorch-gpu'
++ export MODULES_LMCONFLICT
++ . /gpfslocalsup/pub/anaconda-py3/2021.05/etc/profile.d/conda.sh
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ '[' -z '' ']'
+++ export CONDA_SHLVL=0
+++ CONDA_SHLVL=0
+++ '[' -n '' ']'
+++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
++++ dirname /gpfslocalsup/pub/anaconda-py3/2021.05/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export PATH
+++ '[' -z '' ']'
+++ PS1=
++ conda activate python-3.10.4
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate python-3.10.4
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate python-3.10.4
+++ /gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda shell.posix activate python-3.10.4
++ ask_conda='PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
++ eval 'PS1='\''(python-3.10.4) '\''
export PATH='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin'\''
export CONDA_PREFIX='\''/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4'\''
export CONDA_SHLVL='\''1'\''
export CONDA_DEFAULT_ENV='\''python-3.10.4'\''
export CONDA_PROMPT_MODIFIER='\''(python-3.10.4) '\''
export CONDA_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python'\''
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh"
. "/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh"'
+++ PS1='(python-3.10.4) '
+++ export PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+++ export CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ CONDA_PREFIX=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4
+++ export CONDA_SHLVL=1
+++ CONDA_SHLVL=1
+++ export CONDA_DEFAULT_ENV=python-3.10.4
+++ CONDA_DEFAULT_ENV=python-3.10.4
+++ export 'CONDA_PROMPT_MODIFIER=(python-3.10.4) '
+++ CONDA_PROMPT_MODIFIER='(python-3.10.4) '
+++ export CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ CONDA_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ CONDA_PYTHON_EXE=/gpfslocalsup/pub/anaconda-py3/2021.05/bin/python
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/gdal-activate.sh
++++ [[ -n '' ]]
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal ']'
++++ export GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ GDAL_DATA=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/gdal
++++ export GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ GDAL_DRIVER_PATH=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins
++++ [[ ! -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/lib/gdalplugins ]]
++++ unset GDAL_DRIVER_PATH
++++ export CPL_ZIP_ENCODING=UTF-8
++++ CPL_ZIP_ENCODING=UTF-8
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/geotiff-activate.sh
++++ [[ -n '' ]]
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/epsg_csv ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/Library/share/epsg_csv ']'
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/libglib_activate.sh
++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ export GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
++++ GSETTINGS_SCHEMA_DIR=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/glib-2.0/schemas
+++ . /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/etc/conda/activate.d/proj4-activate.sh
++++ '[' -n '' ']'
++++ '[' -d /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj ']'
++++ export PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ PROJ_LIB=/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj
++++ '[' -f /gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/share/proj/copyright_and_licenses.csv ']'
++++ export PROJ_NETWORK=ON
++++ PROJ_NETWORK=ON
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
++ test 0
+ _mlstatus=0
+ '[' -n x ']'
+ IFS=' 	
'
+ unset _mlre _mlv _mlrv _mlIFS
+ '[' -n '' ']'
+ unset _mlshdbg
+ return 0
+ export PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ PATH=/gpfswork/rech/btm/uei84ht/.local/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/envs/python-3.10.4/bin:/gpfslocalsup/pub/anaconda-py3/2021.05/condabin:/gpfslocalsup/spack_soft/environment-modules/4.3.1/gcc-4.8.5-ism7cdy4xverxywj27jvjstqwk5oxe2v/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/c3/bin:/usr/lpp/mmfs/bin:/sbin:/bin:/gpfslocalsys/slurm/current/bin:/gpfslocalsup/bin:/gpfslocalsys/bin:/gpfslocalsys/idrzap/current/bin
+ accelerate launch LEGAL-PE/SIGIR_experiments/distributedTraining/dist_deepspeed_LLM_torch_lexglue_.py --to_train True --batch_size 6 --learning_rate 2e-6 --num_warmup_steps 1000 --to_test True --strat 0 --data_path LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/ --dataset_subset ildc --hggfc_model_name EleutherAI/gpt-j-6B
2023-05-20 18:04:20.030512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-20 18:04:21.921665: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:04:29.894724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:04:29.894886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:04:29.894902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-20 18:05:17.749189: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.749514: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.749605: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.749729: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.750219: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:17.750504: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-20 18:05:24.433850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.433850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.433851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.433854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.433855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.433858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.436826: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.436834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.436851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.436868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.436920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.436954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.436971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.437005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.437008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.437033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-05-20 18:05:24.437028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfslocalsys/slurm/current/lib/slurm:/gpfslocalsys/slurm/current/lib
2023-05-20 18:05:24.437066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
--------------------
--------------------Report--------------------
--------------------
--------------------
--------------------Report
--------------------
Report

Report
Report
Report--------------------

--------------------

Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)----------------------------------------
--------------------
Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)


Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)
Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)--------------------Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)
--------------------Namespace(to_train=True, batch_size=6, learning_rate=2e-06, epochs=3, num_warmup_steps=1000, to_test=True, testing_model_path=None, testing_model_epoch=None, load_and_retrain=False, retraining_model_path=None, strat=0, dataset_subset='ildc', data_path='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/', hggfc_model_name='EleutherAI/gpt-j-6B', SAVE_DIR='LEGAL-P_E/SIGIR_experiments/finetuned_models/with_correct_pad/ildc/EleutherAI_gpt-j-6B/Strategy_0/Training_data/chunks_with_100_overlap_and_512_input-length/tuned_model_lr2e-06_warmup1000/', trained_with_deepspeed_accelerate=None, trained_with_accelerate=None, trained_without_accelerate=None, convert_to_torch_model=False)


--------------------

----------------------------------------
--------------------


[2023-05-20 18:05:44,678] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
train_labels:torch.Size([392632])
[2023-05-20 18:06:50,505] [INFO] [partition_parameters.py:454:__exit__] finished initializing model with 5.84B parameters
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-20 18:06:50,629] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.1, git-hash=unknown, git-branch=unknown
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of GPTJForSequenceClassification were not initialized from the model checkpoint at /gpfsdswork/dataset/HuggingFace_Models/EleutherAI/gpt-j-6B and are newly initialized because the shapes did not match:
- wte.weight: found shape torch.Size([50400, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.0.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.1.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.2.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.3.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.4.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.5.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.6.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.7.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.8.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.9.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.10.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.11.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.12.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.13.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.14.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.15.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.16.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.17.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.18.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.19.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.20.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.21.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.22.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.23.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.24.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.25.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.26.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.ln_1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.k_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.v_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.q_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.attn.out_proj.weight: found shape torch.Size([4096, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.weight: found shape torch.Size([16384, 4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_in.bias: found shape torch.Size([16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.weight: found shape torch.Size([4096, 16384]) in the checkpoint and torch.Size([0]) in the model instantiated
- h.27.mlp.fc_out.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.weight: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
- ln_f.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([0]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/linkhome/rech/geniri01/uei84ht/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[2023-05-20 18:06:50,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-05-20 18:06:50,690] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-05-20 18:06:50,690] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-05-20 18:06:50,698] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-05-20 18:06:50,698] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'transformers.optimization.AdamW'>
[2023-05-20 18:06:50,698] [WARNING] [engine.py:1098:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
[2023-05-20 18:06:50,699] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2023-05-20 18:06:50,942] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-05-20 18:06:50,942] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 2.15 GB         CA 5.58 GB         Max_CA 6 GB 
[2023-05-20 18:06:50,943] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.0 GB, percent = 10.9%
[2023-05-20 18:06:50,944] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-05-20 18:06:50,944] [INFO] [stage3.py:114:__init__] Prefetch bucket size 50,000,000
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...


Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Emitting ninja build file /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.22885918617248535 seconds
Loading extension module utils...Loading extension module utils...Loading extension module utils...
Loading extension module utils...
Loading extension module utils...


Time to load utils op: 0.3199942111968994 seconds
Time to load utils op: 0.3186335563659668 secondsTime to load utils op: 0.31946778297424316 seconds

Time to load utils op: 0.31835317611694336 secondsTime to load utils op: 0.31997108459472656 seconds

[2023-05-20 18:07:06,075] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-05-20 18:07:06,076] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 1.92 GB         CA 5.58 GB         Max_CA 6 GB 
[2023-05-20 18:07:06,076] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
Parameter Offload: Total persistent parameters: 819200 in 115 params
[2023-05-20 18:07:06,203] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-05-20 18:07:06,203] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 1.92 GB         CA 5.58 GB         Max_CA 6 GB 
[2023-05-20 18:07:06,204] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
[2023-05-20 18:07:06,318] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-05-20 18:07:06,318] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 1.92 GB         CA 5.58 GB         Max_CA 6 GB 
[2023-05-20 18:07:06,318] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.04 GB, percent = 10.9%
[2023-05-20 18:07:09,130] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1
[2023-05-20 18:07:09,131] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 1.92 GB         CA 4.21 GB         Max_CA 6 GB 
[2023-05-20 18:07:09,131] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 56.91 GB, percent = 11.3%
[2023-05-20 18:07:09,245] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-05-20 18:07:09,246] [INFO] [utils.py:786:see_memory_usage] MA 1.92 GB         Max_MA 1.92 GB         CA 4.21 GB         Max_CA 4 GB 
[2023-05-20 18:07:09,246] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 56.99 GB, percent = 11.3%
[2023-05-20 18:07:09,364] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-05-20 18:07:09,365] [INFO] [utils.py:786:see_memory_usage] MA 5.55 GB         Max_MA 7.37 GB         CA 9.65 GB         Max_CA 10 GB 
[2023-05-20 18:07:09,365] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 57.08 GB, percent = 11.3%
[2023-05-20 18:07:12,262] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-05-20 18:07:12,262] [INFO] [utils.py:786:see_memory_usage] MA 5.55 GB         Max_MA 5.55 GB         CA 9.65 GB         Max_CA 10 GB 
[2023-05-20 18:07:12,263] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.05 GB, percent = 10.9%
[2023-05-20 18:07:12,386] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-05-20 18:07:12,387] [INFO] [utils.py:786:see_memory_usage] MA 12.81 GB         Max_MA 20.07 GB         CA 24.17 GB         Max_CA 24 GB 
[2023-05-20 18:07:12,387] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.05 GB, percent = 10.9%
[2023-05-20 18:07:12,387] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...

Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007698535919189453 secondsNo modifications detected for re-loaded extension module utils, skipping build step...
No modifications detected for re-loaded extension module utils, skipping build step...

Loading extension module utils...Loading extension module utils...

No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009305477142333984 secondsTime to load utils op: 0.0008416175842285156 seconds

Time to load utils op: 0.000823974609375 seconds
Time to load utils op: 0.0006816387176513672 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...
  0%|          | 0/3 [00:00<?, ?it/s]  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ================ Epoch 1 / 3 ========

Training...Training...  0%|          | 0/3 [00:00<?, ?it/s]

======== Epoch 1 / 3 ========
Training...
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 0/10907 [00:00<?, ?it/s]
[A  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 0/10907 [00:00<?, ?it/s][A[2023-05-20 18:07:12,619] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-05-20 18:07:12,620] [INFO] [utils.py:786:see_memory_usage] MA 15.56 GB         Max_MA 16.33 GB         CA 24.17 GB         Max_CA 24 GB 
[2023-05-20 18:07:12,620] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 55.05 GB, percent = 10.9%
[2023-05-20 18:07:12,620] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-05-20 18:07:12,620] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-05-20 18:07:12,620] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2023-05-20 18:07:12,620] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2023-05-20 18:07:12,621] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   amp_params ................... False
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   bfloat16_enabled ............. True
[2023-05-20 18:07:12,621] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x15317495d5a0>
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   dump_state ................... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... None
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   fp16_auto_cast ............... None
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   fp16_enabled ................. False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 1
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 1
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   loss_scale ................... 1.0
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-05-20 18:07:12,622] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   pld_params ................... False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   steps_per_print .............. inf
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   train_batch_size ............. 36
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  6
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   world_size ................... 6
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  True
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=True
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-05-20 18:07:12,623] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-05-20 18:07:12,623] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 36, 
    "train_micro_batch_size_per_gpu": 6, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "offload_param": {
            "device": "none"
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
Using /gpfs7kw/linkhome/rech/geniri01/uei84ht/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0004634857177734375 seconds
  0%|          | 0/3 [00:00<?, ?it/s]======== Epoch 1 / 3 ========
Training...

  0%|          | 0/10907 [00:00<?, ?it/s][A
  0%|          | 1/10907 [00:03<10:45:10,  3.55s/it][A
  0%|          | 1/10907 [00:03<10:46:44,  3.56s/it][A
  0%|          | 1/10907 [00:03<10:48:05,  3.57s/it][A
  0%|          | 1/10907 [00:03<10:48:31,  3.57s/it][A
  0%|          | 1/10907 [00:03<10:28:33,  3.46s/it][A
  0%|          | 1/10907 [00:03<10:48:55,  3.57s/it][A
  0%|          | 2/10907 [00:05<7:26:43,  2.46s/it] [A
  0%|          | 2/10907 [00:05<7:27:37,  2.46s/it] [A


  0%|          | 2/10907 [00:05<7:27:10,  2.46s/it] [A  0%|          | 2/10907 [00:05<7:27:25,  2.46s/it] [A  0%|          | 2/10907 [00:05<7:27:01,  2.46s/it] [A
  0%|          | 2/10907 [00:05<7:18:48,  2.41s/it] [A
  0%|          | 3/10907 [00:06<6:16:44,  2.07s/it][A
  0%|          | 3/10907 [00:06<6:16:49,  2.07s/it][A
  0%|          | 3/10907 [00:06<6:12:47,  2.05s/it][A
  0%|          | 3/10907 [00:06<6:17:39,  2.08s/it][A

  0%|          | 3/10907 [00:06<6:17:56,  2.08s/it][A  0%|          | 3/10907 [00:06<6:17:45,  2.08s/it][A
  0%|          | 4/10907 [00:08<5:41:13,  1.88s/it][A
  0%|          | 4/10907 [00:08<5:44:08,  1.89s/it][A
  0%|          | 4/10907 [00:08<5:44:13,  1.89s/it][A
  0%|          | 4/10907 [00:08<5:44:17,  1.89s/it][A
  0%|          | 4/10907 [00:08<5:44:42,  1.90s/it][A
  0%|          | 4/10907 [00:08<5:45:01,  1.90s/it][A
  0%|          | 5/10907 [00:10<5:26:12,  1.80s/it][A
  0%|          | 5/10907 [00:10<5:26:17,  1.80s/it][A
  0%|          | 5/10907 [00:10<5:26:23,  1.80s/it][A
  0%|          | 5/10907 [00:10<5:26:18,  1.80s/it][A

  0%|          | 5/10907 [00:09<5:24:42,  1.79s/it][A  0%|          | 5/10907 [00:10<5:26:28,  1.80s/it][A
  0%|          | 6/10907 [00:11<5:15:10,  1.73s/it][A
  0%|          | 6/10907 [00:11<5:15:11,  1.73s/it][A

  0%|          | 6/10907 [00:11<5:15:17,  1.74s/it][A  0%|          | 6/10907 [00:11<5:15:19,  1.74s/it][A
  0%|          | 6/10907 [00:11<5:14:08,  1.73s/it][A
  0%|          | 6/10907 [00:11<5:15:20,  1.74s/it][A
  0%|          | 7/10907 [00:13<5:06:41,  1.69s/it][A
  0%|          | 7/10907 [00:13<5:07:27,  1.69s/it][A
  0%|          | 7/10907 [00:13<5:07:40,  1.69s/it][A
  0%|          | 7/10907 [00:13<5:07:44,  1.69s/it][A
  0%|          | 7/10907 [00:13<5:07:46,  1.69s/it][A
  0%|          | 7/10907 [00:13<5:07:52,  1.69s/it][A
  0%|          | 8/10907 [00:14<5:02:57,  1.67s/it][A
  0%|          | 8/10907 [00:14<5:02:59,  1.67s/it][A
  0%|          | 8/10907 [00:14<5:02:57,  1.67s/it][A
  0%|          | 8/10907 [00:14<5:02:31,  1.67s/it][A
  0%|          | 8/10907 [00:14<5:03:06,  1.67s/it][A
  0%|          | 8/10907 [00:14<5:03:09,  1.67s/it][A
  0%|          | 9/10907 [00:16<5:00:08,  1.65s/it][A

  0%|          | 9/10907 [00:16<5:00:17,  1.65s/it][A  0%|          | 9/10907 [00:16<5:00:16,  1.65s/it][A
  0%|          | 9/10907 [00:16<5:00:16,  1.65s/it][A

  0%|          | 9/10907 [00:16<5:00:18,  1.65s/it][A  0%|          | 9/10907 [00:16<4:59:59,  1.65s/it][A
  0%|          | 10/10907 [00:18<4:57:56,  1.64s/it][A
  0%|          | 10/10907 [00:18<4:58:01,  1.64s/it][A
  0%|          | 10/10907 [00:18<4:57:47,  1.64s/it][A
  0%|          | 10/10907 [00:18<4:58:04,  1.64s/it][A
  0%|          | 10/10907 [00:18<4:58:06,  1.64s/it][A
  0%|          | 10/10907 [00:18<4:58:17,  1.64s/it][A
  0%|          | 11/10907 [00:19<4:56:14,  1.63s/it][A
  0%|          | 11/10907 [00:19<4:56:03,  1.63s/it][A
  0%|          | 11/10907 [00:19<4:56:24,  1.63s/it][A

  0%|          | 11/10907 [00:19<4:56:23,  1.63s/it][A  0%|          | 11/10907 [00:19<4:56:30,  1.63s/it][A
  0%|          | 11/10907 [00:19<4:56:33,  1.63s/it][A
  0%|          | 12/10907 [00:21<4:55:09,  1.63s/it][A
  0%|          | 12/10907 [00:21<4:55:10,  1.63s/it][A
  0%|          | 12/10907 [00:21<4:55:18,  1.63s/it][A
  0%|          | 12/10907 [00:21<4:55:11,  1.63s/it][A

  0%|          | 12/10907 [00:21<4:55:21,  1.63s/it][A  0%|          | 12/10907 [00:21<4:55:18,  1.63s/it][A
  0%|          | 13/10907 [00:22<4:54:13,  1.62s/it][A
  0%|          | 13/10907 [00:23<4:54:26,  1.62s/it][A
  0%|          | 13/10907 [00:23<4:54:26,  1.62s/it][A

  0%|          | 13/10907 [00:23<4:54:29,  1.62s/it][A  0%|          | 13/10907 [00:23<4:54:27,  1.62s/it][A
  0%|          | 13/10907 [00:23<4:54:41,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:06,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:17,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:23,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:22,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:25,  1.62s/it][A
  0%|          | 14/10907 [00:24<4:54:31,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:08,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:11,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:20,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:36,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:26,  1.62s/it][A
  0%|          | 15/10907 [00:26<4:54:30,  1.62s/it][A

  0%|          | 16/10907 [00:27<4:53:23,  1.62s/it][A  0%|          | 16/10907 [00:27<4:53:26,  1.62s/it][A
  0%|          | 16/10907 [00:27<4:53:35,  1.62s/it][A
  0%|          | 16/10907 [00:27<4:53:23,  1.62s/it][A
  0%|          | 16/10907 [00:27<4:53:33,  1.62s/it][A
  0%|          | 16/10907 [00:27<4:53:33,  1.62s/it][A
  0%|          | 17/10907 [00:29<4:53:17,  1.62s/it][A
  0%|          | 17/10907 [00:29<4:53:13,  1.62s/it][A
  0%|          | 17/10907 [00:29<4:53:21,  1.62s/it][A


  0%|          | 17/10907 [00:29<4:53:29,  1.62s/it][A  0%|          | 17/10907 [00:29<4:53:27,  1.62s/it][A  0%|          | 17/10907 [00:29<4:53:14,  1.62s/it][A
  0%|          | 18/10907 [00:31<4:52:27,  1.61s/it][A
  0%|          | 18/10907 [00:31<4:52:51,  1.61s/it][A
  0%|          | 18/10907 [00:31<4:53:18,  1.62s/it][A
  0%|          | 18/10907 [00:31<4:53:21,  1.62s/it][A

  0%|          | 18/10907 [00:30<4:53:22,  1.62s/it][A  0%|          | 18/10907 [00:31<4:53:19,  1.62s/it][A
  0%|          | 19/10907 [00:32<4:52:53,  1.61s/it][A
  0%|          | 19/10907 [00:32<4:53:01,  1.61s/it][A
  0%|          | 19/10907 [00:32<4:52:57,  1.61s/it][A
  0%|          | 19/10907 [00:32<4:53:06,  1.62s/it][A
  0%|          | 19/10907 [00:32<4:53:06,  1.62s/it][A
  0%|          | 19/10907 [00:32<4:53:15,  1.62s/it][A

  0%|          | 20/10907 [00:34<4:52:23,  1.61s/it][A  0%|          | 20/10907 [00:34<4:52:29,  1.61s/it][A
  0%|          | 20/10907 [00:34<4:53:08,  1.62s/it][A
  0%|          | 20/10907 [00:34<4:53:13,  1.62s/it][A
  0%|          | 20/10907 [00:34<4:53:17,  1.62s/it][A
  0%|          | 20/10907 [00:34<4:53:24,  1.62s/it][A
  0%|          | 21/10907 [00:36<5:06:15,  1.69s/it][A
  0%|          | 21/10907 [00:36<5:06:24,  1.69s/it][A
  0%|          | 21/10907 [00:36<5:06:27,  1.69s/it][A

  0%|          | 21/10907 [00:36<5:06:42,  1.69s/it][A  0%|          | 21/10907 [00:36<5:06:27,  1.69s/it][A
  0%|          | 21/10907 [00:36<5:06:36,  1.69s/it][A
  0%|          | 22/10907 [00:37<5:08:52,  1.70s/it][A
  0%|          | 22/10907 [00:37<5:09:14,  1.70s/it][A
  0%|          | 22/10907 [00:37<5:09:32,  1.71s/it][A
  0%|          | 22/10907 [00:37<5:09:27,  1.71s/it][A

  0%|          | 22/10907 [00:37<5:09:20,  1.71s/it]  0%|          | 22/10907 [00:37<5:09:20,  1.71s/it][A[A
  0%|          | 23/10907 [00:39<5:03:56,  1.68s/it][A
  0%|          | 23/10907 [00:39<5:04:09,  1.68s/it][A
  0%|          | 23/10907 [00:39<5:04:05,  1.68s/it][A
  0%|          | 23/10907 [00:39<5:04:00,  1.68s/it][A

  0%|          | 23/10907 [00:39<5:04:17,  1.68s/it][A  0%|          | 23/10907 [00:39<5:04:04,  1.68s/it][A
  0%|          | 24/10907 [00:41<5:00:10,  1.65s/it][A
  0%|          | 24/10907 [00:41<5:00:12,  1.66s/it][A
  0%|          | 24/10907 [00:41<5:01:03,  1.66s/it][A
  0%|          | 24/10907 [00:41<5:01:04,  1.66s/it][A

  0%|          | 24/10907 [00:41<5:01:01,  1.66s/it][A  0%|          | 24/10907 [00:41<5:01:08,  1.66s/it][A
  0%|          | 25/10907 [00:42<4:58:05,  1.64s/it][A
  0%|          | 25/10907 [00:42<4:58:27,  1.65s/it][A
  0%|          | 25/10907 [00:42<4:58:27,  1.65s/it][A
  0%|          | 25/10907 [00:42<4:58:29,  1.65s/it][A
  0%|          | 25/10907 [00:42<4:58:37,  1.65s/it][A
  0%|          | 25/10907 [00:42<4:58:38,  1.65s/it][A

  0%|          | 26/10907 [00:44<4:56:36,  1.64s/it][A  0%|          | 26/10907 [00:44<4:56:37,  1.64s/it][A
  0%|          | 26/10907 [00:44<4:56:49,  1.64s/it][A
  0%|          | 26/10907 [00:44<4:57:19,  1.64s/it][A
  0%|          | 26/10907 [00:44<4:57:24,  1.64s/it][A
  0%|          | 26/10907 [00:44<4:57:25,  1.64s/it][A

  0%|          | 27/10907 [00:46<4:55:34,  1.63s/it][A
  0%|          | 27/10907 [00:46<4:55:45,  1.63s/it][A  0%|          | 27/10907 [00:45<4:55:39,  1.63s/it][A
  0%|          | 27/10907 [00:46<4:55:51,  1.63s/it][A
  0%|          | 27/10907 [00:46<4:55:44,  1.63s/it][A
  0%|          | 27/10907 [00:46<4:55:42,  1.63s/it][A
  0%|          | 28/10907 [00:47<4:54:59,  1.63s/it][A
  0%|          | 28/10907 [00:47<4:54:55,  1.63s/it][A

  0%|          | 28/10907 [00:47<4:54:58,  1.63s/it][A  0%|          | 28/10907 [00:47<4:54:56,  1.63s/it][A

  0%|          | 28/10907 [00:47<4:55:05,  1.63s/it][A  0%|          | 28/10907 [00:47<4:55:02,  1.63s/it][A
  0%|          | 29/10907 [00:49<4:54:14,  1.62s/it][A
  0%|          | 29/10907 [00:49<4:54:18,  1.62s/it][A
  0%|          | 29/10907 [00:49<4:54:27,  1.62s/it][A
  0%|          | 29/10907 [00:49<4:54:34,  1.62s/it][A
  0%|          | 29/10907 [00:49<4:54:26,  1.62s/it][A
  0%|          | 29/10907 [00:49<4:54:37,  1.63s/it][A
  0%|          | 30/10907 [00:50<4:53:43,  1.62s/it][A
  0%|          | 30/10907 [00:50<4:53:42,  1.62s/it][A
  0%|          | 30/10907 [00:50<4:53:48,  1.62s/it][A
  0%|          | 30/10907 [00:50<4:54:06,  1.62s/it][A
  0%|          | 30/10907 [00:50<4:54:11,  1.62s/it][A
  0%|          | 30/10907 [00:50<4:54:07,  1.62s/it][A
  0%|          | 31/10907 [00:52<4:53:18,  1.62s/it][A
  0%|          | 31/10907 [00:52<4:54:08,  1.62s/it]
[A  0%|          | 31/10907 [00:52<4:54:09,  1.62s/it][A
  0%|          | 31/10907 [00:52<4:54:02,  1.62s/it][A
  0%|          | 31/10907 [00:52<4:53:59,  1.62s/it][A
  0%|          | 31/10907 [00:52<4:54:13,  1.62s/it][A
  0%|          | 32/10907 [00:54<4:53:42,  1.62s/it][A
  0%|          | 32/10907 [00:54<4:53:44,  1.62s/it][A
  0%|          | 32/10907 [00:54<4:53:49,  1.62s/it][A
  0%|          | 32/10907 [00:54<4:54:03,  1.62s/it][A
  0%|          | 32/10907 [00:54<4:54:01,  1.62s/it][A
  0%|          | 32/10907 [00:53<4:54:23,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:53:02,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:53:07,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:54:05,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:54:07,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:54:05,  1.62s/it][A
  0%|          | 33/10907 [00:55<4:54:05,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:53:51,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:54:01,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:54:14,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:53:59,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:54:15,  1.62s/it][A
  0%|          | 34/10907 [00:57<4:54:10,  1.62s/it][A
  0%|          | 35/10907 [00:58<4:53:46,  1.62s/it][A



  0%|          | 35/10907 [00:58<4:54:06,  1.62s/it][A  0%|          | 35/10907 [00:58<4:53:59,  1.62s/it][A  0%|          | 35/10907 [00:58<4:53:58,  1.62s/it][A  0%|          | 35/10907 [00:58<4:53:54,  1.62s/it][A
  0%|          | 35/10907 [00:58<4:53:55,  1.62s/it][A
  0%|          | 36/10907 [01:00<4:53:49,  1.62s/it]
[A  0%|          | 36/10907 [01:00<4:53:51,  1.62s/it][A
  0%|          | 36/10907 [01:00<4:53:48,  1.62s/it][A
  0%|          | 36/10907 [01:00<4:53:59,  1.62s/it][A
  0%|          | 36/10907 [01:00<4:53:49,  1.62s/it][A
  0%|          | 36/10907 [01:00<4:53:59,  1.62s/it][A


  0%|          | 37/10907 [01:02<4:53:45,  1.62s/it][A
  0%|          | 37/10907 [01:02<4:53:47,  1.62s/it]  0%|          | 37/10907 [01:02<4:53:49,  1.62s/it][A[A  0%|          | 37/10907 [01:02<4:53:40,  1.62s/it][A
  0%|          | 37/10907 [01:02<4:53:46,  1.62s/it][A
  0%|          | 37/10907 [01:02<4:53:51,  1.62s/it][A
  0%|          | 38/10907 [01:03<4:52:53,  1.62s/it][A
  0%|          | 38/10907 [01:03<4:53:19,  1.62s/it][A
  0%|          | 38/10907 [01:03<4:53:29,  1.62s/it][A

  0%|          | 38/10907 [01:03<4:53:25,  1.62s/it][A  0%|          | 38/10907 [01:03<4:53:33,  1.62s/it][A
  0%|          | 38/10907 [01:03<4:53:24,  1.62s/it][A
  0%|          | 39/10907 [01:05<4:53:02,  1.62s/it][A
  0%|          | 39/10907 [01:05<4:53:09,  1.62s/it][A
  0%|          | 39/10907 [01:05<4:53:21,  1.62s/it][A
  0%|          | 39/10907 [01:05<4:53:08,  1.62s/it][A

  0%|          | 39/10907 [01:05<4:53:11,  1.62s/it][A  0%|          | 39/10907 [01:05<4:53:17,  1.62s/it][A
  0%|          | 40/10907 [01:07<4:52:41,  1.62s/it][A
  0%|          | 40/10907 [01:07<4:52:57,  1.62s/it][A
  0%|          | 40/10907 [01:07<4:53:06,  1.62s/it][A
  0%|          | 40/10907 [01:06<4:53:18,  1.62s/it][A
  0%|          | 40/10907 [01:07<4:53:30,  1.62s/it][A
  0%|          | 40/10907 [01:07<4:53:18,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:53:08,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:53:06,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:53:07,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:52:58,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:53:03,  1.62s/it][A
  0%|          | 41/10907 [01:08<4:53:08,  1.62s/it][A
  0%|          | 42/10907 [01:10<4:52:02,  1.61s/it][A
  0%|          | 42/10907 [01:10<4:52:08,  1.61s/it][A
  0%|          | 42/10907 [01:10<4:52:52,  1.62s/it][A
  0%|          | 42/10907 [01:10<4:52:56,  1.62s/it][A
  0%|          | 42/10907 [01:10<4:52:56,  1.62s/it][A
  0%|          | 42/10907 [01:10<4:53:01,  1.62s/it][A
  0%|          | 43/10907 [01:12<5:05:54,  1.69s/it][A
  0%|          | 43/10907 [01:12<5:06:03,  1.69s/it][A
  0%|          | 43/10907 [01:12<5:06:14,  1.69s/it][A
  0%|          | 43/10907 [01:12<5:06:44,  1.69s/it][A
  0%|          | 43/10907 [01:12<5:06:42,  1.69s/it][A
  0%|          | 43/10907 [01:12<5:06:24,  1.69s/it][A
  0%|          | 44/10907 [01:13<5:09:36,  1.71s/it][A

  0%|          | 44/10907 [01:13<5:09:21,  1.71s/it][A  0%|          | 44/10907 [01:13<5:09:33,  1.71s/it][A

  0%|          | 44/10907 [01:13<5:09:22,  1.71s/it][A  0%|          | 44/10907 [01:13<5:09:39,  1.71s/it][A
  0%|          | 44/10907 [01:13<5:09:20,  1.71s/it][A
  0%|          | 45/10907 [01:15<5:04:45,  1.68s/it][A
  0%|          | 45/10907 [01:15<5:04:46,  1.68s/it][A

  0%|          | 45/10907 [01:15<5:05:15,  1.69s/it][A  0%|          | 45/10907 [01:15<5:05:00,  1.68s/it][A
  0%|          | 45/10907 [01:15<5:05:13,  1.69s/it][A
  0%|          | 45/10907 [01:15<5:05:03,  1.69s/it][A
  0%|          | 46/10907 [01:17<5:01:04,  1.66s/it][A

  0%|          | 46/10907 [01:17<5:01:08,  1.66s/it][A  0%|          | 46/10907 [01:17<5:01:15,  1.66s/it][A

  0%|          | 46/10907 [01:17<5:01:09,  1.66s/it][A
  0%|          | 46/10907 [01:17<5:01:23,  1.66s/it][A  0%|          | 46/10907 [01:17<5:01:09,  1.66s/it][A
  0%|          | 47/10907 [01:18<4:58:56,  1.65s/it][A

  0%|          | 47/10907 [01:18<4:59:00,  1.65s/it][A  0%|          | 47/10907 [01:18<4:58:57,  1.65s/it][A
  0%|          | 47/10907 [01:18<4:58:52,  1.65s/it][A
  0%|          | 47/10907 [01:18<4:58:54,  1.65s/it][A
  0%|          | 47/10907 [01:18<4:58:54,  1.65s/it][A
  0%|          | 48/10907 [01:20<4:56:36,  1.64s/it][A
  0%|          | 48/10907 [01:20<4:56:59,  1.64s/it][A
  0%|          | 48/10907 [01:20<4:57:21,  1.64s/it][A
  0%|          | 48/10907 [01:20<4:57:35,  1.64s/it][A
  0%|          | 48/10907 [01:20<4:57:34,  1.64s/it][A
  0%|          | 48/10907 [01:20<4:57:37,  1.64s/it][A
  0%|          | 49/10907 [01:22<4:55:34,  1.63s/it][A
  0%|          | 49/10907 [01:22<4:55:41,  1.63s/it][A

  0%|          | 49/10907 [01:21<4:55:39,  1.63s/it][A  0%|          | 49/10907 [01:22<4:55:50,  1.63s/it][A
  0%|          | 49/10907 [01:22<4:56:01,  1.64s/it][A
  0%|          | 49/10907 [01:22<4:55:56,  1.64s/it][A
  0%|          | 50/10907 [01:23<4:53:39,  1.62s/it][A
  0%|          | 50/10907 [01:23<4:53:53,  1.62s/it][A
  0%|          | 50/10907 [01:23<4:54:36,  1.63s/it][A
  0%|          | 50/10907 [01:23<4:54:56,  1.63s/it][A
  0%|          | 50/10907 [01:23<4:54:52,  1.63s/it][A
  0%|          | 50/10907 [01:23<4:54:50,  1.63s/it][A
  0%|          | 51/10907 [01:25<4:53:29,  1.62s/it][A
  0%|          | 51/10907 [01:25<4:53:27,  1.62s/it]
[A  0%|          | 51/10907 [01:25<4:53:57,  1.62s/it][A
  0%|          | 51/10907 [01:25<4:53:40,  1.62s/it][A
  0%|          | 51/10907 [01:25<4:54:04,  1.63s/it][A
  0%|          | 51/10907 [01:25<4:53:46,  1.62s/it][A
  0%|          | 52/10907 [01:26<4:53:29,  1.62s/it][A
  0%|          | 52/10907 [01:26<4:53:40,  1.62s/it][A
  0%|          | 52/10907 [01:26<4:53:40,  1.62s/it][A

  0%|          | 52/10907 [01:26<4:53:29,  1.62s/it][A  0%|          | 52/10907 [01:26<4:53:27,  1.62s/it][A
  0%|          | 52/10907 [01:26<4:53:33,  1.62s/it][A

  0%|          | 53/10907 [01:28<4:53:18,  1.62s/it][A  0%|          | 53/10907 [01:28<4:53:14,  1.62s/it][A
  0%|          | 53/10907 [01:28<4:53:12,  1.62s/it][A

  0%|          | 53/10907 [01:28<4:53:06,  1.62s/it][A  0%|          | 53/10907 [01:28<4:53:05,  1.62s/it][A
  0%|          | 53/10907 [01:28<4:53:15,  1.62s/it][A
  0%|          | 54/10907 [01:30<4:52:30,  1.62s/it][A
  0%|          | 54/10907 [01:30<4:52:48,  1.62s/it][A
  0%|          | 54/10907 [01:30<4:52:56,  1.62s/it][A
  0%|          | 54/10907 [01:29<4:52:46,  1.62s/it][A

  0%|          | 54/10907 [01:30<4:52:51,  1.62s/it][A  0%|          | 54/10907 [01:30<4:52:49,  1.62s/it][A

  1%|          | 55/10907 [01:31<4:52:36,  1.62s/it][A  1%|          | 55/10907 [01:31<4:52:40,  1.62s/it][A
  1%|          | 55/10907 [01:31<4:52:29,  1.62s/it][A
  1%|          | 55/10907 [01:31<4:52:35,  1.62s/it][A
  1%|          | 55/10907 [01:31<4:52:37,  1.62s/it][A
  1%|          | 55/10907 [01:31<4:52:48,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:10,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:21,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:35,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:26,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:40,  1.62s/it][A
  1%|          | 56/10907 [01:33<4:52:40,  1.62s/it][A
  1%|          | 57/10907 [01:34<4:51:51,  1.61s/it][A
  1%|          | 57/10907 [01:34<4:52:10,  1.62s/it][A
  1%|          | 57/10907 [01:34<4:52:35,  1.62s/it][A
  1%|          | 57/10907 [01:34<4:52:42,  1.62s/it][A
  1%|          | 57/10907 [01:34<4:52:40,  1.62s/it][A
  1%|          | 57/10907 [01:34<4:52:42,  1.62s/it][A
  1%|          | 58/10907 [01:36<4:52:32,  1.62s/it][A
  1%|          | 58/10907 [01:36<4:52:31,  1.62s/it][A
  1%|          | 58/10907 [01:36<4:52:47,  1.62s/it][A
  1%|          | 58/10907 [01:36<4:52:42,  1.62s/it][A

  1%|          | 58/10907 [01:36<4:52:44,  1.62s/it][A  1%|          | 58/10907 [01:36<4:53:04,  1.62s/it][A
  1%|          | 59/10907 [01:38<4:53:01,  1.62s/it][A
  1%|          | 59/10907 [01:38<4:53:15,  1.62s/it][A
  1%|          | 59/10907 [01:38<4:53:19,  1.62s/it][A

  1%|          | 59/10907 [01:38<4:53:15,  1.62s/it]  1%|          | 59/10907 [01:38<4:53:16,  1.62s/it][A
[A  1%|          | 59/10907 [01:38<4:53:22,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:42,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:52,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:56,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:46,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:51,  1.62s/it][A
  1%|          | 60/10907 [01:39<4:52:50,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:42,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:36,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:48,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:38,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:38,  1.62s/it][A
  1%|          | 61/10907 [01:41<4:52:54,  1.62s/it][A
  1%|          | 62/10907 [01:43<4:52:13,  1.62s/it][A
  1%|          | 62/10907 [01:43<4:52:08,  1.62s/it][A
  1%|          | 62/10907 [01:42<4:52:10,  1.62s/it][A
  1%|          | 62/10907 [01:43<4:52:32,  1.62s/it][A
  1%|          | 62/10907 [01:43<4:52:38,  1.62s/it][A
  1%|          | 62/10907 [01:43<4:52:57,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:52:28,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:52:44,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:52:45,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:52:48,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:52:56,  1.62s/it][A
  1%|          | 63/10907 [01:44<4:53:05,  1.62s/it][A
  1%|          | 64/10907 [01:46<5:07:11,  1.70s/it][A
  1%|          | 64/10907 [01:46<5:07:19,  1.70s/it][A
  1%|          | 64/10907 [01:46<5:07:23,  1.70s/it][A
  1%|          | 64/10907 [01:46<5:07:28,  1.70s/it][A
  1%|          | 64/10907 [01:46<5:07:24,  1.70s/it][A
  1%|          | 64/10907 [01:46<5:07:21,  1.70s/it][A
  1%|          | 65/10907 [01:48<5:02:43,  1.68s/it][A
  1%|          | 65/10907 [01:48<5:02:54,  1.68s/it][A
  1%|          | 65/10907 [01:48<5:02:56,  1.68s/it][A
  1%|          | 65/10907 [01:48<5:02:59,  1.68s/it][A
  1%|          | 65/10907 [01:48<5:03:04,  1.68s/it][A
  1%|          | 65/10907 [01:48<5:03:04,  1.68s/it][A
  1%|          | 66/10907 [01:49<4:59:33,  1.66s/it][A
  1%|          | 66/10907 [01:49<4:59:38,  1.66s/it][A
  1%|          | 66/10907 [01:49<4:59:41,  1.66s/it][A
  1%|          | 66/10907 [01:49<4:59:54,  1.66s/it][A
  1%|          | 66/10907 [01:49<4:59:48,  1.66s/it][A
  1%|          | 66/10907 [01:49<5:00:11,  1.66s/it][A
  1%|          | 67/10907 [01:51<4:57:35,  1.65s/it][A

  1%|          | 67/10907 [01:51<4:57:33,  1.65s/it][A

  1%|          | 67/10907 [01:51<4:57:50,  1.65s/it][A  1%|          | 67/10907 [01:51<4:57:45,  1.65s/it][A  1%|          | 67/10907 [01:51<4:57:41,  1.65s/it][A
  1%|          | 67/10907 [01:51<4:57:42,  1.65s/it][A
  1%|          | 68/10907 [01:53<5:02:38,  1.68s/it][A
  1%|          | 68/10907 [01:53<5:02:51,  1.68s/it][A
  1%|          | 68/10907 [01:53<5:03:09,  1.68s/it][A
  1%|          | 68/10907 [01:53<5:03:23,  1.68s/it][A
  1%|          | 68/10907 [01:53<5:03:20,  1.68s/it][A
  1%|          | 68/10907 [01:53<5:03:25,  1.68s/it][A
  1%|          | 69/10907 [01:54<4:59:45,  1.66s/it][A
  1%|          | 69/10907 [01:54<5:00:08,  1.66s/it][A
  1%|          | 69/10907 [01:54<5:00:09,  1.66s/it]
[A  1%|          | 69/10907 [01:54<4:59:52,  1.66s/it][A
  1%|          | 69/10907 [01:54<4:59:54,  1.66s/it]
[A  1%|          | 69/10907 [01:54<4:59:51,  1.66s/it][A
  1%|          | 70/10907 [01:56<4:58:10,  1.65s/it][A
  1%|          | 70/10907 [01:56<4:58:16,  1.65s/it][A
  1%|          | 70/10907 [01:56<4:58:05,  1.65s/it][A
  1%|          | 70/10907 [01:56<4:58:06,  1.65s/it][A
  1%|          | 70/10907 [01:56<4:58:16,  1.65s/it][A
  1%|          | 70/10907 [01:56<4:58:09,  1.65s/it][A
  1%|          | 71/10907 [01:58<4:55:35,  1.64s/it][A
  1%|          | 71/10907 [01:58<4:55:40,  1.64s/it][A

  1%|          | 71/10907 [01:58<4:56:31,  1.64s/it][A  1%|          | 71/10907 [01:58<4:56:35,  1.64s/it][A

  1%|          | 71/10907 [01:57<4:56:36,  1.64s/it][A  1%|          | 71/10907 [01:58<4:56:47,  1.64s/it][A
  1%|          | 72/10907 [01:59<4:55:39,  1.64s/it][A
  1%|          | 72/10907 [01:59<4:55:20,  1.64s/it][A
  1%|          | 72/10907 [01:59<4:55:14,  1.63s/it][A

  1%|          | 72/10907 [01:59<4:55:35,  1.64s/it][A
  1%|          | 72/10907 [01:59<4:55:15,  1.64s/it][A  1%|          | 72/10907 [01:59<4:55:13,  1.63s/it][A

  1%|          | 73/10907 [02:01<4:53:57,  1.63s/it][A  1%|          | 73/10907 [02:01<4:54:03,  1.63s/it][A
  1%|          | 73/10907 [02:01<4:54:29,  1.63s/it][A
  1%|          | 73/10907 [02:01<4:54:21,  1.63s/it][A

  1%|          | 73/10907 [02:01<4:54:23,  1.63s/it][A  1%|          | 73/10907 [02:01<4:54:39,  1.63s/it][A
  1%|          | 74/10907 [02:02<4:54:07,  1.63s/it][A

  1%|          | 74/10907 [02:02<4:54:26,  1.63s/it][A  1%|          | 74/10907 [02:02<4:54:09,  1.63s/it][A
  1%|          | 74/10907 [02:02<4:54:21,  1.63s/it][A
  1%|          | 74/10907 [02:02<4:54:20,  1.63s/it][A
  1%|          | 74/10907 [02:02<4:54:10,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:39,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:45,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:40,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:41,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:54,  1.63s/it][A
  1%|          | 75/10907 [02:04<4:53:53,  1.63s/it][A
  1%|          | 76/10907 [02:06<4:53:20,  1.62s/it][A
  1%|          | 76/10907 [02:06<4:53:14,  1.62s/it][A
  1%|          | 76/10907 [02:06<4:53:28,  1.63s/it][A
  1%|          | 76/10907 [02:06<4:53:23,  1.63s/it][A
  1%|          | 76/10907 [02:06<4:53:19,  1.62s/it][A
  1%|          | 76/10907 [02:06<4:53:27,  1.63s/it][A
  1%|          | 77/10907 [02:07<4:52:36,  1.62s/it][A
  1%|          | 77/10907 [02:07<4:52:28,  1.62s/it][A

  1%|          | 77/10907 [02:07<4:52:36,  1.62s/it][A  1%|          | 77/10907 [02:07<4:52:31,  1.62s/it][A
  1%|          | 77/10907 [02:07<4:52:37,  1.62s/it][A
  1%|          | 77/10907 [02:07<4:52:41,  1.62s/it][A
  1%|          | 78/10907 [02:09<4:52:33,  1.62s/it][A
  1%|          | 78/10907 [02:09<4:52:31,  1.62s/it][A
  1%|          | 78/10907 [02:09<4:52:33,  1.62s/it][A

  1%|          | 78/10907 [02:09<4:52:32,  1.62s/it][A  1%|          | 78/10907 [02:09<4:52:43,  1.62s/it][A
  1%|          | 78/10907 [02:09<4:52:32,  1.62s/it][A
  1%|          | 79/10907 [02:10<4:52:33,  1.62s/it][A
  1%|          | 79/10907 [02:10<4:52:36,  1.62s/it][A
  1%|          | 79/10907 [02:10<4:52:41,  1.62s/it][A

  1%|          | 79/10907 [02:10<4:52:32,  1.62s/it][A  1%|          | 79/10907 [02:10<4:52:38,  1.62s/it][A
  1%|          | 79/10907 [02:10<4:52:35,  1.62s/it][A
  1%|          | 80/10907 [02:12<4:52:03,  1.62s/it][A
  1%|          | 80/10907 [02:12<4:52:15,  1.62s/it][A

  1%|          | 80/10907 [02:12<4:52:34,  1.62s/it][A  1%|          | 80/10907 [02:12<4:52:31,  1.62s/it][A
  1%|          | 80/10907 [02:12<4:52:31,  1.62s/it][A
  1%|          | 80/10907 [02:12<4:52:36,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:51:56,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:52:19,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:52:29,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:52:40,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:52:48,  1.62s/it][A
  1%|          | 81/10907 [02:14<4:52:41,  1.62s/it][A
  1%|          | 82/10907 [02:15<4:52:50,  1.62s/it][A
  1%|          | 82/10907 [02:15<4:53:07,  1.62s/it][A
  1%|          | 82/10907 [02:15<4:53:07,  1.62s/it][A
  1%|          | 82/10907 [02:15<4:53:17,  1.63s/it][A
  1%|          | 82/10907 [02:15<4:53:24,  1.63s/it][A
  1%|          | 82/10907 [02:15<4:53:34,  1.63s/it][A
  1%|          | 83/10907 [02:17<4:52:37,  1.62s/it][A
  1%|          | 83/10907 [02:17<4:52:39,  1.62s/it][A
  1%|          | 83/10907 [02:17<4:52:47,  1.62s/it][A
  1%|          | 83/10907 [02:17<4:53:10,  1.63s/it][A
  1%|          | 83/10907 [02:17<4:52:56,  1.62s/it][A
  1%|          | 83/10907 [02:17<4:52:56,  1.62s/it][A
  1%|          | 84/10907 [02:19<4:52:39,  1.62s/it][A
  1%|          | 84/10907 [02:18<4:52:54,  1.62s/it][A
  1%|          | 84/10907 [02:19<4:52:55,  1.62s/it][A
  1%|          | 84/10907 [02:19<4:52:59,  1.62s/it][A
  1%|          | 84/10907 [02:19<4:53:08,  1.63s/it][A
  1%|          | 84/10907 [02:19<4:53:16,  1.63s/it][A
  1%|          | 85/10907 [02:20<5:06:17,  1.70s/it]
[A  1%|          | 85/10907 [02:20<5:06:16,  1.70s/it][A
  1%|          | 85/10907 [02:20<5:06:28,  1.70s/it][A
  1%|          | 85/10907 [02:20<5:06:37,  1.70s/it][A
  1%|          | 85/10907 [02:20<5:06:40,  1.70s/it][A
  1%|          | 85/10907 [02:20<5:07:02,  1.70s/it][A
  1%|          | 86/10907 [02:22<5:02:11,  1.68s/it][A
  1%|          | 86/10907 [02:22<5:01:48,  1.67s/it][A
  1%|          | 86/10907 [02:22<5:02:08,  1.68s/it][A

  1%|          | 86/10907 [02:22<5:02:21,  1.68s/it][A  1%|          | 86/10907 [02:22<5:02:21,  1.68s/it][A
  1%|          | 86/10907 [02:22<5:02:22,  1.68s/it][A
  1%|          | 87/10907 [02:24<4:58:22,  1.65s/it][A
  1%|          | 87/10907 [02:24<4:59:00,  1.66s/it][A
  1%|          | 87/10907 [02:24<4:59:07,  1.66s/it][A
  1%|          | 87/10907 [02:24<4:59:05,  1.66s/it][A
  1%|          | 87/10907 [02:24<4:59:10,  1.66s/it][A
  1%|          | 87/10907 [02:24<4:59:07,  1.66s/it][A
  1%|          | 88/10907 [02:25<4:55:48,  1.64s/it][A
  1%|          | 88/10907 [02:25<4:55:53,  1.64s/it][A
  1%|          | 88/10907 [02:25<4:56:35,  1.64s/it][A
  1%|          | 88/10907 [02:25<4:56:41,  1.65s/it][A

  1%|          | 88/10907 [02:25<4:56:47,  1.65s/it][A  1%|          | 88/10907 [02:25<4:56:44,  1.65s/it][A
  1%|          | 89/10907 [02:27<4:54:37,  1.63s/it][A
  1%|          | 89/10907 [02:27<4:55:10,  1.64s/it][A
  1%|          | 89/10907 [02:27<4:54:51,  1.64s/it][A
  1%|          | 89/10907 [02:27<4:55:10,  1.64s/it][A
  1%|          | 89/10907 [02:27<4:54:55,  1.64s/it][A
  1%|          | 89/10907 [02:27<4:55:01,  1.64s/it][A
  1%|          | 90/10907 [02:29<5:01:31,  1.67s/it][A
  1%|          | 90/10907 [02:29<5:01:22,  1.67s/it][A
  1%|          | 90/10907 [02:29<5:01:23,  1.67s/it][A

  1%|          | 90/10907 [02:29<5:01:26,  1.67s/it][A  1%|          | 90/10907 [02:29<5:01:43,  1.67s/it][A
  1%|          | 90/10907 [02:29<5:01:37,  1.67s/it][A
  1%|          | 91/10907 [02:30<4:58:20,  1.66s/it][A

  1%|          | 91/10907 [02:30<4:58:22,  1.66s/it][A  1%|          | 91/10907 [02:30<4:58:24,  1.66s/it][A
  1%|          | 91/10907 [02:30<4:58:26,  1.66s/it][A
  1%|          | 91/10907 [02:30<4:58:32,  1.66s/it][A
  1%|          | 91/10907 [02:30<4:58:40,  1.66s/it][A
  1%|          | 92/10907 [02:32<4:56:18,  1.64s/it][A
  1%|          | 92/10907 [02:32<4:56:21,  1.64s/it][A
  1%|          | 92/10907 [02:32<4:56:35,  1.65s/it][A
  1%|          | 92/10907 [02:32<4:56:20,  1.64s/it][A
  1%|          | 92/10907 [02:32<4:56:26,  1.64s/it][A
  1%|          | 92/10907 [02:32<4:56:29,  1.64s/it][A

  1%|          | 93/10907 [02:33<4:55:05,  1.64s/it][A  1%|          | 93/10907 [02:34<4:55:10,  1.64s/it][A
  1%|          | 93/10907 [02:34<4:55:11,  1.64s/it][A

  1%|          | 93/10907 [02:34<4:55:20,  1.64s/it][A  1%|          | 93/10907 [02:34<4:55:07,  1.64s/it][A
  1%|          | 93/10907 [02:34<4:55:13,  1.64s/it][A
  1%|          | 94/10907 [02:35<4:54:03,  1.63s/it][A
  1%|          | 94/10907 [02:35<4:54:09,  1.63s/it][A
  1%|          | 94/10907 [02:35<4:54:07,  1.63s/it][A
  1%|          | 94/10907 [02:35<4:54:08,  1.63s/it][A
  1%|          | 94/10907 [02:35<4:54:12,  1.63s/it][A
  1%|          | 94/10907 [02:35<4:54:07,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:53:18,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:53:37,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:54:06,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:54:06,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:54:03,  1.63s/it][A
  1%|          | 95/10907 [02:37<4:54:07,  1.63s/it][A
  1%|          | 96/10907 [02:38<4:53:10,  1.63s/it][A
  1%|          | 96/10907 [02:38<4:53:19,  1.63s/it][A
  1%|          | 96/10907 [02:38<4:53:14,  1.63s/it][A

  1%|          | 96/10907 [02:38<4:53:19,  1.63s/it][A  1%|          | 96/10907 [02:38<4:53:33,  1.63s/it][A
  1%|          | 96/10907 [02:38<4:53:30,  1.63s/it][A
  1%|          | 97/10907 [02:40<4:52:35,  1.62s/it][A
  1%|          | 97/10907 [02:40<4:52:43,  1.62s/it][A
  1%|          | 97/10907 [02:40<4:52:54,  1.63s/it][A


  1%|          | 97/10907 [02:40<4:52:53,  1.63s/it][A  1%|          | 97/10907 [02:40<4:52:53,  1.63s/it]  1%|          | 97/10907 [02:40<4:52:52,  1.63s/it][A[A
  1%|          | 98/10907 [02:42<4:52:20,  1.62s/it][A
  1%|          | 98/10907 [02:42<4:52:27,  1.62s/it][A
  1%|          | 98/10907 [02:42<4:52:33,  1.62s/it][A
  1%|          | 98/10907 [02:42<4:52:32,  1.62s/it][A

  1%|          | 98/10907 [02:42<4:52:37,  1.62s/it][A  1%|          | 98/10907 [02:42<4:52:34,  1.62s/it][A
  1%|          | 99/10907 [02:43<4:52:38,  1.62s/it][A
  1%|          | 99/10907 [02:43<4:52:45,  1.63s/it][A


  1%|          | 99/10907 [02:43<4:52:50,  1.63s/it]
[A  1%|          | 99/10907 [02:43<4:52:53,  1.63s/it][A  1%|          | 99/10907 [02:43<4:52:48,  1.63s/it][A  1%|          | 99/10907 [02:43<4:52:52,  1.63s/it][A
  1%|          | 100/10907 [02:45<4:51:38,  1.62s/it][A
  1%|          | 100/10907 [02:45<4:52:25,  1.62s/it][A
  1%|          | 100/10907 [02:45<4:52:36,  1.62s/it][A
  1%|          | 100/10907 [02:45<4:52:44,  1.63s/it][A
  1%|          | 100/10907 [02:45<4:52:46,  1.63s/it][A
  1%|          | 100/10907 [02:45<4:52:54,  1.63s/it][A
  1%|          | 101/10907 [02:47<4:51:11,  1.62s/it][A
  1%|          | 101/10907 [02:47<4:51:27,  1.62s/it][A

  1%|          | 101/10907 [02:46<4:51:46,  1.62s/it][A  1%|          | 101/10907 [02:47<4:51:22,  1.62s/it][A
  1%|          | 101/10907 [02:47<4:51:24,  1.62s/it][A
  1%|          | 101/10907 [02:47<4:51:52,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:09,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:18,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:36,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:27,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:19,  1.62s/it][A
  1%|          | 102/10907 [02:48<4:51:30,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:50:58,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:51:09,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:51:07,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:51:22,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:51:15,  1.62s/it][A
  1%|          | 103/10907 [02:50<4:51:10,  1.62s/it][A
  1%|          | 104/10907 [02:51<4:50:35,  1.61s/it][A
  1%|          | 104/10907 [02:51<4:50:36,  1.61s/it][A
  1%|          | 104/10907 [02:51<4:50:35,  1.61s/it][A
  1%|          | 104/10907 [02:51<4:50:40,  1.61s/it][A
  1%|          | 104/10907 [02:51<4:50:34,  1.61s/it][A
  1%|          | 104/10907 [02:51<4:50:48,  1.62s/it][A
  1%|          | 105/10907 [02:53<4:50:19,  1.61s/it][A
  1%|          | 105/10907 [02:53<4:50:44,  1.61s/it][A
  1%|          | 105/10907 [02:53<4:50:46,  1.62s/it][A
  1%|          | 105/10907 [02:53<4:51:04,  1.62s/it][A

  1%|          | 105/10907 [02:53<4:50:59,  1.62s/it][A  1%|          | 105/10907 [02:53<4:51:08,  1.62s/it][A

  1%|          | 106/10907 [02:55<5:05:34,  1.70s/it][A  1%|          | 106/10907 [02:55<5:05:40,  1.70s/it][A
  1%|          | 106/10907 [02:55<5:05:46,  1.70s/it][A
  1%|          | 106/10907 [02:55<5:05:41,  1.70s/it][A
  1%|          | 106/10907 [02:55<5:05:54,  1.70s/it][A
  1%|          | 106/10907 [02:55<5:06:13,  1.70s/it][A
  1%|          | 107/10907 [02:56<5:01:02,  1.67s/it][A
  1%|          | 107/10907 [02:56<5:01:20,  1.67s/it][A


  1%|          | 107/10907 [02:56<5:01:21,  1.67s/it][A  1%|          | 107/10907 [02:56<5:01:11,  1.67s/it][A  1%|          | 107/10907 [02:56<5:01:17,  1.67s/it][A
  1%|          | 107/10907 [02:56<5:01:25,  1.67s/it][A
  1%|          | 108/10907 [02:58<4:58:22,  1.66s/it][A
  1%|          | 108/10907 [02:58<4:58:31,  1.66s/it][A
  1%|          | 108/10907 [02:58<4:58:35,  1.66s/it][A
  1%|          | 108/10907 [02:58<4:58:38,  1.66s/it][A
  1%|          | 108/10907 [02:58<4:58:34,  1.66s/it][A
  1%|          | 108/10907 [02:58<4:59:08,  1.66s/it][A
  1%|          | 109/10907 [03:00<4:56:15,  1.65s/it][A

  1%|          | 109/10907 [03:00<4:56:27,  1.65s/it][A  1%|          | 109/10907 [03:00<4:56:34,  1.65s/it][A
  1%|          | 109/10907 [03:00<4:56:32,  1.65s/it][A
  1%|          | 109/10907 [03:00<4:56:44,  1.65s/it][A
  1%|          | 109/10907 [03:00<4:56:54,  1.65s/it][A
  1%|          | 110/10907 [03:01<4:54:10,  1.63s/it][A
  1%|          | 110/10907 [03:01<4:54:06,  1.63s/it][A
  1%|          | 110/10907 [03:01<4:54:41,  1.64s/it][A


  1%|          | 110/10907 [03:01<4:54:45,  1.64s/it][A  1%|          | 110/10907 [03:01<4:54:55,  1.64s/it][A  1%|          | 110/10907 [03:01<4:54:45,  1.64s/it][A
  1%|          | 111/10907 [03:03<4:53:14,  1.63s/it][A
  1%|          | 111/10907 [03:03<4:53:10,  1.63s/it][A

  1%|          | 111/10907 [03:03<4:53:28,  1.63s/it][A  1%|          | 111/10907 [03:03<4:53:20,  1.63s/it][A
  1%|          | 111/10907 [03:03<4:53:21,  1.63s/it][A
  1%|          | 111/10907 [03:03<4:53:22,  1.63s/it][A
  1%|          | 112/10907 [03:05<4:52:40,  1.63s/it][A
  1%|          | 112/10907 [03:05<4:52:46,  1.63s/it][A
  1%|          | 112/10907 [03:05<4:52:44,  1.63s/it][A
  1%|          | 112/10907 [03:04<4:52:42,  1.63s/it][A
  1%|          | 112/10907 [03:05<4:52:43,  1.63s/it][A
  1%|          | 112/10907 [03:05<4:52:47,  1.63s/it][A
  1%|          | 113/10907 [03:06<4:51:37,  1.62s/it][A
  1%|          | 113/10907 [03:06<4:51:51,  1.62s/it][A
  1%|          | 113/10907 [03:06<4:52:29,  1.63s/it][A
  1%|          | 113/10907 [03:06<4:52:28,  1.63s/it][A
  1%|          | 113/10907 [03:06<4:52:27,  1.63s/it][A
  1%|          | 113/10907 [03:06<4:52:41,  1.63s/it][A
  1%|          | 114/10907 [03:08<4:59:47,  1.67s/it][A

  1%|          | 114/10907 [03:08<4:59:42,  1.67s/it][A  1%|          | 114/10907 [03:08<5:00:03,  1.67s/it][A
  1%|          | 114/10907 [03:08<4:59:53,  1.67s/it][A
  1%|          | 114/10907 [03:08<4:59:58,  1.67s/it][A
  1%|          | 114/10907 [03:08<4:59:49,  1.67s/it][A
  1%|          | 115/10907 [03:10<4:56:49,  1.65s/it][A
  1%|          | 115/10907 [03:10<4:56:51,  1.65s/it][A
  1%|          | 115/10907 [03:09<4:56:50,  1.65s/it][A
  1%|          | 115/10907 [03:10<4:57:37,  1.65s/it][A
  1%|          | 115/10907 [03:10<4:57:33,  1.65s/it][A
  1%|          | 115/10907 [03:10<4:57:27,  1.65s/it][A
  1%|          | 116/10907 [03:11<4:55:28,  1.64s/it][A

  1%|          | 116/10907 [03:11<4:55:39,  1.64s/it][A  1%|          | 116/10907 [03:11<4:55:24,  1.64s/it][A

  1%|          | 116/10907 [03:11<4:55:20,  1.64s/it][A  1%|          | 116/10907 [03:11<4:55:36,  1.64s/it][A
  1%|          | 116/10907 [03:11<4:55:48,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:37,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:31,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:44,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:44,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:44,  1.64s/it][A
  1%|          | 117/10907 [03:13<4:54:35,  1.64s/it][A
  1%|          | 118/10907 [03:14<4:52:19,  1.63s/it][A
  1%|          | 118/10907 [03:14<4:52:35,  1.63s/it][A
  1%|          | 118/10907 [03:14<4:53:25,  1.63s/it][A

  1%|          | 118/10907 [03:14<4:53:31,  1.63s/it][A  1%|          | 118/10907 [03:14<4:53:24,  1.63s/it][A
  1%|          | 118/10907 [03:14<4:53:19,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:53:05,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:52:44,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:53:07,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:52:49,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:52:43,  1.63s/it][A
  1%|          | 119/10907 [03:16<4:52:56,  1.63s/it][A
  1%|          | 120/10907 [03:18<4:52:17,  1.63s/it][A
  1%|          | 120/10907 [03:18<4:52:35,  1.63s/it][A
  1%|          | 120/10907 [03:18<4:52:21,  1.63s/it][A
  1%|          | 120/10907 [03:18<4:52:27,  1.63s/it][A

  1%|          | 120/10907 [03:18<4:52:44,  1.63s/it][A  1%|          | 120/10907 [03:18<4:52:24,  1.63s/it][A
  1%|          | 121/10907 [03:19<4:52:05,  1.62s/it][A
  1%|          | 121/10907 [03:19<4:52:16,  1.63s/it][A

  1%|          | 121/10907 [03:19<4:52:10,  1.63s/it][A  1%|          | 121/10907 [03:19<4:52:07,  1.63s/it][A
  1%|          | 121/10907 [03:19<4:52:25,  1.63s/it][A
  1%|          | 121/10907 [03:19<4:52:11,  1.63s/it][A
  1%|          | 122/10907 [03:21<4:51:55,  1.62s/it][A
  1%|          | 122/10907 [03:21<4:51:53,  1.62s/it][A
  1%|          | 122/10907 [03:21<4:51:57,  1.62s/it][A
  1%|          | 122/10907 [03:21<4:52:02,  1.62s/it][A
  1%|          | 122/10907 [03:21<4:51:54,  1.62s/it][A
  1%|          | 122/10907 [03:21<4:52:06,  1.63s/it][A
  1%|          | 123/10907 [03:23<4:51:14,  1.62s/it][A
  1%|          | 123/10907 [03:23<4:51:22,  1.62s/it][A

  1%|          | 123/10907 [03:22<4:51:34,  1.62s/it][A  1%|          | 123/10907 [03:23<4:51:26,  1.62s/it][A
  1%|          | 123/10907 [03:23<4:51:20,  1.62s/it][A
  1%|          | 123/10907 [03:23<4:51:28,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:27,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:23,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:25,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:26,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:34,  1.62s/it][A
  1%|          | 124/10907 [03:24<4:51:32,  1.62s/it][A
  1%|          | 125/10907 [03:26<4:50:51,  1.62s/it][A

  1%|          | 125/10907 [03:26<4:50:49,  1.62s/it][A  1%|          | 125/10907 [03:26<4:50:50,  1.62s/it][A
  1%|          | 125/10907 [03:26<4:50:57,  1.62s/it][A
  1%|          | 125/10907 [03:26<4:51:00,  1.62s/it][A
  1%|          | 125/10907 [03:26<4:51:10,  1.62s/it][A
  1%|          | 126/10907 [03:27<4:50:48,  1.62s/it][A
  1%|          | 126/10907 [03:27<4:50:59,  1.62s/it][A
  1%|          | 126/10907 [03:27<4:51:02,  1.62s/it][A


  1%|          | 126/10907 [03:27<4:50:55,  1.62s/it][A  1%|          | 126/10907 [03:27<4:51:01,  1.62s/it][A  1%|          | 126/10907 [03:27<4:51:05,  1.62s/it][A
  1%|          | 127/10907 [03:29<5:04:20,  1.69s/it][A
  1%|          | 127/10907 [03:29<5:04:31,  1.69s/it][A
  1%|          | 127/10907 [03:29<5:04:27,  1.69s/it][A
  1%|          | 127/10907 [03:29<5:04:27,  1.69s/it][A
  1%|          | 127/10907 [03:29<5:04:26,  1.69s/it][A
  1%|          | 127/10907 [03:29<5:04:33,  1.70s/it][A
  1%|          | 128/10907 [03:31<4:59:52,  1.67s/it][A
  1%|          | 128/10907 [03:31<4:59:59,  1.67s/it][A
  1%|          | 128/10907 [03:31<5:00:31,  1.67s/it][A
  1%|          | 128/10907 [03:31<5:00:41,  1.67s/it][A
  1%|          | 128/10907 [03:31<5:00:37,  1.67s/it][A
  1%|          | 128/10907 [03:31<5:00:49,  1.67s/it][A
  1%|          | 129/10907 [03:33<4:57:59,  1.66s/it][A
  1%|          | 129/10907 [03:33<4:57:55,  1.66s/it][A
  1%|          | 129/10907 [03:33<4:58:02,  1.66s/it][A
  1%|          | 129/10907 [03:32<4:58:05,  1.66s/it][A
  1%|          | 129/10907 [03:33<4:57:58,  1.66s/it][A
  1%|          | 129/10907 [03:33<4:58:15,  1.66s/it][A
  1%|          | 130/10907 [03:34<4:55:56,  1.65s/it][A

  1%|          | 130/10907 [03:34<4:55:56,  1.65s/it][A  1%|          | 130/10907 [03:34<4:56:08,  1.65s/it][A

  1%|          | 130/10907 [03:34<4:56:30,  1.65s/it][A  1%|          | 130/10907 [03:34<4:56:19,  1.65s/it][A
  1%|          | 130/10907 [03:34<4:56:18,  1.65s/it][A
  1%|          | 131/10907 [03:36<4:54:04,  1.64s/it][A
  1%|          | 131/10907 [03:36<4:54:25,  1.64s/it][A
  1%|          | 131/10907 [03:36<4:54:33,  1.64s/it][A
  1%|          | 131/10907 [03:36<4:54:39,  1.64s/it][A
  1%|          | 131/10907 [03:36<4:54:33,  1.64s/it][A
  1%|          | 131/10907 [03:36<4:54:35,  1.64s/it][A
  1%|          | 132/10907 [03:37<4:53:31,  1.63s/it][A
  1%|          | 132/10907 [03:37<4:53:42,  1.64s/it][A

  1%|          | 132/10907 [03:37<4:53:32,  1.63s/it][A  1%|          | 132/10907 [03:37<4:53:43,  1.64s/it][A
  1%|          | 132/10907 [03:37<4:53:42,  1.64s/it][A
  1%|          | 132/10907 [03:37<4:53:40,  1.64s/it][A
  1%|          | 133/10907 [03:39<4:52:51,  1.63s/it][A
  1%|          | 133/10907 [03:39<4:52:53,  1.63s/it][A

  1%|          | 133/10907 [03:39<4:52:45,  1.63s/it][A  1%|          | 133/10907 [03:39<4:52:57,  1.63s/it][A
  1%|          | 133/10907 [03:39<4:52:55,  1.63s/it][A
  1%|          | 133/10907 [03:39<4:52:58,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:35,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:38,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:39,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:34,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:40,  1.63s/it][A
  1%|          | 134/10907 [03:41<4:52:38,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:51:50,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:51:54,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:52:00,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:52:04,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:52:04,  1.63s/it][A
  1%|          | 135/10907 [03:42<4:52:04,  1.63s/it][A
  1%|          | 136/10907 [03:44<4:59:13,  1.67s/it][A
  1%|          | 136/10907 [03:44<4:59:09,  1.67s/it][A
  1%|          | 136/10907 [03:44<4:59:16,  1.67s/it][A
  1%|          | 136/10907 [03:44<4:59:08,  1.67s/it][A

  1%|          | 136/10907 [03:44<4:59:12,  1.67s/it][A  1%|          | 136/10907 [03:44<4:59:14,  1.67s/it][A
  1%|▏         | 137/10907 [03:46<4:56:09,  1.65s/it][A

  1%|▏         | 137/10907 [03:46<4:56:37,  1.65s/it][A  1%|▏         | 137/10907 [03:46<4:56:35,  1.65s/it][A
  1%|▏         | 137/10907 [03:46<4:56:39,  1.65s/it][A

  1%|▏         | 137/10907 [03:46<4:56:32,  1.65s/it][A  1%|▏         | 137/10907 [03:46<4:56:28,  1.65s/it][A
  1%|▏         | 138/10907 [03:47<4:54:48,  1.64s/it][A
  1%|▏         | 138/10907 [03:47<4:55:04,  1.64s/it][A
  1%|▏         | 138/10907 [03:47<4:55:09,  1.64s/it][A
  1%|▏         | 138/10907 [03:47<4:55:17,  1.65s/it]
[A
  1%|▏         | 138/10907 [03:47<4:55:14,  1.64s/it][A  1%|▏         | 138/10907 [03:47<4:55:21,  1.65s/it][A
  1%|▏         | 139/10907 [03:49<4:53:43,  1.64s/it][A
  1%|▏         | 139/10907 [03:49<4:53:46,  1.64s/it][A

  1%|▏         | 139/10907 [03:49<4:53:55,  1.64s/it][A
  1%|▏         | 139/10907 [03:49<4:53:50,  1.64s/it][A  1%|▏         | 139/10907 [03:49<4:53:51,  1.64s/it][A
  1%|▏         | 139/10907 [03:49<4:53:46,  1.64s/it][A
  1%|▏         | 140/10907 [03:51<4:52:52,  1.63s/it][A
  1%|▏         | 140/10907 [03:50<4:52:55,  1.63s/it][A
  1%|▏         | 140/10907 [03:51<4:53:00,  1.63s/it][A

  1%|▏         | 140/10907 [03:51<4:53:07,  1.63s/it][A  1%|▏         | 140/10907 [03:51<4:53:00,  1.63s/it][A
  1%|▏         | 140/10907 [03:51<4:53:05,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:00,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:18,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:22,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:29,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:20,  1.63s/it][A
  1%|▏         | 141/10907 [03:52<4:52:25,  1.63s/it][A
  1%|▏         | 142/10907 [03:54<4:50:58,  1.62s/it][A
  1%|▏         | 142/10907 [03:54<4:51:14,  1.62s/it][A
  1%|▏         | 142/10907 [03:54<4:51:56,  1.63s/it][A
  1%|▏         | 142/10907 [03:54<4:51:55,  1.63s/it][A
  1%|▏         | 142/10907 [03:54<4:51:55,  1.63s/it][A
  1%|▏         | 142/10907 [03:54<4:52:05,  1.63s/it][A
  1%|▏         | 143/10907 [03:55<4:50:55,  1.62s/it][A
  1%|▏         | 143/10907 [03:55<4:50:52,  1.62s/it][A
  1%|▏         | 143/10907 [03:55<4:51:02,  1.62s/it][A
  1%|▏         | 143/10907 [03:55<4:51:53,  1.63s/it][A
  1%|▏         | 143/10907 [03:55<4:51:42,  1.63s/it][A
  1%|▏         | 143/10907 [03:55<4:51:54,  1.63s/it][A
  1%|▏         | 144/10907 [03:57<4:50:34,  1.62s/it][A
  1%|▏         | 144/10907 [03:57<4:51:01,  1.62s/it][A
  1%|▏         | 144/10907 [03:57<4:50:56,  1.62s/it][A
  1%|▏         | 144/10907 [03:57<4:51:02,  1.62s/it][A
  1%|▏         | 144/10907 [03:57<4:51:10,  1.62s/it][A
  1%|▏         | 144/10907 [03:57<4:51:04,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:50:50,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:51:03,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:51:18,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:51:19,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:51:17,  1.62s/it][A
  1%|▏         | 145/10907 [03:59<4:51:20,  1.62s/it][A
  1%|▏         | 146/10907 [04:00<4:50:41,  1.62s/it][A
  1%|▏         | 146/10907 [04:00<4:50:55,  1.62s/it][A
  1%|▏         | 146/10907 [04:00<4:50:54,  1.62s/it][A
  1%|▏         | 146/10907 [04:00<4:50:53,  1.62s/it][A

  1%|▏         | 146/10907 [04:00<4:50:53,  1.62s/it][A  1%|▏         | 146/10907 [04:00<4:50:51,  1.62s/it][A
  1%|▏         | 147/10907 [04:02<4:50:58,  1.62s/it][A
  1%|▏         | 147/10907 [04:02<4:51:04,  1.62s/it][A
  1%|▏         | 147/10907 [04:02<4:50:53,  1.62s/it][A

  1%|▏         | 147/10907 [04:02<4:50:57,  1.62s/it][A  1%|▏         | 147/10907 [04:02<4:50:52,  1.62s/it]
[A  1%|▏         | 147/10907 [04:02<4:51:00,  1.62s/it][A
  1%|▏         | 148/10907 [04:04<5:03:05,  1.69s/it][A
  1%|▏         | 148/10907 [04:04<5:03:03,  1.69s/it][A
  1%|▏         | 148/10907 [04:04<5:03:07,  1.69s/it][A
  1%|▏         | 148/10907 [04:04<5:03:19,  1.69s/it][A
  1%|▏         | 148/10907 [04:04<5:03:28,  1.69s/it][A
  1%|▏         | 148/10907 [04:04<5:03:27,  1.69s/it][A
  1%|▏         | 149/10907 [04:05<4:59:40,  1.67s/it][A

  1%|▏         | 149/10907 [04:05<4:59:37,  1.67s/it][A  1%|▏         | 149/10907 [04:05<4:59:48,  1.67s/it][A

  1%|▏         | 149/10907 [04:05<4:59:45,  1.67s/it][A  1%|▏         | 149/10907 [04:05<4:59:36,  1.67s/it][A
  1%|▏         | 149/10907 [04:05<4:59:57,  1.67s/it][A
  1%|▏         | 150/10907 [04:07<4:57:04,  1.66s/it][A
  1%|▏         | 150/10907 [04:07<4:57:10,  1.66s/it][A
  1%|▏         | 150/10907 [04:07<4:57:24,  1.66s/it][A
  1%|▏         | 150/10907 [04:07<4:57:26,  1.66s/it][A
  1%|▏         | 150/10907 [04:07<4:57:22,  1.66s/it][A
  1%|▏         | 150/10907 [04:07<4:57:23,  1.66s/it][A
  1%|▏         | 151/10907 [04:09<4:55:17,  1.65s/it][A

  1%|▏         | 151/10907 [04:09<4:55:16,  1.65s/it][A  1%|▏         | 151/10907 [04:09<4:55:21,  1.65s/it][A
  1%|▏         | 151/10907 [04:08<4:55:32,  1.65s/it][A
  1%|▏         | 151/10907 [04:09<4:55:23,  1.65s/it][A
  1%|▏         | 151/10907 [04:09<4:55:24,  1.65s/it][A
  1%|▏         | 152/10907 [04:10<4:53:58,  1.64s/it][A
  1%|▏         | 152/10907 [04:10<4:53:59,  1.64s/it][A
  1%|▏         | 152/10907 [04:10<4:54:01,  1.64s/it][A
  1%|▏         | 152/10907 [04:10<4:53:59,  1.64s/it][A
  1%|▏         | 152/10907 [04:10<4:53:58,  1.64s/it][A
  1%|▏         | 152/10907 [04:10<4:54:00,  1.64s/it][A
  1%|▏         | 153/10907 [04:12<4:52:48,  1.63s/it][A

  1%|▏         | 153/10907 [04:12<4:52:49,  1.63s/it][A  1%|▏         | 153/10907 [04:12<4:52:49,  1.63s/it][A

  1%|▏         | 153/10907 [04:12<4:52:48,  1.63s/it][A  1%|▏         | 153/10907 [04:12<4:52:43,  1.63s/it][A
  1%|▏         | 153/10907 [04:12<4:52:45,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:22,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:16,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:22,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:29,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:31,  1.63s/it][A
  1%|▏         | 154/10907 [04:13<4:52:28,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:45,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:46,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:49,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:48,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:47,  1.63s/it][A
  1%|▏         | 155/10907 [04:15<4:51:58,  1.63s/it][A
  1%|▏         | 156/10907 [04:17<4:51:09,  1.62s/it][A
  1%|▏         | 156/10907 [04:17<4:51:13,  1.63s/it][A
  1%|▏         | 156/10907 [04:17<4:51:11,  1.63s/it][A
  1%|▏         | 156/10907 [04:17<4:51:11,  1.63s/it][A
  1%|▏         | 156/10907 [04:17<4:51:17,  1.63s/it][A
  1%|▏         | 156/10907 [04:17<4:51:40,  1.63s/it][A
  1%|▏         | 157/10907 [04:18<4:58:22,  1.67s/it][A
  1%|▏         | 157/10907 [04:18<4:58:29,  1.67s/it][A
  1%|▏         | 157/10907 [04:18<4:58:29,  1.67s/it][A
  1%|▏         | 157/10907 [04:18<4:58:24,  1.67s/it][A
  1%|▏         | 157/10907 [04:18<4:58:29,  1.67s/it][A
  1%|▏         | 157/10907 [04:18<4:58:34,  1.67s/it][A
  1%|▏         | 158/10907 [04:20<4:56:07,  1.65s/it][A
  1%|▏         | 158/10907 [04:20<4:56:10,  1.65s/it][A
  1%|▏         | 158/10907 [04:20<4:56:10,  1.65s/it][A
  1%|▏         | 158/10907 [04:20<4:56:18,  1.65s/it][A
  1%|▏         | 158/10907 [04:20<4:56:22,  1.65s/it][A
  1%|▏         | 158/10907 [04:20<4:56:16,  1.65s/it][A
  1%|▏         | 159/10907 [04:22<4:53:47,  1.64s/it][A
  1%|▏         | 159/10907 [04:22<4:53:52,  1.64s/it][A
  1%|▏         | 159/10907 [04:22<4:54:00,  1.64s/it][A
  1%|▏         | 159/10907 [04:22<4:54:10,  1.64s/it][A
  1%|▏         | 159/10907 [04:22<4:54:13,  1.64s/it][A
  1%|▏         | 159/10907 [04:22<4:54:24,  1.64s/it][A

  1%|▏         | 160/10907 [04:23<4:52:31,  1.63s/it][A
  1%|▏         | 160/10907 [04:23<4:52:37,  1.63s/it][A  1%|▏         | 160/10907 [04:23<4:52:33,  1.63s/it][A

  1%|▏         | 160/10907 [04:23<4:53:03,  1.64s/it][A  1%|▏         | 160/10907 [04:23<4:53:09,  1.64s/it][A
  1%|▏         | 160/10907 [04:23<4:53:01,  1.64s/it][A

  1%|▏         | 161/10907 [04:25<4:51:55,  1.63s/it][A  1%|▏         | 161/10907 [04:25<4:51:57,  1.63s/it][A
  1%|▏         | 161/10907 [04:25<4:52:02,  1.63s/it][A
  1%|▏         | 161/10907 [04:25<4:52:03,  1.63s/it]
[A  1%|▏         | 161/10907 [04:25<4:52:05,  1.63s/it][A
  1%|▏         | 161/10907 [04:25<4:52:09,  1.63s/it][A
  1%|▏         | 162/10907 [04:27<4:51:51,  1.63s/it][A
  1%|▏         | 162/10907 [04:27<4:51:57,  1.63s/it][A
  1%|▏         | 162/10907 [04:26<4:52:03,  1.63s/it][A
  1%|▏         | 162/10907 [04:27<4:52:01,  1.63s/it][A
  1%|▏         | 162/10907 [04:27<4:52:06,  1.63s/it][A
  1%|▏         | 162/10907 [04:27<4:52:12,  1.63s/it][A
  1%|▏         | 163/10907 [04:28<4:50:37,  1.62s/it][A
  1%|▏         | 163/10907 [04:28<4:50:52,  1.62s/it][A
  1%|▏         | 163/10907 [04:28<4:51:11,  1.63s/it][A
  1%|▏         | 163/10907 [04:28<4:51:11,  1.63s/it][A
  1%|▏         | 163/10907 [04:28<4:51:33,  1.63s/it][A
  1%|▏         | 163/10907 [04:28<4:51:40,  1.63s/it][A
  2%|▏         | 164/10907 [04:30<4:50:51,  1.62s/it][A

  2%|▏         | 164/10907 [04:30<4:50:48,  1.62s/it][A  2%|▏         | 164/10907 [04:30<4:50:47,  1.62s/it][A
  2%|▏         | 164/10907 [04:30<4:50:58,  1.63s/it][A
  2%|▏         | 164/10907 [04:30<4:51:07,  1.63s/it][A
  2%|▏         | 164/10907 [04:30<4:51:12,  1.63s/it][A
  2%|▏         | 165/10907 [04:31<4:49:57,  1.62s/it][A
  2%|▏         | 165/10907 [04:31<4:50:15,  1.62s/it][A
  2%|▏         | 165/10907 [04:31<4:50:24,  1.62s/it][A
  2%|▏         | 165/10907 [04:31<4:50:36,  1.62s/it][A
  2%|▏         | 165/10907 [04:31<4:50:43,  1.62s/it][A
  2%|▏         | 165/10907 [04:31<4:50:45,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:07,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:06,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:20,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:17,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:16,  1.62s/it][A
  2%|▏         | 166/10907 [04:33<4:50:25,  1.62s/it][A
  2%|▏         | 167/10907 [04:35<4:50:04,  1.62s/it][A
  2%|▏         | 167/10907 [04:35<4:50:01,  1.62s/it][A
  2%|▏         | 167/10907 [04:35<4:50:09,  1.62s/it][A

  2%|▏         | 167/10907 [04:35<4:50:03,  1.62s/it][A  2%|▏         | 167/10907 [04:35<4:50:15,  1.62s/it][A
  2%|▏         | 167/10907 [04:35<4:50:19,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:49:54,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:50:00,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:49:58,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:50:07,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:50:08,  1.62s/it][A
  2%|▏         | 168/10907 [04:36<4:50:12,  1.62s/it][A
  2%|▏         | 169/10907 [04:38<5:03:08,  1.69s/it][A
  2%|▏         | 169/10907 [04:38<5:03:08,  1.69s/it][A
  2%|▏         | 169/10907 [04:38<5:03:16,  1.69s/it][A

  2%|▏         | 169/10907 [04:38<5:03:13,  1.69s/it][A
  2%|▏         | 169/10907 [04:38<5:03:16,  1.69s/it][A  2%|▏         | 169/10907 [04:38<5:03:19,  1.69s/it][A
  2%|▏         | 170/10907 [04:40<4:58:12,  1.67s/it][A
  2%|▏         | 170/10907 [04:40<4:58:48,  1.67s/it][A
  2%|▏         | 170/10907 [04:40<4:59:05,  1.67s/it][A


  2%|▏         | 170/10907 [04:40<4:59:08,  1.67s/it][A  2%|▏         | 170/10907 [04:40<4:59:10,  1.67s/it][A  2%|▏         | 170/10907 [04:40<4:59:06,  1.67s/it][A
  2%|▏         | 171/10907 [04:41<4:55:20,  1.65s/it][A
  2%|▏         | 171/10907 [04:41<4:55:38,  1.65s/it][A

  2%|▏         | 171/10907 [04:41<4:56:07,  1.65s/it][A  2%|▏         | 171/10907 [04:41<4:56:07,  1.65s/it][A

  2%|▏         | 171/10907 [04:41<4:56:34,  1.66s/it][A  2%|▏         | 171/10907 [04:41<4:56:14,  1.66s/it][A
  2%|▏         | 172/10907 [04:43<4:54:10,  1.64s/it][A
  2%|▏         | 172/10907 [04:43<4:54:15,  1.64s/it][A

  2%|▏         | 172/10907 [04:43<4:54:27,  1.65s/it][A  2%|▏         | 172/10907 [04:43<4:54:17,  1.64s/it][A

  2%|▏         | 172/10907 [04:43<4:54:33,  1.65s/it][A  2%|▏         | 172/10907 [04:43<4:54:38,  1.65s/it][A
  2%|▏         | 173/10907 [04:45<4:52:00,  1.63s/it][A
  2%|▏         | 173/10907 [04:45<4:52:04,  1.63s/it][A
  2%|▏         | 173/10907 [04:45<4:52:42,  1.64s/it][A
  2%|▏         | 173/10907 [04:45<4:53:05,  1.64s/it][A
  2%|▏         | 173/10907 [04:45<4:53:09,  1.64s/it][A
  2%|▏         | 173/10907 [04:45<4:53:24,  1.64s/it][A
  2%|▏         | 174/10907 [04:46<4:52:03,  1.63s/it][A
  2%|▏         | 174/10907 [04:46<4:52:02,  1.63s/it][A
  2%|▏         | 174/10907 [04:46<4:52:28,  1.63s/it][A
  2%|▏         | 174/10907 [04:46<4:52:40,  1.64s/it][A
  2%|▏         | 174/10907 [04:46<4:52:36,  1.64s/it][A
  2%|▏         | 174/10907 [04:46<4:52:27,  1.63s/it][A
  2%|▏         | 175/10907 [04:48<4:51:21,  1.63s/it][A
  2%|▏         | 175/10907 [04:48<4:51:39,  1.63s/it][A
  2%|▏         | 175/10907 [04:48<4:51:56,  1.63s/it][A

  2%|▏         | 175/10907 [04:48<4:51:59,  1.63s/it][A  2%|▏         | 175/10907 [04:48<4:51:56,  1.63s/it][A
  2%|▏         | 175/10907 [04:48<4:51:58,  1.63s/it][A
  2%|▏         | 176/10907 [04:49<4:50:34,  1.62s/it][A
  2%|▏         | 176/10907 [04:49<4:51:00,  1.63s/it][A
  2%|▏         | 176/10907 [04:49<4:51:06,  1.63s/it][A
  2%|▏         | 176/10907 [04:49<4:50:56,  1.63s/it][A
  2%|▏         | 176/10907 [04:49<4:50:51,  1.63s/it][A
  2%|▏         | 176/10907 [04:49<4:51:03,  1.63s/it][A
  2%|▏         | 177/10907 [04:51<4:50:35,  1.62s/it][A

  2%|▏         | 177/10907 [04:51<4:50:44,  1.63s/it][A  2%|▏         | 177/10907 [04:51<4:50:40,  1.63s/it]
[A  2%|▏         | 177/10907 [04:51<4:50:30,  1.62s/it][A

  2%|▏         | 177/10907 [04:51<4:50:36,  1.63s/it][A  2%|▏         | 177/10907 [04:51<4:50:44,  1.63s/it][A
  2%|▏         | 178/10907 [04:53<4:55:49,  1.65s/it][A
  2%|▏         | 178/10907 [04:53<4:55:53,  1.65s/it][A
  2%|▏         | 178/10907 [04:53<4:56:58,  1.66s/it][A
  2%|▏         | 178/10907 [04:53<4:57:03,  1.66s/it][A
  2%|▏         | 178/10907 [04:53<4:57:13,  1.66s/it][A
  2%|▏         | 178/10907 [04:53<4:57:17,  1.66s/it][A
  2%|▏         | 179/10907 [04:54<4:55:10,  1.65s/it][A
  2%|▏         | 179/10907 [04:54<4:54:44,  1.65s/it][A

  2%|▏         | 179/10907 [04:54<4:54:43,  1.65s/it][A  2%|▏         | 179/10907 [04:54<4:54:35,  1.65s/it][A

  2%|▏         | 179/10907 [04:54<4:54:50,  1.65s/it][A  2%|▏         | 179/10907 [04:54<4:55:07,  1.65s/it][A
  2%|▏         | 180/10907 [04:56<4:52:20,  1.64s/it][A
  2%|▏         | 180/10907 [04:56<4:52:33,  1.64s/it][A
  2%|▏         | 180/10907 [04:56<4:53:12,  1.64s/it][A


  2%|▏         | 180/10907 [04:56<4:53:07,  1.64s/it][A  2%|▏         | 180/10907 [04:56<4:52:58,  1.64s/it][A  2%|▏         | 180/10907 [04:56<4:53:25,  1.64s/it][A
  2%|▏         | 181/10907 [04:58<4:52:09,  1.63s/it][A
  2%|▏         | 181/10907 [04:58<4:52:12,  1.63s/it][A
  2%|▏         | 181/10907 [04:58<4:51:58,  1.63s/it][A
  2%|▏         | 181/10907 [04:58<4:52:18,  1.64s/it][A

  2%|▏         | 181/10907 [04:58<4:52:13,  1.63s/it][A  2%|▏         | 181/10907 [04:58<4:52:07,  1.63s/it][A

  2%|▏         | 182/10907 [04:59<4:51:51,  1.63s/it][A  2%|▏         | 182/10907 [04:59<4:51:57,  1.63s/it][A
  2%|▏         | 182/10907 [04:59<4:51:44,  1.63s/it][A
  2%|▏         | 182/10907 [04:59<4:51:58,  1.63s/it][A
  2%|▏         | 182/10907 [04:59<4:51:59,  1.63s/it][A
  2%|▏         | 182/10907 [04:59<4:51:52,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:09,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:24,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:27,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:21,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:25,  1.63s/it][A
  2%|▏         | 183/10907 [05:01<4:51:30,  1.63s/it][A

  2%|▏         | 184/10907 [05:03<4:50:36,  1.63s/it][A  2%|▏         | 184/10907 [05:03<4:50:41,  1.63s/it][A
  2%|▏         | 184/10907 [05:02<4:50:40,  1.63s/it][A
  2%|▏         | 184/10907 [05:03<4:50:44,  1.63s/it][A
  2%|▏         | 184/10907 [05:03<4:50:43,  1.63s/it][A
  2%|▏         | 184/10907 [05:03<4:50:44,  1.63s/it][A
  2%|▏         | 185/10907 [05:04<4:49:18,  1.62s/it][A
  2%|▏         | 185/10907 [05:04<4:49:19,  1.62s/it][A
  2%|▏         | 185/10907 [05:04<4:50:14,  1.62s/it][A
  2%|▏         | 185/10907 [05:04<4:50:30,  1.63s/it][A

  2%|▏         | 185/10907 [05:04<4:50:38,  1.63s/it][A  2%|▏         | 185/10907 [05:04<4:50:41,  1.63s/it][A
  2%|▏         | 186/10907 [05:06<4:49:51,  1.62s/it][A
  2%|▏         | 186/10907 [05:06<4:50:02,  1.62s/it][A
  2%|▏         | 186/10907 [05:06<4:50:17,  1.62s/it][A
  2%|▏         | 186/10907 [05:06<4:50:06,  1.62s/it][A
  2%|▏         | 186/10907 [05:06<4:50:06,  1.62s/it][A
  2%|▏         | 186/10907 [05:06<4:50:29,  1.63s/it][A
  2%|▏         | 187/10907 [05:07<4:49:17,  1.62s/it][A
  2%|▏         | 187/10907 [05:07<4:49:25,  1.62s/it][A
  2%|▏         | 187/10907 [05:07<4:49:27,  1.62s/it][A
  2%|▏         | 187/10907 [05:07<4:49:42,  1.62s/it][A
  2%|▏         | 187/10907 [05:07<4:49:45,  1.62s/it][A
  2%|▏         | 187/10907 [05:07<4:49:41,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:12,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:17,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:12,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:07,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:14,  1.62s/it][A
  2%|▏         | 188/10907 [05:09<4:49:24,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:48:55,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:49:05,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:48:58,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:49:09,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:49:04,  1.62s/it][A
  2%|▏         | 189/10907 [05:11<4:49:06,  1.62s/it][A
  2%|▏         | 190/10907 [05:13<5:03:03,  1.70s/it][A
  2%|▏         | 190/10907 [05:12<5:03:05,  1.70s/it][A
  2%|▏         | 190/10907 [05:13<5:03:12,  1.70s/it][A


  2%|▏         | 190/10907 [05:13<5:03:08,  1.70s/it][A  2%|▏         | 190/10907 [05:13<5:03:03,  1.70s/it][A  2%|▏         | 190/10907 [05:13<5:03:06,  1.70s/it][A
  2%|▏         | 191/10907 [05:14<4:58:49,  1.67s/it][A
  2%|▏         | 191/10907 [05:14<4:58:51,  1.67s/it][A

  2%|▏         | 191/10907 [05:14<4:58:54,  1.67s/it][A  2%|▏         | 191/10907 [05:14<4:58:56,  1.67s/it][A
  2%|▏         | 191/10907 [05:14<4:59:01,  1.67s/it][A
  2%|▏         | 191/10907 [05:14<4:59:04,  1.67s/it][A
  2%|▏         | 192/10907 [05:16<4:55:49,  1.66s/it][A
  2%|▏         | 192/10907 [05:16<4:55:57,  1.66s/it][A
  2%|▏         | 192/10907 [05:16<4:55:52,  1.66s/it][A
  2%|▏         | 192/10907 [05:16<4:55:59,  1.66s/it][A

  2%|▏         | 192/10907 [05:16<4:55:56,  1.66s/it][A  2%|▏         | 192/10907 [05:16<4:55:58,  1.66s/it][A
  2%|▏         | 193/10907 [05:17<4:53:40,  1.64s/it][A
  2%|▏         | 193/10907 [05:17<4:53:40,  1.64s/it][A
  2%|▏         | 193/10907 [05:17<4:53:45,  1.65s/it][A
  2%|▏         | 193/10907 [05:17<4:53:50,  1.65s/it][A
  2%|▏         | 193/10907 [05:17<4:53:50,  1.65s/it][A
  2%|▏         | 193/10907 [05:17<4:53:51,  1.65s/it][A
  2%|▏         | 194/10907 [05:19<4:52:28,  1.64s/it][A
  2%|▏         | 194/10907 [05:19<4:52:27,  1.64s/it][A

  2%|▏         | 194/10907 [05:19<4:52:29,  1.64s/it][A  2%|▏         | 194/10907 [05:19<4:52:34,  1.64s/it][A
  2%|▏         | 194/10907 [05:19<4:52:28,  1.64s/it][A
  2%|▏         | 194/10907 [05:19<4:52:33,  1.64s/it][A
  2%|▏         | 195/10907 [05:21<4:50:29,  1.63s/it][A
  2%|▏         | 195/10907 [05:21<4:50:46,  1.63s/it][A
  2%|▏         | 195/10907 [05:21<4:50:55,  1.63s/it][A
  2%|▏         | 195/10907 [05:21<4:51:02,  1.63s/it][A

  2%|▏         | 195/10907 [05:21<4:51:06,  1.63s/it][A  2%|▏         | 195/10907 [05:21<4:51:10,  1.63s/it][A
  2%|▏         | 196/10907 [05:22<4:50:09,  1.63s/it][A
  2%|▏         | 196/10907 [05:22<4:50:26,  1.63s/it][A
  2%|▏         | 196/10907 [05:22<4:50:28,  1.63s/it][A
  2%|▏         | 196/10907 [05:22<4:50:16,  1.63s/it][A

  2%|▏         | 196/10907 [05:22<4:50:16,  1.63s/it][A  2%|▏         | 196/10907 [05:22<4:50:20,  1.63s/it][A
  2%|▏         | 197/10907 [05:24<4:49:58,  1.62s/it][A
  2%|▏         | 197/10907 [05:24<4:49:55,  1.62s/it][A
  2%|▏         | 197/10907 [05:24<4:50:08,  1.63s/it][A
  2%|▏         | 197/10907 [05:24<4:50:03,  1.62s/it][A
  2%|▏         | 197/10907 [05:24<4:50:03,  1.62s/it][A
  2%|▏         | 197/10907 [05:24<4:50:04,  1.63s/it][A
  2%|▏         | 198/10907 [05:25<4:49:29,  1.62s/it][A
  2%|▏         | 198/10907 [05:25<4:49:38,  1.62s/it][A
  2%|▏         | 198/10907 [05:25<4:49:35,  1.62s/it][A
  2%|▏         | 198/10907 [05:25<4:49:44,  1.62s/it][A
  2%|▏         | 198/10907 [05:25<4:49:53,  1.62s/it][A
  2%|▏         | 198/10907 [05:25<4:49:48,  1.62s/it][A
  2%|▏         | 199/10907 [05:27<4:56:02,  1.66s/it][A

  2%|▏         | 199/10907 [05:27<4:56:10,  1.66s/it]
[A  2%|▏         | 199/10907 [05:27<4:56:02,  1.66s/it][A  2%|▏         | 199/10907 [05:27<4:56:21,  1.66s/it][A
  2%|▏         | 199/10907 [05:27<4:56:11,  1.66s/it][A
  2%|▏         | 199/10907 [05:27<4:56:05,  1.66s/it][A
  2%|▏         | 200/10907 [05:29<4:54:05,  1.65s/it][A
  2%|▏         | 200/10907 [05:29<4:53:57,  1.65s/it][A

  2%|▏         | 200/10907 [05:29<4:54:36,  1.65s/it][A  2%|▏         | 200/10907 [05:29<4:54:33,  1.65s/it][A
  2%|▏         | 200/10907 [05:29<4:54:47,  1.65s/it][A
  2%|▏         | 200/10907 [05:29<4:55:00,  1.65s/it][A
  2%|▏         | 201/10907 [05:30<4:52:37,  1.64s/it][A
  2%|▏         | 201/10907 [05:30<4:52:59,  1.64s/it][A
  2%|▏         | 201/10907 [05:30<4:52:51,  1.64s/it][A
  2%|▏         | 201/10907 [05:30<4:52:47,  1.64s/it][A
  2%|▏         | 201/10907 [05:30<4:52:56,  1.64s/it][A
  2%|▏         | 201/10907 [05:30<4:52:49,  1.64s/it][A
  2%|▏         | 202/10907 [05:32<4:51:33,  1.63s/it][A
  2%|▏         | 202/10907 [05:32<4:51:34,  1.63s/it][A
  2%|▏         | 202/10907 [05:32<4:51:31,  1.63s/it][A
  2%|▏         | 202/10907 [05:32<4:51:36,  1.63s/it][A
  2%|▏         | 202/10907 [05:32<4:51:44,  1.64s/it][A
  2%|▏         | 202/10907 [05:32<4:51:50,  1.64s/it][A
  2%|▏         | 203/10907 [05:34<4:50:36,  1.63s/it][A
  2%|▏         | 203/10907 [05:34<4:50:42,  1.63s/it][A
  2%|▏         | 203/10907 [05:34<4:50:48,  1.63s/it][A
  2%|▏         | 203/10907 [05:34<4:50:47,  1.63s/it][A
  2%|▏         | 203/10907 [05:34<4:50:55,  1.63s/it][A
  2%|▏         | 203/10907 [05:34<4:50:57,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:07,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:07,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:15,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:19,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:17,  1.63s/it][A
  2%|▏         | 204/10907 [05:35<4:50:26,  1.63s/it][A
  2%|▏         | 205/10907 [05:37<4:49:03,  1.62s/it][A
  2%|▏         | 205/10907 [05:37<4:49:05,  1.62s/it][A
  2%|▏         | 205/10907 [05:37<4:49:49,  1.62s/it][A
  2%|▏         | 205/10907 [05:37<4:50:05,  1.63s/it][A
  2%|▏         | 205/10907 [05:37<4:50:05,  1.63s/it][A
  2%|▏         | 205/10907 [05:37<4:49:58,  1.63s/it][A
  2%|▏         | 206/10907 [05:39<4:49:26,  1.62s/it][A
  2%|▏         | 206/10907 [05:39<4:49:45,  1.62s/it][A
  2%|▏         | 206/10907 [05:39<4:49:17,  1.62s/it][A
  2%|▏         | 206/10907 [05:39<4:49:29,  1.62s/it][A

  2%|▏         | 206/10907 [05:38<4:49:39,  1.62s/it][A  2%|▏         | 206/10907 [05:39<4:49:51,  1.63s/it][A
  2%|▏         | 207/10907 [05:40<4:49:10,  1.62s/it][A
  2%|▏         | 207/10907 [05:40<4:49:10,  1.62s/it][A
  2%|▏         | 207/10907 [05:40<4:49:05,  1.62s/it][A
  2%|▏         | 207/10907 [05:40<4:49:38,  1.62s/it][A

  2%|▏         | 207/10907 [05:40<4:49:45,  1.62s/it][A  2%|▏         | 207/10907 [05:40<4:49:57,  1.63s/it][A
  2%|▏         | 208/10907 [05:42<4:48:45,  1.62s/it][A
  2%|▏         | 208/10907 [05:42<4:49:04,  1.62s/it][A
  2%|▏         | 208/10907 [05:42<4:49:17,  1.62s/it][A
  2%|▏         | 208/10907 [05:42<4:49:12,  1.62s/it][A

  2%|▏         | 208/10907 [05:42<4:49:11,  1.62s/it][A  2%|▏         | 208/10907 [05:42<4:49:34,  1.62s/it][A
  2%|▏         | 209/10907 [05:43<4:48:51,  1.62s/it][A
  2%|▏         | 209/10907 [05:43<4:49:01,  1.62s/it][A

  2%|▏         | 209/10907 [05:43<4:49:06,  1.62s/it][A
  2%|▏         | 209/10907 [05:43<4:48:58,  1.62s/it][A  2%|▏         | 209/10907 [05:43<4:49:10,  1.62s/it][A
  2%|▏         | 209/10907 [05:43<4:48:52,  1.62s/it][A
  2%|▏         | 210/10907 [05:45<4:48:43,  1.62s/it][A

  2%|▏         | 210/10907 [05:45<4:48:59,  1.62s/it][A  2%|▏         | 210/10907 [05:45<4:48:55,  1.62s/it][A
  2%|▏         | 210/10907 [05:45<4:48:55,  1.62s/it][A
  2%|▏         | 210/10907 [05:45<4:49:05,  1.62s/it][A
  2%|▏         | 210/10907 [05:45<4:49:07,  1.62s/it][A
  2%|▏         | 211/10907 [05:47<5:01:29,  1.69s/it][A

  2%|▏         | 211/10907 [05:47<5:01:23,  1.69s/it][A  2%|▏         | 211/10907 [05:47<5:01:27,  1.69s/it][A
  2%|▏         | 211/10907 [05:47<5:01:32,  1.69s/it][A
  2%|▏         | 211/10907 [05:47<5:01:31,  1.69s/it][A
  2%|▏         | 211/10907 [05:47<5:01:34,  1.69s/it][A
  2%|▏         | 212/10907 [05:49<4:57:23,  1.67s/it][A
  2%|▏         | 212/10907 [05:49<4:57:36,  1.67s/it][A
  2%|▏         | 212/10907 [05:49<4:57:41,  1.67s/it][A


  2%|▏         | 212/10907 [05:49<4:57:33,  1.67s/it][A  2%|▏         | 212/10907 [05:48<4:57:36,  1.67s/it][A  2%|▏         | 212/10907 [05:49<4:57:31,  1.67s/it][A
  2%|▏         | 213/10907 [05:50<4:54:29,  1.65s/it][A
  2%|▏         | 213/10907 [05:50<4:54:39,  1.65s/it][A
  2%|▏         | 213/10907 [05:50<4:54:46,  1.65s/it][A
  2%|▏         | 213/10907 [05:50<4:55:13,  1.66s/it][A
  2%|▏         | 213/10907 [05:50<4:55:08,  1.66s/it][A
  2%|▏         | 213/10907 [05:50<4:55:11,  1.66s/it][A

  2%|▏         | 214/10907 [05:52<4:53:05,  1.64s/it][A  2%|▏         | 214/10907 [05:52<4:52:53,  1.64s/it][A
  2%|▏         | 214/10907 [05:52<4:53:02,  1.64s/it][A

  2%|▏         | 214/10907 [05:52<4:52:57,  1.64s/it][A  2%|▏         | 214/10907 [05:52<4:52:56,  1.64s/it][A
  2%|▏         | 214/10907 [05:52<4:53:35,  1.65s/it][A
  2%|▏         | 215/10907 [05:53<4:51:23,  1.64s/it][A

  2%|▏         | 215/10907 [05:53<4:51:15,  1.63s/it][A  2%|▏         | 215/10907 [05:53<4:51:26,  1.64s/it][A

  2%|▏         | 215/10907 [05:53<4:51:34,  1.64s/it][A
  2%|▏         | 215/10907 [05:53<4:51:21,  1.63s/it][A  2%|▏         | 215/10907 [05:53<4:51:18,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:50:03,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:49:56,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:50:10,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:50:07,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:50:14,  1.63s/it][A
  2%|▏         | 216/10907 [05:55<4:50:14,  1.63s/it][A
  2%|▏         | 217/10907 [05:57<4:48:38,  1.62s/it][A
  2%|▏         | 217/10907 [05:56<4:48:40,  1.62s/it][A
  2%|▏         | 217/10907 [05:57<4:49:47,  1.63s/it][A
  2%|▏         | 217/10907 [05:57<4:50:03,  1.63s/it][A

  2%|▏         | 217/10907 [05:57<4:49:57,  1.63s/it][A  2%|▏         | 217/10907 [05:57<4:50:03,  1.63s/it][A
  2%|▏         | 218/10907 [05:58<4:49:01,  1.62s/it][A

  2%|▏         | 218/10907 [05:58<4:49:19,  1.62s/it][A  2%|▏         | 218/10907 [05:58<4:49:34,  1.63s/it][A
  2%|▏         | 218/10907 [05:58<4:49:47,  1.63s/it][A
  2%|▏         | 218/10907 [05:58<4:49:31,  1.63s/it][A
  2%|▏         | 218/10907 [05:58<4:49:52,  1.63s/it][A
  2%|▏         | 219/10907 [06:00<4:49:16,  1.62s/it][A

  2%|▏         | 219/10907 [06:00<4:49:26,  1.62s/it][A  2%|▏         | 219/10907 [06:00<4:49:18,  1.62s/it][A
  2%|▏         | 219/10907 [06:00<4:49:11,  1.62s/it][A
  2%|▏         | 219/10907 [06:00<4:49:33,  1.63s/it][A
  2%|▏         | 219/10907 [06:00<4:49:20,  1.62s/it][A
  2%|▏         | 220/10907 [06:02<4:56:12,  1.66s/it][A
  2%|▏         | 220/10907 [06:02<4:56:12,  1.66s/it][A

  2%|▏         | 220/10907 [06:02<4:56:18,  1.66s/it][A  2%|▏         | 220/10907 [06:02<4:56:10,  1.66s/it][A
  2%|▏         | 220/10907 [06:02<4:56:25,  1.66s/it][A
  2%|▏         | 220/10907 [06:02<4:56:40,  1.67s/it][A
  2%|▏         | 221/10907 [06:03<4:53:38,  1.65s/it][A
  2%|▏         | 221/10907 [06:03<4:53:34,  1.65s/it][A
  2%|▏         | 221/10907 [06:03<4:53:41,  1.65s/it][A


  2%|▏         | 221/10907 [06:03<4:53:39,  1.65s/it][A  2%|▏         | 221/10907 [06:03<4:53:47,  1.65s/it][A  2%|▏         | 221/10907 [06:03<4:53:44,  1.65s/it][A
  2%|▏         | 222/10907 [06:05<4:50:28,  1.63s/it][A
  2%|▏         | 222/10907 [06:05<4:51:05,  1.63s/it][A
  2%|▏         | 222/10907 [06:05<4:51:18,  1.64s/it][A

  2%|▏         | 222/10907 [06:05<4:52:03,  1.64s/it][A  2%|▏         | 222/10907 [06:05<4:52:01,  1.64s/it][A
  2%|▏         | 222/10907 [06:05<4:52:00,  1.64s/it][A
  2%|▏         | 223/10907 [06:06<4:50:11,  1.63s/it][A
  2%|▏         | 223/10907 [06:06<4:50:13,  1.63s/it][A
  2%|▏         | 223/10907 [06:06<4:50:32,  1.63s/it][A
  2%|▏         | 223/10907 [06:06<4:51:08,  1.64s/it][A
  2%|▏         | 223/10907 [06:06<4:51:21,  1.64s/it][A
  2%|▏         | 223/10907 [06:06<4:50:58,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:01,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:34,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:24,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:30,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:34,  1.63s/it][A
  2%|▏         | 224/10907 [06:08<4:50:35,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:49:53,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:50:08,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:50:17,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:50:10,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:50:16,  1.63s/it][A
  2%|▏         | 225/10907 [06:10<4:50:37,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:49:29,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:49:35,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:50:18,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:50:22,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:50:28,  1.63s/it][A
  2%|▏         | 226/10907 [06:11<4:50:24,  1.63s/it][A
  2%|▏         | 227/10907 [06:13<4:49:08,  1.62s/it][A
  2%|▏         | 227/10907 [06:13<4:49:15,  1.63s/it][A
  2%|▏         | 227/10907 [06:13<4:49:27,  1.63s/it][A
  2%|▏         | 227/10907 [06:13<4:49:22,  1.63s/it][A
  2%|▏         | 227/10907 [06:13<4:49:29,  1.63s/it][A
  2%|▏         | 227/10907 [06:13<4:49:33,  1.63s/it][A

  2%|▏         | 228/10907 [06:15<4:48:58,  1.62s/it][A  2%|▏         | 228/10907 [06:15<4:48:57,  1.62s/it][A
  2%|▏         | 228/10907 [06:15<4:49:01,  1.62s/it][A
  2%|▏         | 228/10907 [06:15<4:48:56,  1.62s/it][A
  2%|▏         | 228/10907 [06:15<4:49:05,  1.62s/it][A
  2%|▏         | 228/10907 [06:14<4:49:05,  1.62s/it][A
  2%|▏         | 229/10907 [06:16<4:48:09,  1.62s/it][A
  2%|▏         | 229/10907 [06:16<4:48:18,  1.62s/it][A
  2%|▏         | 229/10907 [06:16<4:48:22,  1.62s/it][A
  2%|▏         | 229/10907 [06:16<4:48:26,  1.62s/it][A

  2%|▏         | 229/10907 [06:16<4:48:22,  1.62s/it][A  2%|▏         | 229/10907 [06:16<4:48:25,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:20,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:28,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:31,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:27,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:28,  1.62s/it][A
  2%|▏         | 230/10907 [06:18<4:48:35,  1.62s/it][A
  2%|▏         | 231/10907 [06:19<4:47:58,  1.62s/it][A
  2%|▏         | 231/10907 [06:19<4:48:14,  1.62s/it][A
  2%|▏         | 231/10907 [06:19<4:48:13,  1.62s/it][A


  2%|▏         | 231/10907 [06:19<4:48:19,  1.62s/it][A  2%|▏         | 231/10907 [06:19<4:48:16,  1.62s/it][A  2%|▏         | 231/10907 [06:19<4:48:25,  1.62s/it][A
  2%|▏         | 232/10907 [06:21<5:01:44,  1.70s/it][A

  2%|▏         | 232/10907 [06:21<5:01:49,  1.70s/it][A  2%|▏         | 232/10907 [06:21<5:01:52,  1.70s/it][A

  2%|▏         | 232/10907 [06:21<5:01:46,  1.70s/it]
[A  2%|▏         | 232/10907 [06:21<5:01:48,  1.70s/it][A  2%|▏         | 232/10907 [06:21<5:01:50,  1.70s/it][A
  2%|▏         | 233/10907 [06:23<4:57:33,  1.67s/it][A
  2%|▏         | 233/10907 [06:23<4:57:42,  1.67s/it][A

  2%|▏         | 233/10907 [06:23<4:57:44,  1.67s/it][A  2%|▏         | 233/10907 [06:23<4:57:41,  1.67s/it][A
  2%|▏         | 233/10907 [06:23<4:57:45,  1.67s/it][A
  2%|▏         | 233/10907 [06:23<4:58:00,  1.68s/it][A
  2%|▏         | 234/10907 [06:25<4:54:35,  1.66s/it][A
  2%|▏         | 234/10907 [06:25<4:54:59,  1.66s/it][A
  2%|▏         | 234/10907 [06:25<4:55:09,  1.66s/it][A
  2%|▏         | 234/10907 [06:24<4:54:59,  1.66s/it][A

  2%|▏         | 234/10907 [06:25<4:55:06,  1.66s/it][A  2%|▏         | 234/10907 [06:25<4:55:03,  1.66s/it][A
  2%|▏         | 235/10907 [06:26<4:52:29,  1.64s/it][A
  2%|▏         | 235/10907 [06:26<4:52:57,  1.65s/it][A
  2%|▏         | 235/10907 [06:26<4:52:51,  1.65s/it][A
  2%|▏         | 235/10907 [06:26<4:53:06,  1.65s/it][A
  2%|▏         | 235/10907 [06:26<4:53:06,  1.65s/it][A
  2%|▏         | 235/10907 [06:26<4:53:12,  1.65s/it][A



  2%|▏         | 236/10907 [06:28<4:52:14,  1.64s/it][A  2%|▏         | 236/10907 [06:28<4:52:04,  1.64s/it][A  2%|▏         | 236/10907 [06:28<4:51:56,  1.64s/it][A  2%|▏         | 236/10907 [06:28<4:52:17,  1.64s/it][A

  2%|▏         | 236/10907 [06:28<4:51:58,  1.64s/it][A  2%|▏         | 236/10907 [06:28<4:52:06,  1.64s/it][A
  2%|▏         | 237/10907 [06:29<4:50:07,  1.63s/it][A
  2%|▏         | 237/10907 [06:29<4:50:22,  1.63s/it][A
  2%|▏         | 237/10907 [06:29<4:50:09,  1.63s/it][A
  2%|▏         | 237/10907 [06:29<4:50:14,  1.63s/it][A
  2%|▏         | 237/10907 [06:29<4:50:21,  1.63s/it][A
  2%|▏         | 237/10907 [06:29<4:50:24,  1.63s/it][A
  2%|▏         | 238/10907 [06:31<4:49:05,  1.63s/it][A
  2%|▏         | 238/10907 [06:31<4:49:30,  1.63s/it][A
  2%|▏         | 238/10907 [06:31<4:49:27,  1.63s/it][A
  2%|▏         | 238/10907 [06:31<4:49:31,  1.63s/it][A

  2%|▏         | 238/10907 [06:31<4:49:42,  1.63s/it][A  2%|▏         | 238/10907 [06:31<4:49:33,  1.63s/it][A
  2%|▏         | 239/10907 [06:33<4:48:49,  1.62s/it][A
  2%|▏         | 239/10907 [06:33<4:48:57,  1.63s/it][A
  2%|▏         | 239/10907 [06:33<4:49:13,  1.63s/it][A
  2%|▏         | 239/10907 [06:33<4:49:04,  1.63s/it][A

  2%|▏         | 239/10907 [06:33<4:49:00,  1.63s/it][A  2%|▏         | 239/10907 [06:33<4:49:00,  1.63s/it][A

  2%|▏         | 240/10907 [06:34<4:48:16,  1.62s/it][A  2%|▏         | 240/10907 [06:34<4:48:11,  1.62s/it][A

  2%|▏         | 240/10907 [06:34<4:48:48,  1.62s/it]  2%|▏         | 240/10907 [06:34<4:48:44,  1.62s/it][A[A
  2%|▏         | 240/10907 [06:34<4:48:44,  1.62s/it][A
  2%|▏         | 240/10907 [06:34<4:48:45,  1.62s/it][A
  2%|▏         | 241/10907 [06:36<4:54:37,  1.66s/it][A
  2%|▏         | 241/10907 [06:36<4:54:41,  1.66s/it][A
  2%|▏         | 241/10907 [06:36<4:54:50,  1.66s/it][A
  2%|▏         | 241/10907 [06:36<4:55:02,  1.66s/it][A
  2%|▏         | 241/10907 [06:36<4:54:57,  1.66s/it][A
  2%|▏         | 241/10907 [06:36<4:54:55,  1.66s/it][A


  2%|▏         | 242/10907 [06:38<4:52:24,  1.65s/it][A  2%|▏         | 242/10907 [06:38<4:52:20,  1.64s/it][A  2%|▏         | 242/10907 [06:38<4:52:25,  1.65s/it][A
  2%|▏         | 242/10907 [06:38<4:52:22,  1.64s/it][A
  2%|▏         | 242/10907 [06:38<4:52:16,  1.64s/it][A
  2%|▏         | 242/10907 [06:38<4:52:39,  1.65s/it][A
  2%|▏         | 243/10907 [06:39<4:49:26,  1.63s/it][A
  2%|▏         | 243/10907 [06:39<4:49:39,  1.63s/it][A
  2%|▏         | 243/10907 [06:39<4:50:33,  1.63s/it][A
  2%|▏         | 243/10907 [06:39<4:50:56,  1.64s/it][A
  2%|▏         | 243/10907 [06:39<4:51:03,  1.64s/it][A
  2%|▏         | 243/10907 [06:39<4:51:06,  1.64s/it][A
  2%|▏         | 244/10907 [06:41<4:48:37,  1.62s/it][A
  2%|▏         | 244/10907 [06:41<4:48:48,  1.63s/it][A
  2%|▏         | 244/10907 [06:41<4:49:54,  1.63s/it]
[A  2%|▏         | 244/10907 [06:41<4:49:44,  1.63s/it][A
  2%|▏         | 244/10907 [06:41<4:50:13,  1.63s/it][A
  2%|▏         | 244/10907 [06:41<4:50:18,  1.63s/it][A
  2%|▏         | 245/10907 [06:42<4:48:57,  1.63s/it][A

  2%|▏         | 245/10907 [06:42<4:49:02,  1.63s/it][A  2%|▏         | 245/10907 [06:42<4:49:11,  1.63s/it][A
  2%|▏         | 245/10907 [06:42<4:49:10,  1.63s/it][A

  2%|▏         | 245/10907 [06:42<4:49:16,  1.63s/it][A  2%|▏         | 245/10907 [06:42<4:49:00,  1.63s/it][A
  2%|▏         | 246/10907 [06:44<4:48:52,  1.63s/it][A
  2%|▏         | 246/10907 [06:44<4:49:04,  1.63s/it][A

  2%|▏         | 246/10907 [06:44<4:49:03,  1.63s/it][A  2%|▏         | 246/10907 [06:44<4:49:10,  1.63s/it][A
  2%|▏         | 246/10907 [06:44<4:48:57,  1.63s/it][A
  2%|▏         | 246/10907 [06:44<4:49:13,  1.63s/it][A

  2%|▏         | 247/10907 [06:46<4:48:23,  1.62s/it][A  2%|▏         | 247/10907 [06:46<4:48:17,  1.62s/it][A
  2%|▏         | 247/10907 [06:46<4:48:26,  1.62s/it][A

  2%|▏         | 247/10907 [06:46<4:48:33,  1.62s/it][A  2%|▏         | 247/10907 [06:46<4:48:45,  1.63s/it][A
  2%|▏         | 247/10907 [06:46<4:48:45,  1.63s/it][A
  2%|▏         | 248/10907 [06:47<4:48:10,  1.62s/it][A
  2%|▏         | 248/10907 [06:47<4:48:08,  1.62s/it][A
  2%|▏         | 248/10907 [06:47<4:48:24,  1.62s/it][A

  2%|▏         | 248/10907 [06:47<4:48:22,  1.62s/it][A  2%|▏         | 248/10907 [06:47<4:48:19,  1.62s/it][A
  2%|▏         | 248/10907 [06:47<4:48:26,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:24,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:28,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:35,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:33,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:35,  1.62s/it][A
  2%|▏         | 249/10907 [06:49<4:47:32,  1.62s/it][A
  2%|▏         | 250/10907 [06:51<4:46:47,  1.61s/it][A
  2%|▏         | 250/10907 [06:51<4:47:46,  1.62s/it][A
  2%|▏         | 250/10907 [06:51<4:47:44,  1.62s/it][A
  2%|▏         | 250/10907 [06:51<4:47:49,  1.62s/it][A

  2%|▏         | 250/10907 [06:51<4:47:51,  1.62s/it][A  2%|▏         | 250/10907 [06:50<4:47:51,  1.62s/it][A
  2%|▏         | 251/10907 [06:52<4:47:51,  1.62s/it][A
  2%|▏         | 251/10907 [06:52<4:47:45,  1.62s/it][A

  2%|▏         | 251/10907 [06:52<4:47:48,  1.62s/it][A  2%|▏         | 251/10907 [06:52<4:48:10,  1.62s/it][A
  2%|▏         | 251/10907 [06:52<4:47:56,  1.62s/it][A
  2%|▏         | 251/10907 [06:52<4:47:54,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:47:27,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:47:19,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:47:43,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:47:46,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:47:56,  1.62s/it][A
  2%|▏         | 252/10907 [06:54<4:48:01,  1.62s/it][A
  2%|▏         | 253/10907 [06:56<5:00:51,  1.69s/it][A
  2%|▏         | 253/10907 [06:56<5:01:15,  1.70s/it][A
  2%|▏         | 253/10907 [06:56<5:01:33,  1.70s/it][A
  2%|▏         | 253/10907 [06:56<5:01:57,  1.70s/it][A
  2%|▏         | 253/10907 [06:56<5:01:47,  1.70s/it][A
  2%|▏         | 253/10907 [06:56<5:01:55,  1.70s/it][A

  2%|▏         | 254/10907 [06:57<4:57:33,  1.68s/it][A  2%|▏         | 254/10907 [06:57<4:58:00,  1.68s/it][A
  2%|▏         | 254/10907 [06:57<4:57:50,  1.68s/it][A
  2%|▏         | 254/10907 [06:57<4:57:53,  1.68s/it][A
  2%|▏         | 254/10907 [06:57<4:57:35,  1.68s/it][A
  2%|▏         | 254/10907 [06:57<4:57:47,  1.68s/it][A
  2%|▏         | 255/10907 [06:59<4:53:54,  1.66s/it][A
  2%|▏         | 255/10907 [06:59<4:53:59,  1.66s/it][A
  2%|▏         | 255/10907 [06:59<4:54:53,  1.66s/it][A
  2%|▏         | 255/10907 [06:59<4:54:36,  1.66s/it][A

  2%|▏         | 255/10907 [06:59<4:54:49,  1.66s/it][A  2%|▏         | 255/10907 [06:59<4:54:36,  1.66s/it][A
  2%|▏         | 256/10907 [07:01<4:51:55,  1.64s/it][A
  2%|▏         | 256/10907 [07:01<4:52:14,  1.65s/it][A

  2%|▏         | 256/10907 [07:01<4:52:01,  1.65s/it][A  2%|▏         | 256/10907 [07:01<4:52:19,  1.65s/it][A
  2%|▏         | 256/10907 [07:01<4:52:12,  1.65s/it][A
  2%|▏         | 256/10907 [07:00<4:52:31,  1.65s/it][A
  2%|▏         | 257/10907 [07:02<4:50:30,  1.64s/it][A
  2%|▏         | 257/10907 [07:02<4:50:34,  1.64s/it][A
  2%|▏         | 257/10907 [07:02<4:50:24,  1.64s/it][A
  2%|▏         | 257/10907 [07:02<4:50:33,  1.64s/it][A
  2%|▏         | 257/10907 [07:02<4:50:37,  1.64s/it][A
  2%|▏         | 257/10907 [07:02<4:50:54,  1.64s/it][A
  2%|▏         | 258/10907 [07:04<4:49:33,  1.63s/it][A
  2%|▏         | 258/10907 [07:04<4:49:39,  1.63s/it][A
  2%|▏         | 258/10907 [07:04<4:49:47,  1.63s/it][A
  2%|▏         | 258/10907 [07:04<4:50:05,  1.63s/it][A

  2%|▏         | 258/10907 [07:04<4:50:03,  1.63s/it][A  2%|▏         | 258/10907 [07:04<4:50:12,  1.64s/it][A
  2%|▏         | 259/10907 [07:05<4:48:53,  1.63s/it][A
  2%|▏         | 259/10907 [07:05<4:48:54,  1.63s/it][A
  2%|▏         | 259/10907 [07:05<4:49:09,  1.63s/it][A
  2%|▏         | 259/10907 [07:05<4:48:50,  1.63s/it][A
  2%|▏         | 259/10907 [07:05<4:48:58,  1.63s/it][A
  2%|▏         | 259/10907 [07:05<4:48:57,  1.63s/it][A
  2%|▏         | 260/10907 [07:07<4:48:03,  1.62s/it][A
  2%|▏         | 260/10907 [07:07<4:48:17,  1.62s/it][A
  2%|▏         | 260/10907 [07:07<4:48:14,  1.62s/it][A

  2%|▏         | 260/10907 [07:07<4:48:27,  1.63s/it]
[A  2%|▏         | 260/10907 [07:07<4:48:12,  1.62s/it][A  2%|▏         | 260/10907 [07:07<4:48:16,  1.62s/it][A
  2%|▏         | 261/10907 [07:09<4:47:19,  1.62s/it][A
  2%|▏         | 261/10907 [07:09<4:47:44,  1.62s/it][A
  2%|▏         | 261/10907 [07:09<4:47:53,  1.62s/it][A
  2%|▏         | 261/10907 [07:09<4:47:47,  1.62s/it][A

  2%|▏         | 261/10907 [07:09<4:47:51,  1.62s/it][A  2%|▏         | 261/10907 [07:09<4:47:46,  1.62s/it][A
  2%|▏         | 262/10907 [07:10<4:54:16,  1.66s/it][A
  2%|▏         | 262/10907 [07:10<4:54:21,  1.66s/it][A
  2%|▏         | 262/10907 [07:10<4:54:11,  1.66s/it][A
  2%|▏         | 262/10907 [07:10<4:54:14,  1.66s/it][A
  2%|▏         | 262/10907 [07:10<4:54:35,  1.66s/it][A
  2%|▏         | 262/10907 [07:10<4:54:24,  1.66s/it][A
  2%|▏         | 263/10907 [07:12<4:51:46,  1.64s/it][A
  2%|▏         | 263/10907 [07:12<4:51:55,  1.65s/it][A
  2%|▏         | 263/10907 [07:12<4:52:07,  1.65s/it][A
  2%|▏         | 263/10907 [07:12<4:52:21,  1.65s/it][A
  2%|▏         | 263/10907 [07:12<4:52:23,  1.65s/it][A
  2%|▏         | 263/10907 [07:12<4:52:15,  1.65s/it][A
  2%|▏         | 264/10907 [07:14<4:50:51,  1.64s/it][A
  2%|▏         | 264/10907 [07:14<4:50:56,  1.64s/it][A
  2%|▏         | 264/10907 [07:14<4:50:58,  1.64s/it][A
  2%|▏         | 264/10907 [07:14<4:51:03,  1.64s/it][A

  2%|▏         | 264/10907 [07:14<4:51:00,  1.64s/it][A  2%|▏         | 264/10907 [07:14<4:51:11,  1.64s/it][A
  2%|▏         | 265/10907 [07:15<4:49:10,  1.63s/it][A
  2%|▏         | 265/10907 [07:15<4:49:29,  1.63s/it][A


  2%|▏         | 265/10907 [07:15<4:49:31,  1.63s/it][A  2%|▏         | 265/10907 [07:15<4:49:32,  1.63s/it][A  2%|▏         | 265/10907 [07:15<4:49:30,  1.63s/it][A
  2%|▏         | 265/10907 [07:15<4:49:27,  1.63s/it][A
  2%|▏         | 266/10907 [07:17<4:48:14,  1.63s/it][A
  2%|▏         | 266/10907 [07:17<4:48:27,  1.63s/it][A

  2%|▏         | 266/10907 [07:17<4:48:28,  1.63s/it][A  2%|▏         | 266/10907 [07:17<4:48:40,  1.63s/it][A
  2%|▏         | 266/10907 [07:17<4:48:33,  1.63s/it][A
  2%|▏         | 266/10907 [07:17<4:48:32,  1.63s/it][A
  2%|▏         | 267/10907 [07:18<4:47:44,  1.62s/it][A
  2%|▏         | 267/10907 [07:18<4:47:44,  1.62s/it][A
  2%|▏         | 267/10907 [07:18<4:47:59,  1.62s/it][A
  2%|▏         | 267/10907 [07:18<4:48:11,  1.63s/it][A

  2%|▏         | 267/10907 [07:18<4:48:06,  1.62s/it][A  2%|▏         | 267/10907 [07:18<4:47:59,  1.62s/it][A
  2%|▏         | 268/10907 [07:20<4:47:08,  1.62s/it][A
  2%|▏         | 268/10907 [07:20<4:47:29,  1.62s/it][A
  2%|▏         | 268/10907 [07:20<4:48:06,  1.62s/it][A
  2%|▏         | 268/10907 [07:20<4:48:27,  1.63s/it][A
  2%|▏         | 268/10907 [07:20<4:48:36,  1.63s/it][A
  2%|▏         | 268/10907 [07:20<4:48:29,  1.63s/it][A
  2%|▏         | 269/10907 [07:22<4:48:15,  1.63s/it][A
  2%|▏         | 269/10907 [07:22<4:47:55,  1.62s/it][A
  2%|▏         | 269/10907 [07:22<4:48:27,  1.63s/it][A
  2%|▏         | 269/10907 [07:22<4:48:20,  1.63s/it][A
  2%|▏         | 269/10907 [07:22<4:48:12,  1.63s/it][A
  2%|▏         | 269/10907 [07:22<4:48:06,  1.62s/it][A
  2%|▏         | 270/10907 [07:23<4:47:18,  1.62s/it][A
  2%|▏         | 270/10907 [07:23<4:47:26,  1.62s/it][A

  2%|▏         | 270/10907 [07:23<4:47:39,  1.62s/it][A  2%|▏         | 270/10907 [07:23<4:47:50,  1.62s/it][A
  2%|▏         | 270/10907 [07:23<4:48:01,  1.62s/it][A
  2%|▏         | 270/10907 [07:23<4:47:34,  1.62s/it][A

  2%|▏         | 271/10907 [07:25<4:46:54,  1.62s/it][A  2%|▏         | 271/10907 [07:25<4:46:57,  1.62s/it][A
  2%|▏         | 271/10907 [07:25<4:47:15,  1.62s/it][A

  2%|▏         | 271/10907 [07:25<4:46:58,  1.62s/it][A  2%|▏         | 271/10907 [07:25<4:47:11,  1.62s/it][A
  2%|▏         | 271/10907 [07:25<4:47:25,  1.62s/it][A
  2%|▏         | 272/10907 [07:27<4:45:57,  1.61s/it][A
  2%|▏         | 272/10907 [07:27<4:45:50,  1.61s/it][A

  2%|▏         | 272/10907 [07:27<4:46:51,  1.62s/it][A  2%|▏         | 272/10907 [07:27<4:46:54,  1.62s/it][A
  2%|▏         | 272/10907 [07:27<4:46:52,  1.62s/it][A
  2%|▏         | 272/10907 [07:26<4:47:05,  1.62s/it][A
  3%|▎         | 273/10907 [07:28<4:46:37,  1.62s/it][A

  3%|▎         | 273/10907 [07:28<4:46:47,  1.62s/it][A  3%|▎         | 273/10907 [07:28<4:46:36,  1.62s/it][A
  3%|▎         | 273/10907 [07:28<4:46:42,  1.62s/it][A
  3%|▎         | 273/10907 [07:28<4:46:43,  1.62s/it][A
  3%|▎         | 273/10907 [07:28<4:47:14,  1.62s/it][A
  3%|▎         | 274/10907 [07:30<5:00:34,  1.70s/it][A
  3%|▎         | 274/10907 [07:30<5:00:38,  1.70s/it][A
  3%|▎         | 274/10907 [07:30<5:00:37,  1.70s/it][A


  3%|▎         | 274/10907 [07:30<5:00:51,  1.70s/it][A  3%|▎         | 274/10907 [07:30<5:00:39,  1.70s/it][A  3%|▎         | 274/10907 [07:30<5:00:45,  1.70s/it][A
  3%|▎         | 275/10907 [07:32<4:58:04,  1.68s/it][A
  3%|▎         | 275/10907 [07:32<4:58:15,  1.68s/it][A
  3%|▎         | 275/10907 [07:32<4:58:20,  1.68s/it][A
  3%|▎         | 275/10907 [07:32<4:58:43,  1.69s/it][A
  3%|▎         | 275/10907 [07:32<4:58:38,  1.69s/it][A
  3%|▎         | 275/10907 [07:32<4:58:45,  1.69s/it][A

  3%|▎         | 276/10907 [07:33<4:54:57,  1.66s/it][A  3%|▎         | 276/10907 [07:33<4:54:58,  1.66s/it][A
  3%|▎         | 276/10907 [07:33<4:55:06,  1.67s/it][A

  3%|▎         | 276/10907 [07:33<4:54:56,  1.66s/it][A  3%|▎         | 276/10907 [07:33<4:54:54,  1.66s/it][A
  3%|▎         | 276/10907 [07:33<4:55:06,  1.67s/it][A
  3%|▎         | 277/10907 [07:35<4:50:59,  1.64s/it][A
  3%|▎         | 277/10907 [07:35<4:50:57,  1.64s/it][A

  3%|▎         | 277/10907 [07:35<4:52:03,  1.65s/it][A  3%|▎         | 277/10907 [07:35<4:52:06,  1.65s/it][A

  3%|▎         | 277/10907 [07:35<4:52:05,  1.65s/it][A  3%|▎         | 277/10907 [07:35<4:52:08,  1.65s/it][A
  3%|▎         | 278/10907 [07:36<4:49:40,  1.64s/it][A
  3%|▎         | 278/10907 [07:37<4:49:58,  1.64s/it][A
  3%|▎         | 278/10907 [07:37<4:50:20,  1.64s/it][A

  3%|▎         | 278/10907 [07:37<4:49:58,  1.64s/it][A  3%|▎         | 278/10907 [07:37<4:50:16,  1.64s/it][A
  3%|▎         | 278/10907 [07:37<4:49:58,  1.64s/it][A
  3%|▎         | 279/10907 [07:38<4:49:10,  1.63s/it][A
  3%|▎         | 279/10907 [07:38<4:49:11,  1.63s/it][A
  3%|▎         | 279/10907 [07:38<4:49:09,  1.63s/it][A
  3%|▎         | 279/10907 [07:38<4:49:11,  1.63s/it][A
  3%|▎         | 279/10907 [07:38<4:49:26,  1.63s/it][A
  3%|▎         | 279/10907 [07:38<4:49:14,  1.63s/it][A
  3%|▎         | 280/10907 [07:40<4:47:38,  1.62s/it][A
  3%|▎         | 280/10907 [07:40<4:48:25,  1.63s/it][A
  3%|▎         | 280/10907 [07:40<4:48:46,  1.63s/it][A
  3%|▎         | 280/10907 [07:40<4:48:42,  1.63s/it][A
  3%|▎         | 280/10907 [07:40<4:48:59,  1.63s/it][A
  3%|▎         | 280/10907 [07:40<4:48:48,  1.63s/it][A
  3%|▎         | 281/10907 [07:41<4:47:40,  1.62s/it][A
  3%|▎         | 281/10907 [07:41<4:47:48,  1.63s/it][A
  3%|▎         | 281/10907 [07:41<4:47:43,  1.62s/it][A

  3%|▎         | 281/10907 [07:41<4:48:18,  1.63s/it][A  3%|▎         | 281/10907 [07:41<4:48:13,  1.63s/it][A
  3%|▎         | 281/10907 [07:41<4:48:05,  1.63s/it][A
  3%|▎         | 282/10907 [07:43<4:46:10,  1.62s/it][A
  3%|▎         | 282/10907 [07:43<4:46:24,  1.62s/it][A
  3%|▎         | 282/10907 [07:43<4:47:23,  1.62s/it][A
  3%|▎         | 282/10907 [07:43<4:47:47,  1.63s/it][A
  3%|▎         | 282/10907 [07:43<4:47:52,  1.63s/it][A
  3%|▎         | 282/10907 [07:43<4:47:43,  1.62s/it][A
  3%|▎         | 283/10907 [07:45<4:53:49,  1.66s/it][A
  3%|▎         | 283/10907 [07:45<4:53:52,  1.66s/it][A
  3%|▎         | 283/10907 [07:45<4:53:41,  1.66s/it][A
  3%|▎         | 283/10907 [07:45<4:53:45,  1.66s/it][A
  3%|▎         | 283/10907 [07:45<4:53:56,  1.66s/it][A
  3%|▎         | 283/10907 [07:45<4:53:57,  1.66s/it][A
  3%|▎         | 284/10907 [07:46<4:51:30,  1.65s/it][A
  3%|▎         | 284/10907 [07:46<4:51:40,  1.65s/it][A

  3%|▎         | 284/10907 [07:46<4:52:01,  1.65s/it]
[A
  3%|▎         | 284/10907 [07:46<4:51:44,  1.65s/it][A  3%|▎         | 284/10907 [07:46<4:51:54,  1.65s/it][A  3%|▎         | 284/10907 [07:46<4:51:47,  1.65s/it][A
  3%|▎         | 285/10907 [07:48<4:49:35,  1.64s/it][A
  3%|▎         | 285/10907 [07:48<4:49:43,  1.64s/it][A
  3%|▎         | 285/10907 [07:48<4:49:54,  1.64s/it][A
  3%|▎         | 285/10907 [07:48<4:49:58,  1.64s/it][A
  3%|▎         | 285/10907 [07:48<4:50:09,  1.64s/it][A
  3%|▎         | 285/10907 [07:48<4:50:04,  1.64s/it][A
  3%|▎         | 286/10907 [07:50<4:48:39,  1.63s/it][A

  3%|▎         | 286/10907 [07:50<4:48:39,  1.63s/it][A  3%|▎         | 286/10907 [07:50<4:48:33,  1.63s/it][A
  3%|▎         | 286/10907 [07:50<4:48:34,  1.63s/it][A
  3%|▎         | 286/10907 [07:50<4:48:44,  1.63s/it][A
  3%|▎         | 286/10907 [07:50<4:48:53,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:14,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:11,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:11,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:13,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:19,  1.63s/it][A
  3%|▎         | 287/10907 [07:51<4:48:13,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:47:41,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:47:43,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:47:53,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:48:02,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:48:09,  1.63s/it][A
  3%|▎         | 288/10907 [07:53<4:48:03,  1.63s/it][A
  3%|▎         | 289/10907 [07:55<4:47:20,  1.62s/it][A
  3%|▎         | 289/10907 [07:55<4:47:23,  1.62s/it][A
  3%|▎         | 289/10907 [07:54<4:47:25,  1.62s/it][A
  3%|▎         | 289/10907 [07:55<4:47:25,  1.62s/it][A
  3%|▎         | 289/10907 [07:55<4:47:30,  1.62s/it][A
  3%|▎         | 289/10907 [07:55<4:47:25,  1.62s/it][A
  3%|▎         | 290/10907 [07:56<4:46:33,  1.62s/it][A
  3%|▎         | 290/10907 [07:56<4:47:00,  1.62s/it][A
  3%|▎         | 290/10907 [07:56<4:47:22,  1.62s/it][A

  3%|▎         | 290/10907 [07:56<4:47:20,  1.62s/it][A  3%|▎         | 290/10907 [07:56<4:47:24,  1.62s/it][A
  3%|▎         | 290/10907 [07:56<4:47:33,  1.63s/it][A

  3%|▎         | 291/10907 [07:58<4:47:03,  1.62s/it][A  3%|▎         | 291/10907 [07:58<4:47:02,  1.62s/it][A
  3%|▎         | 291/10907 [07:58<4:47:14,  1.62s/it][A

  3%|▎         | 291/10907 [07:58<4:47:06,  1.62s/it][A  3%|▎         | 291/10907 [07:58<4:47:08,  1.62s/it][A
  3%|▎         | 291/10907 [07:58<4:47:09,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:46:34,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:46:45,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:46:57,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:46:55,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:47:02,  1.62s/it][A
  3%|▎         | 292/10907 [07:59<4:47:00,  1.62s/it][A
  3%|▎         | 293/10907 [08:01<4:46:49,  1.62s/it][A


  3%|▎         | 293/10907 [08:01<4:46:56,  1.62s/it][A
  3%|▎         | 293/10907 [08:01<4:46:51,  1.62s/it][A  3%|▎         | 293/10907 [08:01<4:46:55,  1.62s/it][A  3%|▎         | 293/10907 [08:01<4:46:46,  1.62s/it][A
  3%|▎         | 293/10907 [08:01<4:46:52,  1.62s/it][A
  3%|▎         | 294/10907 [08:03<4:46:59,  1.62s/it][A
  3%|▎         | 294/10907 [08:02<4:46:58,  1.62s/it][A
  3%|▎         | 294/10907 [08:03<4:46:58,  1.62s/it][A
  3%|▎         | 294/10907 [08:03<4:47:01,  1.62s/it][A
  3%|▎         | 294/10907 [08:03<4:46:59,  1.62s/it][A
  3%|▎         | 294/10907 [08:03<4:47:15,  1.62s/it][A
  3%|▎         | 295/10907 [08:04<4:59:55,  1.70s/it][A
  3%|▎         | 295/10907 [08:04<4:59:57,  1.70s/it][A
  3%|▎         | 295/10907 [08:04<5:00:03,  1.70s/it][A
  3%|▎         | 295/10907 [08:04<4:59:57,  1.70s/it][A
  3%|▎         | 295/10907 [08:04<5:00:02,  1.70s/it][A
  3%|▎         | 295/10907 [08:04<5:00:03,  1.70s/it][A
  3%|▎         | 296/10907 [08:06<4:55:58,  1.67s/it][A
  3%|▎         | 296/10907 [08:06<4:55:59,  1.67s/it][A
  3%|▎         | 296/10907 [08:06<4:56:03,  1.67s/it][A

  3%|▎         | 296/10907 [08:06<4:56:01,  1.67s/it]
[A  3%|▎         | 296/10907 [08:06<4:55:59,  1.67s/it][A  3%|▎         | 296/10907 [08:06<4:55:59,  1.67s/it][A
  3%|▎         | 297/10907 [08:08<4:52:51,  1.66s/it][A
  3%|▎         | 297/10907 [08:08<4:53:04,  1.66s/it][A

  3%|▎         | 297/10907 [08:08<4:53:08,  1.66s/it][A  3%|▎         | 297/10907 [08:08<4:53:10,  1.66s/it][A
  3%|▎         | 297/10907 [08:08<4:53:16,  1.66s/it][A
  3%|▎         | 297/10907 [08:08<4:53:15,  1.66s/it][A
  3%|▎         | 298/10907 [08:09<4:50:50,  1.64s/it][A
  3%|▎         | 298/10907 [08:09<4:50:44,  1.64s/it][A
  3%|▎         | 298/10907 [08:09<4:50:56,  1.65s/it][A

  3%|▎         | 298/10907 [08:09<4:51:00,  1.65s/it][A  3%|▎         | 298/10907 [08:09<4:50:58,  1.65s/it][A
  3%|▎         | 298/10907 [08:09<4:51:06,  1.65s/it][A
  3%|▎         | 299/10907 [08:11<4:49:57,  1.64s/it][A
  3%|▎         | 299/10907 [08:11<4:50:01,  1.64s/it][A
  3%|▎         | 299/10907 [08:11<4:50:03,  1.64s/it][A

  3%|▎         | 299/10907 [08:11<4:50:02,  1.64s/it][A  3%|▎         | 299/10907 [08:11<4:50:04,  1.64s/it][A
  3%|▎         | 299/10907 [08:11<4:50:11,  1.64s/it][A
  3%|▎         | 300/10907 [08:13<4:47:52,  1.63s/it][A
  3%|▎         | 300/10907 [08:13<4:47:54,  1.63s/it][A
  3%|▎         | 300/10907 [08:13<4:48:23,  1.63s/it][A
  3%|▎         | 300/10907 [08:13<4:48:58,  1.63s/it][A
  3%|▎         | 300/10907 [08:12<4:49:03,  1.64s/it][A
  3%|▎         | 300/10907 [08:13<4:49:05,  1.64s/it][A
  3%|▎         | 301/10907 [08:14<4:48:07,  1.63s/it][A
  3%|▎         | 301/10907 [08:14<4:47:47,  1.63s/it][A
  3%|▎         | 301/10907 [08:14<4:47:49,  1.63s/it][A

  3%|▎         | 301/10907 [08:14<4:48:12,  1.63s/it][A  3%|▎         | 301/10907 [08:14<4:48:10,  1.63s/it][A
  3%|▎         | 301/10907 [08:14<4:47:50,  1.63s/it][A
  3%|▎         | 302/10907 [08:16<4:47:23,  1.63s/it][A

  3%|▎         | 302/10907 [08:16<4:47:42,  1.63s/it][A  3%|▎         | 302/10907 [08:16<4:47:40,  1.63s/it][A
  3%|▎         | 302/10907 [08:16<4:47:30,  1.63s/it][A
  3%|▎         | 302/10907 [08:16<4:47:38,  1.63s/it][A
  3%|▎         | 302/10907 [08:16<4:47:42,  1.63s/it][A
  3%|▎         | 303/10907 [08:17<4:46:21,  1.62s/it][A
  3%|▎         | 303/10907 [08:17<4:46:50,  1.62s/it][A
  3%|▎         | 303/10907 [08:17<4:47:16,  1.63s/it][A
  3%|▎         | 303/10907 [08:17<4:47:24,  1.63s/it][A
  3%|▎         | 303/10907 [08:17<4:47:09,  1.62s/it][A
  3%|▎         | 303/10907 [08:17<4:47:17,  1.63s/it][A
  3%|▎         | 304/10907 [08:19<4:53:13,  1.66s/it][A

  3%|▎         | 304/10907 [08:19<4:53:18,  1.66s/it][A  3%|▎         | 304/10907 [08:19<4:53:27,  1.66s/it][A
  3%|▎         | 304/10907 [08:19<4:53:06,  1.66s/it][A
  3%|▎         | 304/10907 [08:19<4:53:16,  1.66s/it][A
  3%|▎         | 304/10907 [08:19<4:53:06,  1.66s/it][A

  3%|▎         | 305/10907 [08:21<4:50:34,  1.64s/it][A  3%|▎         | 305/10907 [08:21<4:50:39,  1.64s/it][A
  3%|▎         | 305/10907 [08:21<4:50:54,  1.65s/it][A
  3%|▎         | 305/10907 [08:21<4:51:19,  1.65s/it]
[A  3%|▎         | 305/10907 [08:21<4:51:13,  1.65s/it][A
  3%|▎         | 305/10907 [08:21<4:51:13,  1.65s/it][A
  3%|▎         | 306/10907 [08:22<4:49:40,  1.64s/it][A

  3%|▎         | 306/10907 [08:22<4:49:47,  1.64s/it][A  3%|▎         | 306/10907 [08:22<4:49:45,  1.64s/it][A
  3%|▎         | 306/10907 [08:22<4:49:41,  1.64s/it][A
  3%|▎         | 306/10907 [08:22<4:49:39,  1.64s/it][A
  3%|▎         | 306/10907 [08:22<4:49:46,  1.64s/it][A
  3%|▎         | 307/10907 [08:24<4:47:35,  1.63s/it][A
  3%|▎         | 307/10907 [08:24<4:48:15,  1.63s/it][A
  3%|▎         | 307/10907 [08:24<4:48:41,  1.63s/it][A
  3%|▎         | 307/10907 [08:24<4:48:46,  1.63s/it][A
  3%|▎         | 307/10907 [08:24<4:48:49,  1.63s/it][A
  3%|▎         | 307/10907 [08:24<4:48:59,  1.64s/it][A
  3%|▎         | 308/10907 [08:26<4:47:47,  1.63s/it][A
  3%|▎         | 308/10907 [08:26<4:47:56,  1.63s/it][A
  3%|▎         | 308/10907 [08:26<4:48:12,  1.63s/it][A
  3%|▎         | 308/10907 [08:26<4:48:09,  1.63s/it][A
  3%|▎         | 308/10907 [08:26<4:48:22,  1.63s/it][A
  3%|▎         | 308/10907 [08:26<4:48:22,  1.63s/it][A
  3%|▎         | 309/10907 [08:27<4:47:10,  1.63s/it][A
  3%|▎         | 309/10907 [08:27<4:47:25,  1.63s/it][A
  3%|▎         | 309/10907 [08:27<4:47:29,  1.63s/it][A
  3%|▎         | 309/10907 [08:27<4:47:38,  1.63s/it][A

  3%|▎         | 309/10907 [08:27<4:47:18,  1.63s/it][A  3%|▎         | 309/10907 [08:27<4:47:23,  1.63s/it][A
  3%|▎         | 310/10907 [08:29<4:46:59,  1.62s/it][A
  3%|▎         | 310/10907 [08:29<4:47:05,  1.63s/it][A
  3%|▎         | 310/10907 [08:29<4:47:01,  1.63s/it][A
  3%|▎         | 310/10907 [08:29<4:47:12,  1.63s/it][A

  3%|▎         | 310/10907 [08:29<4:47:10,  1.63s/it][A  3%|▎         | 310/10907 [08:29<4:47:22,  1.63s/it][A
  3%|▎         | 311/10907 [08:31<4:47:05,  1.63s/it][A


  3%|▎         | 311/10907 [08:31<4:47:08,  1.63s/it][A  3%|▎         | 311/10907 [08:31<4:47:00,  1.63s/it][A  3%|▎         | 311/10907 [08:31<4:47:07,  1.63s/it][A
  3%|▎         | 311/10907 [08:30<4:47:01,  1.63s/it][A
  3%|▎         | 311/10907 [08:31<4:47:08,  1.63s/it][A
  3%|▎         | 312/10907 [08:32<4:45:54,  1.62s/it][A
  3%|▎         | 312/10907 [08:32<4:45:59,  1.62s/it][A
  3%|▎         | 312/10907 [08:32<4:47:03,  1.63s/it][A
  3%|▎         | 312/10907 [08:32<4:47:05,  1.63s/it][A
  3%|▎         | 312/10907 [08:32<4:47:11,  1.63s/it][A
  3%|▎         | 312/10907 [08:32<4:47:14,  1.63s/it][A
  3%|▎         | 313/10907 [08:34<4:46:22,  1.62s/it][A

  3%|▎         | 313/10907 [08:34<4:46:34,  1.62s/it][A  3%|▎         | 313/10907 [08:34<4:46:37,  1.62s/it][A
  3%|▎         | 313/10907 [08:34<4:47:04,  1.63s/it][A
  3%|▎         | 313/10907 [08:34<4:46:55,  1.63s/it][A
  3%|▎         | 313/10907 [08:34<4:47:17,  1.63s/it][A
  3%|▎         | 314/10907 [08:35<4:46:23,  1.62s/it][A
  3%|▎         | 314/10907 [08:35<4:46:40,  1.62s/it][A
  3%|▎         | 314/10907 [08:35<4:46:25,  1.62s/it][A
  3%|▎         | 314/10907 [08:35<4:46:38,  1.62s/it][A
  3%|▎         | 314/10907 [08:35<4:46:34,  1.62s/it][A
  3%|▎         | 314/10907 [08:35<4:46:28,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:16,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:24,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:31,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:42,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:40,  1.62s/it][A
  3%|▎         | 315/10907 [08:37<4:46:38,  1.62s/it][A
  3%|▎         | 316/10907 [08:39<4:58:18,  1.69s/it][A
  3%|▎         | 316/10907 [08:39<4:58:26,  1.69s/it][A
  3%|▎         | 316/10907 [08:39<4:58:34,  1.69s/it][A
  3%|▎         | 316/10907 [08:39<4:58:34,  1.69s/it][A
  3%|▎         | 316/10907 [08:39<4:58:36,  1.69s/it][A
  3%|▎         | 316/10907 [08:39<4:58:42,  1.69s/it][A
  3%|▎         | 317/10907 [08:40<4:54:40,  1.67s/it][A

  3%|▎         | 317/10907 [08:40<4:54:43,  1.67s/it][A  3%|▎         | 317/10907 [08:40<4:54:40,  1.67s/it][A
  3%|▎         | 317/10907 [08:40<4:54:47,  1.67s/it][A
  3%|▎         | 317/10907 [08:40<4:54:40,  1.67s/it][A
  3%|▎         | 317/10907 [08:40<4:54:55,  1.67s/it][A
  3%|▎         | 318/10907 [08:42<4:51:28,  1.65s/it][A
  3%|▎         | 318/10907 [08:42<4:51:44,  1.65s/it][A
  3%|▎         | 318/10907 [08:42<4:52:26,  1.66s/it][A
  3%|▎         | 318/10907 [08:42<4:52:31,  1.66s/it][A

  3%|▎         | 318/10907 [08:42<4:52:32,  1.66s/it][A  3%|▎         | 318/10907 [08:42<4:52:27,  1.66s/it][A

  3%|▎         | 319/10907 [08:44<4:49:37,  1.64s/it][A  3%|▎         | 319/10907 [08:44<4:49:16,  1.64s/it][A
  3%|▎         | 319/10907 [08:44<4:50:15,  1.64s/it][A
  3%|▎         | 319/10907 [08:44<4:50:27,  1.65s/it][A
  3%|▎         | 319/10907 [08:44<4:50:28,  1.65s/it][A
  3%|▎         | 319/10907 [08:44<4:50:51,  1.65s/it][A
  3%|▎         | 320/10907 [08:45<4:48:00,  1.63s/it][A
  3%|▎         | 320/10907 [08:45<4:48:14,  1.63s/it][A
  3%|▎         | 320/10907 [08:45<4:48:49,  1.64s/it][A
  3%|▎         | 320/10907 [08:45<4:49:10,  1.64s/it][A
  3%|▎         | 320/10907 [08:45<4:49:15,  1.64s/it][A
  3%|▎         | 320/10907 [08:45<4:49:34,  1.64s/it][A
  3%|▎         | 321/10907 [08:47<4:47:44,  1.63s/it][A
  3%|▎         | 321/10907 [08:47<4:47:54,  1.63s/it][A
  3%|▎         | 321/10907 [08:47<4:48:05,  1.63s/it][A
  3%|▎         | 321/10907 [08:47<4:48:07,  1.63s/it][A
  3%|▎         | 321/10907 [08:47<4:48:18,  1.63s/it][A
  3%|▎         | 321/10907 [08:47<4:48:14,  1.63s/it][A
  3%|▎         | 322/10907 [08:49<4:47:20,  1.63s/it][A
  3%|▎         | 322/10907 [08:49<4:47:17,  1.63s/it][A
  3%|▎         | 322/10907 [08:49<4:47:28,  1.63s/it][A
  3%|▎         | 322/10907 [08:49<4:47:27,  1.63s/it][A
  3%|▎         | 322/10907 [08:49<4:47:29,  1.63s/it][A
  3%|▎         | 322/10907 [08:48<4:47:38,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:46:40,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:46:45,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:46:48,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:46:44,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:46:52,  1.63s/it][A
  3%|▎         | 323/10907 [08:50<4:47:05,  1.63s/it][A
  3%|▎         | 324/10907 [08:52<4:46:09,  1.62s/it][A
  3%|▎         | 324/10907 [08:52<4:46:10,  1.62s/it][A
  3%|▎         | 324/10907 [08:52<4:46:24,  1.62s/it][A
  3%|▎         | 324/10907 [08:52<4:46:29,  1.62s/it][A
  3%|▎         | 324/10907 [08:52<4:46:41,  1.63s/it][A
  3%|▎         | 324/10907 [08:52<4:46:38,  1.63s/it][A
  3%|▎         | 325/10907 [08:54<4:52:05,  1.66s/it][A
  3%|▎         | 325/10907 [08:54<4:53:01,  1.66s/it][A
  3%|▎         | 325/10907 [08:53<4:52:49,  1.66s/it][A
  3%|▎         | 325/10907 [08:54<4:53:49,  1.67s/it][A
  3%|▎         | 325/10907 [08:54<4:54:00,  1.67s/it][A
  3%|▎         | 325/10907 [08:54<4:53:49,  1.67s/it][A
  3%|▎         | 326/10907 [08:55<4:51:29,  1.65s/it][A
  3%|▎         | 326/10907 [08:55<4:51:22,  1.65s/it][A
  3%|▎         | 326/10907 [08:55<4:51:14,  1.65s/it][A
  3%|▎         | 326/10907 [08:55<4:51:22,  1.65s/it][A

  3%|▎         | 326/10907 [08:55<4:51:46,  1.65s/it][A  3%|▎         | 326/10907 [08:55<4:51:12,  1.65s/it][A
  3%|▎         | 327/10907 [08:57<4:48:47,  1.64s/it][A
  3%|▎         | 327/10907 [08:57<4:49:09,  1.64s/it][A
  3%|▎         | 327/10907 [08:57<4:48:55,  1.64s/it][A
  3%|▎         | 327/10907 [08:57<4:49:35,  1.64s/it][A
  3%|▎         | 327/10907 [08:57<4:49:51,  1.64s/it][A
  3%|▎         | 327/10907 [08:57<4:49:45,  1.64s/it][A
  3%|▎         | 328/10907 [08:58<4:47:51,  1.63s/it][A
  3%|▎         | 328/10907 [08:58<4:47:48,  1.63s/it][A
  3%|▎         | 328/10907 [08:58<4:48:41,  1.64s/it][A
  3%|▎         | 328/10907 [08:58<4:48:46,  1.64s/it][A

  3%|▎         | 328/10907 [08:58<4:48:38,  1.64s/it][A  3%|▎         | 328/10907 [08:58<4:48:37,  1.64s/it][A
  3%|▎         | 329/10907 [09:00<4:47:44,  1.63s/it][A

  3%|▎         | 329/10907 [09:00<4:47:40,  1.63s/it][A  3%|▎         | 329/10907 [09:00<4:47:39,  1.63s/it][A
  3%|▎         | 329/10907 [09:00<4:48:08,  1.63s/it][A

  3%|▎         | 329/10907 [09:00<4:47:37,  1.63s/it][A  3%|▎         | 329/10907 [09:00<4:47:36,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:46:50,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:46:47,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:46:59,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:47:08,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:47:20,  1.63s/it][A
  3%|▎         | 330/10907 [09:02<4:47:21,  1.63s/it][A
  3%|▎         | 331/10907 [09:03<4:46:14,  1.62s/it][A

  3%|▎         | 331/10907 [09:03<4:46:10,  1.62s/it][A  3%|▎         | 331/10907 [09:03<4:46:39,  1.63s/it][A
  3%|▎         | 331/10907 [09:03<4:46:12,  1.62s/it][A
  3%|▎         | 331/10907 [09:03<4:46:25,  1.62s/it][A
  3%|▎         | 331/10907 [09:03<4:46:35,  1.63s/it][A
  3%|▎         | 332/10907 [09:05<4:45:51,  1.62s/it][A

  3%|▎         | 332/10907 [09:05<4:45:50,  1.62s/it][A  3%|▎         | 332/10907 [09:05<4:45:49,  1.62s/it][A
  3%|▎         | 332/10907 [09:05<4:46:00,  1.62s/it][A
  3%|▎         | 332/10907 [09:05<4:45:57,  1.62s/it][A
  3%|▎         | 332/10907 [09:05<4:46:03,  1.62s/it][A
  3%|▎         | 333/10907 [09:06<4:45:33,  1.62s/it][A

  3%|▎         | 333/10907 [09:07<4:45:50,  1.62s/it][A  3%|▎         | 333/10907 [09:07<4:46:13,  1.62s/it][A
  3%|▎         | 333/10907 [09:07<4:45:52,  1.62s/it][A
  3%|▎         | 333/10907 [09:07<4:45:56,  1.62s/it][A
  3%|▎         | 333/10907 [09:07<4:45:57,  1.62s/it][A
  3%|▎         | 334/10907 [09:08<4:46:08,  1.62s/it][A
  3%|▎         | 334/10907 [09:08<4:46:25,  1.63s/it][A
  3%|▎         | 334/10907 [09:08<4:46:13,  1.62s/it][A
  3%|▎         | 334/10907 [09:08<4:46:13,  1.62s/it][A
  3%|▎         | 334/10907 [09:08<4:46:19,  1.62s/it][A
  3%|▎         | 334/10907 [09:08<4:46:21,  1.63s/it][A
  3%|▎         | 335/10907 [09:10<4:45:55,  1.62s/it][A
  3%|▎         | 335/10907 [09:10<4:45:51,  1.62s/it][A

  3%|▎         | 335/10907 [09:10<4:46:03,  1.62s/it][A  3%|▎         | 335/10907 [09:10<4:45:52,  1.62s/it][A

  3%|▎         | 335/10907 [09:10<4:45:59,  1.62s/it][A  3%|▎         | 335/10907 [09:10<4:45:57,  1.62s/it][A
  3%|▎         | 336/10907 [09:11<4:44:53,  1.62s/it][A
  3%|▎         | 336/10907 [09:11<4:45:05,  1.62s/it][A
  3%|▎         | 336/10907 [09:11<4:45:08,  1.62s/it][A
  3%|▎         | 336/10907 [09:11<4:45:05,  1.62s/it][A

  3%|▎         | 336/10907 [09:11<4:45:27,  1.62s/it][A  3%|▎         | 336/10907 [09:11<4:45:26,  1.62s/it][A
  3%|▎         | 337/10907 [09:13<4:59:45,  1.70s/it][A
  3%|▎         | 337/10907 [09:13<4:59:50,  1.70s/it][A

  3%|▎         | 337/10907 [09:13<4:59:58,  1.70s/it][A  3%|▎         | 337/10907 [09:13<5:00:05,  1.70s/it][A
  3%|▎         | 337/10907 [09:13<5:00:01,  1.70s/it][A
  3%|▎         | 337/10907 [09:13<4:59:54,  1.70s/it][A
  3%|▎         | 338/10907 [09:15<4:55:13,  1.68s/it][A

  3%|▎         | 338/10907 [09:15<4:55:21,  1.68s/it][A  3%|▎         | 338/10907 [09:15<4:55:17,  1.68s/it][A
  3%|▎         | 338/10907 [09:15<4:55:23,  1.68s/it][A
  3%|▎         | 338/10907 [09:15<4:55:25,  1.68s/it][A
  3%|▎         | 338/10907 [09:15<4:55:24,  1.68s/it][A
  3%|▎         | 339/10907 [09:17<4:52:48,  1.66s/it][A

  3%|▎         | 339/10907 [09:17<4:52:39,  1.66s/it][A  3%|▎         | 339/10907 [09:16<4:52:42,  1.66s/it][A

  3%|▎         | 339/10907 [09:17<4:52:36,  1.66s/it][A  3%|▎         | 339/10907 [09:17<4:52:41,  1.66s/it][A
  3%|▎         | 339/10907 [09:17<4:52:34,  1.66s/it][A
  3%|▎         | 340/10907 [09:18<4:50:06,  1.65s/it][A
  3%|▎         | 340/10907 [09:18<4:49:56,  1.65s/it][A
  3%|▎         | 340/10907 [09:18<4:50:27,  1.65s/it][A
  3%|▎         | 340/10907 [09:18<4:50:43,  1.65s/it][A
  3%|▎         | 340/10907 [09:18<4:50:37,  1.65s/it][A
  3%|▎         | 340/10907 [09:18<4:50:48,  1.65s/it][A
  3%|▎         | 341/10907 [09:20<4:49:16,  1.64s/it][A
  3%|▎         | 341/10907 [09:20<4:49:13,  1.64s/it][A

  3%|▎         | 341/10907 [09:20<4:49:28,  1.64s/it][A  3%|▎         | 341/10907 [09:20<4:49:19,  1.64s/it][A

  3%|▎         | 341/10907 [09:20<4:49:24,  1.64s/it][A  3%|▎         | 341/10907 [09:20<4:49:41,  1.65s/it][A
  3%|▎         | 342/10907 [09:21<4:47:55,  1.64s/it][A
  3%|▎         | 342/10907 [09:21<4:48:06,  1.64s/it][A
  3%|▎         | 342/10907 [09:21<4:48:01,  1.64s/it][A
  3%|▎         | 342/10907 [09:21<4:48:07,  1.64s/it][A
  3%|▎         | 342/10907 [09:21<4:48:19,  1.64s/it][A
  3%|▎         | 342/10907 [09:21<4:48:07,  1.64s/it][A
  3%|▎         | 343/10907 [09:23<4:46:25,  1.63s/it][A
  3%|▎         | 343/10907 [09:23<4:46:28,  1.63s/it][A
  3%|▎         | 343/10907 [09:23<4:46:37,  1.63s/it][A
  3%|▎         | 343/10907 [09:23<4:47:04,  1.63s/it][A
  3%|▎         | 343/10907 [09:23<4:47:04,  1.63s/it][A
  3%|▎         | 343/10907 [09:23<4:46:58,  1.63s/it][A
  3%|▎         | 344/10907 [09:25<4:45:54,  1.62s/it][A
  3%|▎         | 344/10907 [09:25<4:46:14,  1.63s/it][A
  3%|▎         | 344/10907 [09:25<4:46:16,  1.63s/it][A
  3%|▎         | 344/10907 [09:25<4:46:30,  1.63s/it][A
  3%|▎         | 344/10907 [09:25<4:46:19,  1.63s/it][A
  3%|▎         | 344/10907 [09:25<4:46:24,  1.63s/it][A
  3%|▎         | 345/10907 [09:26<4:45:47,  1.62s/it][A
  3%|▎         | 345/10907 [09:26<4:45:35,  1.62s/it][A
  3%|▎         | 345/10907 [09:26<4:45:51,  1.62s/it][A
  3%|▎         | 345/10907 [09:26<4:46:27,  1.63s/it][A
  3%|▎         | 345/10907 [09:26<4:46:27,  1.63s/it][A
  3%|▎         | 345/10907 [09:26<4:46:28,  1.63s/it][A
  3%|▎         | 346/10907 [09:28<4:53:17,  1.67s/it][A

  3%|▎         | 346/10907 [09:28<4:53:14,  1.67s/it][A  3%|▎         | 346/10907 [09:28<4:53:18,  1.67s/it][A
  3%|▎         | 346/10907 [09:28<4:53:24,  1.67s/it][A

  3%|▎         | 346/10907 [09:28<4:53:28,  1.67s/it][A  3%|▎         | 346/10907 [09:28<4:53:41,  1.67s/it][A
  3%|▎         | 347/10907 [09:30<4:51:19,  1.66s/it][A
  3%|▎         | 347/10907 [09:30<4:51:36,  1.66s/it][A
  3%|▎         | 347/10907 [09:30<4:51:50,  1.66s/it][A
  3%|▎         | 347/10907 [09:30<4:51:46,  1.66s/it][A

  3%|▎         | 347/10907 [09:30<4:51:53,  1.66s/it][A  3%|▎         | 347/10907 [09:30<4:51:48,  1.66s/it][A
  3%|▎         | 348/10907 [09:31<4:49:03,  1.64s/it][A
  3%|▎         | 348/10907 [09:31<4:49:20,  1.64s/it][A
  3%|▎         | 348/10907 [09:31<4:49:32,  1.65s/it][A
  3%|▎         | 348/10907 [09:31<4:49:47,  1.65s/it][A

  3%|▎         | 348/10907 [09:31<4:49:43,  1.65s/it][A  3%|▎         | 348/10907 [09:31<4:49:39,  1.65s/it][A
  3%|▎         | 349/10907 [09:33<4:49:02,  1.64s/it][A

  3%|▎         | 349/10907 [09:33<4:48:57,  1.64s/it][A  3%|▎         | 349/10907 [09:33<4:49:03,  1.64s/it][A


  3%|▎         | 349/10907 [09:33<4:48:58,  1.64s/it][A  3%|▎         | 349/10907 [09:33<4:48:56,  1.64s/it][A  3%|▎         | 349/10907 [09:33<4:49:16,  1.64s/it][A
  3%|▎         | 350/10907 [09:35<4:47:33,  1.63s/it][A
  3%|▎         | 350/10907 [09:35<4:47:45,  1.64s/it][A
  3%|▎         | 350/10907 [09:34<4:48:13,  1.64s/it][A
  3%|▎         | 350/10907 [09:35<4:48:15,  1.64s/it][A
  3%|▎         | 350/10907 [09:35<4:48:22,  1.64s/it][A
  3%|▎         | 350/10907 [09:35<4:48:32,  1.64s/it][A
  3%|▎         | 351/10907 [09:36<4:47:24,  1.63s/it][A


  3%|▎         | 351/10907 [09:36<4:47:18,  1.63s/it][A  3%|▎         | 351/10907 [09:36<4:47:40,  1.64s/it][A  3%|▎         | 351/10907 [09:36<4:47:36,  1.63s/it][A

  3%|▎         | 351/10907 [09:36<4:47:35,  1.63s/it][A  3%|▎         | 351/10907 [09:36<4:47:22,  1.63s/it][A
  3%|▎         | 352/10907 [09:38<4:47:12,  1.63s/it][A
  3%|▎         | 352/10907 [09:38<4:47:16,  1.63s/it][A

  3%|▎         | 352/10907 [09:38<4:47:15,  1.63s/it][A  3%|▎         | 352/10907 [09:38<4:47:24,  1.63s/it][A

  3%|▎         | 352/10907 [09:38<4:47:32,  1.63s/it][A  3%|▎         | 352/10907 [09:38<4:47:18,  1.63s/it][A
  3%|▎         | 353/10907 [09:39<4:46:58,  1.63s/it][A
  3%|▎         | 353/10907 [09:39<4:46:57,  1.63s/it][A
  3%|▎         | 353/10907 [09:39<4:47:16,  1.63s/it][A
  3%|▎         | 353/10907 [09:39<4:47:10,  1.63s/it][A

  3%|▎         | 353/10907 [09:39<4:47:24,  1.63s/it]  3%|▎         | 353/10907 [09:39<4:47:13,  1.63s/it][A[A
  3%|▎         | 354/10907 [09:41<4:45:57,  1.63s/it][A
  3%|▎         | 354/10907 [09:41<4:46:13,  1.63s/it][A
  3%|▎         | 354/10907 [09:41<4:46:16,  1.63s/it][A
  3%|▎         | 354/10907 [09:41<4:46:14,  1.63s/it][A

  3%|▎         | 354/10907 [09:41<4:46:23,  1.63s/it][A  3%|▎         | 354/10907 [09:41<4:46:13,  1.63s/it][A

  3%|▎         | 355/10907 [09:43<4:45:48,  1.63s/it][A  3%|▎         | 355/10907 [09:43<4:45:48,  1.63s/it][A
  3%|▎         | 355/10907 [09:43<4:45:54,  1.63s/it][A
  3%|▎         | 355/10907 [09:43<4:46:02,  1.63s/it][A
  3%|▎         | 355/10907 [09:43<4:46:05,  1.63s/it][A
  3%|▎         | 355/10907 [09:43<4:46:04,  1.63s/it][A
  3%|▎         | 356/10907 [09:44<4:45:01,  1.62s/it][A

  3%|▎         | 356/10907 [09:44<4:45:24,  1.62s/it][A  3%|▎         | 356/10907 [09:44<4:45:33,  1.62s/it][A
  3%|▎         | 356/10907 [09:44<4:45:40,  1.62s/it][A
  3%|▎         | 356/10907 [09:44<4:45:31,  1.62s/it][A
  3%|▎         | 356/10907 [09:44<4:45:31,  1.62s/it][A
  3%|▎         | 357/10907 [09:46<4:43:25,  1.61s/it][A
  3%|▎         | 357/10907 [09:46<4:44:07,  1.62s/it][A
  3%|▎         | 357/10907 [09:46<4:44:32,  1.62s/it][A
  3%|▎         | 357/10907 [09:46<4:45:01,  1.62s/it][A
  3%|▎         | 357/10907 [09:46<4:44:55,  1.62s/it][A
  3%|▎         | 357/10907 [09:46<4:45:06,  1.62s/it][A
  3%|▎         | 358/10907 [09:48<4:57:51,  1.69s/it][A
  3%|▎         | 358/10907 [09:48<4:58:38,  1.70s/it][A
  3%|▎         | 358/10907 [09:48<4:58:33,  1.70s/it][A
  3%|▎         | 358/10907 [09:48<4:58:29,  1.70s/it][A
  3%|▎         | 358/10907 [09:48<4:58:35,  1.70s/it][A
  3%|▎         | 358/10907 [09:48<4:58:38,  1.70s/it][A

  3%|▎         | 359/10907 [09:49<4:54:23,  1.67s/it][A  3%|▎         | 359/10907 [09:49<4:54:45,  1.68s/it][A

  3%|▎         | 359/10907 [09:49<4:54:20,  1.67s/it][A
  3%|▎         | 359/10907 [09:49<4:54:11,  1.67s/it][A
  3%|▎         | 359/10907 [09:49<4:54:07,  1.67s/it][A  3%|▎         | 359/10907 [09:49<4:54:40,  1.68s/it][A
  3%|▎         | 360/10907 [09:51<4:51:04,  1.66s/it][A
  3%|▎         | 360/10907 [09:51<4:51:33,  1.66s/it][A
  3%|▎         | 360/10907 [09:51<4:51:29,  1.66s/it][A
  3%|▎         | 360/10907 [09:51<4:51:37,  1.66s/it][A
  3%|▎         | 360/10907 [09:51<4:51:56,  1.66s/it][A
  3%|▎         | 360/10907 [09:51<4:52:13,  1.66s/it][A
  3%|▎         | 361/10907 [09:53<4:49:14,  1.65s/it][A
  3%|▎         | 361/10907 [09:53<4:49:36,  1.65s/it][A
  3%|▎         | 361/10907 [09:53<4:49:21,  1.65s/it][A
  3%|▎         | 361/10907 [09:53<4:49:32,  1.65s/it][A

  3%|▎         | 361/10907 [09:53<4:49:51,  1.65s/it][A  3%|▎         | 361/10907 [09:53<4:49:48,  1.65s/it][A
  3%|▎         | 362/10907 [09:54<4:48:11,  1.64s/it][A
  3%|▎         | 362/10907 [09:54<4:48:19,  1.64s/it][A
  3%|▎         | 362/10907 [09:54<4:48:14,  1.64s/it][A
  3%|▎         | 362/10907 [09:54<4:48:26,  1.64s/it][A

  3%|▎         | 362/10907 [09:54<4:48:29,  1.64s/it][A  3%|▎         | 362/10907 [09:54<4:48:19,  1.64s/it][A
  3%|▎         | 363/10907 [09:56<4:47:07,  1.63s/it][A
  3%|▎         | 363/10907 [09:56<4:47:43,  1.64s/it][A
  3%|▎         | 363/10907 [09:56<4:47:47,  1.64s/it][A
  3%|▎         | 363/10907 [09:56<4:47:47,  1.64s/it][A

  3%|▎         | 363/10907 [09:56<4:47:50,  1.64s/it][A  3%|▎         | 363/10907 [09:56<4:47:50,  1.64s/it][A
  3%|▎         | 364/10907 [09:58<4:46:37,  1.63s/it][A
  3%|▎         | 364/10907 [09:58<4:46:33,  1.63s/it][A
  3%|▎         | 364/10907 [09:58<4:46:58,  1.63s/it][A

  3%|▎         | 364/10907 [09:57<4:46:50,  1.63s/it][A  3%|▎         | 364/10907 [09:58<4:46:46,  1.63s/it][A
  3%|▎         | 364/10907 [09:58<4:46:43,  1.63s/it][A
  3%|▎         | 365/10907 [09:59<4:45:44,  1.63s/it][A
  3%|▎         | 365/10907 [09:59<4:46:03,  1.63s/it][A
  3%|▎         | 365/10907 [09:59<4:46:00,  1.63s/it][A
  3%|▎         | 365/10907 [09:59<4:45:54,  1.63s/it]
[A  3%|▎         | 365/10907 [09:59<4:45:58,  1.63s/it][A
  3%|▎         | 365/10907 [09:59<4:45:52,  1.63s/it][A
  3%|▎         | 366/10907 [10:01<4:45:03,  1.62s/it][A
  3%|▎         | 366/10907 [10:01<4:45:09,  1.62s/it][A
  3%|▎         | 366/10907 [10:01<4:45:14,  1.62s/it][A
  3%|▎         | 366/10907 [10:01<4:45:03,  1.62s/it][A
  3%|▎         | 366/10907 [10:01<4:45:08,  1.62s/it][A
  3%|▎         | 366/10907 [10:01<4:45:14,  1.62s/it][A
  3%|▎         | 367/10907 [10:03<4:52:07,  1.66s/it][A
  3%|▎         | 367/10907 [10:03<4:52:06,  1.66s/it][A
  3%|▎         | 367/10907 [10:03<4:52:03,  1.66s/it][A
  3%|▎         | 367/10907 [10:02<4:52:13,  1.66s/it][A
  3%|▎         | 367/10907 [10:03<4:52:11,  1.66s/it][A
  3%|▎         | 367/10907 [10:03<4:52:15,  1.66s/it][A
  3%|▎         | 368/10907 [10:04<4:49:58,  1.65s/it][A
  3%|▎         | 368/10907 [10:04<4:50:02,  1.65s/it][A

  3%|▎         | 368/10907 [10:04<4:50:09,  1.65s/it][A  3%|▎         | 368/10907 [10:04<4:50:08,  1.65s/it][A

  3%|▎         | 368/10907 [10:04<4:50:00,  1.65s/it][A  3%|▎         | 368/10907 [10:04<4:50:01,  1.65s/it][A
  3%|▎         | 369/10907 [10:06<4:48:24,  1.64s/it][A
  3%|▎         | 369/10907 [10:06<4:48:45,  1.64s/it][A
  3%|▎         | 369/10907 [10:06<4:48:43,  1.64s/it][A
  3%|▎         | 369/10907 [10:06<4:48:47,  1.64s/it][A
  3%|▎         | 369/10907 [10:06<4:48:57,  1.65s/it][A
  3%|▎         | 369/10907 [10:06<4:48:56,  1.65s/it][A
  3%|▎         | 370/10907 [10:07<4:46:39,  1.63s/it][A
  3%|▎         | 370/10907 [10:07<4:47:49,  1.64s/it][A
  3%|▎         | 370/10907 [10:07<4:47:42,  1.64s/it][A
  3%|▎         | 370/10907 [10:07<4:47:46,  1.64s/it][A
  3%|▎         | 370/10907 [10:07<4:47:55,  1.64s/it][A
  3%|▎         | 370/10907 [10:07<4:47:54,  1.64s/it][A
  3%|▎         | 371/10907 [10:09<4:46:22,  1.63s/it][A
  3%|▎         | 371/10907 [10:09<4:46:26,  1.63s/it][A

  3%|▎         | 371/10907 [10:09<4:46:34,  1.63s/it][A  3%|▎         | 371/10907 [10:09<4:46:44,  1.63s/it][A

  3%|▎         | 371/10907 [10:09<4:46:58,  1.63s/it][A  3%|▎         | 371/10907 [10:09<4:46:36,  1.63s/it][A
  3%|▎         | 372/10907 [10:11<4:46:03,  1.63s/it][A
  3%|▎         | 372/10907 [10:11<4:46:13,  1.63s/it][A


  3%|▎         | 372/10907 [10:11<4:46:21,  1.63s/it][A  3%|▎         | 372/10907 [10:11<4:46:14,  1.63s/it][A  3%|▎         | 372/10907 [10:11<4:46:15,  1.63s/it][A
  3%|▎         | 372/10907 [10:11<4:46:31,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:44,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:50,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:43,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:45,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:49,  1.63s/it][A
  3%|▎         | 373/10907 [10:12<4:45:52,  1.63s/it][A
  3%|▎         | 374/10907 [10:14<4:45:12,  1.62s/it][A
  3%|▎         | 374/10907 [10:14<4:45:24,  1.63s/it][A

  3%|▎         | 374/10907 [10:14<4:45:27,  1.63s/it][A  3%|▎         | 374/10907 [10:14<4:45:33,  1.63s/it][A
  3%|▎         | 374/10907 [10:14<4:45:25,  1.63s/it][A
  3%|▎         | 374/10907 [10:14<4:45:25,  1.63s/it][A
  3%|▎         | 375/10907 [10:15<4:44:07,  1.62s/it][A
  3%|▎         | 375/10907 [10:15<4:44:34,  1.62s/it][A
  3%|▎         | 375/10907 [10:15<4:44:58,  1.62s/it][A
  3%|▎         | 375/10907 [10:15<4:45:29,  1.63s/it][A
  3%|▎         | 375/10907 [10:15<4:45:43,  1.63s/it][A
  3%|▎         | 375/10907 [10:16<4:45:47,  1.63s/it][A

  3%|▎         | 376/10907 [10:17<4:45:04,  1.62s/it][A  3%|▎         | 376/10907 [10:17<4:45:11,  1.62s/it][A
  3%|▎         | 376/10907 [10:17<4:45:09,  1.62s/it][A
  3%|▎         | 376/10907 [10:17<4:45:28,  1.63s/it][A

  3%|▎         | 376/10907 [10:17<4:45:19,  1.63s/it][A  3%|▎         | 376/10907 [10:17<4:45:35,  1.63s/it][A

  3%|▎         | 377/10907 [10:19<4:44:42,  1.62s/it][A  3%|▎         | 377/10907 [10:19<4:44:43,  1.62s/it][A
  3%|▎         | 377/10907 [10:19<4:45:05,  1.62s/it][A
  3%|▎         | 377/10907 [10:19<4:44:57,  1.62s/it][A
  3%|▎         | 377/10907 [10:19<4:45:06,  1.62s/it][A
  3%|▎         | 377/10907 [10:19<4:45:14,  1.63s/it][A
  3%|▎         | 378/10907 [10:20<4:44:35,  1.62s/it][A

  3%|▎         | 378/10907 [10:20<4:44:37,  1.62s/it][A  3%|▎         | 378/10907 [10:20<4:44:35,  1.62s/it][A
  3%|▎         | 378/10907 [10:20<4:44:46,  1.62s/it][A
  3%|▎         | 378/10907 [10:20<4:44:41,  1.62s/it][A
  3%|▎         | 378/10907 [10:20<4:44:44,  1.62s/it][A
  3%|▎         | 379/10907 [10:22<4:56:35,  1.69s/it][A
  3%|▎         | 379/10907 [10:22<4:56:44,  1.69s/it][A

  3%|▎         | 379/10907 [10:22<4:56:46,  1.69s/it][A  3%|▎         | 379/10907 [10:22<4:56:47,  1.69s/it][A
  3%|▎         | 379/10907 [10:22<4:56:55,  1.69s/it][A
  3%|▎         | 379/10907 [10:22<4:56:47,  1.69s/it][A
  3%|▎         | 380/10907 [10:24<5:05:31,  1.74s/it][A

  3%|▎         | 380/10907 [10:24<5:05:29,  1.74s/it][A  3%|▎         | 380/10907 [10:24<5:05:24,  1.74s/it]
[A

  3%|▎         | 380/10907 [10:24<5:05:31,  1.74s/it][A  3%|▎         | 380/10907 [10:24<5:05:31,  1.74s/it][A  3%|▎         | 380/10907 [10:24<5:05:32,  1.74s/it][A
  3%|▎         | 381/10907 [10:26<4:59:36,  1.71s/it][A
  3%|▎         | 381/10907 [10:26<4:59:42,  1.71s/it][A
  3%|▎         | 381/10907 [10:26<4:59:50,  1.71s/it][A
  3%|▎         | 381/10907 [10:26<4:59:59,  1.71s/it][A
  3%|▎         | 381/10907 [10:26<4:59:58,  1.71s/it][A
  3%|▎         | 381/10907 [10:26<5:00:00,  1.71s/it][A
  4%|▎         | 382/10907 [10:27<4:54:54,  1.68s/it][A
  4%|▎         | 382/10907 [10:27<4:55:03,  1.68s/it][A

  4%|▎         | 382/10907 [10:27<4:54:59,  1.68s/it][A  4%|▎         | 382/10907 [10:27<4:55:01,  1.68s/it][A
  4%|▎         | 382/10907 [10:27<4:55:00,  1.68s/it][A
  4%|▎         | 382/10907 [10:27<4:55:04,  1.68s/it][A
  4%|▎         | 383/10907 [10:29<4:51:22,  1.66s/it][A
  4%|▎         | 383/10907 [10:29<4:51:29,  1.66s/it][A
  4%|▎         | 383/10907 [10:29<4:51:30,  1.66s/it][A
  4%|▎         | 383/10907 [10:29<4:51:24,  1.66s/it][A

  4%|▎         | 383/10907 [10:29<4:51:32,  1.66s/it][A  4%|▎         | 383/10907 [10:29<4:51:36,  1.66s/it][A
  4%|▎         | 384/10907 [10:31<4:48:52,  1.65s/it][A
  4%|▎         | 384/10907 [10:31<4:49:00,  1.65s/it][A
  4%|▎         | 384/10907 [10:31<4:49:05,  1.65s/it][A
  4%|▎         | 384/10907 [10:31<4:49:00,  1.65s/it][A
  4%|▎         | 384/10907 [10:30<4:49:08,  1.65s/it][A
  4%|▎         | 384/10907 [10:31<4:49:03,  1.65s/it][A
  4%|▎         | 385/10907 [10:32<4:47:11,  1.64s/it][A
  4%|▎         | 385/10907 [10:32<4:47:13,  1.64s/it][A
  4%|▎         | 385/10907 [10:32<4:47:11,  1.64s/it][A
  4%|▎         | 385/10907 [10:32<4:47:21,  1.64s/it][A
  4%|▎         | 385/10907 [10:32<4:47:23,  1.64s/it][A
  4%|▎         | 385/10907 [10:32<4:47:22,  1.64s/it][A
  4%|▎         | 386/10907 [10:34<4:46:08,  1.63s/it][A

  4%|▎         | 386/10907 [10:34<4:46:12,  1.63s/it][A  4%|▎         | 386/10907 [10:34<4:46:09,  1.63s/it][A
  4%|▎         | 386/10907 [10:34<4:46:33,  1.63s/it][A
  4%|▎         | 386/10907 [10:34<4:46:37,  1.63s/it][A
  4%|▎         | 386/10907 [10:34<4:46:39,  1.63s/it][A
  4%|▎         | 387/10907 [10:35<4:45:14,  1.63s/it][A
  4%|▎         | 387/10907 [10:35<4:45:27,  1.63s/it][A
  4%|▎         | 387/10907 [10:35<4:45:33,  1.63s/it]
[A
  4%|▎         | 387/10907 [10:35<4:45:39,  1.63s/it][A  4%|▎         | 387/10907 [10:35<4:45:37,  1.63s/it][A
  4%|▎         | 387/10907 [10:35<4:45:38,  1.63s/it][A
  4%|▎         | 388/10907 [10:37<4:51:37,  1.66s/it][A
  4%|▎         | 388/10907 [10:37<4:51:43,  1.66s/it][A
  4%|▎         | 388/10907 [10:37<4:51:47,  1.66s/it][A
  4%|▎         | 388/10907 [10:37<4:51:54,  1.67s/it][A
  4%|▎         | 388/10907 [10:37<4:51:53,  1.66s/it][A
  4%|▎         | 388/10907 [10:37<4:51:48,  1.66s/it][A
  4%|▎         | 389/10907 [10:39<4:49:19,  1.65s/it][A
  4%|▎         | 389/10907 [10:39<4:49:18,  1.65s/it][A
  4%|▎         | 389/10907 [10:39<4:49:23,  1.65s/it][A

  4%|▎         | 389/10907 [10:39<4:49:27,  1.65s/it][A  4%|▎         | 389/10907 [10:39<4:49:33,  1.65s/it][A
  4%|▎         | 389/10907 [10:39<4:49:26,  1.65s/it][A
  4%|▎         | 390/10907 [10:40<4:47:25,  1.64s/it][A
  4%|▎         | 390/10907 [10:40<4:47:39,  1.64s/it][A
  4%|▎         | 390/10907 [10:40<4:47:39,  1.64s/it][A
  4%|▎         | 390/10907 [10:40<4:47:37,  1.64s/it][A
  4%|▎         | 390/10907 [10:40<4:47:42,  1.64s/it][A
  4%|▎         | 390/10907 [10:40<4:47:43,  1.64s/it][A
  4%|▎         | 391/10907 [10:42<4:46:42,  1.64s/it][A
  4%|▎         | 391/10907 [10:42<4:46:46,  1.64s/it][A
  4%|▎         | 391/10907 [10:42<4:46:36,  1.64s/it][A
  4%|▎         | 391/10907 [10:42<4:46:47,  1.64s/it][A

  4%|▎         | 391/10907 [10:42<4:46:53,  1.64s/it][A  4%|▎         | 391/10907 [10:42<4:46:46,  1.64s/it][A
  4%|▎         | 392/10907 [10:44<4:45:38,  1.63s/it][A
  4%|▎         | 392/10907 [10:44<4:45:30,  1.63s/it][A
  4%|▎         | 392/10907 [10:44<4:45:52,  1.63s/it][A
  4%|▎         | 392/10907 [10:44<4:46:06,  1.63s/it][A
  4%|▎         | 392/10907 [10:44<4:46:08,  1.63s/it][A
  4%|▎         | 392/10907 [10:44<4:46:04,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:17,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:22,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:32,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:21,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:27,  1.63s/it][A
  4%|▎         | 393/10907 [10:45<4:45:35,  1.63s/it][A
  4%|▎         | 394/10907 [10:47<4:44:26,  1.62s/it][A
  4%|▎         | 394/10907 [10:47<4:44:28,  1.62s/it][A
  4%|▎         | 394/10907 [10:47<4:44:34,  1.62s/it][A
  4%|▎         | 394/10907 [10:47<4:44:34,  1.62s/it][A
  4%|▎         | 394/10907 [10:47<4:44:42,  1.62s/it][A
  4%|▎         | 394/10907 [10:47<4:44:38,  1.62s/it][A
  4%|▎         | 395/10907 [10:48<4:43:58,  1.62s/it][A

  4%|▎         | 395/10907 [10:48<4:44:02,  1.62s/it][A  4%|▎         | 395/10907 [10:48<4:44:04,  1.62s/it][A
  4%|▎         | 395/10907 [10:48<4:44:09,  1.62s/it][A

  4%|▎         | 395/10907 [10:48<4:44:14,  1.62s/it][A  4%|▎         | 395/10907 [10:48<4:44:18,  1.62s/it][A
  4%|▎         | 396/10907 [10:50<4:43:34,  1.62s/it][A
  4%|▎         | 396/10907 [10:50<4:43:39,  1.62s/it][A

  4%|▎         | 396/10907 [10:50<4:44:00,  1.62s/it][A  4%|▎         | 396/10907 [10:50<4:44:02,  1.62s/it][A
  4%|▎         | 396/10907 [10:50<4:44:00,  1.62s/it][A
  4%|▎         | 396/10907 [10:50<4:44:10,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:02,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:05,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:29,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:10,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:20,  1.62s/it][A
  4%|▎         | 397/10907 [10:52<4:44:16,  1.62s/it][A

  4%|▎         | 398/10907 [10:53<4:44:08,  1.62s/it][A
  4%|▎         | 398/10907 [10:53<4:44:17,  1.62s/it]
[A  4%|▎         | 398/10907 [10:53<4:44:03,  1.62s/it][A  4%|▎         | 398/10907 [10:53<4:44:04,  1.62s/it][A
  4%|▎         | 398/10907 [10:53<4:44:01,  1.62s/it][A
  4%|▎         | 398/10907 [10:53<4:44:11,  1.62s/it][A

  4%|▎         | 399/10907 [10:55<4:43:10,  1.62s/it][A  4%|▎         | 399/10907 [10:55<4:43:06,  1.62s/it][A
  4%|▎         | 399/10907 [10:55<4:43:18,  1.62s/it][A
  4%|▎         | 399/10907 [10:55<4:43:39,  1.62s/it][A
  4%|▎         | 399/10907 [10:55<4:43:52,  1.62s/it][A
  4%|▎         | 399/10907 [10:55<4:43:42,  1.62s/it][A
  4%|▎         | 400/10907 [10:57<4:55:26,  1.69s/it][A
  4%|▎         | 400/10907 [10:57<4:55:30,  1.69s/it][A

  4%|▎         | 400/10907 [10:57<4:55:53,  1.69s/it][A  4%|▎         | 400/10907 [10:57<4:56:03,  1.69s/it][A
  4%|▎         | 400/10907 [10:57<4:56:01,  1.69s/it][A
  4%|▎         | 400/10907 [10:57<4:55:55,  1.69s/it][A
  4%|▎         | 401/10907 [10:59<5:03:43,  1.73s/it][A
  4%|▎         | 401/10907 [10:59<5:04:05,  1.74s/it][A
  4%|▎         | 401/10907 [10:59<5:04:04,  1.74s/it][A
  4%|▎         | 401/10907 [10:59<5:04:11,  1.74s/it][A
  4%|▎         | 401/10907 [10:59<5:04:07,  1.74s/it][A
  4%|▎         | 401/10907 [10:59<5:04:15,  1.74s/it][A
  4%|▎         | 402/10907 [11:00<4:57:29,  1.70s/it][A
  4%|▎         | 402/10907 [11:00<4:57:27,  1.70s/it][A

  4%|▎         | 402/10907 [11:00<4:57:41,  1.70s/it][A  4%|▎         | 402/10907 [11:00<4:57:53,  1.70s/it][A
  4%|▎         | 402/10907 [11:00<4:57:46,  1.70s/it][A
  4%|▎         | 402/10907 [11:00<4:58:02,  1.70s/it][A
  4%|▎         | 403/10907 [11:02<4:53:55,  1.68s/it][A
  4%|▎         | 403/10907 [11:02<4:54:04,  1.68s/it][A
  4%|▎         | 403/10907 [11:02<4:53:58,  1.68s/it][A
  4%|▎         | 403/10907 [11:02<4:54:02,  1.68s/it][A
  4%|▎         | 403/10907 [11:02<4:53:58,  1.68s/it][A
  4%|▎         | 403/10907 [11:02<4:54:28,  1.68s/it][A
  4%|▎         | 404/10907 [11:03<4:50:47,  1.66s/it][A
  4%|▎         | 404/10907 [11:04<4:50:43,  1.66s/it][A
  4%|▎         | 404/10907 [11:04<4:50:48,  1.66s/it][A
  4%|▎         | 404/10907 [11:04<4:51:01,  1.66s/it][A
  4%|▎         | 404/10907 [11:04<4:51:13,  1.66s/it][A
  4%|▎         | 404/10907 [11:04<4:51:01,  1.66s/it][A
  4%|▎         | 405/10907 [11:05<4:48:13,  1.65s/it][A

  4%|▎         | 405/10907 [11:05<4:48:16,  1.65s/it][A  4%|▎         | 405/10907 [11:05<4:48:14,  1.65s/it][A
  4%|▎         | 405/10907 [11:05<4:48:28,  1.65s/it][A
  4%|▎         | 405/10907 [11:05<4:48:30,  1.65s/it][A
  4%|▎         | 405/10907 [11:05<4:48:26,  1.65s/it][A
  4%|▎         | 406/10907 [11:07<4:46:01,  1.63s/it][A
  4%|▎         | 406/10907 [11:07<4:46:39,  1.64s/it][A
  4%|▎         | 406/10907 [11:07<4:46:38,  1.64s/it][A

  4%|▎         | 406/10907 [11:07<4:46:48,  1.64s/it][A  4%|▎         | 406/10907 [11:07<4:46:42,  1.64s/it][A
  4%|▎         | 406/10907 [11:07<4:46:42,  1.64s/it][A
  4%|▎         | 407/10907 [11:08<4:46:02,  1.63s/it]
[A  4%|▎         | 407/10907 [11:08<4:45:51,  1.63s/it][A
  4%|▎         | 407/10907 [11:08<4:45:49,  1.63s/it]
[A  4%|▎         | 407/10907 [11:08<4:45:46,  1.63s/it][A
  4%|▎         | 407/10907 [11:08<4:45:47,  1.63s/it][A
  4%|▎         | 407/10907 [11:08<4:45:50,  1.63s/it][A
  4%|▎         | 408/10907 [11:10<4:45:04,  1.63s/it][A
  4%|▎         | 408/10907 [11:10<4:45:15,  1.63s/it][A
  4%|▎         | 408/10907 [11:10<4:45:03,  1.63s/it][A

  4%|▎         | 408/10907 [11:10<4:45:09,  1.63s/it]
[A  4%|▎         | 408/10907 [11:10<4:45:08,  1.63s/it][A  4%|▎         | 408/10907 [11:10<4:45:14,  1.63s/it][A
  4%|▎         | 409/10907 [11:12<4:52:49,  1.67s/it][A
  4%|▎         | 409/10907 [11:12<4:52:46,  1.67s/it][A
  4%|▎         | 409/10907 [11:12<4:52:41,  1.67s/it][A

  4%|▎         | 409/10907 [11:12<4:52:47,  1.67s/it][A
  4%|▎         | 409/10907 [11:12<4:52:46,  1.67s/it][A  4%|▎         | 409/10907 [11:12<4:52:44,  1.67s/it][A
  4%|▍         | 410/10907 [11:13<4:49:25,  1.65s/it][A
  4%|▍         | 410/10907 [11:13<4:49:26,  1.65s/it][A

  4%|▍         | 410/10907 [11:13<4:49:25,  1.65s/it][A  4%|▍         | 410/10907 [11:13<4:49:38,  1.66s/it][A
  4%|▍         | 410/10907 [11:13<4:49:32,  1.65s/it][A
  4%|▍         | 410/10907 [11:13<4:49:33,  1.66s/it][A
  4%|▍         | 411/10907 [11:15<4:47:07,  1.64s/it][A
  4%|▍         | 411/10907 [11:15<4:47:15,  1.64s/it][A
  4%|▍         | 411/10907 [11:15<4:47:07,  1.64s/it][A
  4%|▍         | 411/10907 [11:15<4:47:10,  1.64s/it][A

  4%|▍         | 411/10907 [11:15<4:47:19,  1.64s/it][A  4%|▍         | 411/10907 [11:15<4:47:15,  1.64s/it][A
  4%|▍         | 412/10907 [11:17<4:46:35,  1.64s/it][A

  4%|▍         | 412/10907 [11:17<4:46:38,  1.64s/it][A  4%|▍         | 412/10907 [11:17<4:46:30,  1.64s/it][A
  4%|▍         | 412/10907 [11:17<4:46:35,  1.64s/it][A
  4%|▍         | 412/10907 [11:17<4:46:37,  1.64s/it][A
  4%|▍         | 412/10907 [11:17<4:46:39,  1.64s/it][A
  4%|▍         | 413/10907 [11:18<4:46:18,  1.64s/it][A
  4%|▍         | 413/10907 [11:18<4:46:13,  1.64s/it][A

  4%|▍         | 413/10907 [11:18<4:46:14,  1.64s/it][A  4%|▍         | 413/10907 [11:18<4:46:17,  1.64s/it][A

  4%|▍         | 413/10907 [11:18<4:46:14,  1.64s/it][A  4%|▍         | 413/10907 [11:18<4:46:27,  1.64s/it][Aslurmstepd: error: *** JOB 1772856 ON jean-zay-iam11 CANCELLED AT 2023-05-20T18:18:31 ***
